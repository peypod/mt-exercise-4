2025-05-22 14:30:46,995 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-22 14:30:46,996 - INFO - joeynmt.helpers -                           cfg.name : transformer_enit_config
2025-05-22 14:30:46,997 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-22 14:30:46,997 - INFO - joeynmt.helpers -                     cfg.data.train : data/train.de-nl
2025-05-22 14:30:46,997 - INFO - joeynmt.helpers -                       cfg.data.dev : data/dev.de-nl
2025-05-22 14:30:46,997 - INFO - joeynmt.helpers -                      cfg.data.test : data/test.de-nl
2025-05-22 14:30:46,998 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-22 14:30:46,998 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2025-05-22 14:30:46,999 - INFO - joeynmt.helpers -                 cfg.data.src.level : word
2025-05-22 14:30:46,999 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-22 14:30:46,999 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-22 14:30:46,999 - INFO - joeynmt.helpers -             cfg.data.src.voc_limit : 2000
2025-05-22 14:30:46,999 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : space
2025-05-22 14:30:46,999 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenizer : moses
2025-05-22 14:30:46,999 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : nl
2025-05-22 14:30:46,999 - INFO - joeynmt.helpers -                 cfg.data.trg.level : word
2025-05-22 14:30:46,999 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-22 14:30:46,999 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -             cfg.data.trg.voc_limit : 2000
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : space
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenizer : moses
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 3
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-22 14:30:47,000 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/transformer_enit
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-22 14:30:47,001 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : False
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-22 14:30:47,002 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-22 14:30:47,003 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-22 14:30:47,003 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-22 14:30:47,003 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-22 14:30:47,003 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-22 14:30:47,003 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-22 14:30:47,003 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-22 14:30:47,003 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-22 14:30:47,003 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-22 14:30:47,003 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-22 14:30:47,003 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-22 14:30:47,270 - INFO - joeynmt.data - Building tokenizer...
2025-05-22 14:30:47,828 - INFO - joeynmt.tokenizers - de tokenizer: BasicTokenizer(level=word, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses)
2025-05-22 14:30:47,829 - INFO - joeynmt.tokenizers - nl tokenizer: BasicTokenizer(level=word, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses)
2025-05-22 14:30:47,829 - INFO - joeynmt.data - Loading train set...
2025-05-22 14:31:38,092 - INFO - joeynmt.data - Building vocabulary...
2025-05-22 14:31:41,785 - INFO - joeynmt.data - Loading dev set...
2025-05-22 14:31:41,969 - INFO - joeynmt.data - Loading test set...
2025-05-22 14:31:42,318 - INFO - joeynmt.data - Data loaded.
2025-05-22 14:31:42,318 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=216893, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2025-05-22 14:31:42,318 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1001, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2025-05-22 14:31:42,318 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1779, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2025-05-22 14:31:42,318 - INFO - joeynmt.data - First training example:
	[SRC] Al Gore : Die Abwendung der Klimakatastrophe
	[TRG] Al Gore over het afwenden van de klimaatcrisis
2025-05-22 14:31:42,319 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) die (7) und (8) der (9) ist
2025-05-22 14:31:42,319 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) de (7) een (8) het (9) van
2025-05-22 14:31:42,319 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2004
2025-05-22 14:31:42,319 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2004
2025-05-22 14:31:42,332 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-22 14:31:42,478 - INFO - joeynmt.model - Enc-dec model built.
2025-05-22 14:31:42,496 - INFO - joeynmt.model - Total params: 3925248
2025-05-22 14:31:42,497 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2025-05-22 14:31:42,497 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-22 14:31:42,656 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2025-05-22 14:31:42,657 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2025-05-22 14:31:42,657 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2025-05-22 14:31:42,657 - INFO - joeynmt.training - EPOCH 1
2025-05-22 14:32:07,324 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.031976, Batch Acc: 0.193158, Tokens per Sec:     2722, Lr: 0.000300
2025-05-22 14:32:12,564 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     2.837064, Batch Acc: 0.243724, Tokens per Sec:    12617, Lr: 0.000300
2025-05-22 14:32:17,834 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     2.818166, Batch Acc: 0.268184, Tokens per Sec:    12806, Lr: 0.000300
2025-05-22 14:32:24,053 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     2.628671, Batch Acc: 0.289944, Tokens per Sec:    10581, Lr: 0.000300
2025-05-22 14:32:29,892 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     2.480490, Batch Acc: 0.304704, Tokens per Sec:    11466, Lr: 0.000300
2025-05-22 14:32:29,894 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:32:29,895 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:32:38,752 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.57, ppl:  13.08, acc:   0.30, generation: 8.7885[sec], evaluation: 0.0000[sec]
2025-05-22 14:32:38,753 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:32:38,947 - INFO - joeynmt.training - Example #0
2025-05-22 14:32:38,948 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:32:38,949 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:32:38,950 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', '<unk>', 'ik', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', ',', 'dat', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:32:38,951 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:32:38,951 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:32:38,951 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> <unk> ik de <unk> van de <unk> <unk> <unk>, de <unk> <unk> <unk>, dat <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>.
2025-05-22 14:32:38,951 - INFO - joeynmt.training - Example #1
2025-05-22 14:32:38,951 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:32:38,951 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:32:38,951 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'niet', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', ',', 'het', '<unk>', ',', 'het', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:32:38,951 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:32:38,952 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:32:38,952 - INFO - joeynmt.training - 	Hypothesis: Maar het niet niet de <unk> van de <unk>, het <unk>, het <unk> <unk> <unk>.
2025-05-22 14:32:38,952 - INFO - joeynmt.training - Example #2
2025-05-22 14:32:38,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:32:38,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:32:38,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:32:38,952 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:32:38,952 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:32:38,952 - INFO - joeynmt.training - 	Hypothesis: In de <unk> is de <unk> <unk> <unk> <unk> <unk>.
2025-05-22 14:32:38,952 - INFO - joeynmt.training - Example #3
2025-05-22 14:32:38,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:32:38,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:32:38,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'is', 'de', '<unk>', 'en', '<unk>', 'en', '<unk>', '.', '</s>']
2025-05-22 14:32:38,953 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:32:38,953 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:32:38,953 - INFO - joeynmt.training - 	Hypothesis: Ze is de <unk> en <unk> en <unk>.
2025-05-22 14:32:38,953 - INFO - joeynmt.training - Example #4
2025-05-22 14:32:38,954 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:32:38,954 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:32:38,954 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', '<unk>', '<unk>', ',', 'ik', 'ik', 'ik', 'ik', 'ik', 'dat', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'is', '.', '</s>']
2025-05-22 14:32:38,954 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:32:38,955 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:32:38,955 - INFO - joeynmt.training - 	Hypothesis: De <unk> <unk>, ik ik ik ik ik dat <unk> <unk> <unk> <unk> <unk> is.
2025-05-22 14:32:44,707 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     2.570986, Batch Acc: 0.318388, Tokens per Sec:    11070, Lr: 0.000300
2025-05-22 14:32:50,579 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     2.441278, Batch Acc: 0.332488, Tokens per Sec:    11082, Lr: 0.000300
2025-05-22 14:32:56,531 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     2.409366, Batch Acc: 0.337088, Tokens per Sec:    11082, Lr: 0.000300
2025-05-22 14:33:02,435 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     2.384090, Batch Acc: 0.343489, Tokens per Sec:    11077, Lr: 0.000300
2025-05-22 14:33:08,172 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     2.210312, Batch Acc: 0.349357, Tokens per Sec:    11518, Lr: 0.000300
2025-05-22 14:33:08,173 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:33:08,173 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:33:17,092 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.36, ppl:  10.60, acc:   0.34, generation: 8.8622[sec], evaluation: 0.0000[sec]
2025-05-22 14:33:17,093 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:33:17,251 - INFO - joeynmt.training - Example #0
2025-05-22 14:33:17,252 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:33:17,252 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:33:17,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'geleden', 'ik', 'deze', '<unk>', '<unk>', '<unk>', ',', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'voor', '<unk>', 'voor', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:33:17,252 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:33:17,252 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:33:17,253 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar geleden ik deze <unk> <unk> <unk>, <unk> dat de <unk> <unk> <unk> <unk> <unk> voor <unk> voor <unk> <unk> <unk> <unk>.
2025-05-22 14:33:17,253 - INFO - joeynmt.training - Example #1
2025-05-22 14:33:17,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:33:17,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:33:17,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', 'het', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:33:17,255 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:33:17,255 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:33:17,255 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> <unk> <unk>, <unk> <unk>, <unk> <unk>, <unk> het <unk> van de <unk>.
2025-05-22 14:33:17,255 - INFO - joeynmt.training - Example #2
2025-05-22 14:33:17,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:33:17,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:33:17,256 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:33:17,257 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:33:17,257 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:33:17,258 - INFO - joeynmt.training - 	Hypothesis: In de <unk> is de <unk> <unk> <unk> <unk>.
2025-05-22 14:33:17,258 - INFO - joeynmt.training - Example #3
2025-05-22 14:33:17,258 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:33:17,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:33:17,258 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', '<unk>', 'en', '<unk>', '.', '</s>']
2025-05-22 14:33:17,259 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:33:17,259 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:33:17,259 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de <unk> en <unk>.
2025-05-22 14:33:17,259 - INFO - joeynmt.training - Example #4
2025-05-22 14:33:17,260 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:33:17,260 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:33:17,260 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', '<unk>', '<unk>', 'die', 'ik', 'jullie', 'een', '<unk>', 'is', ',', 'een', '<unk>', 'in', 'de', '<unk>', '.', '</s>']
2025-05-22 14:33:17,260 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:33:17,261 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:33:17,261 - INFO - joeynmt.training - 	Hypothesis: De <unk> <unk> die ik jullie een <unk> is, een <unk> in de <unk>.
2025-05-22 14:33:24,124 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     2.349544, Batch Acc: 0.356667, Tokens per Sec:     9324, Lr: 0.000300
2025-05-22 14:33:30,865 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     1.993729, Batch Acc: 0.365529, Tokens per Sec:     9770, Lr: 0.000300
2025-05-22 14:33:37,138 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     2.118004, Batch Acc: 0.373470, Tokens per Sec:    10704, Lr: 0.000300
2025-05-22 14:33:42,971 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     2.164695, Batch Acc: 0.375536, Tokens per Sec:    11367, Lr: 0.000300
2025-05-22 14:33:48,948 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     2.187817, Batch Acc: 0.381333, Tokens per Sec:    10957, Lr: 0.000300
2025-05-22 14:33:48,949 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:33:48,949 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:33:56,775 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.23, ppl:   9.33, acc:   0.36, generation: 7.7674[sec], evaluation: 0.0000[sec]
2025-05-22 14:33:56,776 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:33:56,907 - INFO - joeynmt.training - Example #0
2025-05-22 14:33:56,908 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:33:56,908 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:33:56,908 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'geleden', '<unk>', 'ik', 'deze', 'twee', '<unk>', '<unk>', '<unk>', ',', 'om', 'de', '<unk>', '<unk>', 'te', '<unk>', ',', '<unk>', ',', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:33:56,909 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:33:56,909 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:33:56,909 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar geleden <unk> ik deze twee <unk> <unk> <unk>, om de <unk> <unk> te <unk>, <unk>, <unk> <unk> <unk>, <unk> <unk> <unk>.
2025-05-22 14:33:56,909 - INFO - joeynmt.training - Example #1
2025-05-22 14:33:56,909 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:33:56,909 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:33:56,909 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'zo', '&apos;', 's', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:33:56,909 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:33:56,909 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:33:56,910 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet zo 's <unk> <unk> <unk> <unk> <unk>, <unk> <unk>, <unk> <unk> <unk>.
2025-05-22 14:33:56,910 - INFO - joeynmt.training - Example #2
2025-05-22 14:33:56,910 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:33:56,910 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:33:56,910 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:33:56,911 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:33:56,912 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:33:56,912 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> <unk> <unk> <unk>.
2025-05-22 14:33:56,912 - INFO - joeynmt.training - Example #3
2025-05-22 14:33:56,912 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:33:56,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:33:56,912 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', '<unk>', '<unk>', 'en', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:33:56,913 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:33:56,913 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:33:56,913 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de <unk> <unk> en <unk> <unk>.
2025-05-22 14:33:56,913 - INFO - joeynmt.training - Example #4
2025-05-22 14:33:56,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:33:56,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:33:56,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', '<unk>', '<unk>', 'die', 'ik', 'jullie', 'jullie', 'zien', ',', 'een', '<unk>', '<unk>', 'in', 'de', 'laatste', 'laatste', 'laatste', 'jaar', '.', '</s>']
2025-05-22 14:33:56,913 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:33:56,913 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:33:56,914 - INFO - joeynmt.training - 	Hypothesis: De <unk> <unk> die ik jullie jullie zien, een <unk> <unk> in de laatste laatste laatste jaar.
2025-05-22 14:34:02,803 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     2.130964, Batch Acc: 0.390979, Tokens per Sec:    11257, Lr: 0.000300
2025-05-22 14:34:09,107 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     2.118019, Batch Acc: 0.400601, Tokens per Sec:    10828, Lr: 0.000300
2025-05-22 14:34:15,960 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.015107, Batch Acc: 0.403686, Tokens per Sec:     9722, Lr: 0.000300
2025-05-22 14:34:22,599 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     2.192871, Batch Acc: 0.405277, Tokens per Sec:    10037, Lr: 0.000300
2025-05-22 14:34:30,229 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     1.953993, Batch Acc: 0.411356, Tokens per Sec:     8618, Lr: 0.000300
2025-05-22 14:34:30,230 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:34:30,230 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:34:40,415 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.12, ppl:   8.32, acc:   0.39, generation: 10.1199[sec], evaluation: 0.0000[sec]
2025-05-22 14:34:40,416 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:34:40,560 - INFO - joeynmt.training - Example #0
2025-05-22 14:34:40,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:34:40,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:34:40,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', 'voor', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:34:40,561 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:34:40,561 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:34:40,561 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> dat de <unk> <unk> <unk>, <unk> <unk> voor drie miljoen jaar <unk> <unk> <unk> <unk> <unk>.
2025-05-22 14:34:40,561 - INFO - joeynmt.training - Example #1
2025-05-22 14:34:40,561 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:34:40,561 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:34:40,561 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'van', 'dit', '<unk>', '<unk>', 'van', 'dit', '<unk>', ',', 'het', '<unk>', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:34:40,561 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:34:40,561 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:34:40,562 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg van dit <unk> <unk> van dit <unk>, het <unk> niet de <unk> van de <unk> <unk>.
2025-05-22 14:34:40,562 - INFO - joeynmt.training - Example #2
2025-05-22 14:34:40,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:34:40,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:34:40,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', 'het', '<unk>', 'van', 'onze', '<unk>', '.', '</s>']
2025-05-22 14:34:40,562 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:34:40,562 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:34:40,562 - INFO - joeynmt.training - 	Hypothesis: In <unk> is de <unk> <unk> <unk> het <unk> van onze <unk>.
2025-05-22 14:34:40,562 - INFO - joeynmt.training - Example #3
2025-05-22 14:34:40,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:34:40,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:34:40,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', '<unk>', '.', '</s>']
2025-05-22 14:34:40,563 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:34:40,563 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:34:40,564 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de <unk> en <unk> in de <unk>.
2025-05-22 14:34:40,564 - INFO - joeynmt.training - Example #4
2025-05-22 14:34:40,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:34:40,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:34:40,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'zien', ',', 'is', 'een', '<unk>', 'van', 'de', 'laatste', 'laatste', 'jaar', '.', '</s>']
2025-05-22 14:34:40,565 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:34:40,565 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:34:40,565 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie zien, is een <unk> van de laatste laatste jaar.
2025-05-22 14:34:47,794 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.101619, Batch Acc: 0.417551, Tokens per Sec:     8872, Lr: 0.000300
2025-05-22 14:34:54,250 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.157672, Batch Acc: 0.424318, Tokens per Sec:     9985, Lr: 0.000300
2025-05-22 14:35:00,288 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     1.843412, Batch Acc: 0.427545, Tokens per Sec:    11086, Lr: 0.000300
2025-05-22 14:35:05,854 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.019034, Batch Acc: 0.430793, Tokens per Sec:    11882, Lr: 0.000300
2025-05-22 14:35:11,645 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.063147, Batch Acc: 0.432891, Tokens per Sec:    11524, Lr: 0.000300
2025-05-22 14:35:11,646 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:35:11,646 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:35:20,690 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.04, ppl:   7.70, acc:   0.41, generation: 8.9787[sec], evaluation: 0.0000[sec]
2025-05-22 14:35:20,690 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:35:20,827 - INFO - joeynmt.training - Example #0
2025-05-22 14:35:20,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:35:20,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:35:20,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', ',', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', 'van', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:35:20,827 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:35:20,827 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:35:20,827 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk>, om te <unk> dat de <unk> van drie miljoen jaar <unk> <unk>, <unk> <unk> <unk>.
2025-05-22 14:35:20,827 - INFO - joeynmt.training - Example #1
2025-05-22 14:35:20,828 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:35:20,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:35:20,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:35:20,828 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:35:20,828 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:35:20,828 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg genoeg de <unk> van dit <unk> <unk>, het niet de <unk> van de <unk> van de <unk>.
2025-05-22 14:35:20,828 - INFO - joeynmt.training - Example #2
2025-05-22 14:35:20,828 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:35:20,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:35:20,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:35:20,829 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:35:20,829 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:35:20,829 - INFO - joeynmt.training - 	Hypothesis: In <unk> is de <unk> <unk> <unk> <unk> <unk> <unk>.
2025-05-22 14:35:20,829 - INFO - joeynmt.training - Example #3
2025-05-22 14:35:20,829 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:35:20,829 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:35:20,829 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', '<unk>', '.', '</s>']
2025-05-22 14:35:20,829 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:35:20,829 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:35:20,829 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de <unk> en <unk> in de <unk>.
2025-05-22 14:35:20,830 - INFO - joeynmt.training - Example #4
2025-05-22 14:35:20,830 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:35:20,830 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:35:20,830 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'wil', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'in', 'de', 'laatste', 'laatste', 'jaar', '.', '</s>']
2025-05-22 14:35:20,830 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:35:20,830 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:35:20,830 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie wil zien, is een <unk> wat in de laatste laatste jaar.
2025-05-22 14:35:26,722 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     1.956351, Batch Acc: 0.437460, Tokens per Sec:    10824, Lr: 0.000300
2025-05-22 14:35:33,026 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     1.937672, Batch Acc: 0.437856, Tokens per Sec:    10539, Lr: 0.000300
2025-05-22 14:35:39,425 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     1.821340, Batch Acc: 0.439519, Tokens per Sec:    10227, Lr: 0.000300
2025-05-22 14:35:45,839 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.034341, Batch Acc: 0.439482, Tokens per Sec:    10722, Lr: 0.000300
2025-05-22 14:35:52,285 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     1.853249, Batch Acc: 0.445459, Tokens per Sec:    10244, Lr: 0.000300
2025-05-22 14:35:52,286 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:35:52,286 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:36:01,311 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.33, acc:   0.42, generation: 8.9421[sec], evaluation: 0.0000[sec]
2025-05-22 14:36:01,312 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:36:01,471 - INFO - joeynmt.helpers - delete models/transformer_enit/500.ckpt
2025-05-22 14:36:01,475 - INFO - joeynmt.training - Example #0
2025-05-22 14:36:01,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:36:01,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:36:01,475 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', '<unk>', 'om', 'te', '<unk>', 'te', '<unk>', ',', 'de', '<unk>', 'voor', '<unk>', ',', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:36:01,476 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:36:01,476 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:36:01,476 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> <unk> om te <unk> te <unk>, de <unk> voor <unk>, de <unk> van de <unk> <unk>, <unk> <unk> <unk>.
2025-05-22 14:36:01,476 - INFO - joeynmt.training - Example #1
2025-05-22 14:36:01,476 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:36:01,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:36:01,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'genoeg', 'de', '<unk>', 'van', 'het', '<unk>', 'van', 'het', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2025-05-22 14:36:01,476 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:36:01,476 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:36:01,476 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg genoeg de <unk> van het <unk> van het <unk> van het <unk>.
2025-05-22 14:36:01,476 - INFO - joeynmt.training - Example #2
2025-05-22 14:36:01,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:36:01,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:36:01,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', '<unk>', 'het', '<unk>', '<unk>', 'van', 'ons', 'hart', '.', '</s>']
2025-05-22 14:36:01,477 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:36:01,477 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:36:01,477 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> <unk> het <unk> <unk> van ons hart.
2025-05-22 14:36:01,477 - INFO - joeynmt.training - Example #3
2025-05-22 14:36:01,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:36:01,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:36:01,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:36:01,478 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:36:01,478 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:36:01,478 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in het <unk> en <unk> in de zomer.
2025-05-22 14:36:01,478 - INFO - joeynmt.training - Example #4
2025-05-22 14:36:01,478 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:36:01,478 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:36:01,478 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'zal', 'zien', ',', 'is', 'een', '<unk>', '<unk>', 'van', 'de', 'afgelopen', '<unk>', 'jaar', '.', '</s>']
2025-05-22 14:36:01,479 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:36:01,479 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:36:01,479 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik zal zien, is een <unk> <unk> van de afgelopen <unk> jaar.
2025-05-22 14:36:08,682 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     1.774441, Batch Acc: 0.451489, Tokens per Sec:     9193, Lr: 0.000300
2025-05-22 14:36:15,999 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     1.875756, Batch Acc: 0.451199, Tokens per Sec:     8960, Lr: 0.000300
2025-05-22 14:36:21,916 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     1.821283, Batch Acc: 0.450721, Tokens per Sec:    11201, Lr: 0.000300
2025-05-22 14:36:27,800 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     1.976115, Batch Acc: 0.454679, Tokens per Sec:    10980, Lr: 0.000300
2025-05-22 14:36:33,686 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     1.909801, Batch Acc: 0.456516, Tokens per Sec:    11184, Lr: 0.000300
2025-05-22 14:36:33,687 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:36:33,687 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:36:40,751 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.96, acc:   0.44, generation: 6.9989[sec], evaluation: 0.0000[sec]
2025-05-22 14:36:40,752 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:36:40,887 - INFO - joeynmt.helpers - delete models/transformer_enit/1000.ckpt
2025-05-22 14:36:40,891 - INFO - joeynmt.training - Example #0
2025-05-22 14:36:40,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:36:40,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:36:40,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:36:40,892 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:36:40,892 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:36:40,892 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die voor <unk> <unk>, de <unk> <unk> <unk> <unk>, <unk> <unk> <unk>, <unk> <unk>.
2025-05-22 14:36:40,892 - INFO - joeynmt.training - Example #1
2025-05-22 14:36:40,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:36:40,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:36:40,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'zo', 'goed', 'genoeg', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:36:40,893 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:36:40,893 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:36:40,893 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet zo goed genoeg de <unk> van de <unk> <unk>, omdat het niet de <unk> van de <unk> <unk>.
2025-05-22 14:36:40,893 - INFO - joeynmt.training - Example #2
2025-05-22 14:36:40,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:36:40,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:36:40,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:36:40,894 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:36:40,894 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:36:40,894 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> <unk> van de <unk> <unk>.
2025-05-22 14:36:40,894 - INFO - joeynmt.training - Example #3
2025-05-22 14:36:40,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:36:40,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:36:40,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:36:40,895 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:36:40,895 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:36:40,895 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de <unk> en <unk> in de zomer.
2025-05-22 14:36:40,895 - INFO - joeynmt.training - Example #4
2025-05-22 14:36:40,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:36:40,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:36:40,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'zien', ',', 'is', 'een', '<unk>', 'van', '25', 'jaar', '.', '</s>']
2025-05-22 14:36:40,896 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:36:40,896 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:36:40,896 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie zien, is een <unk> van 25 jaar.
2025-05-22 14:36:47,103 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     1.838855, Batch Acc: 0.460630, Tokens per Sec:    10384, Lr: 0.000300
2025-05-22 14:36:53,678 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.007719, Batch Acc: 0.461313, Tokens per Sec:    10377, Lr: 0.000300
2025-05-22 14:37:00,336 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     1.880581, Batch Acc: 0.464936, Tokens per Sec:     9958, Lr: 0.000300
2025-05-22 14:37:07,026 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.058610, Batch Acc: 0.464492, Tokens per Sec:    10010, Lr: 0.000300
2025-05-22 14:37:13,771 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     1.786592, Batch Acc: 0.463984, Tokens per Sec:     9841, Lr: 0.000300
2025-05-22 14:37:13,772 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:37:13,772 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:37:22,619 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.78, acc:   0.44, generation: 8.7649[sec], evaluation: 0.0000[sec]
2025-05-22 14:37:22,619 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:37:22,764 - INFO - joeynmt.helpers - delete models/transformer_enit/1500.ckpt
2025-05-22 14:37:22,774 - INFO - joeynmt.training - Example #0
2025-05-22 14:37:22,774 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:37:22,774 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:37:22,774 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'geleden', '<unk>', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'voor', '<unk>', ',', 'de', '<unk>', 'voor', '<unk>', ',', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2025-05-22 14:37:22,775 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:37:22,775 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:37:22,775 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar geleden <unk> ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> voor <unk>, de <unk> voor <unk>, om 40 procent te <unk>.
2025-05-22 14:37:22,775 - INFO - joeynmt.training - Example #1
2025-05-22 14:37:22,775 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:37:22,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:37:22,775 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'het', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:37:22,775 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:37:22,776 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:37:22,776 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg de <unk> van het <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 14:37:22,776 - INFO - joeynmt.training - Example #2
2025-05-22 14:37:22,776 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:37:22,776 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:37:22,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', 'het', 'hart', 'van', 'ons', 'hart', '.', '</s>']
2025-05-22 14:37:22,776 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:37:22,776 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:37:22,776 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> <unk> het hart van ons hart.
2025-05-22 14:37:22,776 - INFO - joeynmt.training - Example #3
2025-05-22 14:37:22,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:37:22,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:37:22,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:37:22,777 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:37:22,777 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:37:22,777 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in <unk> en <unk> in de zomer.
2025-05-22 14:37:22,777 - INFO - joeynmt.training - Example #4
2025-05-22 14:37:22,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:37:22,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:37:22,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 14:37:22,778 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:37:22,778 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:37:22,778 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie zien, is een <unk> wat in de laatste 25 jaar.
2025-05-22 14:37:29,255 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     1.776378, Batch Acc: 0.467722, Tokens per Sec:     9886, Lr: 0.000300
2025-05-22 14:37:35,517 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     1.832696, Batch Acc: 0.462393, Tokens per Sec:    10061, Lr: 0.000300
2025-05-22 14:37:41,617 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     1.836284, Batch Acc: 0.471384, Tokens per Sec:    11050, Lr: 0.000300
2025-05-22 14:37:47,595 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:     1.949065, Batch Acc: 0.475054, Tokens per Sec:    10803, Lr: 0.000300
2025-05-22 14:37:53,742 - INFO - joeynmt.training - Epoch   1, Step:     4500, Batch Loss:     1.815335, Batch Acc: 0.468864, Tokens per Sec:    10749, Lr: 0.000300
2025-05-22 14:37:53,743 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:37:53,743 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:38:02,673 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.55, acc:   0.45, generation: 8.8409[sec], evaluation: 0.0000[sec]
2025-05-22 14:38:02,674 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:38:02,861 - INFO - joeynmt.helpers - delete models/transformer_enit/2000.ckpt
2025-05-22 14:38:02,876 - INFO - joeynmt.training - Example #0
2025-05-22 14:38:02,876 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:38:02,876 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:38:02,876 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', ',', '<unk>', 'procent', '<unk>', '.', '</s>']
2025-05-22 14:38:02,877 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:38:02,877 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:38:02,877 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> <unk> om te <unk> dat de <unk> <unk> <unk> drie miljoen jaar <unk> <unk> <unk> <unk> <unk>, <unk> <unk> <unk>, <unk> procent <unk>.
2025-05-22 14:38:02,877 - INFO - joeynmt.training - Example #1
2025-05-22 14:38:02,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:38:02,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:38:02,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'genoeg', '<unk>', 'van', 'dit', '<unk>', '<unk>', '<unk>', ',', 'omdat', 'het', '<unk>', 'van', 'het', '<unk>', '<unk>', 'toont', '.', '</s>']
2025-05-22 14:38:02,878 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:38:02,879 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:38:02,879 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg genoeg <unk> van dit <unk> <unk> <unk>, omdat het <unk> van het <unk> <unk> toont.
2025-05-22 14:38:02,879 - INFO - joeynmt.training - Example #2
2025-05-22 14:38:02,879 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:38:02,879 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:38:02,879 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', 'het', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:38:02,880 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:38:02,881 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:38:02,881 - INFO - joeynmt.training - 	Hypothesis: In <unk> is de <unk> <unk> <unk> het hart van ons <unk>.
2025-05-22 14:38:02,881 - INFO - joeynmt.training - Example #3
2025-05-22 14:38:02,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:38:02,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:38:02,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:38:02,882 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:38:02,882 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:38:02,882 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in het <unk> en <unk> in de zomer.
2025-05-22 14:38:02,883 - INFO - joeynmt.training - Example #4
2025-05-22 14:38:02,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:38:02,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:38:02,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'gebeurt', '.', '</s>']
2025-05-22 14:38:02,884 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:38:02,884 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:38:02,885 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien, is een <unk> wat er in de laatste 25 jaar gebeurt.
2025-05-22 14:38:10,117 - INFO - joeynmt.training - Epoch   1, Step:     4600, Batch Loss:     1.814236, Batch Acc: 0.472395, Tokens per Sec:     8701, Lr: 0.000300
2025-05-22 14:38:17,374 - INFO - joeynmt.training - Epoch   1, Step:     4700, Batch Loss:     1.724386, Batch Acc: 0.471849, Tokens per Sec:     9369, Lr: 0.000300
2025-05-22 14:38:24,799 - INFO - joeynmt.training - Epoch   1, Step:     4800, Batch Loss:     1.754484, Batch Acc: 0.473817, Tokens per Sec:     8669, Lr: 0.000300
2025-05-22 14:38:32,315 - INFO - joeynmt.training - Epoch   1, Step:     4900, Batch Loss:     1.736507, Batch Acc: 0.475825, Tokens per Sec:     8918, Lr: 0.000300
2025-05-22 14:38:39,390 - INFO - joeynmt.training - Epoch   1, Step:     5000, Batch Loss:     1.831170, Batch Acc: 0.476208, Tokens per Sec:     9206, Lr: 0.000300
2025-05-22 14:38:39,391 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:38:39,391 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:38:48,612 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.42, acc:   0.45, generation: 9.1436[sec], evaluation: 0.0000[sec]
2025-05-22 14:38:48,613 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:38:48,758 - INFO - joeynmt.helpers - delete models/transformer_enit/2500.ckpt
2025-05-22 14:38:48,762 - INFO - joeynmt.training - Example #0
2025-05-22 14:38:48,762 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:38:48,762 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:38:48,762 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', 'voor', '<unk>', ',', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:38:48,762 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:38:48,763 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:38:48,763 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, de <unk> <unk> voor <unk>, <unk> <unk> <unk> <unk>.
2025-05-22 14:38:48,763 - INFO - joeynmt.training - Example #1
2025-05-22 14:38:48,763 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:38:48,763 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:38:48,763 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'veel', '<unk>', '<unk>', '<unk>', 'uit', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:38:48,763 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:38:48,764 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:38:48,764 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet veel <unk> <unk> <unk> uit, want het is niet de <unk> van de <unk> <unk>.
2025-05-22 14:38:48,764 - INFO - joeynmt.training - Example #2
2025-05-22 14:38:48,764 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:38:48,764 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:38:48,764 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'van', 'onze', '<unk>', '.', '</s>']
2025-05-22 14:38:48,764 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:38:48,764 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:38:48,764 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> van onze <unk>.
2025-05-22 14:38:48,765 - INFO - joeynmt.training - Example #3
2025-05-22 14:38:48,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:38:48,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:38:48,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:38:48,765 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:38:48,765 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:38:48,765 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de <unk> en <unk> in de zomer.
2025-05-22 14:38:48,765 - INFO - joeynmt.training - Example #4
2025-05-22 14:38:48,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:38:48,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:38:48,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 14:38:48,766 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:38:48,766 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:38:48,766 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien, is een <unk> wat in de laatste 25 jaar.
2025-05-22 14:38:55,509 - INFO - joeynmt.training - Epoch   1, Step:     5100, Batch Loss:     1.671542, Batch Acc: 0.473314, Tokens per Sec:     9390, Lr: 0.000300
2025-05-22 14:39:01,559 - INFO - joeynmt.training - Epoch   1, Step:     5200, Batch Loss:     1.905166, Batch Acc: 0.479009, Tokens per Sec:    11075, Lr: 0.000300
2025-05-22 14:39:07,667 - INFO - joeynmt.training - Epoch   1, Step:     5300, Batch Loss:     1.843926, Batch Acc: 0.477929, Tokens per Sec:    10924, Lr: 0.000300
2025-05-22 14:39:13,701 - INFO - joeynmt.training - Epoch   1, Step:     5400, Batch Loss:     1.855241, Batch Acc: 0.483179, Tokens per Sec:    10985, Lr: 0.000300
2025-05-22 14:39:19,781 - INFO - joeynmt.training - Epoch   1, Step:     5500, Batch Loss:     1.752530, Batch Acc: 0.482637, Tokens per Sec:    10816, Lr: 0.000300
2025-05-22 14:39:19,782 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:39:19,782 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:39:27,151 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.34, acc:   0.45, generation: 7.2865[sec], evaluation: 0.0000[sec]
2025-05-22 14:39:27,152 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:39:27,301 - INFO - joeynmt.helpers - delete models/transformer_enit/3000.ckpt
2025-05-22 14:39:27,304 - INFO - joeynmt.training - Example #0
2025-05-22 14:39:27,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:39:27,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:39:27,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', 'voor', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:39:27,306 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:39:27,306 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:39:27,306 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, de <unk> voor <unk> <unk> <unk>, de <unk> <unk> <unk> van de <unk> <unk> <unk> van de <unk> <unk> <unk>.
2025-05-22 14:39:27,306 - INFO - joeynmt.training - Example #1
2025-05-22 14:39:27,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:39:27,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:39:27,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:39:27,308 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:39:27,308 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:39:27,308 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg de <unk> van dit <unk>, omdat het niet de <unk> van de <unk> <unk>.
2025-05-22 14:39:27,308 - INFO - joeynmt.training - Example #2
2025-05-22 14:39:27,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:39:27,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:39:27,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:39:27,309 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:39:27,309 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:39:27,309 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 14:39:27,309 - INFO - joeynmt.training - Example #3
2025-05-22 14:39:27,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:39:27,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:39:27,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:39:27,310 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:39:27,310 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:39:27,310 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in <unk> en <unk> in de zomer.
2025-05-22 14:39:27,311 - INFO - joeynmt.training - Example #4
2025-05-22 14:39:27,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:39:27,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:39:27,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'zal', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 14:39:27,312 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:39:27,312 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:39:27,312 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie zal zien, is een <unk> wat in de laatste 25 jaar is.
2025-05-22 14:39:34,325 - INFO - joeynmt.training - Epoch   1, Step:     5600, Batch Loss:     1.594619, Batch Acc: 0.479305, Tokens per Sec:     9284, Lr: 0.000300
2025-05-22 14:39:41,164 - INFO - joeynmt.training - Epoch   1, Step:     5700, Batch Loss:     1.858458, Batch Acc: 0.480107, Tokens per Sec:     9717, Lr: 0.000300
2025-05-22 14:39:48,313 - INFO - joeynmt.training - Epoch   1, Step:     5800, Batch Loss:     1.701994, Batch Acc: 0.482852, Tokens per Sec:     9081, Lr: 0.000300
2025-05-22 14:39:55,024 - INFO - joeynmt.training - Epoch   1, Step:     5900, Batch Loss:     1.669295, Batch Acc: 0.479092, Tokens per Sec:    10164, Lr: 0.000300
2025-05-22 14:39:57,176 - INFO - joeynmt.training - Epoch   1: total training loss 12107.32
2025-05-22 14:39:57,176 - INFO - joeynmt.training - EPOCH 2
2025-05-22 14:40:01,736 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     1.802924, Batch Acc: 0.492186, Tokens per Sec:     9701, Lr: 0.000300
2025-05-22 14:40:01,736 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:40:01,736 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:40:10,318 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.33, acc:   0.46, generation: 8.4859[sec], evaluation: 0.0000[sec]
2025-05-22 14:40:10,319 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:40:10,505 - INFO - joeynmt.helpers - delete models/transformer_enit/3500.ckpt
2025-05-22 14:40:10,510 - INFO - joeynmt.training - Example #0
2025-05-22 14:40:10,511 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:40:10,511 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:40:10,511 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:40:10,512 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:40:10,512 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:40:10,512 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die voor <unk> drie miljoen jaar <unk> <unk> <unk>.
2025-05-22 14:40:10,512 - INFO - joeynmt.training - Example #1
2025-05-22 14:40:10,512 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:40:10,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:40:10,513 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:40:10,514 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:40:10,514 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:40:10,514 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk> van de <unk>.
2025-05-22 14:40:10,514 - INFO - joeynmt.training - Example #2
2025-05-22 14:40:10,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:40:10,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:40:10,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:40:10,515 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:40:10,515 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:40:10,515 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het hart van ons <unk>.
2025-05-22 14:40:10,515 - INFO - joeynmt.training - Example #3
2025-05-22 14:40:10,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:40:10,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:40:10,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:40:10,516 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:40:10,516 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:40:10,516 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de <unk> en <unk> in de zomer.
2025-05-22 14:40:10,516 - INFO - joeynmt.training - Example #4
2025-05-22 14:40:10,517 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:40:10,517 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:40:10,517 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', ',', 'is', 'een', '<unk>', 'van', '25', 'jaar', '.', '</s>']
2025-05-22 14:40:10,518 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:40:10,518 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:40:10,518 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien, is een <unk> van 25 jaar.
2025-05-22 14:40:17,591 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     1.674461, Batch Acc: 0.491926, Tokens per Sec:     9279, Lr: 0.000300
2025-05-22 14:40:24,125 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     1.691176, Batch Acc: 0.489821, Tokens per Sec:     9849, Lr: 0.000300
2025-05-22 14:40:30,986 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     1.733781, Batch Acc: 0.491541, Tokens per Sec:     9605, Lr: 0.000300
2025-05-22 14:40:37,633 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     1.773249, Batch Acc: 0.495153, Tokens per Sec:    10044, Lr: 0.000300
2025-05-22 14:40:46,560 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     1.807699, Batch Acc: 0.494418, Tokens per Sec:     7556, Lr: 0.000300
2025-05-22 14:40:46,561 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:40:46,561 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:41:01,087 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.15, acc:   0.46, generation: 14.4082[sec], evaluation: 0.0000[sec]
2025-05-22 14:41:01,089 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:41:01,270 - INFO - joeynmt.helpers - delete models/transformer_enit/4000.ckpt
2025-05-22 14:41:01,273 - INFO - joeynmt.training - Example #0
2025-05-22 14:41:01,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:41:01,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:41:01,274 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', 'van', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'van', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:41:01,274 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:41:01,275 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:41:01,275 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, de <unk> van drie miljoen jaar de <unk> van de <unk> <unk> van <unk> <unk>.
2025-05-22 14:41:01,275 - INFO - joeynmt.training - Example #1
2025-05-22 14:41:01,275 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:41:01,275 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:41:01,275 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'sterk', 'genoeg', 'is', 'dat', '<unk>', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:41:01,276 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:41:01,276 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:41:01,276 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet sterk genoeg is dat <unk> <unk> <unk>, omdat het niet de <unk> van de <unk> van de <unk> <unk>.
2025-05-22 14:41:01,276 - INFO - joeynmt.training - Example #2
2025-05-22 14:41:01,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:41:01,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:41:01,276 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', '<unk>', '<unk>', 'van', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:41:01,277 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:41:01,277 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:41:01,277 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> <unk> <unk> van het <unk> hart van ons <unk>.
2025-05-22 14:41:01,277 - INFO - joeynmt.training - Example #3
2025-05-22 14:41:01,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:41:01,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:41:01,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:41:01,278 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:41:01,278 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:41:01,278 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de <unk> en <unk> in de zomer.
2025-05-22 14:41:01,278 - INFO - joeynmt.training - Example #4
2025-05-22 14:41:01,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:41:01,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:41:01,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 14:41:01,279 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:41:01,279 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:41:01,279 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien, is een <unk> wat in de laatste 25 jaar is.
2025-05-22 14:41:10,458 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     1.683534, Batch Acc: 0.487782, Tokens per Sec:     7128, Lr: 0.000300
2025-05-22 14:41:20,034 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     1.680934, Batch Acc: 0.494883, Tokens per Sec:     6982, Lr: 0.000300
2025-05-22 14:41:28,037 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     1.804738, Batch Acc: 0.491490, Tokens per Sec:     8355, Lr: 0.000300
2025-05-22 14:41:36,526 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     1.566794, Batch Acc: 0.493371, Tokens per Sec:     7784, Lr: 0.000300
2025-05-22 14:41:46,827 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     1.677519, Batch Acc: 0.494704, Tokens per Sec:     6462, Lr: 0.000300
2025-05-22 14:41:46,834 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:41:46,835 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:41:56,491 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.04, acc:   0.47, generation: 9.5575[sec], evaluation: 0.0000[sec]
2025-05-22 14:41:56,491 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:41:56,643 - INFO - joeynmt.helpers - delete models/transformer_enit/4500.ckpt
2025-05-22 14:41:56,650 - INFO - joeynmt.training - Example #0
2025-05-22 14:41:56,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:41:56,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:41:56,651 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'om', '40', 'procent', '<unk>', 'is', '.', '</s>']
2025-05-22 14:41:56,652 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:41:56,652 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:41:56,652 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> zien om te <unk> dat de <unk> <unk> <unk> <unk>, de <unk> <unk> <unk>, de <unk> <unk> <unk> <unk>, om 40 procent <unk> is.
2025-05-22 14:41:56,652 - INFO - joeynmt.training - Example #1
2025-05-22 14:41:56,652 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:41:56,653 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:41:56,653 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'toont', '.', '</s>']
2025-05-22 14:41:56,653 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:41:56,653 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:41:56,653 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet sterk genoeg <unk> de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> toont.
2025-05-22 14:41:56,653 - INFO - joeynmt.training - Example #2
2025-05-22 14:41:56,653 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:41:56,654 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:41:56,654 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:41:56,654 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:41:56,654 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:41:56,654 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het hart van ons <unk>.
2025-05-22 14:41:56,654 - INFO - joeynmt.training - Example #3
2025-05-22 14:41:56,654 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:41:56,654 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:41:56,655 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:41:56,655 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:41:56,655 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:41:56,655 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:41:56,655 - INFO - joeynmt.training - Example #4
2025-05-22 14:41:56,655 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:41:56,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:41:56,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'wat', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 14:41:56,656 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:41:56,656 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:41:56,657 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> wat in de afgelopen 25 jaar is.
2025-05-22 14:42:04,767 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     1.684347, Batch Acc: 0.493781, Tokens per Sec:     7860, Lr: 0.000300
2025-05-22 14:42:12,701 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     1.743562, Batch Acc: 0.495598, Tokens per Sec:     8490, Lr: 0.000300
2025-05-22 14:42:19,498 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     1.730520, Batch Acc: 0.493027, Tokens per Sec:     9422, Lr: 0.000300
2025-05-22 14:42:26,384 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     1.699091, Batch Acc: 0.497362, Tokens per Sec:     9387, Lr: 0.000300
2025-05-22 14:42:33,615 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     1.580680, Batch Acc: 0.500229, Tokens per Sec:     9071, Lr: 0.000300
2025-05-22 14:42:33,615 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:42:33,615 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:42:43,118 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.08, acc:   0.46, generation: 9.4126[sec], evaluation: 0.0000[sec]
2025-05-22 14:42:43,263 - INFO - joeynmt.helpers - delete models/transformer_enit/5000.ckpt
2025-05-22 14:42:43,278 - INFO - joeynmt.training - Example #0
2025-05-22 14:42:43,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:42:43,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:42:43,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:42:43,279 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:42:43,279 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:42:43,279 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, de <unk> <unk> <unk>, de <unk> <unk> <unk> <unk>, <unk> <unk>, <unk>, <unk>, <unk>, <unk> <unk>.
2025-05-22 14:42:43,279 - INFO - joeynmt.training - Example #1
2025-05-22 14:42:43,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:42:43,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:42:43,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'is', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', '<unk>', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:42:43,280 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:42:43,280 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:42:43,280 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg is de <unk> van dit <unk> <unk>, <unk> het niet de <unk> van de <unk>.
2025-05-22 14:42:43,281 - INFO - joeynmt.training - Example #2
2025-05-22 14:42:43,281 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:42:43,281 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:42:43,281 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:42:43,281 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:42:43,281 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:42:43,282 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van de <unk>.
2025-05-22 14:42:43,282 - INFO - joeynmt.training - Example #3
2025-05-22 14:42:43,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:42:43,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:42:43,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:42:43,282 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:42:43,282 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:42:43,282 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:42:43,282 - INFO - joeynmt.training - Example #4
2025-05-22 14:42:43,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:42:43,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:42:43,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 14:42:43,283 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:42:43,283 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:42:43,283 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> wat in de afgelopen 25 jaar is.
2025-05-22 14:42:50,337 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     1.790521, Batch Acc: 0.497752, Tokens per Sec:     9062, Lr: 0.000300
2025-05-22 14:42:57,392 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     1.861536, Batch Acc: 0.495211, Tokens per Sec:     9368, Lr: 0.000300
2025-05-22 14:43:04,382 - INFO - joeynmt.training - Epoch   2, Step:     7800, Batch Loss:     1.818736, Batch Acc: 0.500410, Tokens per Sec:     9432, Lr: 0.000300
2025-05-22 14:43:11,361 - INFO - joeynmt.training - Epoch   2, Step:     7900, Batch Loss:     1.651250, Batch Acc: 0.501737, Tokens per Sec:     9364, Lr: 0.000300
2025-05-22 14:43:18,398 - INFO - joeynmt.training - Epoch   2, Step:     8000, Batch Loss:     1.675950, Batch Acc: 0.500123, Tokens per Sec:     9216, Lr: 0.000300
2025-05-22 14:43:18,399 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:43:18,399 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:43:25,718 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   6.00, acc:   0.47, generation: 7.2469[sec], evaluation: 0.0000[sec]
2025-05-22 14:43:25,719 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:43:25,860 - INFO - joeynmt.helpers - delete models/transformer_enit/5500.ckpt
2025-05-22 14:43:25,872 - INFO - joeynmt.training - Example #0
2025-05-22 14:43:25,873 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:43:25,873 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:43:25,873 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', '<unk>', ',', 'voor', '<unk>', '<unk>', ',', 'voor', '<unk>', '<unk>', 'staten', ',', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2025-05-22 14:43:25,874 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:43:25,874 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:43:25,874 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, die voor <unk> <unk>, voor <unk> <unk>, voor <unk> <unk> staten, om 40 procent te <unk>.
2025-05-22 14:43:25,874 - INFO - joeynmt.training - Example #1
2025-05-22 14:43:25,874 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:43:25,874 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:43:25,874 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'is', 'dat', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', 'van', 'het', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2025-05-22 14:43:25,875 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:43:25,875 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:43:25,875 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg is dat <unk> <unk>, omdat het niet de <unk> van het <unk> van het <unk> van het <unk>.
2025-05-22 14:43:25,875 - INFO - joeynmt.training - Example #2
2025-05-22 14:43:25,876 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:43:25,876 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:43:25,876 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:43:25,876 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:43:25,877 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:43:25,877 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> hart van ons <unk>.
2025-05-22 14:43:25,877 - INFO - joeynmt.training - Example #3
2025-05-22 14:43:25,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:43:25,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:43:25,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:43:25,878 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:43:25,878 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:43:25,878 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:43:25,878 - INFO - joeynmt.training - Example #4
2025-05-22 14:43:25,878 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:43:25,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:43:25,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 14:43:25,879 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:43:25,879 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:43:25,879 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> van de laatste 25 jaar.
2025-05-22 14:43:32,199 - INFO - joeynmt.training - Epoch   2, Step:     8100, Batch Loss:     1.794343, Batch Acc: 0.499771, Tokens per Sec:    10447, Lr: 0.000300
2025-05-22 14:43:38,446 - INFO - joeynmt.training - Epoch   2, Step:     8200, Batch Loss:     1.730090, Batch Acc: 0.492226, Tokens per Sec:    11101, Lr: 0.000300
2025-05-22 14:43:45,061 - INFO - joeynmt.training - Epoch   2, Step:     8300, Batch Loss:     1.860340, Batch Acc: 0.495693, Tokens per Sec:     9933, Lr: 0.000300
2025-05-22 14:43:52,121 - INFO - joeynmt.training - Epoch   2, Step:     8400, Batch Loss:     1.684331, Batch Acc: 0.499759, Tokens per Sec:     9112, Lr: 0.000300
2025-05-22 14:43:59,161 - INFO - joeynmt.training - Epoch   2, Step:     8500, Batch Loss:     1.819969, Batch Acc: 0.496950, Tokens per Sec:     9340, Lr: 0.000300
2025-05-22 14:43:59,161 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:43:59,162 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:44:07,917 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.92, acc:   0.47, generation: 8.6701[sec], evaluation: 0.0000[sec]
2025-05-22 14:44:07,918 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:44:08,066 - INFO - joeynmt.helpers - delete models/transformer_enit/6000.ckpt
2025-05-22 14:44:08,076 - INFO - joeynmt.training - Example #0
2025-05-22 14:44:08,076 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:44:08,076 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:44:08,076 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', '<unk>', 'ik', 'deze', 'twee', '<unk>', '<unk>', ',', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', ',', 'en', '40', '%', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:44:08,076 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:44:08,077 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:44:08,077 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar <unk> ik deze twee <unk> <unk>, om te <unk> dat de <unk> <unk> <unk>, die voor <unk> drie miljoen jaar <unk> de <unk> van de <unk> staten, en 40% van de <unk>.
2025-05-22 14:44:08,077 - INFO - joeynmt.training - Example #1
2025-05-22 14:44:08,077 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:44:08,077 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:44:08,077 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'is', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'het', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:44:08,077 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:44:08,077 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:44:08,077 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg is de <unk> van de <unk> van het <unk> <unk>.
2025-05-22 14:44:08,077 - INFO - joeynmt.training - Example #2
2025-05-22 14:44:08,078 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:44:08,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:44:08,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:44:08,078 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:44:08,078 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:44:08,078 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 14:44:08,078 - INFO - joeynmt.training - Example #3
2025-05-22 14:44:08,078 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:44:08,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:44:08,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', '<unk>', 'in', 'de', 'zomer', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:44:08,079 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:44:08,079 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:44:08,079 - INFO - joeynmt.training - 	Hypothesis: Ze <unk> in de zomer en <unk> in de zomer.
2025-05-22 14:44:08,079 - INFO - joeynmt.training - Example #4
2025-05-22 14:44:08,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:44:08,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:44:08,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:44:08,079 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:44:08,080 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:44:08,080 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> <unk> <unk>.
2025-05-22 14:44:14,937 - INFO - joeynmt.training - Epoch   2, Step:     8600, Batch Loss:     1.554966, Batch Acc: 0.497049, Tokens per Sec:     9245, Lr: 0.000300
2025-05-22 14:44:21,926 - INFO - joeynmt.training - Epoch   2, Step:     8700, Batch Loss:     1.608880, Batch Acc: 0.501162, Tokens per Sec:     9731, Lr: 0.000300
2025-05-22 14:44:28,938 - INFO - joeynmt.training - Epoch   2, Step:     8800, Batch Loss:     1.551585, Batch Acc: 0.498540, Tokens per Sec:     9379, Lr: 0.000300
2025-05-22 14:44:36,176 - INFO - joeynmt.training - Epoch   2, Step:     8900, Batch Loss:     1.751863, Batch Acc: 0.499618, Tokens per Sec:     9054, Lr: 0.000300
2025-05-22 14:44:42,673 - INFO - joeynmt.training - Epoch   2, Step:     9000, Batch Loss:     1.582142, Batch Acc: 0.504187, Tokens per Sec:    10000, Lr: 0.000300
2025-05-22 14:44:42,673 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:44:42,674 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:44:49,169 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.84, acc:   0.47, generation: 6.4271[sec], evaluation: 0.0000[sec]
2025-05-22 14:44:49,169 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:44:49,308 - INFO - joeynmt.helpers - delete models/transformer_enit/6500.ckpt
2025-05-22 14:44:49,319 - INFO - joeynmt.training - Example #0
2025-05-22 14:44:49,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:44:49,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:44:49,320 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'had', '<unk>', ',', '<unk>', ',', '<unk>', 'is', '.', '</s>']
2025-05-22 14:44:49,320 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:44:49,320 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:44:49,320 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die voor <unk> drie miljoen jaar <unk> <unk> <unk> <unk>, had <unk>, <unk>, <unk> is.
2025-05-22 14:44:49,320 - INFO - joeynmt.training - Example #1
2025-05-22 14:44:49,322 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:44:49,322 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:44:49,322 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'zo', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:44:49,323 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:44:49,323 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:44:49,323 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet zo <unk> genoeg de <unk> van dit <unk>, want het is niet de <unk> van de <unk>.
2025-05-22 14:44:49,323 - INFO - joeynmt.training - Example #2
2025-05-22 14:44:49,323 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:44:49,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:44:49,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:44:49,324 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:44:49,324 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:44:49,324 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 14:44:49,324 - INFO - joeynmt.training - Example #3
2025-05-22 14:44:49,324 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:44:49,324 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:44:49,324 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:44:49,324 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:44:49,324 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:44:49,325 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:44:49,325 - INFO - joeynmt.training - Example #4
2025-05-22 14:44:49,325 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:44:49,325 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:44:49,325 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 14:44:49,325 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:44:49,325 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:44:49,325 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> wat er in de laatste 25 jaar is.
2025-05-22 14:44:55,523 - INFO - joeynmt.training - Epoch   2, Step:     9100, Batch Loss:     1.631929, Batch Acc: 0.499977, Tokens per Sec:    10251, Lr: 0.000300
2025-05-22 14:45:01,843 - INFO - joeynmt.training - Epoch   2, Step:     9200, Batch Loss:     1.619031, Batch Acc: 0.497304, Tokens per Sec:    10682, Lr: 0.000300
2025-05-22 14:45:08,831 - INFO - joeynmt.training - Epoch   2, Step:     9300, Batch Loss:     1.679150, Batch Acc: 0.506141, Tokens per Sec:     9403, Lr: 0.000300
2025-05-22 14:45:15,712 - INFO - joeynmt.training - Epoch   2, Step:     9400, Batch Loss:     1.612315, Batch Acc: 0.498245, Tokens per Sec:     9687, Lr: 0.000300
2025-05-22 14:45:22,909 - INFO - joeynmt.training - Epoch   2, Step:     9500, Batch Loss:     1.697054, Batch Acc: 0.503636, Tokens per Sec:     9076, Lr: 0.000300
2025-05-22 14:45:22,910 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:45:22,910 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:45:31,124 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.81, acc:   0.47, generation: 8.1307[sec], evaluation: 0.0000[sec]
2025-05-22 14:45:31,125 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:45:31,278 - INFO - joeynmt.helpers - delete models/transformer_enit/7500.ckpt
2025-05-22 14:45:31,288 - INFO - joeynmt.training - Example #0
2025-05-22 14:45:31,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:45:31,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:45:31,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2025-05-22 14:45:31,290 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:45:31,290 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:45:31,290 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die voor <unk> drie miljoen jaar <unk> <unk> <unk>, om 40 procent <unk> te <unk>.
2025-05-22 14:45:31,290 - INFO - joeynmt.training - Example #1
2025-05-22 14:45:31,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:45:31,291 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:45:31,291 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', '<unk>', 'genoeg', '<unk>', ',', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:45:31,291 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:45:31,292 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:45:31,292 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg <unk> genoeg <unk>, <unk>, omdat het niet de <unk> van de <unk> van de <unk>.
2025-05-22 14:45:31,292 - INFO - joeynmt.training - Example #2
2025-05-22 14:45:31,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:45:31,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:45:31,292 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', '<unk>', ',', 'het', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:45:31,293 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:45:31,293 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:45:31,293 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> <unk>, het hart van ons <unk>.
2025-05-22 14:45:31,293 - INFO - joeynmt.training - Example #3
2025-05-22 14:45:31,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:45:31,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:45:31,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', 'zomer', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:45:31,294 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:45:31,294 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:45:31,294 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer en <unk> in de zomer.
2025-05-22 14:45:31,294 - INFO - joeynmt.training - Example #4
2025-05-22 14:45:31,295 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:45:31,295 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:45:31,295 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 14:45:31,295 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:45:31,296 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:45:31,296 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> in de afgelopen 25 jaar.
2025-05-22 14:45:38,340 - INFO - joeynmt.training - Epoch   2, Step:     9600, Batch Loss:     1.681214, Batch Acc: 0.500633, Tokens per Sec:     9089, Lr: 0.000300
2025-05-22 14:45:45,229 - INFO - joeynmt.training - Epoch   2, Step:     9700, Batch Loss:     1.642569, Batch Acc: 0.504119, Tokens per Sec:     9763, Lr: 0.000300
2025-05-22 14:45:52,345 - INFO - joeynmt.training - Epoch   2, Step:     9800, Batch Loss:     1.563521, Batch Acc: 0.502511, Tokens per Sec:     9657, Lr: 0.000300
2025-05-22 14:45:59,223 - INFO - joeynmt.training - Epoch   2, Step:     9900, Batch Loss:     1.737414, Batch Acc: 0.504199, Tokens per Sec:     9611, Lr: 0.000300
2025-05-22 14:46:05,913 - INFO - joeynmt.training - Epoch   2, Step:    10000, Batch Loss:     1.611115, Batch Acc: 0.502470, Tokens per Sec:     9955, Lr: 0.000300
2025-05-22 14:46:05,913 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:46:05,913 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:46:14,851 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.77, acc:   0.47, generation: 8.8391[sec], evaluation: 0.0000[sec]
2025-05-22 14:46:14,852 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:46:15,012 - INFO - joeynmt.helpers - delete models/transformer_enit/7000.ckpt
2025-05-22 14:46:15,024 - INFO - joeynmt.training - Example #0
2025-05-22 14:46:15,025 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:46:15,025 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:46:15,025 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',']
2025-05-22 14:46:15,026 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:46:15,026 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:46:15,026 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, de <unk> <unk>, de <unk> <unk> <unk>, de <unk> <unk> <unk>, de <unk> <unk> <unk>, <unk> <unk>, <unk>, <unk> <unk>, de <unk> <unk> <unk>, de <unk> <unk> <unk>, de <unk> <unk> <unk>, de <unk> <unk> <unk> <unk>,
2025-05-22 14:46:15,026 - INFO - joeynmt.training - Example #1
2025-05-22 14:46:15,026 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:46:15,027 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:46:15,027 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:46:15,027 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:46:15,027 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:46:15,028 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> van de <unk>.
2025-05-22 14:46:15,028 - INFO - joeynmt.training - Example #2
2025-05-22 14:46:15,028 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:46:15,028 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:46:15,028 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:46:15,028 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:46:15,029 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:46:15,029 - INFO - joeynmt.training - 	Hypothesis: In <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 14:46:15,029 - INFO - joeynmt.training - Example #3
2025-05-22 14:46:15,029 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:46:15,029 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:46:15,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeien', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:46:15,031 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:46:15,031 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:46:15,031 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de <unk> en <unk> in de zomer.
2025-05-22 14:46:15,033 - INFO - joeynmt.training - Example #4
2025-05-22 14:46:15,033 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:46:15,033 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:46:15,033 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 14:46:15,034 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:46:15,034 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:46:15,034 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> wat de laatste 25 jaar is.
2025-05-22 14:46:22,587 - INFO - joeynmt.training - Epoch   2, Step:    10100, Batch Loss:     1.521256, Batch Acc: 0.502374, Tokens per Sec:     8578, Lr: 0.000300
2025-05-22 14:46:29,469 - INFO - joeynmt.training - Epoch   2, Step:    10200, Batch Loss:     1.551897, Batch Acc: 0.502519, Tokens per Sec:     9778, Lr: 0.000300
2025-05-22 14:46:38,325 - INFO - joeynmt.training - Epoch   2, Step:    10300, Batch Loss:     1.715640, Batch Acc: 0.501282, Tokens per Sec:     7311, Lr: 0.000300
2025-05-22 14:46:46,839 - INFO - joeynmt.training - Epoch   2, Step:    10400, Batch Loss:     1.701385, Batch Acc: 0.507036, Tokens per Sec:     7738, Lr: 0.000300
2025-05-22 14:46:54,324 - INFO - joeynmt.training - Epoch   2, Step:    10500, Batch Loss:     1.812147, Batch Acc: 0.502108, Tokens per Sec:     8970, Lr: 0.000300
2025-05-22 14:46:54,325 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:46:54,325 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:47:04,113 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.73, acc:   0.48, generation: 9.6827[sec], evaluation: 0.0000[sec]
2025-05-22 14:47:04,114 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:47:04,286 - INFO - joeynmt.helpers - delete models/transformer_enit/8000.ckpt
2025-05-22 14:47:04,302 - INFO - joeynmt.training - Example #0
2025-05-22 14:47:04,302 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:47:04,302 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:47:04,302 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', 'is', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2025-05-22 14:47:04,303 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:47:04,303 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:47:04,303 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, de <unk> <unk> <unk>, de <unk> <unk> <unk>, <unk>, <unk> <unk>, <unk> is om 40 procent <unk> te <unk>.
2025-05-22 14:47:04,303 - INFO - joeynmt.training - Example #1
2025-05-22 14:47:04,304 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:47:04,304 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:47:04,304 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:47:04,305 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:47:04,305 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:47:04,305 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> van de <unk>.
2025-05-22 14:47:04,305 - INFO - joeynmt.training - Example #2
2025-05-22 14:47:04,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:47:04,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:47:04,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:47:04,307 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:47:04,307 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:47:04,307 - INFO - joeynmt.training - 	Hypothesis: In <unk> is de <unk> <unk> het hart van ons <unk>.
2025-05-22 14:47:04,308 - INFO - joeynmt.training - Example #3
2025-05-22 14:47:04,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:47:04,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:47:04,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:47:04,309 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:47:04,309 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:47:04,309 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2025-05-22 14:47:04,309 - INFO - joeynmt.training - Example #4
2025-05-22 14:47:04,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:47:04,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:47:04,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 14:47:04,310 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:47:04,310 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:47:04,310 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> wat de laatste 25 jaar is.
2025-05-22 14:47:14,556 - INFO - joeynmt.training - Epoch   2, Step:    10600, Batch Loss:     1.675737, Batch Acc: 0.510675, Tokens per Sec:     6647, Lr: 0.000300
2025-05-22 14:47:22,721 - INFO - joeynmt.training - Epoch   2, Step:    10700, Batch Loss:     1.693931, Batch Acc: 0.502597, Tokens per Sec:     8104, Lr: 0.000300
2025-05-22 14:47:30,485 - INFO - joeynmt.training - Epoch   2, Step:    10800, Batch Loss:     1.635962, Batch Acc: 0.501070, Tokens per Sec:     8425, Lr: 0.000300
2025-05-22 14:47:38,037 - INFO - joeynmt.training - Epoch   2, Step:    10900, Batch Loss:     1.606555, Batch Acc: 0.504534, Tokens per Sec:     9099, Lr: 0.000300
2025-05-22 14:47:44,815 - INFO - joeynmt.training - Epoch   2, Step:    11000, Batch Loss:     1.496375, Batch Acc: 0.505991, Tokens per Sec:     9851, Lr: 0.000300
2025-05-22 14:47:44,815 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:47:44,815 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:47:54,568 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.70, acc:   0.48, generation: 9.6685[sec], evaluation: 0.0000[sec]
2025-05-22 14:47:54,569 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:47:54,719 - INFO - joeynmt.helpers - delete models/transformer_enit/8500.ckpt
2025-05-22 14:47:54,732 - INFO - joeynmt.training - Example #0
2025-05-22 14:47:54,732 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:47:54,732 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:47:54,732 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', ',', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2025-05-22 14:47:54,734 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:47:54,734 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:47:54,734 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, de <unk> <unk> <unk>, de <unk> van de <unk> staten, om 40 procent <unk> te <unk>.
2025-05-22 14:47:54,734 - INFO - joeynmt.training - Example #1
2025-05-22 14:47:54,734 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:47:54,734 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:47:54,734 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:47:54,735 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:47:54,735 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:47:54,735 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg de <unk> van deze <unk> <unk>, omdat het niet <unk> van de <unk> <unk>.
2025-05-22 14:47:54,736 - INFO - joeynmt.training - Example #2
2025-05-22 14:47:54,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:47:54,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:47:54,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'onze', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 14:47:54,737 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:47:54,737 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:47:54,737 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van onze wereldwijde <unk>.
2025-05-22 14:47:54,737 - INFO - joeynmt.training - Example #3
2025-05-22 14:47:54,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:47:54,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:47:54,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', 'zomer', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:47:54,738 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:47:54,738 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:47:54,739 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer en <unk> in de zomer.
2025-05-22 14:47:54,739 - INFO - joeynmt.training - Example #4
2025-05-22 14:47:54,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:47:54,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:47:54,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', '<unk>', 'wat', 'de', 'laatste', '25', 'jaar', 'gebeurt', '.', '</s>']
2025-05-22 14:47:54,740 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:47:54,740 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:47:54,741 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> <unk> wat de laatste 25 jaar gebeurt.
2025-05-22 14:48:01,160 - INFO - joeynmt.training - Epoch   2, Step:    11100, Batch Loss:     1.657061, Batch Acc: 0.504269, Tokens per Sec:     9772, Lr: 0.000300
2025-05-22 14:48:07,624 - INFO - joeynmt.training - Epoch   2, Step:    11200, Batch Loss:     1.747088, Batch Acc: 0.501572, Tokens per Sec:    10233, Lr: 0.000300
2025-05-22 14:48:14,731 - INFO - joeynmt.training - Epoch   2, Step:    11300, Batch Loss:     1.639686, Batch Acc: 0.504230, Tokens per Sec:     9315, Lr: 0.000300
2025-05-22 14:48:22,395 - INFO - joeynmt.training - Epoch   2, Step:    11400, Batch Loss:     1.840606, Batch Acc: 0.506061, Tokens per Sec:     8495, Lr: 0.000300
2025-05-22 14:48:29,105 - INFO - joeynmt.training - Epoch   2, Step:    11500, Batch Loss:     1.625404, Batch Acc: 0.504577, Tokens per Sec:     9883, Lr: 0.000300
2025-05-22 14:48:29,106 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:48:29,106 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:48:37,373 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.70, acc:   0.48, generation: 8.1934[sec], evaluation: 0.0000[sec]
2025-05-22 14:48:37,374 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:48:37,522 - INFO - joeynmt.helpers - delete models/transformer_enit/9000.ckpt
2025-05-22 14:48:37,533 - INFO - joeynmt.training - Example #0
2025-05-22 14:48:37,534 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:48:37,534 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:48:37,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', '<unk>', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:48:37,534 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:48:37,534 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:48:37,534 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar <unk> ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> <unk>, die voor <unk> drie miljoen jaar <unk> <unk>.
2025-05-22 14:48:37,534 - INFO - joeynmt.training - Example #1
2025-05-22 14:48:37,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:48:37,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:48:37,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'goed', '<unk>', '.', '</s>']
2025-05-22 14:48:37,535 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:48:37,535 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:48:37,535 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg <unk> <unk> van deze <unk> <unk>, omdat het niet goed <unk>.
2025-05-22 14:48:37,535 - INFO - joeynmt.training - Example #2
2025-05-22 14:48:37,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:48:37,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:48:37,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:48:37,536 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:48:37,536 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:48:37,536 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 14:48:37,536 - INFO - joeynmt.training - Example #3
2025-05-22 14:48:37,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:48:37,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:48:37,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:48:37,536 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:48:37,536 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:48:37,537 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:48:37,537 - INFO - joeynmt.training - Example #4
2025-05-22 14:48:37,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:48:37,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:48:37,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 14:48:37,537 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:48:37,537 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:48:37,537 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> wat er in de afgelopen 25 jaar is.
2025-05-22 14:48:44,571 - INFO - joeynmt.training - Epoch   2, Step:    11600, Batch Loss:     1.575811, Batch Acc: 0.505607, Tokens per Sec:     9131, Lr: 0.000300
2025-05-22 14:48:51,131 - INFO - joeynmt.training - Epoch   2, Step:    11700, Batch Loss:     1.851226, Batch Acc: 0.509012, Tokens per Sec:     9967, Lr: 0.000300
2025-05-22 14:48:57,669 - INFO - joeynmt.training - Epoch   2, Step:    11800, Batch Loss:     1.788728, Batch Acc: 0.505347, Tokens per Sec:    10540, Lr: 0.000300
2025-05-22 14:49:01,572 - INFO - joeynmt.training - Epoch   2: total training loss 9934.74
2025-05-22 14:49:01,573 - INFO - joeynmt.training - EPOCH 3
2025-05-22 14:49:03,795 - INFO - joeynmt.training - Epoch   3, Step:    11900, Batch Loss:     1.542697, Batch Acc: 0.518056, Tokens per Sec:    10428, Lr: 0.000300
2025-05-22 14:49:09,838 - INFO - joeynmt.training - Epoch   3, Step:    12000, Batch Loss:     1.747098, Batch Acc: 0.520293, Tokens per Sec:    10797, Lr: 0.000300
2025-05-22 14:49:09,839 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:49:09,839 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:49:16,479 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.63, acc:   0.48, generation: 6.5711[sec], evaluation: 0.0000[sec]
2025-05-22 14:49:16,480 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:49:16,618 - INFO - joeynmt.helpers - delete models/transformer_enit/9500.ckpt
2025-05-22 14:49:16,625 - INFO - joeynmt.training - Example #0
2025-05-22 14:49:16,626 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:49:16,626 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:49:16,626 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2025-05-22 14:49:16,627 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:49:16,627 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:49:16,627 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien dat de <unk> <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk> <unk>, om 40 procent <unk> te <unk>.
2025-05-22 14:49:16,627 - INFO - joeynmt.training - Example #1
2025-05-22 14:49:16,627 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:49:16,628 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:49:16,628 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', ',', 'want', 'het', '<unk>', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2025-05-22 14:49:16,628 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:49:16,629 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:49:16,629 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet sterk genoeg <unk>, want het <unk> <unk> <unk>, want het is niet <unk> van het <unk>.
2025-05-22 14:49:16,629 - INFO - joeynmt.training - Example #2
2025-05-22 14:49:16,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:49:16,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:49:16,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', '<unk>', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:49:16,630 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:49:16,630 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:49:16,630 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> <unk> van ons <unk> <unk>.
2025-05-22 14:49:16,630 - INFO - joeynmt.training - Example #3
2025-05-22 14:49:16,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:49:16,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:49:16,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:49:16,631 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:49:16,631 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:49:16,631 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:49:16,631 - INFO - joeynmt.training - Example #4
2025-05-22 14:49:16,632 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:49:16,632 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:49:16,632 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'gebeurt', '.', '</s>']
2025-05-22 14:49:16,633 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:49:16,633 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:49:16,633 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> wat er in de laatste 25 jaar gebeurt.
2025-05-22 14:49:22,554 - INFO - joeynmt.training - Epoch   3, Step:    12100, Batch Loss:     1.534564, Batch Acc: 0.521700, Tokens per Sec:    10905, Lr: 0.000300
2025-05-22 14:49:28,812 - INFO - joeynmt.training - Epoch   3, Step:    12200, Batch Loss:     1.613037, Batch Acc: 0.517808, Tokens per Sec:    10507, Lr: 0.000300
2025-05-22 14:49:35,449 - INFO - joeynmt.training - Epoch   3, Step:    12300, Batch Loss:     1.578122, Batch Acc: 0.515833, Tokens per Sec:     9831, Lr: 0.000300
2025-05-22 14:49:42,058 - INFO - joeynmt.training - Epoch   3, Step:    12400, Batch Loss:     1.466036, Batch Acc: 0.524518, Tokens per Sec:    10124, Lr: 0.000300
2025-05-22 14:49:48,567 - INFO - joeynmt.training - Epoch   3, Step:    12500, Batch Loss:     1.730212, Batch Acc: 0.516519, Tokens per Sec:    10060, Lr: 0.000300
2025-05-22 14:49:48,567 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:49:48,567 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:49:56,216 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.62, acc:   0.48, generation: 7.5739[sec], evaluation: 0.0000[sec]
2025-05-22 14:49:56,216 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:49:56,365 - INFO - joeynmt.helpers - delete models/transformer_enit/10000.ckpt
2025-05-22 14:49:56,374 - INFO - joeynmt.training - Example #0
2025-05-22 14:49:56,375 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:49:56,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:49:56,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:49:56,375 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:49:56,375 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:49:56,375 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> <unk> om te <unk> dat de <unk> <unk> die voor <unk> drie miljoen jaar <unk> <unk>.
2025-05-22 14:49:56,375 - INFO - joeynmt.training - Example #1
2025-05-22 14:49:56,376 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:49:56,376 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:49:56,376 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2025-05-22 14:49:56,377 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:49:56,377 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:49:56,377 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet sterk genoeg <unk> <unk>, want het is niet <unk> van het <unk>.
2025-05-22 14:49:56,377 - INFO - joeynmt.training - Example #2
2025-05-22 14:49:56,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:49:56,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:49:56,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:49:56,378 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:49:56,378 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:49:56,378 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het hart van ons <unk>.
2025-05-22 14:49:56,378 - INFO - joeynmt.training - Example #3
2025-05-22 14:49:56,379 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:49:56,379 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:49:56,379 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:49:56,380 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:49:56,380 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:49:56,380 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:49:56,380 - INFO - joeynmt.training - Example #4
2025-05-22 14:49:56,380 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:49:56,380 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:49:56,380 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'van', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 14:49:56,381 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:49:56,381 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:49:56,381 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> van de afgelopen 25 jaar.
2025-05-22 14:50:03,012 - INFO - joeynmt.training - Epoch   3, Step:    12600, Batch Loss:     1.610274, Batch Acc: 0.515728, Tokens per Sec:     9589, Lr: 0.000300
2025-05-22 14:50:09,756 - INFO - joeynmt.training - Epoch   3, Step:    12700, Batch Loss:     1.614676, Batch Acc: 0.519247, Tokens per Sec:     9643, Lr: 0.000300
2025-05-22 14:50:16,438 - INFO - joeynmt.training - Epoch   3, Step:    12800, Batch Loss:     1.624417, Batch Acc: 0.519708, Tokens per Sec:     9471, Lr: 0.000300
2025-05-22 14:50:23,110 - INFO - joeynmt.training - Epoch   3, Step:    12900, Batch Loss:     1.619577, Batch Acc: 0.517362, Tokens per Sec:    10135, Lr: 0.000300
2025-05-22 14:50:29,272 - INFO - joeynmt.training - Epoch   3, Step:    13000, Batch Loss:     1.644153, Batch Acc: 0.516407, Tokens per Sec:    10702, Lr: 0.000300
2025-05-22 14:50:29,272 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:50:29,273 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:50:36,383 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.64, acc:   0.48, generation: 7.0192[sec], evaluation: 0.0000[sec]
2025-05-22 14:50:36,558 - INFO - joeynmt.helpers - delete models/transformer_enit/10500.ckpt
2025-05-22 14:50:36,572 - INFO - joeynmt.training - Example #0
2025-05-22 14:50:36,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:50:36,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:50:36,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'om', '40', '%', '<unk>', 'te', 'zijn', '.', '</s>']
2025-05-22 14:50:36,573 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:50:36,573 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:50:36,574 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> staten, om 40% <unk> te zijn.
2025-05-22 14:50:36,574 - INFO - joeynmt.training - Example #1
2025-05-22 14:50:36,574 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:50:36,574 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:50:36,574 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'sterk', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 14:50:36,575 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:50:36,575 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:50:36,575 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 14:50:36,575 - INFO - joeynmt.training - Example #2
2025-05-22 14:50:36,575 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:50:36,575 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:50:36,575 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'van', 'ons', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:50:36,576 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:50:36,576 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:50:36,576 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> van ons <unk> <unk> <unk>.
2025-05-22 14:50:36,576 - INFO - joeynmt.training - Example #3
2025-05-22 14:50:36,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:50:36,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:50:36,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeien', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:50:36,577 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:50:36,577 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:50:36,577 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de <unk> en <unk> in de zomer.
2025-05-22 14:50:36,577 - INFO - joeynmt.training - Example #4
2025-05-22 14:50:36,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:50:36,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:50:36,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 14:50:36,578 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:50:36,579 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:50:36,579 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> wat er in de afgelopen 25 jaar is.
2025-05-22 14:50:44,199 - INFO - joeynmt.training - Epoch   3, Step:    13100, Batch Loss:     1.562305, Batch Acc: 0.517704, Tokens per Sec:     8204, Lr: 0.000300
2025-05-22 14:50:51,455 - INFO - joeynmt.training - Epoch   3, Step:    13200, Batch Loss:     1.537349, Batch Acc: 0.514108, Tokens per Sec:     9461, Lr: 0.000300
2025-05-22 14:50:57,888 - INFO - joeynmt.training - Epoch   3, Step:    13300, Batch Loss:     1.526219, Batch Acc: 0.519706, Tokens per Sec:    10098, Lr: 0.000300
2025-05-22 14:51:04,499 - INFO - joeynmt.training - Epoch   3, Step:    13400, Batch Loss:     1.617773, Batch Acc: 0.516894, Tokens per Sec:     9955, Lr: 0.000300
2025-05-22 14:51:11,157 - INFO - joeynmt.training - Epoch   3, Step:    13500, Batch Loss:     1.537652, Batch Acc: 0.513613, Tokens per Sec:     9709, Lr: 0.000300
2025-05-22 14:51:11,158 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:51:11,158 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:51:19,282 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.65, acc:   0.48, generation: 8.0399[sec], evaluation: 0.0000[sec]
2025-05-22 14:51:19,423 - INFO - joeynmt.helpers - delete models/transformer_enit/11000.ckpt
2025-05-22 14:51:19,430 - INFO - joeynmt.training - Example #0
2025-05-22 14:51:19,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:51:19,431 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:51:19,431 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', ',', '<unk>', ',', 'om', '40', 'procent', '<unk>', '<unk>', 'staten', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2025-05-22 14:51:19,431 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:51:19,432 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:51:19,432 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die <unk> <unk> <unk> <unk>, <unk>, <unk>, <unk>, om 40 procent <unk> <unk> staten, om 40 procent <unk> te <unk>.
2025-05-22 14:51:19,432 - INFO - joeynmt.training - Example #1
2025-05-22 14:51:19,432 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:51:19,432 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:51:19,432 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:51:19,432 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:51:19,432 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:51:19,433 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet sterk genoeg <unk>, omdat het niet de <unk> van het <unk> <unk>.
2025-05-22 14:51:19,433 - INFO - joeynmt.training - Example #2
2025-05-22 14:51:19,433 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:51:19,433 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:51:19,433 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:51:19,434 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:51:19,434 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:51:19,434 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> van ons <unk>.
2025-05-22 14:51:19,434 - INFO - joeynmt.training - Example #3
2025-05-22 14:51:19,434 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:51:19,434 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:51:19,434 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:51:19,435 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:51:19,435 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:51:19,435 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2025-05-22 14:51:19,435 - INFO - joeynmt.training - Example #4
2025-05-22 14:51:19,435 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:51:19,435 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:51:19,435 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'zal', 'laten', 'zien', ',', 'is', 'een', '<unk>', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 14:51:19,436 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:51:19,436 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:51:19,436 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie zal laten zien, is een <unk> in de afgelopen 25 jaar.
2025-05-22 14:51:26,128 - INFO - joeynmt.training - Epoch   3, Step:    13600, Batch Loss:     1.473456, Batch Acc: 0.519991, Tokens per Sec:     9496, Lr: 0.000300
2025-05-22 14:51:32,747 - INFO - joeynmt.training - Epoch   3, Step:    13700, Batch Loss:     1.658412, Batch Acc: 0.511552, Tokens per Sec:    10011, Lr: 0.000300
2025-05-22 14:51:38,887 - INFO - joeynmt.training - Epoch   3, Step:    13800, Batch Loss:     1.621648, Batch Acc: 0.510382, Tokens per Sec:    11070, Lr: 0.000300
2025-05-22 14:51:44,963 - INFO - joeynmt.training - Epoch   3, Step:    13900, Batch Loss:     1.454080, Batch Acc: 0.514723, Tokens per Sec:    11034, Lr: 0.000300
2025-05-22 14:51:51,048 - INFO - joeynmt.training - Epoch   3, Step:    14000, Batch Loss:     1.662145, Batch Acc: 0.518366, Tokens per Sec:    10772, Lr: 0.000300
2025-05-22 14:51:51,048 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:51:51,048 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:51:58,834 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.58, acc:   0.48, generation: 7.7054[sec], evaluation: 0.0000[sec]
2025-05-22 14:51:58,834 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:51:58,972 - INFO - joeynmt.helpers - delete models/transformer_enit/11500.ckpt
2025-05-22 14:51:58,982 - INFO - joeynmt.training - Example #0
2025-05-22 14:51:58,982 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:51:58,982 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:51:58,982 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2025-05-22 14:51:58,983 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:51:58,983 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:51:58,983 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> <unk> om te <unk> dat de <unk> <unk> die voor <unk> <unk> <unk>, die voor <unk> <unk> <unk> <unk> <unk>, om 40 procent <unk> te <unk>.
2025-05-22 14:51:58,983 - INFO - joeynmt.training - Example #1
2025-05-22 14:51:58,983 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:51:58,983 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:51:58,984 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'erg', 'genoeg', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '<unk>', 'toont', '.', '</s>']
2025-05-22 14:51:58,984 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:51:58,984 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:51:58,984 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet erg genoeg <unk> van dit <unk> <unk>, omdat het niet de <unk> van het <unk> <unk> toont.
2025-05-22 14:51:58,984 - INFO - joeynmt.training - Example #2
2025-05-22 14:51:58,985 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:51:58,985 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:51:58,985 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:51:58,985 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:51:58,985 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:51:58,986 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> van ons <unk>.
2025-05-22 14:51:58,986 - INFO - joeynmt.training - Example #3
2025-05-22 14:51:58,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:51:58,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:51:58,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:51:58,987 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:51:58,987 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:51:58,987 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:51:58,987 - INFO - joeynmt.training - Example #4
2025-05-22 14:51:58,987 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:51:58,987 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:51:58,987 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 14:51:58,988 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:51:58,988 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:51:58,988 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> in de afgelopen 25 jaar.
2025-05-22 14:52:06,435 - INFO - joeynmt.training - Epoch   3, Step:    14100, Batch Loss:     1.618791, Batch Acc: 0.518185, Tokens per Sec:     8555, Lr: 0.000300
2025-05-22 14:52:13,575 - INFO - joeynmt.training - Epoch   3, Step:    14200, Batch Loss:     1.595764, Batch Acc: 0.519442, Tokens per Sec:     9257, Lr: 0.000300
2025-05-22 14:52:20,675 - INFO - joeynmt.training - Epoch   3, Step:    14300, Batch Loss:     1.517951, Batch Acc: 0.517772, Tokens per Sec:     9282, Lr: 0.000300
2025-05-22 14:52:27,395 - INFO - joeynmt.training - Epoch   3, Step:    14400, Batch Loss:     1.485554, Batch Acc: 0.513092, Tokens per Sec:    10174, Lr: 0.000300
2025-05-22 14:52:34,384 - INFO - joeynmt.training - Epoch   3, Step:    14500, Batch Loss:     1.576817, Batch Acc: 0.516016, Tokens per Sec:     9394, Lr: 0.000300
2025-05-22 14:52:34,385 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:52:34,385 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:52:42,389 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.55, acc:   0.48, generation: 7.9114[sec], evaluation: 0.0000[sec]
2025-05-22 14:52:42,390 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:52:42,581 - INFO - joeynmt.helpers - delete models/transformer_enit/13500.ckpt
2025-05-22 14:52:42,595 - INFO - joeynmt.training - Example #0
2025-05-22 14:52:42,596 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:52:42,596 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:52:42,596 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', 'had', 'ik', 'een', '<unk>', '.', '</s>']
2025-05-22 14:52:42,597 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:52:42,597 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:52:42,597 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, die voor <unk> drie miljoen jaar <unk> van de <unk> <unk> <unk>, had ik een <unk>.
2025-05-22 14:52:42,597 - INFO - joeynmt.training - Example #1
2025-05-22 14:52:42,597 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:52:42,597 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:52:42,598 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', '<unk>', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:52:42,598 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:52:42,598 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:52:42,599 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg <unk> de <unk> van dit <unk> <unk>, want het is niet de <unk> van de <unk>.
2025-05-22 14:52:42,599 - INFO - joeynmt.training - Example #2
2025-05-22 14:52:42,599 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:52:42,599 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:52:42,599 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:52:42,600 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:52:42,600 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:52:42,600 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 14:52:42,600 - INFO - joeynmt.training - Example #3
2025-05-22 14:52:42,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:52:42,600 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:52:42,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:52:42,601 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:52:42,601 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:52:42,602 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:52:42,602 - INFO - joeynmt.training - Example #4
2025-05-22 14:52:42,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:52:42,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:52:42,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 14:52:42,603 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:52:42,603 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:52:42,603 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> <unk> in de laatste 25 jaar.
2025-05-22 14:52:49,583 - INFO - joeynmt.training - Epoch   3, Step:    14600, Batch Loss:     1.698059, Batch Acc: 0.517114, Tokens per Sec:     9422, Lr: 0.000300
2025-05-22 14:52:56,311 - INFO - joeynmt.training - Epoch   3, Step:    14700, Batch Loss:     1.631963, Batch Acc: 0.515777, Tokens per Sec:     9823, Lr: 0.000300
2025-05-22 14:53:02,413 - INFO - joeynmt.training - Epoch   3, Step:    14800, Batch Loss:     1.609420, Batch Acc: 0.516742, Tokens per Sec:    10973, Lr: 0.000300
2025-05-22 14:53:08,400 - INFO - joeynmt.training - Epoch   3, Step:    14900, Batch Loss:     1.639729, Batch Acc: 0.518199, Tokens per Sec:    10857, Lr: 0.000300
2025-05-22 14:53:14,439 - INFO - joeynmt.training - Epoch   3, Step:    15000, Batch Loss:     1.618941, Batch Acc: 0.515306, Tokens per Sec:    10919, Lr: 0.000300
2025-05-22 14:53:14,440 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:53:14,440 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:53:22,857 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.55, acc:   0.48, generation: 8.3351[sec], evaluation: 0.0000[sec]
2025-05-22 14:53:22,857 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:53:23,002 - INFO - joeynmt.helpers - delete models/transformer_enit/13000.ckpt
2025-05-22 14:53:23,009 - INFO - joeynmt.training - Example #0
2025-05-22 14:53:23,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:53:23,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:53:23,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:53:23,010 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:53:23,010 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:53:23,010 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk> <unk>.
2025-05-22 14:53:23,010 - INFO - joeynmt.training - Example #1
2025-05-22 14:53:23,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:53:23,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:53:23,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'toont', '.', '</s>']
2025-05-22 14:53:23,011 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:53:23,011 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:53:23,011 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet <unk> genoeg de <unk> van dit <unk> <unk>, want het is niet de <unk> van de <unk> toont.
2025-05-22 14:53:23,011 - INFO - joeynmt.training - Example #2
2025-05-22 14:53:23,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:53:23,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:53:23,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:53:23,012 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:53:23,012 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:53:23,012 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 14:53:23,012 - INFO - joeynmt.training - Example #3
2025-05-22 14:53:23,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:53:23,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:53:23,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:53:23,013 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:53:23,013 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:53:23,013 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:53:23,013 - INFO - joeynmt.training - Example #4
2025-05-22 14:53:23,014 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:53:23,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:53:23,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 14:53:23,014 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:53:23,014 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:53:23,015 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> van de laatste 25 jaar.
2025-05-22 14:53:29,235 - INFO - joeynmt.training - Epoch   3, Step:    15100, Batch Loss:     1.573069, Batch Acc: 0.512871, Tokens per Sec:    10015, Lr: 0.000300
2025-05-22 14:53:35,826 - INFO - joeynmt.training - Epoch   3, Step:    15200, Batch Loss:     1.627790, Batch Acc: 0.520935, Tokens per Sec:     9932, Lr: 0.000300
2025-05-22 14:53:42,614 - INFO - joeynmt.training - Epoch   3, Step:    15300, Batch Loss:     1.718498, Batch Acc: 0.516294, Tokens per Sec:     9836, Lr: 0.000300
2025-05-22 14:53:49,490 - INFO - joeynmt.training - Epoch   3, Step:    15400, Batch Loss:     1.476918, Batch Acc: 0.519624, Tokens per Sec:     9449, Lr: 0.000300
2025-05-22 14:53:56,379 - INFO - joeynmt.training - Epoch   3, Step:    15500, Batch Loss:     1.664757, Batch Acc: 0.517102, Tokens per Sec:     9837, Lr: 0.000300
2025-05-22 14:53:56,379 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:53:56,380 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:54:04,437 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.48, acc:   0.49, generation: 7.9736[sec], evaluation: 0.0000[sec]
2025-05-22 14:54:04,437 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:54:04,580 - INFO - joeynmt.helpers - delete models/transformer_enit/12000.ckpt
2025-05-22 14:54:04,591 - INFO - joeynmt.training - Example #0
2025-05-22 14:54:04,592 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:54:04,592 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:54:04,592 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'ongeveer', '40', 'procent', '<unk>', 'is', '.', '</s>']
2025-05-22 14:54:04,592 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:54:04,592 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:54:04,592 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> <unk>, die voor <unk> drie miljoen jaar <unk> de <unk> van de <unk> <unk> <unk> <unk>, ongeveer 40 procent <unk> is.
2025-05-22 14:54:04,592 - INFO - joeynmt.training - Example #1
2025-05-22 14:54:04,593 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:54:04,593 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:54:04,593 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:54:04,593 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:54:04,593 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:54:04,593 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg de <unk> van deze <unk> <unk>, omdat het niet de <unk> van de <unk> <unk>.
2025-05-22 14:54:04,593 - INFO - joeynmt.training - Example #2
2025-05-22 14:54:04,593 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:54:04,593 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:54:04,593 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:54:04,594 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:54:04,594 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:54:04,594 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 14:54:04,594 - INFO - joeynmt.training - Example #3
2025-05-22 14:54:04,594 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:54:04,594 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:54:04,594 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:54:04,594 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:54:04,594 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:54:04,594 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:54:04,594 - INFO - joeynmt.training - Example #4
2025-05-22 14:54:04,594 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:54:04,594 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:54:04,594 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'zal', 'laten', 'zien', ',', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', 'gebeurt', '.', '</s>']
2025-05-22 14:54:04,596 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:54:04,596 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:54:04,596 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie zal laten zien, is een <unk> in de laatste 25 jaar gebeurt.
2025-05-22 14:54:11,229 - INFO - joeynmt.training - Epoch   3, Step:    15600, Batch Loss:     1.478019, Batch Acc: 0.516411, Tokens per Sec:     9601, Lr: 0.000300
2025-05-22 14:54:17,593 - INFO - joeynmt.training - Epoch   3, Step:    15700, Batch Loss:     1.725823, Batch Acc: 0.519307, Tokens per Sec:    10227, Lr: 0.000300
2025-05-22 14:54:23,687 - INFO - joeynmt.training - Epoch   3, Step:    15800, Batch Loss:     1.449596, Batch Acc: 0.516441, Tokens per Sec:    11059, Lr: 0.000300
2025-05-22 14:54:29,688 - INFO - joeynmt.training - Epoch   3, Step:    15900, Batch Loss:     1.738588, Batch Acc: 0.516342, Tokens per Sec:    11059, Lr: 0.000300
2025-05-22 14:54:35,832 - INFO - joeynmt.training - Epoch   3, Step:    16000, Batch Loss:     1.639336, Batch Acc: 0.514980, Tokens per Sec:    11098, Lr: 0.000300
2025-05-22 14:54:35,833 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:54:35,833 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:54:42,910 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.54, acc:   0.49, generation: 7.0083[sec], evaluation: 0.0000[sec]
2025-05-22 14:54:43,040 - INFO - joeynmt.helpers - delete models/transformer_enit/12500.ckpt
2025-05-22 14:54:43,050 - INFO - joeynmt.training - Example #0
2025-05-22 14:54:43,050 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:54:43,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:54:43,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', '<unk>', '<unk>', 'had', 'om', '40', 'procent', '<unk>', '.', '</s>']
2025-05-22 14:54:43,051 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:54:43,051 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:54:43,051 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die voor <unk> drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk> <unk>, die voor <unk> <unk> <unk> had om 40 procent <unk>.
2025-05-22 14:54:43,051 - INFO - joeynmt.training - Example #1
2025-05-22 14:54:43,051 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:54:43,051 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:54:43,051 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', '<unk>', ',', 'omdat', 'het', 'niet', '<unk>', 'van', 'het', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:54:43,051 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:54:43,052 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:54:43,052 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg <unk>, omdat het niet <unk> van het <unk> <unk>.
2025-05-22 14:54:43,052 - INFO - joeynmt.training - Example #2
2025-05-22 14:54:43,052 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:54:43,052 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:54:43,052 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:54:43,052 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:54:43,052 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:54:43,052 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 14:54:43,052 - INFO - joeynmt.training - Example #3
2025-05-22 14:54:43,052 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:54:43,052 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:54:43,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', 'zomer', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:54:43,053 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:54:43,053 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:54:43,053 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer en <unk> in de zomer.
2025-05-22 14:54:43,053 - INFO - joeynmt.training - Example #4
2025-05-22 14:54:43,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:54:43,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:54:43,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 14:54:43,054 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:54:43,054 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:54:43,054 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> van wat er in de laatste 25 jaar is gebeurd.
2025-05-22 14:54:49,328 - INFO - joeynmt.training - Epoch   3, Step:    16100, Batch Loss:     1.681444, Batch Acc: 0.518577, Tokens per Sec:    10487, Lr: 0.000300
2025-05-22 14:54:56,108 - INFO - joeynmt.training - Epoch   3, Step:    16200, Batch Loss:     1.695704, Batch Acc: 0.516272, Tokens per Sec:     9576, Lr: 0.000300
2025-05-22 14:55:02,866 - INFO - joeynmt.training - Epoch   3, Step:    16300, Batch Loss:     1.869300, Batch Acc: 0.519190, Tokens per Sec:     9941, Lr: 0.000300
2025-05-22 14:55:09,447 - INFO - joeynmt.training - Epoch   3, Step:    16400, Batch Loss:     1.734060, Batch Acc: 0.523982, Tokens per Sec:     9961, Lr: 0.000300
2025-05-22 14:55:16,114 - INFO - joeynmt.training - Epoch   3, Step:    16500, Batch Loss:     1.532589, Batch Acc: 0.519469, Tokens per Sec:     9979, Lr: 0.000300
2025-05-22 14:55:16,115 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:55:16,115 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:55:23,686 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.46, acc:   0.49, generation: 7.4792[sec], evaluation: 0.0000[sec]
2025-05-22 14:55:23,687 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:55:23,845 - INFO - joeynmt.helpers - delete models/transformer_enit/14000.ckpt
2025-05-22 14:55:23,858 - INFO - joeynmt.training - Example #0
2025-05-22 14:55:23,859 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:55:23,859 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:55:23,859 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', 'procent', '.', '</s>']
2025-05-22 14:55:23,860 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:55:23,860 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:55:23,860 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk>, <unk>, <unk> procent.
2025-05-22 14:55:23,860 - INFO - joeynmt.training - Example #1
2025-05-22 14:55:23,860 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:55:23,860 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:55:23,861 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2025-05-22 14:55:23,861 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:55:23,861 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:55:23,862 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg <unk> van dit <unk> <unk>, omdat het niet de <unk> van het <unk>.
2025-05-22 14:55:23,862 - INFO - joeynmt.training - Example #2
2025-05-22 14:55:23,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:55:23,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:55:23,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:55:23,862 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:55:23,863 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:55:23,863 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> van ons <unk> <unk>.
2025-05-22 14:55:23,863 - INFO - joeynmt.training - Example #3
2025-05-22 14:55:23,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:55:23,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:55:23,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:55:23,864 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:55:23,864 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:55:23,864 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:55:23,864 - INFO - joeynmt.training - Example #4
2025-05-22 14:55:23,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:55:23,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:55:23,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:55:23,865 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:55:23,866 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:55:23,866 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> <unk>.
2025-05-22 14:55:30,592 - INFO - joeynmt.training - Epoch   3, Step:    16600, Batch Loss:     1.430449, Batch Acc: 0.522674, Tokens per Sec:     9623, Lr: 0.000300
2025-05-22 14:55:36,994 - INFO - joeynmt.training - Epoch   3, Step:    16700, Batch Loss:     1.609671, Batch Acc: 0.518569, Tokens per Sec:    10348, Lr: 0.000300
2025-05-22 14:55:43,180 - INFO - joeynmt.training - Epoch   3, Step:    16800, Batch Loss:     1.519342, Batch Acc: 0.514695, Tokens per Sec:    10552, Lr: 0.000300
2025-05-22 14:55:49,254 - INFO - joeynmt.training - Epoch   3, Step:    16900, Batch Loss:     1.457558, Batch Acc: 0.521104, Tokens per Sec:    10903, Lr: 0.000300
2025-05-22 14:55:55,367 - INFO - joeynmt.training - Epoch   3, Step:    17000, Batch Loss:     1.501564, Batch Acc: 0.520499, Tokens per Sec:    10640, Lr: 0.000300
2025-05-22 14:55:55,368 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:55:55,368 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:56:02,975 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.46, acc:   0.49, generation: 7.5349[sec], evaluation: 0.0000[sec]
2025-05-22 14:56:02,976 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:56:03,132 - INFO - joeynmt.helpers - delete models/transformer_enit/14500.ckpt
2025-05-22 14:56:03,142 - INFO - joeynmt.training - Example #0
2025-05-22 14:56:03,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:56:03,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:56:03,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 14:56:03,143 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:56:03,143 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:56:03,143 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> <unk> <unk> <unk>.
2025-05-22 14:56:03,143 - INFO - joeynmt.training - Example #1
2025-05-22 14:56:03,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:56:03,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:56:03,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'is', 'dat', 'het', '<unk>', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'toont', '.', '</s>']
2025-05-22 14:56:03,144 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:56:03,144 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:56:03,144 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg is dat het <unk> <unk> <unk>, omdat het niet de <unk> van de <unk> toont.
2025-05-22 14:56:03,145 - INFO - joeynmt.training - Example #2
2025-05-22 14:56:03,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:56:03,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:56:03,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 14:56:03,145 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:56:03,145 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:56:03,146 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 14:56:03,146 - INFO - joeynmt.training - Example #3
2025-05-22 14:56:03,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:56:03,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:56:03,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:56:03,146 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:56:03,147 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:56:03,147 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:56:03,147 - INFO - joeynmt.training - Example #4
2025-05-22 14:56:03,147 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:56:03,147 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:56:03,147 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'gebeurt', '.', '</s>']
2025-05-22 14:56:03,147 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:56:03,148 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:56:03,148 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> wat er in de afgelopen 25 jaar gebeurt.
2025-05-22 14:56:09,854 - INFO - joeynmt.training - Epoch   3, Step:    17100, Batch Loss:     1.475500, Batch Acc: 0.520036, Tokens per Sec:     9308, Lr: 0.000300
2025-05-22 14:56:16,840 - INFO - joeynmt.training - Epoch   3, Step:    17200, Batch Loss:     1.679561, Batch Acc: 0.515906, Tokens per Sec:     9671, Lr: 0.000300
2025-05-22 14:56:23,632 - INFO - joeynmt.training - Epoch   3, Step:    17300, Batch Loss:     1.563666, Batch Acc: 0.523278, Tokens per Sec:     9969, Lr: 0.000300
2025-05-22 14:56:30,260 - INFO - joeynmt.training - Epoch   3, Step:    17400, Batch Loss:     1.657348, Batch Acc: 0.525195, Tokens per Sec:    10202, Lr: 0.000300
2025-05-22 14:56:37,007 - INFO - joeynmt.training - Epoch   3, Step:    17500, Batch Loss:     1.505377, Batch Acc: 0.517493, Tokens per Sec:     9529, Lr: 0.000300
2025-05-22 14:56:37,007 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:56:37,007 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:56:45,207 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.44, acc:   0.49, generation: 8.1095[sec], evaluation: 0.0000[sec]
2025-05-22 14:56:45,208 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:56:45,343 - INFO - joeynmt.helpers - delete models/transformer_enit/15000.ckpt
2025-05-22 14:56:45,356 - INFO - joeynmt.training - Example #0
2025-05-22 14:56:45,357 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:56:45,357 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:56:45,357 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'om', '40', 'procent', '<unk>', 'te', 'zijn', '.', '</s>']
2025-05-22 14:56:45,358 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:56:45,358 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:56:45,358 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die voor <unk> drie miljoen jaar <unk> <unk> <unk> <unk>, om 40 procent <unk> te zijn.
2025-05-22 14:56:45,358 - INFO - joeynmt.training - Example #1
2025-05-22 14:56:45,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:56:45,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:56:45,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', 'genoeg', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2025-05-22 14:56:45,359 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:56:45,359 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:56:45,359 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet sterk genoeg <unk> genoeg <unk> van deze <unk> <unk>, omdat het niet de <unk> van het <unk>.
2025-05-22 14:56:45,359 - INFO - joeynmt.training - Example #2
2025-05-22 14:56:45,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:56:45,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:56:45,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 14:56:45,360 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:56:45,360 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:56:45,360 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 14:56:45,360 - INFO - joeynmt.training - Example #3
2025-05-22 14:56:45,361 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:56:45,361 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:56:45,361 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', 'zomer', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:56:45,361 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:56:45,361 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:56:45,361 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer en <unk> in de zomer.
2025-05-22 14:56:45,362 - INFO - joeynmt.training - Example #4
2025-05-22 14:56:45,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:56:45,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:56:45,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 14:56:45,362 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:56:45,362 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:56:45,363 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> van de afgelopen 25 jaar.
2025-05-22 14:56:52,010 - INFO - joeynmt.training - Epoch   3, Step:    17600, Batch Loss:     1.506723, Batch Acc: 0.514213, Tokens per Sec:     9573, Lr: 0.000300
2025-05-22 14:56:58,386 - INFO - joeynmt.training - Epoch   3, Step:    17700, Batch Loss:     1.536159, Batch Acc: 0.522271, Tokens per Sec:    10442, Lr: 0.000300
2025-05-22 14:57:04,781 - INFO - joeynmt.training - Epoch   3, Step:    17800, Batch Loss:     1.577886, Batch Acc: 0.521586, Tokens per Sec:    10280, Lr: 0.000300
2025-05-22 14:57:05,660 - INFO - joeynmt.training - Epoch   3: total training loss 9459.75
2025-05-22 14:57:05,661 - INFO - joeynmt.training - EPOCH 4
2025-05-22 14:57:10,920 - INFO - joeynmt.training - Epoch   4, Step:    17900, Batch Loss:     1.513869, Batch Acc: 0.536515, Tokens per Sec:    10838, Lr: 0.000300
2025-05-22 14:57:17,036 - INFO - joeynmt.training - Epoch   4, Step:    18000, Batch Loss:     1.580446, Batch Acc: 0.535242, Tokens per Sec:    10953, Lr: 0.000300
2025-05-22 14:57:17,036 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:57:17,036 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:57:24,042 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.43, acc:   0.49, generation: 6.9390[sec], evaluation: 0.0000[sec]
2025-05-22 14:57:24,043 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:57:24,218 - INFO - joeynmt.helpers - delete models/transformer_enit/16000.ckpt
2025-05-22 14:57:24,229 - INFO - joeynmt.training - Example #0
2025-05-22 14:57:24,229 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:57:24,229 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:57:24,229 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', 'landen', ',', 'met', '40', 'procent', '.', '</s>']
2025-05-22 14:57:24,230 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:57:24,230 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:57:24,230 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien dat de <unk> <unk> die voor <unk> drie miljoen jaar <unk> <unk> van de <unk> landen, met 40 procent.
2025-05-22 14:57:24,230 - INFO - joeynmt.training - Example #1
2025-05-22 14:57:24,230 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:57:24,230 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:57:24,231 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:57:24,231 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:57:24,231 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:57:24,231 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg de <unk> van dit <unk> <unk>, want het is niet de <unk> van de <unk>.
2025-05-22 14:57:24,231 - INFO - joeynmt.training - Example #2
2025-05-22 14:57:24,231 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:57:24,231 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:57:24,233 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'onze', '<unk>', '.', '</s>']
2025-05-22 14:57:24,233 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:57:24,233 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:57:24,233 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van onze <unk>.
2025-05-22 14:57:24,233 - INFO - joeynmt.training - Example #3
2025-05-22 14:57:24,233 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:57:24,234 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:57:24,234 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', 'zomer', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:57:24,234 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:57:24,234 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:57:24,234 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer en <unk> in de zomer.
2025-05-22 14:57:24,234 - INFO - joeynmt.training - Example #4
2025-05-22 14:57:24,235 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:57:24,235 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:57:24,235 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 14:57:24,236 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:57:24,236 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:57:24,236 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> van wat er in de afgelopen 25 jaar is.
2025-05-22 14:57:30,764 - INFO - joeynmt.training - Epoch   4, Step:    18100, Batch Loss:     1.475260, Batch Acc: 0.532666, Tokens per Sec:    10028, Lr: 0.000300
2025-05-22 14:57:37,700 - INFO - joeynmt.training - Epoch   4, Step:    18200, Batch Loss:     1.532307, Batch Acc: 0.531147, Tokens per Sec:     9624, Lr: 0.000300
2025-05-22 14:57:45,156 - INFO - joeynmt.training - Epoch   4, Step:    18300, Batch Loss:     1.523499, Batch Acc: 0.532646, Tokens per Sec:     8814, Lr: 0.000300
2025-05-22 14:57:52,558 - INFO - joeynmt.training - Epoch   4, Step:    18400, Batch Loss:     1.573491, Batch Acc: 0.529132, Tokens per Sec:     9056, Lr: 0.000300
2025-05-22 14:57:59,688 - INFO - joeynmt.training - Epoch   4, Step:    18500, Batch Loss:     1.513785, Batch Acc: 0.529755, Tokens per Sec:     8767, Lr: 0.000300
2025-05-22 14:57:59,689 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:57:59,689 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:58:08,142 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.43, acc:   0.49, generation: 8.3744[sec], evaluation: 0.0000[sec]
2025-05-22 14:58:08,292 - INFO - joeynmt.helpers - delete models/transformer_enit/15500.ckpt
2025-05-22 14:58:08,303 - INFO - joeynmt.training - Example #0
2025-05-22 14:58:08,304 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:58:08,304 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:58:08,304 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', 'staten', 'had', '<unk>', '.', '</s>']
2025-05-22 14:58:08,304 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:58:08,304 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:58:08,305 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die voor <unk> drie miljoen jaar <unk> <unk> van de <unk> staten had <unk>.
2025-05-22 14:58:08,305 - INFO - joeynmt.training - Example #1
2025-05-22 14:58:08,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:58:08,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:58:08,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:58:08,306 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:58:08,306 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:58:08,306 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg <unk> van deze <unk> <unk>, omdat het niet de <unk> van de <unk> van de <unk>.
2025-05-22 14:58:08,306 - INFO - joeynmt.training - Example #2
2025-05-22 14:58:08,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:58:08,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:58:08,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'onze', '<unk>', '.', '</s>']
2025-05-22 14:58:08,307 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:58:08,308 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:58:08,308 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van onze <unk>.
2025-05-22 14:58:08,308 - INFO - joeynmt.training - Example #3
2025-05-22 14:58:08,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:58:08,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:58:08,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:58:08,309 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:58:08,309 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:58:08,309 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 14:58:08,309 - INFO - joeynmt.training - Example #4
2025-05-22 14:58:08,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:58:08,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:58:08,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 14:58:08,310 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:58:08,310 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:58:08,310 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> van de laatste 25 jaar.
2025-05-22 14:58:15,023 - INFO - joeynmt.training - Epoch   4, Step:    18600, Batch Loss:     1.457702, Batch Acc: 0.530242, Tokens per Sec:     9593, Lr: 0.000300
2025-05-22 14:58:21,308 - INFO - joeynmt.training - Epoch   4, Step:    18700, Batch Loss:     1.723009, Batch Acc: 0.528440, Tokens per Sec:    10587, Lr: 0.000300
2025-05-22 14:58:27,257 - INFO - joeynmt.training - Epoch   4, Step:    18800, Batch Loss:     1.567936, Batch Acc: 0.532864, Tokens per Sec:    11120, Lr: 0.000300
2025-05-22 14:58:33,307 - INFO - joeynmt.training - Epoch   4, Step:    18900, Batch Loss:     1.444008, Batch Acc: 0.528666, Tokens per Sec:    10829, Lr: 0.000300
2025-05-22 14:58:39,259 - INFO - joeynmt.training - Epoch   4, Step:    19000, Batch Loss:     1.403738, Batch Acc: 0.529940, Tokens per Sec:    11447, Lr: 0.000300
2025-05-22 14:58:39,259 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:58:39,259 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:58:45,734 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.41, acc:   0.49, generation: 6.4024[sec], evaluation: 0.0000[sec]
2025-05-22 14:58:45,735 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 14:58:45,880 - INFO - joeynmt.helpers - delete models/transformer_enit/16500.ckpt
2025-05-22 14:58:45,891 - INFO - joeynmt.training - Example #0
2025-05-22 14:58:45,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:58:45,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:58:45,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', 'staten', 'had', '<unk>', 'om', '40', 'procent', '<unk>', 'te', 'zijn', '.', '</s>']
2025-05-22 14:58:45,891 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:58:45,892 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:58:45,892 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> <unk> van de <unk> staten had <unk> om 40 procent <unk> te zijn.
2025-05-22 14:58:45,892 - INFO - joeynmt.training - Example #1
2025-05-22 14:58:45,892 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:58:45,892 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:58:45,892 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'om', 'deze', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', 'is', '.', '</s>']
2025-05-22 14:58:45,892 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:58:45,892 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:58:45,892 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg om deze <unk> te <unk>, omdat het niet de <unk> van het <unk> is.
2025-05-22 14:58:45,892 - INFO - joeynmt.training - Example #2
2025-05-22 14:58:45,892 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:58:45,892 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:58:45,892 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 14:58:45,893 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:58:45,893 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:58:45,893 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons mondiale <unk>.
2025-05-22 14:58:45,893 - INFO - joeynmt.training - Example #3
2025-05-22 14:58:45,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:58:45,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:58:45,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:58:45,893 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:58:45,893 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:58:45,894 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2025-05-22 14:58:45,894 - INFO - joeynmt.training - Example #4
2025-05-22 14:58:45,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:58:45,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:58:45,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 14:58:45,894 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:58:45,894 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:58:45,894 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> in de afgelopen 25 jaar.
2025-05-22 14:58:52,395 - INFO - joeynmt.training - Epoch   4, Step:    19100, Batch Loss:     1.469358, Batch Acc: 0.524816, Tokens per Sec:    10045, Lr: 0.000300
2025-05-22 14:58:59,069 - INFO - joeynmt.training - Epoch   4, Step:    19200, Batch Loss:     1.575958, Batch Acc: 0.527855, Tokens per Sec:     9871, Lr: 0.000300
2025-05-22 14:59:05,748 - INFO - joeynmt.training - Epoch   4, Step:    19300, Batch Loss:     1.538157, Batch Acc: 0.533989, Tokens per Sec:     9873, Lr: 0.000300
2025-05-22 14:59:12,605 - INFO - joeynmt.training - Epoch   4, Step:    19400, Batch Loss:     1.650154, Batch Acc: 0.530512, Tokens per Sec:     9877, Lr: 0.000300
2025-05-22 14:59:19,223 - INFO - joeynmt.training - Epoch   4, Step:    19500, Batch Loss:     1.719769, Batch Acc: 0.530782, Tokens per Sec:    10110, Lr: 0.000300
2025-05-22 14:59:19,224 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:59:19,224 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 14:59:27,564 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.42, acc:   0.49, generation: 8.2617[sec], evaluation: 0.0000[sec]
2025-05-22 14:59:27,704 - INFO - joeynmt.helpers - delete models/transformer_enit/17000.ckpt
2025-05-22 14:59:27,715 - INFO - joeynmt.training - Example #0
2025-05-22 14:59:27,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 14:59:27,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 14:59:27,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', ',', '40', 'procent', '<unk>', 'is', '.', '</s>']
2025-05-22 14:59:27,716 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 14:59:27,716 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 14:59:27,716 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> <unk>, <unk>, <unk>, 40 procent <unk> is.
2025-05-22 14:59:27,716 - INFO - joeynmt.training - Example #1
2025-05-22 14:59:27,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 14:59:27,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 14:59:27,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', '<unk>', 'om', 'dit', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 14:59:27,717 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 14:59:27,717 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 14:59:27,717 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg <unk> om dit <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 14:59:27,717 - INFO - joeynmt.training - Example #2
2025-05-22 14:59:27,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 14:59:27,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 14:59:27,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 14:59:27,718 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 14:59:27,718 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 14:59:27,718 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het hart van ons wereldwijde <unk>.
2025-05-22 14:59:27,718 - INFO - joeynmt.training - Example #3
2025-05-22 14:59:27,718 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 14:59:27,718 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 14:59:27,718 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 14:59:27,718 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 14:59:27,719 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 14:59:27,719 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2025-05-22 14:59:27,719 - INFO - joeynmt.training - Example #4
2025-05-22 14:59:27,719 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 14:59:27,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 14:59:27,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 14:59:27,719 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 14:59:27,719 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 14:59:27,719 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> wat er in de laatste 25 jaar is.
2025-05-22 14:59:34,500 - INFO - joeynmt.training - Epoch   4, Step:    19600, Batch Loss:     1.475426, Batch Acc: 0.530539, Tokens per Sec:     9332, Lr: 0.000300
2025-05-22 14:59:40,960 - INFO - joeynmt.training - Epoch   4, Step:    19700, Batch Loss:     1.530677, Batch Acc: 0.529512, Tokens per Sec:    10014, Lr: 0.000300
2025-05-22 14:59:47,427 - INFO - joeynmt.training - Epoch   4, Step:    19800, Batch Loss:     1.606360, Batch Acc: 0.526383, Tokens per Sec:    10314, Lr: 0.000300
2025-05-22 14:59:53,557 - INFO - joeynmt.training - Epoch   4, Step:    19900, Batch Loss:     1.510683, Batch Acc: 0.532392, Tokens per Sec:    10944, Lr: 0.000300
2025-05-22 14:59:59,691 - INFO - joeynmt.training - Epoch   4, Step:    20000, Batch Loss:     1.535131, Batch Acc: 0.525662, Tokens per Sec:    11038, Lr: 0.000300
2025-05-22 14:59:59,691 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 14:59:59,691 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:00:06,905 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.40, acc:   0.49, generation: 7.1381[sec], evaluation: 0.0000[sec]
2025-05-22 15:00:06,906 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:00:07,068 - INFO - joeynmt.helpers - delete models/transformer_enit/17500.ckpt
2025-05-22 15:00:07,079 - INFO - joeynmt.training - Example #0
2025-05-22 15:00:07,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:00:07,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:00:07,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', ',', '40', 'procent', '<unk>', '.', '</s>']
2025-05-22 15:00:07,080 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:00:07,080 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:00:07,080 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die <unk> <unk> <unk> <unk> <unk>, <unk>, <unk>, 40 procent <unk>.
2025-05-22 15:00:07,080 - INFO - joeynmt.training - Example #1
2025-05-22 15:00:07,080 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:00:07,080 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:00:07,080 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', '<unk>', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2025-05-22 15:00:07,080 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:00:07,081 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:00:07,081 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg <unk> om dit <unk> <unk> te <unk>, want het is niet de <unk> van het <unk>.
2025-05-22 15:00:07,081 - INFO - joeynmt.training - Example #2
2025-05-22 15:00:07,081 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:00:07,081 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:00:07,081 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:00:07,082 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:00:07,082 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:00:07,082 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:00:07,082 - INFO - joeynmt.training - Example #3
2025-05-22 15:00:07,082 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:00:07,082 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:00:07,082 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:00:07,083 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:00:07,083 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:00:07,083 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2025-05-22 15:00:07,083 - INFO - joeynmt.training - Example #4
2025-05-22 15:00:07,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:00:07,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:00:07,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 15:00:07,083 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:00:07,083 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:00:07,084 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> <unk> wat er in de afgelopen 25 jaar is.
2025-05-22 15:00:13,761 - INFO - joeynmt.training - Epoch   4, Step:    20100, Batch Loss:     1.557753, Batch Acc: 0.524466, Tokens per Sec:     9573, Lr: 0.000300
2025-05-22 15:00:20,377 - INFO - joeynmt.training - Epoch   4, Step:    20200, Batch Loss:     1.571063, Batch Acc: 0.527486, Tokens per Sec:     9956, Lr: 0.000300
2025-05-22 15:00:27,362 - INFO - joeynmt.training - Epoch   4, Step:    20300, Batch Loss:     1.747132, Batch Acc: 0.527327, Tokens per Sec:     9517, Lr: 0.000300
2025-05-22 15:00:34,007 - INFO - joeynmt.training - Epoch   4, Step:    20400, Batch Loss:     1.660413, Batch Acc: 0.530491, Tokens per Sec:    10006, Lr: 0.000300
2025-05-22 15:00:40,708 - INFO - joeynmt.training - Epoch   4, Step:    20500, Batch Loss:     1.560319, Batch Acc: 0.527135, Tokens per Sec:     9656, Lr: 0.000300
2025-05-22 15:00:40,709 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:00:40,709 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:00:48,930 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.44, acc:   0.49, generation: 8.1349[sec], evaluation: 0.0000[sec]
2025-05-22 15:00:48,937 - INFO - joeynmt.training - Example #0
2025-05-22 15:00:48,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:00:48,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:00:48,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', ',', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', 'met', '40', 'procent', '<unk>', 'is', '.', '</s>']
2025-05-22 15:00:48,939 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:00:48,939 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:00:48,939 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die voor <unk> <unk>, drie miljoen jaar, de <unk> van de <unk> <unk> <unk>, met 40 procent <unk> is.
2025-05-22 15:00:48,939 - INFO - joeynmt.training - Example #1
2025-05-22 15:00:48,940 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:00:48,940 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:00:48,940 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:00:48,940 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:00:48,941 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:00:48,941 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg de <unk> van deze <unk> <unk>, omdat het niet de <unk> van de <unk> van de <unk>.
2025-05-22 15:00:48,941 - INFO - joeynmt.training - Example #2
2025-05-22 15:00:48,941 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:00:48,941 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:00:48,941 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', '<unk>', 'de', '<unk>', '<unk>', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:00:48,942 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:00:48,942 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:00:48,942 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> <unk> de <unk> <unk> van ons <unk>.
2025-05-22 15:00:48,942 - INFO - joeynmt.training - Example #3
2025-05-22 15:00:48,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:00:48,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:00:48,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:00:48,943 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:00:48,943 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:00:48,944 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:00:48,944 - INFO - joeynmt.training - Example #4
2025-05-22 15:00:48,944 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:00:48,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:00:48,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 15:00:48,944 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:00:48,944 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:00:48,944 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie jullie laat zien is een <unk> wat er in de laatste 25 jaar is.
2025-05-22 15:00:55,768 - INFO - joeynmt.training - Epoch   4, Step:    20600, Batch Loss:     1.463252, Batch Acc: 0.529154, Tokens per Sec:     9655, Lr: 0.000300
2025-05-22 15:01:02,104 - INFO - joeynmt.training - Epoch   4, Step:    20700, Batch Loss:     1.652175, Batch Acc: 0.527817, Tokens per Sec:    10215, Lr: 0.000300
2025-05-22 15:01:08,192 - INFO - joeynmt.training - Epoch   4, Step:    20800, Batch Loss:     1.681561, Batch Acc: 0.527342, Tokens per Sec:    11015, Lr: 0.000300
2025-05-22 15:01:14,390 - INFO - joeynmt.training - Epoch   4, Step:    20900, Batch Loss:     1.564768, Batch Acc: 0.526816, Tokens per Sec:    10636, Lr: 0.000300
2025-05-22 15:01:20,469 - INFO - joeynmt.training - Epoch   4, Step:    21000, Batch Loss:     1.598100, Batch Acc: 0.525493, Tokens per Sec:    10644, Lr: 0.000300
2025-05-22 15:01:20,469 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:01:20,469 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:01:27,886 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.40, acc:   0.49, generation: 7.3463[sec], evaluation: 0.0000[sec]
2025-05-22 15:01:27,887 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:01:28,070 - INFO - joeynmt.helpers - delete models/transformer_enit/18500.ckpt
2025-05-22 15:01:28,084 - INFO - joeynmt.training - Example #0
2025-05-22 15:01:28,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:01:28,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:01:28,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', 'staten', ',', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2025-05-22 15:01:28,085 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:01:28,085 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:01:28,085 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die voor <unk> drie miljoen jaar <unk> <unk> van de <unk> staten, om 40 procent te <unk>.
2025-05-22 15:01:28,085 - INFO - joeynmt.training - Example #1
2025-05-22 15:01:28,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:01:28,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:01:28,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:01:28,086 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:01:28,086 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:01:28,086 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:01:28,086 - INFO - joeynmt.training - Example #2
2025-05-22 15:01:28,086 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:01:28,086 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:01:28,086 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:01:28,087 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:01:28,087 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:01:28,087 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> van ons wereldwijde <unk>.
2025-05-22 15:01:28,087 - INFO - joeynmt.training - Example #3
2025-05-22 15:01:28,087 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:01:28,087 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:01:28,087 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:01:28,087 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:01:28,088 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:01:28,088 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:01:28,088 - INFO - joeynmt.training - Example #4
2025-05-22 15:01:28,088 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:01:28,088 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:01:28,088 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 15:01:28,089 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:01:28,089 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:01:28,089 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> van de laatste 25 jaar is gebeurd.
2025-05-22 15:01:34,972 - INFO - joeynmt.training - Epoch   4, Step:    21100, Batch Loss:     1.499386, Batch Acc: 0.528843, Tokens per Sec:     9215, Lr: 0.000300
2025-05-22 15:01:41,675 - INFO - joeynmt.training - Epoch   4, Step:    21200, Batch Loss:     1.485628, Batch Acc: 0.528083, Tokens per Sec:     9874, Lr: 0.000300
2025-05-22 15:01:48,392 - INFO - joeynmt.training - Epoch   4, Step:    21300, Batch Loss:     1.568250, Batch Acc: 0.529714, Tokens per Sec:     9996, Lr: 0.000300
2025-05-22 15:01:55,825 - INFO - joeynmt.training - Epoch   4, Step:    21400, Batch Loss:     1.777050, Batch Acc: 0.529131, Tokens per Sec:     9034, Lr: 0.000300
2025-05-22 15:02:03,034 - INFO - joeynmt.training - Epoch   4, Step:    21500, Batch Loss:     1.372060, Batch Acc: 0.525565, Tokens per Sec:     9259, Lr: 0.000300
2025-05-22 15:02:03,034 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:02:03,034 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:02:10,812 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.31, acc:   0.49, generation: 7.6975[sec], evaluation: 0.0000[sec]
2025-05-22 15:02:10,813 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:02:10,954 - INFO - joeynmt.helpers - delete models/transformer_enit/18000.ckpt
2025-05-22 15:02:10,964 - INFO - joeynmt.training - Example #0
2025-05-22 15:02:10,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:02:10,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:02:10,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', 'met', '40', 'procent', '.', '</s>']
2025-05-22 15:02:10,965 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:02:10,965 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:02:10,965 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk>, <unk> <unk> met 40 procent.
2025-05-22 15:02:10,965 - INFO - joeynmt.training - Example #1
2025-05-22 15:02:10,965 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:02:10,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:02:10,966 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', 'is', 'dat', 'het', '<unk>', '<unk>', ',', 'want', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:02:10,966 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:02:10,966 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:02:10,966 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg is dat het <unk> <unk>, want het niet de <unk> van de <unk>.
2025-05-22 15:02:10,966 - INFO - joeynmt.training - Example #2
2025-05-22 15:02:10,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:02:10,966 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:02:10,966 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:02:10,967 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:02:10,967 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:02:10,967 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:02:10,967 - INFO - joeynmt.training - Example #3
2025-05-22 15:02:10,967 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:02:10,967 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:02:10,967 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:02:10,968 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:02:10,968 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:02:10,968 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:02:10,968 - INFO - joeynmt.training - Example #4
2025-05-22 15:02:10,968 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:02:10,968 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:02:10,968 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:02:10,969 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:02:10,969 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:02:10,969 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> <unk> in de laatste 25 jaar.
2025-05-22 15:02:17,928 - INFO - joeynmt.training - Epoch   4, Step:    21600, Batch Loss:     1.535184, Batch Acc: 0.528330, Tokens per Sec:     9115, Lr: 0.000300
2025-05-22 15:02:24,467 - INFO - joeynmt.training - Epoch   4, Step:    21700, Batch Loss:     1.486238, Batch Acc: 0.529737, Tokens per Sec:     9892, Lr: 0.000300
2025-05-22 15:02:30,852 - INFO - joeynmt.training - Epoch   4, Step:    21800, Batch Loss:     1.475504, Batch Acc: 0.529276, Tokens per Sec:    10388, Lr: 0.000300
2025-05-22 15:02:37,109 - INFO - joeynmt.training - Epoch   4, Step:    21900, Batch Loss:     1.709098, Batch Acc: 0.529226, Tokens per Sec:    10475, Lr: 0.000300
2025-05-22 15:02:43,136 - INFO - joeynmt.training - Epoch   4, Step:    22000, Batch Loss:     1.545911, Batch Acc: 0.524875, Tokens per Sec:    11172, Lr: 0.000300
2025-05-22 15:02:43,137 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:02:43,137 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:02:50,860 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.32, acc:   0.49, generation: 7.6422[sec], evaluation: 0.0000[sec]
2025-05-22 15:02:50,997 - INFO - joeynmt.helpers - delete models/transformer_enit/19500.ckpt
2025-05-22 15:02:51,009 - INFO - joeynmt.training - Example #0
2025-05-22 15:02:51,009 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:02:51,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:02:51,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', 'had', '<unk>', '.', '</s>']
2025-05-22 15:02:51,010 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:02:51,010 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:02:51,010 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk>, had <unk>.
2025-05-22 15:02:51,010 - INFO - joeynmt.training - Example #1
2025-05-22 15:02:51,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:02:51,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:02:51,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', '<unk>', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:02:51,011 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:02:51,011 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:02:51,011 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet <unk> genoeg om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk> van de <unk>.
2025-05-22 15:02:51,011 - INFO - joeynmt.training - Example #2
2025-05-22 15:02:51,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:02:51,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:02:51,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'onze', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:02:51,011 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:02:51,011 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:02:51,012 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van onze wereldwijde <unk>.
2025-05-22 15:02:51,012 - INFO - joeynmt.training - Example #3
2025-05-22 15:02:51,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:02:51,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:02:51,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:02:51,012 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:02:51,012 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:02:51,012 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:02:51,012 - INFO - joeynmt.training - Example #4
2025-05-22 15:02:51,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:02:51,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:02:51,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 15:02:51,013 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:02:51,013 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:02:51,013 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> in de afgelopen 25 jaar.
2025-05-22 15:02:57,800 - INFO - joeynmt.training - Epoch   4, Step:    22100, Batch Loss:     1.552926, Batch Acc: 0.531044, Tokens per Sec:     9707, Lr: 0.000300
2025-05-22 15:03:04,843 - INFO - joeynmt.training - Epoch   4, Step:    22200, Batch Loss:     1.587417, Batch Acc: 0.527568, Tokens per Sec:     9014, Lr: 0.000300
2025-05-22 15:03:11,430 - INFO - joeynmt.training - Epoch   4, Step:    22300, Batch Loss:     1.552859, Batch Acc: 0.529165, Tokens per Sec:     9848, Lr: 0.000300
2025-05-22 15:03:18,183 - INFO - joeynmt.training - Epoch   4, Step:    22400, Batch Loss:     1.544165, Batch Acc: 0.527357, Tokens per Sec:     9793, Lr: 0.000300
2025-05-22 15:03:24,794 - INFO - joeynmt.training - Epoch   4, Step:    22500, Batch Loss:     1.554723, Batch Acc: 0.528070, Tokens per Sec:    10168, Lr: 0.000300
2025-05-22 15:03:24,795 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:03:24,795 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:03:32,978 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.32, acc:   0.50, generation: 8.1064[sec], evaluation: 0.0000[sec]
2025-05-22 15:03:33,116 - INFO - joeynmt.helpers - delete models/transformer_enit/19000.ckpt
2025-05-22 15:03:33,127 - INFO - joeynmt.training - Example #0
2025-05-22 15:03:33,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:03:33,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:03:33,128 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', ',', 'de', '<unk>', '<unk>', '<unk>', 'staten', ',', '<unk>', '<unk>', ',', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2025-05-22 15:03:33,128 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:03:33,128 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:03:33,128 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, de <unk> <unk>, de <unk> <unk> <unk> staten, <unk> <unk>, om 40 procent te <unk>.
2025-05-22 15:03:33,129 - INFO - joeynmt.training - Example #1
2025-05-22 15:03:33,129 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:03:33,129 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:03:33,129 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', '<unk>', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:03:33,129 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:03:33,129 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:03:33,129 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo <unk> genoeg om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:03:33,129 - INFO - joeynmt.training - Example #2
2025-05-22 15:03:33,129 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:03:33,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:03:33,130 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'van', 'ons', '<unk>', 'hart', '.', '</s>']
2025-05-22 15:03:33,130 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:03:33,130 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:03:33,130 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> van ons <unk> hart.
2025-05-22 15:03:33,130 - INFO - joeynmt.training - Example #3
2025-05-22 15:03:33,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:03:33,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:03:33,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:03:33,131 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:03:33,131 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:03:33,131 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:03:33,131 - INFO - joeynmt.training - Example #4
2025-05-22 15:03:33,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:03:33,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:03:33,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:03:33,132 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:03:33,132 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:03:33,132 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:03:39,482 - INFO - joeynmt.training - Epoch   4, Step:    22600, Batch Loss:     1.402738, Batch Acc: 0.531787, Tokens per Sec:    10304, Lr: 0.000300
2025-05-22 15:03:45,803 - INFO - joeynmt.training - Epoch   4, Step:    22700, Batch Loss:     1.425242, Batch Acc: 0.524981, Tokens per Sec:    10578, Lr: 0.000300
2025-05-22 15:03:51,988 - INFO - joeynmt.training - Epoch   4, Step:    22800, Batch Loss:     1.429035, Batch Acc: 0.531161, Tokens per Sec:    10553, Lr: 0.000300
2025-05-22 15:03:58,245 - INFO - joeynmt.training - Epoch   4, Step:    22900, Batch Loss:     1.499201, Batch Acc: 0.524596, Tokens per Sec:    10497, Lr: 0.000300
2025-05-22 15:04:04,540 - INFO - joeynmt.training - Epoch   4, Step:    23000, Batch Loss:     1.593415, Batch Acc: 0.529841, Tokens per Sec:    10612, Lr: 0.000300
2025-05-22 15:04:04,540 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:04:04,540 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:04:11,923 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.30, acc:   0.49, generation: 7.3041[sec], evaluation: 0.0000[sec]
2025-05-22 15:04:11,924 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:04:12,066 - INFO - joeynmt.helpers - delete models/transformer_enit/20000.ckpt
2025-05-22 15:04:12,078 - INFO - joeynmt.training - Example #0
2025-05-22 15:04:12,078 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:04:12,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:04:12,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', ',', '<unk>', ',', 'met', '40', 'procent', '.', '</s>']
2025-05-22 15:04:12,079 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:04:12,079 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:04:12,079 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk> <unk> <unk>, <unk> <unk>, <unk> <unk>, <unk>, <unk>, met 40 procent.
2025-05-22 15:04:12,080 - INFO - joeynmt.training - Example #1
2025-05-22 15:04:12,080 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:04:12,080 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:04:12,080 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:04:12,081 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:04:12,081 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:04:12,081 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg <unk> genoeg de <unk> van deze <unk> <unk>, want het is niet de <unk> van de <unk>.
2025-05-22 15:04:12,081 - INFO - joeynmt.training - Example #2
2025-05-22 15:04:12,081 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:04:12,082 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:04:12,082 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:04:12,082 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:04:12,082 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:04:12,082 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> van ons <unk> <unk>.
2025-05-22 15:04:12,082 - INFO - joeynmt.training - Example #3
2025-05-22 15:04:12,082 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:04:12,082 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:04:12,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:04:12,083 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:04:12,083 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:04:12,083 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2025-05-22 15:04:12,083 - INFO - joeynmt.training - Example #4
2025-05-22 15:04:12,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:04:12,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:04:12,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:04:12,084 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:04:12,084 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:04:12,084 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> in de laatste 25 jaar.
2025-05-22 15:04:18,893 - INFO - joeynmt.training - Epoch   4, Step:    23100, Batch Loss:     1.454184, Batch Acc: 0.532666, Tokens per Sec:     9572, Lr: 0.000300
2025-05-22 15:04:25,503 - INFO - joeynmt.training - Epoch   4, Step:    23200, Batch Loss:     1.537160, Batch Acc: 0.532426, Tokens per Sec:    10271, Lr: 0.000300
2025-05-22 15:04:32,252 - INFO - joeynmt.training - Epoch   4, Step:    23300, Batch Loss:     1.462339, Batch Acc: 0.527924, Tokens per Sec:     9661, Lr: 0.000300
2025-05-22 15:04:38,808 - INFO - joeynmt.training - Epoch   4, Step:    23400, Batch Loss:     1.477401, Batch Acc: 0.526709, Tokens per Sec:     9833, Lr: 0.000300
2025-05-22 15:04:45,492 - INFO - joeynmt.training - Epoch   4, Step:    23500, Batch Loss:     1.560774, Batch Acc: 0.529395, Tokens per Sec:     9698, Lr: 0.000300
2025-05-22 15:04:45,492 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:04:45,492 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:04:53,970 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.34, acc:   0.50, generation: 8.4024[sec], evaluation: 0.0000[sec]
2025-05-22 15:04:54,109 - INFO - joeynmt.helpers - delete models/transformer_enit/21000.ckpt
2025-05-22 15:04:54,121 - INFO - joeynmt.training - Example #0
2025-05-22 15:04:54,122 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:04:54,122 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:04:54,122 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', ',', 'met', '40', '%', '.', '</s>']
2025-05-22 15:04:54,122 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:04:54,123 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:04:54,123 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk>, <unk>, met 40%.
2025-05-22 15:04:54,123 - INFO - joeynmt.training - Example #1
2025-05-22 15:04:54,123 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:04:54,123 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:04:54,123 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:04:54,123 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:04:54,123 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:04:54,123 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet <unk> genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:04:54,124 - INFO - joeynmt.training - Example #2
2025-05-22 15:04:54,124 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:04:54,124 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:04:54,124 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:04:54,124 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:04:54,124 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:04:54,124 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:04:54,124 - INFO - joeynmt.training - Example #3
2025-05-22 15:04:54,124 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:04:54,124 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:04:54,124 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:04:54,125 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:04:54,125 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:04:54,125 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:04:54,125 - INFO - joeynmt.training - Example #4
2025-05-22 15:04:54,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:04:54,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:04:54,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:04:54,126 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:04:54,126 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:04:54,126 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:05:00,334 - INFO - joeynmt.training - Epoch   4, Step:    23600, Batch Loss:     1.684285, Batch Acc: 0.527066, Tokens per Sec:    10311, Lr: 0.000300
2025-05-22 15:05:06,473 - INFO - joeynmt.training - Epoch   4, Step:    23700, Batch Loss:     1.325440, Batch Acc: 0.530362, Tokens per Sec:    10682, Lr: 0.000300
2025-05-22 15:05:09,855 - INFO - joeynmt.training - Epoch   4: total training loss 9148.29
2025-05-22 15:05:09,855 - INFO - joeynmt.training - EPOCH 5
2025-05-22 15:05:12,651 - INFO - joeynmt.training - Epoch   5, Step:    23800, Batch Loss:     1.507317, Batch Acc: 0.538639, Tokens per Sec:    10698, Lr: 0.000300
2025-05-22 15:05:18,713 - INFO - joeynmt.training - Epoch   5, Step:    23900, Batch Loss:     1.376123, Batch Acc: 0.541223, Tokens per Sec:    10662, Lr: 0.000300
2025-05-22 15:05:25,075 - INFO - joeynmt.training - Epoch   5, Step:    24000, Batch Loss:     1.583162, Batch Acc: 0.537909, Tokens per Sec:    10586, Lr: 0.000300
2025-05-22 15:05:25,076 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:05:25,076 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:05:33,420 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.33, acc:   0.50, generation: 8.2604[sec], evaluation: 0.0000[sec]
2025-05-22 15:05:33,561 - INFO - joeynmt.helpers - delete models/transformer_enit/23500.ckpt
2025-05-22 15:05:33,568 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit/23500.ckpt
2025-05-22 15:05:33,568 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit\23500.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit\\23500.ckpt')
2025-05-22 15:05:33,582 - INFO - joeynmt.training - Example #0
2025-05-22 15:05:33,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:05:33,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:05:33,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'om', '40', 'procent', '<unk>', 'te', 'zijn', '.', '</s>']
2025-05-22 15:05:33,583 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:05:33,583 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:05:33,583 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die voor <unk> drie miljoen jaar <unk> <unk> van de <unk> <unk> staten, om 40 procent <unk> te zijn.
2025-05-22 15:05:33,583 - INFO - joeynmt.training - Example #1
2025-05-22 15:05:33,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:05:33,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:05:33,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', '<unk>', 'genoeg', '<unk>', 'van', 'dit', '<unk>', '<unk>', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'is', '.', '</s>']
2025-05-22 15:05:33,585 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:05:33,585 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:05:33,585 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet <unk> genoeg <unk> van dit <unk> <unk> omdat het niet de <unk> van de <unk> is.
2025-05-22 15:05:33,585 - INFO - joeynmt.training - Example #2
2025-05-22 15:05:33,585 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:05:33,585 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:05:33,585 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:05:33,586 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:05:33,586 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:05:33,586 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:05:33,586 - INFO - joeynmt.training - Example #3
2025-05-22 15:05:33,586 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:05:33,586 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:05:33,586 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', 'zomer', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:05:33,587 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:05:33,587 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:05:33,587 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer en <unk> in de zomer.
2025-05-22 15:05:33,587 - INFO - joeynmt.training - Example #4
2025-05-22 15:05:33,587 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:05:33,587 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:05:33,587 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'toon', 'is', 'een', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 15:05:33,589 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:05:33,589 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:05:33,589 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik toon is een <unk> van wat er in de afgelopen 25 jaar is gebeurd.
2025-05-22 15:05:40,197 - INFO - joeynmt.training - Epoch   5, Step:    24100, Batch Loss:     1.596867, Batch Acc: 0.541085, Tokens per Sec:     9710, Lr: 0.000300
2025-05-22 15:05:46,868 - INFO - joeynmt.training - Epoch   5, Step:    24200, Batch Loss:     1.268493, Batch Acc: 0.543814, Tokens per Sec:     9852, Lr: 0.000300
2025-05-22 15:05:53,760 - INFO - joeynmt.training - Epoch   5, Step:    24300, Batch Loss:     1.470282, Batch Acc: 0.536434, Tokens per Sec:     9594, Lr: 0.000300
2025-05-22 15:06:00,376 - INFO - joeynmt.training - Epoch   5, Step:    24400, Batch Loss:     1.330633, Batch Acc: 0.541789, Tokens per Sec:    10225, Lr: 0.000300
2025-05-22 15:06:07,314 - INFO - joeynmt.training - Epoch   5, Step:    24500, Batch Loss:     1.412579, Batch Acc: 0.541403, Tokens per Sec:     9481, Lr: 0.000300
2025-05-22 15:06:07,315 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:06:07,315 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:06:15,423 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.31, acc:   0.49, generation: 8.0275[sec], evaluation: 0.0000[sec]
2025-05-22 15:06:15,561 - INFO - joeynmt.helpers - delete models/transformer_enit/24000.ckpt
2025-05-22 15:06:15,570 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit/24000.ckpt
2025-05-22 15:06:15,572 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit\24000.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit\\24000.ckpt')
2025-05-22 15:06:15,575 - INFO - joeynmt.training - Example #0
2025-05-22 15:06:15,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:06:15,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:06:15,576 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'met', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:06:15,576 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:06:15,576 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:06:15,576 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar de <unk> van de <unk> <unk> <unk> <unk>, met <unk> <unk>.
2025-05-22 15:06:15,576 - INFO - joeynmt.training - Example #1
2025-05-22 15:06:15,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:06:15,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:06:15,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'genoeg', '<unk>', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:06:15,577 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:06:15,577 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:06:15,577 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet genoeg <unk> de <unk> van dit <unk> <unk>, want het is niet de <unk> van de <unk>.
2025-05-22 15:06:15,577 - INFO - joeynmt.training - Example #2
2025-05-22 15:06:15,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:06:15,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:06:15,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:06:15,578 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:06:15,578 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:06:15,578 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:06:15,578 - INFO - joeynmt.training - Example #3
2025-05-22 15:06:15,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:06:15,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:06:15,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:06:15,578 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:06:15,579 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:06:15,579 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:06:15,579 - INFO - joeynmt.training - Example #4
2025-05-22 15:06:15,579 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:06:15,579 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:06:15,579 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:06:15,579 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:06:15,579 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:06:15,579 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> in de laatste 25 jaar.
2025-05-22 15:06:21,665 - INFO - joeynmt.training - Epoch   5, Step:    24600, Batch Loss:     1.408392, Batch Acc: 0.539528, Tokens per Sec:    10745, Lr: 0.000300
2025-05-22 15:06:27,625 - INFO - joeynmt.training - Epoch   5, Step:    24700, Batch Loss:     1.421675, Batch Acc: 0.540053, Tokens per Sec:    11189, Lr: 0.000300
2025-05-22 15:06:33,737 - INFO - joeynmt.training - Epoch   5, Step:    24800, Batch Loss:     1.506771, Batch Acc: 0.542814, Tokens per Sec:    10776, Lr: 0.000300
2025-05-22 15:06:39,617 - INFO - joeynmt.training - Epoch   5, Step:    24900, Batch Loss:     1.385843, Batch Acc: 0.538665, Tokens per Sec:    10792, Lr: 0.000300
2025-05-22 15:06:45,684 - INFO - joeynmt.training - Epoch   5, Step:    25000, Batch Loss:     1.527576, Batch Acc: 0.537944, Tokens per Sec:    10641, Lr: 0.000300
2025-05-22 15:06:45,685 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:06:45,685 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:06:53,126 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.32, acc:   0.50, generation: 7.3743[sec], evaluation: 0.0000[sec]
2025-05-22 15:06:53,269 - INFO - joeynmt.helpers - delete models/transformer_enit/22000.ckpt
2025-05-22 15:06:53,279 - INFO - joeynmt.training - Example #0
2025-05-22 15:06:53,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:06:53,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:06:53,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', ',', 'met', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:06:53,280 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:06:53,280 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:06:53,280 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die voor <unk> drie miljoen jaar <unk> <unk> <unk>, met <unk> <unk>.
2025-05-22 15:06:53,280 - INFO - joeynmt.training - Example #1
2025-05-22 15:06:53,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:06:53,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:06:53,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', '<unk>', 'genoeg', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:06:53,280 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:06:53,281 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:06:53,281 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet <unk> genoeg <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:06:53,281 - INFO - joeynmt.training - Example #2
2025-05-22 15:06:53,281 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:06:53,281 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:06:53,281 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'onze', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 15:06:53,281 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:06:53,281 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:06:53,282 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van onze mondiale <unk>.
2025-05-22 15:06:53,282 - INFO - joeynmt.training - Example #3
2025-05-22 15:06:53,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:06:53,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:06:53,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:06:53,282 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:06:53,282 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:06:53,282 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2025-05-22 15:06:53,282 - INFO - joeynmt.training - Example #4
2025-05-22 15:06:53,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:06:53,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:06:53,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'zal', 'tonen', ',', 'is', 'een', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 15:06:53,284 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:06:53,284 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:06:53,284 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik zal tonen, is een <unk> wat er in de afgelopen 25 jaar is.
2025-05-22 15:06:59,771 - INFO - joeynmt.training - Epoch   5, Step:    25100, Batch Loss:     1.397204, Batch Acc: 0.537340, Tokens per Sec:    10047, Lr: 0.000300
2025-05-22 15:07:06,529 - INFO - joeynmt.training - Epoch   5, Step:    25200, Batch Loss:     1.413364, Batch Acc: 0.537199, Tokens per Sec:     9746, Lr: 0.000300
2025-05-22 15:07:13,086 - INFO - joeynmt.training - Epoch   5, Step:    25300, Batch Loss:     1.582678, Batch Acc: 0.535931, Tokens per Sec:    10383, Lr: 0.000300
2025-05-22 15:07:19,744 - INFO - joeynmt.training - Epoch   5, Step:    25400, Batch Loss:     1.694351, Batch Acc: 0.539699, Tokens per Sec:    10009, Lr: 0.000300
2025-05-22 15:07:26,328 - INFO - joeynmt.training - Epoch   5, Step:    25500, Batch Loss:     1.496777, Batch Acc: 0.535402, Tokens per Sec:    10108, Lr: 0.000300
2025-05-22 15:07:26,329 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:07:26,329 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:07:33,919 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.32, acc:   0.49, generation: 7.5079[sec], evaluation: 0.0000[sec]
2025-05-22 15:07:33,925 - INFO - joeynmt.training - Example #0
2025-05-22 15:07:33,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:07:33,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:07:33,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', 'met', '40', 'procent', '.', '</s>']
2025-05-22 15:07:33,926 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:07:33,926 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:07:33,927 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> <unk> <unk> <unk>, <unk> met 40 procent.
2025-05-22 15:07:33,927 - INFO - joeynmt.training - Example #1
2025-05-22 15:07:33,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:07:33,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:07:33,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', 'is', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2025-05-22 15:07:33,928 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:07:33,928 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:07:33,928 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg is de <unk> van dit <unk> <unk>, omdat het niet de <unk> van het <unk>.
2025-05-22 15:07:33,928 - INFO - joeynmt.training - Example #2
2025-05-22 15:07:33,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:07:33,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:07:33,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:07:33,929 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:07:33,929 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:07:33,929 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons <unk> <unk>.
2025-05-22 15:07:33,929 - INFO - joeynmt.training - Example #3
2025-05-22 15:07:33,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:07:33,930 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:07:33,930 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeien', 'in', 'de', 'zomer', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:07:33,930 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:07:33,930 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:07:33,930 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de zomer en <unk> in de zomer.
2025-05-22 15:07:33,931 - INFO - joeynmt.training - Example #4
2025-05-22 15:07:33,931 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:07:33,931 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:07:33,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 15:07:33,932 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:07:33,932 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:07:33,932 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> <unk> van wat er in de laatste 25 jaar is gebeurd.
2025-05-22 15:07:40,258 - INFO - joeynmt.training - Epoch   5, Step:    25600, Batch Loss:     1.499343, Batch Acc: 0.538881, Tokens per Sec:    10098, Lr: 0.000300
2025-05-22 15:07:47,152 - INFO - joeynmt.training - Epoch   5, Step:    25700, Batch Loss:     1.401750, Batch Acc: 0.540516, Tokens per Sec:     9419, Lr: 0.000300
2025-05-22 15:07:55,386 - INFO - joeynmt.training - Epoch   5, Step:    25800, Batch Loss:     1.260827, Batch Acc: 0.532570, Tokens per Sec:     8207, Lr: 0.000300
2025-05-22 15:08:01,590 - INFO - joeynmt.training - Epoch   5, Step:    25900, Batch Loss:     1.403624, Batch Acc: 0.536204, Tokens per Sec:    10541, Lr: 0.000300
2025-05-22 15:08:08,132 - INFO - joeynmt.training - Epoch   5, Step:    26000, Batch Loss:     1.471850, Batch Acc: 0.537110, Tokens per Sec:    10121, Lr: 0.000300
2025-05-22 15:08:08,133 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:08:08,133 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:08:16,525 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.30, acc:   0.49, generation: 8.3079[sec], evaluation: 0.0000[sec]
2025-05-22 15:08:16,672 - INFO - joeynmt.helpers - delete models/transformer_enit/25000.ckpt
2025-05-22 15:08:16,681 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit/25000.ckpt
2025-05-22 15:08:16,682 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit\25000.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit\\25000.ckpt')
2025-05-22 15:08:16,686 - INFO - joeynmt.training - Example #0
2025-05-22 15:08:16,686 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:08:16,686 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:08:16,686 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'liet', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', 'was', '.', '</s>']
2025-05-22 15:08:16,686 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:08:16,687 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:08:16,687 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar liet ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> <unk>, die voor <unk> drie miljoen jaar <unk> was.
2025-05-22 15:08:16,687 - INFO - joeynmt.training - Example #1
2025-05-22 15:08:16,687 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:08:16,687 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:08:16,687 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'sterk', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2025-05-22 15:08:16,687 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:08:16,687 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:08:16,687 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van het <unk>.
2025-05-22 15:08:16,687 - INFO - joeynmt.training - Example #2
2025-05-22 15:08:16,688 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:08:16,688 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:08:16,688 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', '<unk>', '<unk>', 'is', 'de', '<unk>', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:08:16,688 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:08:16,688 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:08:16,688 - INFO - joeynmt.training - 	Hypothesis: In de <unk> <unk> is de <unk> van ons <unk> <unk>.
2025-05-22 15:08:16,688 - INFO - joeynmt.training - Example #3
2025-05-22 15:08:16,688 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:08:16,688 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:08:16,688 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:08:16,689 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:08:16,689 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:08:16,689 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2025-05-22 15:08:16,689 - INFO - joeynmt.training - Example #4
2025-05-22 15:08:16,689 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:08:16,689 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:08:16,689 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 15:08:16,690 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:08:16,690 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:08:16,690 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> <unk> wat er in de afgelopen 25 jaar is.
2025-05-22 15:08:23,313 - INFO - joeynmt.training - Epoch   5, Step:    26100, Batch Loss:     1.617404, Batch Acc: 0.534321, Tokens per Sec:     9712, Lr: 0.000300
2025-05-22 15:08:29,918 - INFO - joeynmt.training - Epoch   5, Step:    26200, Batch Loss:     1.743024, Batch Acc: 0.540900, Tokens per Sec:    10055, Lr: 0.000300
2025-05-22 15:08:36,537 - INFO - joeynmt.training - Epoch   5, Step:    26300, Batch Loss:     1.738942, Batch Acc: 0.536906, Tokens per Sec:     9929, Lr: 0.000300
2025-05-22 15:08:43,475 - INFO - joeynmt.training - Epoch   5, Step:    26400, Batch Loss:     1.570111, Batch Acc: 0.535433, Tokens per Sec:     9325, Lr: 0.000300
2025-05-22 15:08:50,056 - INFO - joeynmt.training - Epoch   5, Step:    26500, Batch Loss:     1.543690, Batch Acc: 0.539463, Tokens per Sec:     9676, Lr: 0.000300
2025-05-22 15:08:50,056 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:08:50,056 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:08:57,691 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.30, acc:   0.49, generation: 7.5664[sec], evaluation: 0.0000[sec]
2025-05-22 15:08:57,692 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:08:57,827 - INFO - joeynmt.helpers - delete models/transformer_enit/22500.ckpt
2025-05-22 15:08:57,837 - INFO - joeynmt.training - Example #0
2025-05-22 15:08:57,838 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:08:57,838 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:08:57,838 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', '<unk>', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '%', '<unk>', '.', '</s>']
2025-05-22 15:08:57,838 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:08:57,838 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:08:57,838 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> <unk> om te <unk> dat de <unk> <unk>, die <unk> voor <unk> drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk> <unk> <unk>, <unk> <unk>, <unk>% <unk>.
2025-05-22 15:08:57,838 - INFO - joeynmt.training - Example #1
2025-05-22 15:08:57,838 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:08:57,838 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:08:57,839 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:08:57,839 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:08:57,839 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:08:57,839 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg <unk> <unk> van deze <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:08:57,839 - INFO - joeynmt.training - Example #2
2025-05-22 15:08:57,839 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:08:57,839 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:08:57,839 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'onze', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:08:57,840 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:08:57,840 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:08:57,840 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van onze wereldwijde <unk>.
2025-05-22 15:08:57,840 - INFO - joeynmt.training - Example #3
2025-05-22 15:08:57,840 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:08:57,840 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:08:57,840 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeien', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:08:57,840 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:08:57,840 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:08:57,840 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het <unk> en <unk> in de zomer.
2025-05-22 15:08:57,840 - INFO - joeynmt.training - Example #4
2025-05-22 15:08:57,841 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:08:57,841 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:08:57,841 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 15:08:57,841 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:08:57,841 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:08:57,841 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> van wat er in de laatste 25 jaar is gebeurd.
2025-05-22 15:09:04,023 - INFO - joeynmt.training - Epoch   5, Step:    26600, Batch Loss:     1.447076, Batch Acc: 0.534278, Tokens per Sec:    10533, Lr: 0.000300
2025-05-22 15:09:10,134 - INFO - joeynmt.training - Epoch   5, Step:    26700, Batch Loss:     1.395171, Batch Acc: 0.537491, Tokens per Sec:    10968, Lr: 0.000300
2025-05-22 15:09:16,192 - INFO - joeynmt.training - Epoch   5, Step:    26800, Batch Loss:     1.438660, Batch Acc: 0.536067, Tokens per Sec:    10928, Lr: 0.000300
2025-05-22 15:09:22,328 - INFO - joeynmt.training - Epoch   5, Step:    26900, Batch Loss:     1.515430, Batch Acc: 0.535954, Tokens per Sec:    10944, Lr: 0.000300
2025-05-22 15:09:28,838 - INFO - joeynmt.training - Epoch   5, Step:    27000, Batch Loss:     1.480633, Batch Acc: 0.532742, Tokens per Sec:     9986, Lr: 0.000300
2025-05-22 15:09:28,839 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:09:28,839 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:09:36,850 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.29, acc:   0.50, generation: 7.9145[sec], evaluation: 0.0000[sec]
2025-05-22 15:09:36,851 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:09:36,999 - INFO - joeynmt.helpers - delete models/transformer_enit/21500.ckpt
2025-05-22 15:09:37,009 - INFO - joeynmt.training - Example #0
2025-05-22 15:09:37,009 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:09:37,009 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:09:37,009 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', ',', 'om', '40', 'procent', '<unk>', 'is', '.', '</s>']
2025-05-22 15:09:37,010 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:09:37,010 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:09:37,010 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die voor <unk> drie miljoen jaar de <unk> van de <unk> staten, om 40 procent <unk> is.
2025-05-22 15:09:37,010 - INFO - joeynmt.training - Example #1
2025-05-22 15:09:37,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:09:37,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:09:37,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'erg', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:09:37,010 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:09:37,011 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:09:37,011 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:09:37,011 - INFO - joeynmt.training - Example #2
2025-05-22 15:09:37,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:09:37,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:09:37,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:09:37,011 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:09:37,011 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:09:37,011 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:09:37,011 - INFO - joeynmt.training - Example #3
2025-05-22 15:09:37,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:09:37,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:09:37,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:09:37,012 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:09:37,012 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:09:37,012 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:09:37,012 - INFO - joeynmt.training - Example #4
2025-05-22 15:09:37,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:09:37,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:09:37,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:09:37,012 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:09:37,013 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:09:37,013 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> van de laatste 25 jaar.
2025-05-22 15:09:43,725 - INFO - joeynmt.training - Epoch   5, Step:    27100, Batch Loss:     1.542480, Batch Acc: 0.529671, Tokens per Sec:     9432, Lr: 0.000300
2025-05-22 15:09:50,329 - INFO - joeynmt.training - Epoch   5, Step:    27200, Batch Loss:     1.533119, Batch Acc: 0.540477, Tokens per Sec:     9894, Lr: 0.000300
2025-05-22 15:09:57,155 - INFO - joeynmt.training - Epoch   5, Step:    27300, Batch Loss:     1.659219, Batch Acc: 0.535591, Tokens per Sec:    10071, Lr: 0.000300
2025-05-22 15:10:03,918 - INFO - joeynmt.training - Epoch   5, Step:    27400, Batch Loss:     1.467640, Batch Acc: 0.538159, Tokens per Sec:     9864, Lr: 0.000300
2025-05-22 15:10:10,599 - INFO - joeynmt.training - Epoch   5, Step:    27500, Batch Loss:     1.448002, Batch Acc: 0.538995, Tokens per Sec:     9937, Lr: 0.000300
2025-05-22 15:10:10,600 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:10:10,600 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:10:17,902 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.49, generation: 7.2349[sec], evaluation: 0.0000[sec]
2025-05-22 15:10:17,902 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:10:18,037 - INFO - joeynmt.helpers - delete models/transformer_enit/24500.ckpt
2025-05-22 15:10:18,046 - INFO - joeynmt.training - Example #0
2025-05-22 15:10:18,046 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:10:18,047 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:10:18,047 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', 'staten', 'had', '<unk>', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2025-05-22 15:10:18,047 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:10:18,047 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:10:18,047 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> van de <unk> staten had <unk> om 40 procent te <unk>.
2025-05-22 15:10:18,047 - INFO - joeynmt.training - Example #1
2025-05-22 15:10:18,047 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:10:18,047 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:10:18,047 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', 'de', '<unk>', 'van', 'dit', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:10:18,048 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:10:18,048 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:10:18,048 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg <unk> de <unk> van dit <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:10:18,048 - INFO - joeynmt.training - Example #2
2025-05-22 15:10:18,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:10:18,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:10:18,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'onze', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:10:18,049 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:10:18,049 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:10:18,049 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> is de <unk> <unk> het <unk> hart van onze wereldwijde <unk>.
2025-05-22 15:10:18,049 - INFO - joeynmt.training - Example #3
2025-05-22 15:10:18,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:10:18,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:10:18,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:10:18,050 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:10:18,050 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:10:18,050 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:10:18,050 - INFO - joeynmt.training - Example #4
2025-05-22 15:10:18,050 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:10:18,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:10:18,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:10:18,050 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:10:18,051 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:10:18,051 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> <unk> in de laatste 25 jaar.
2025-05-22 15:10:24,173 - INFO - joeynmt.training - Epoch   5, Step:    27600, Batch Loss:     1.426294, Batch Acc: 0.533628, Tokens per Sec:    10820, Lr: 0.000300
2025-05-22 15:10:30,350 - INFO - joeynmt.training - Epoch   5, Step:    27700, Batch Loss:     1.621405, Batch Acc: 0.535053, Tokens per Sec:    10816, Lr: 0.000300
2025-05-22 15:10:36,363 - INFO - joeynmt.training - Epoch   5, Step:    27800, Batch Loss:     1.618905, Batch Acc: 0.538850, Tokens per Sec:    10715, Lr: 0.000300
2025-05-22 15:10:42,534 - INFO - joeynmt.training - Epoch   5, Step:    27900, Batch Loss:     1.375525, Batch Acc: 0.540613, Tokens per Sec:    10324, Lr: 0.000300
2025-05-22 15:10:48,956 - INFO - joeynmt.training - Epoch   5, Step:    28000, Batch Loss:     1.663922, Batch Acc: 0.532427, Tokens per Sec:    10285, Lr: 0.000300
2025-05-22 15:10:48,956 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:10:48,956 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:10:56,445 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.49, generation: 7.4114[sec], evaluation: 0.0000[sec]
2025-05-22 15:10:56,446 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:10:56,589 - INFO - joeynmt.helpers - delete models/transformer_enit/26000.ckpt
2025-05-22 15:10:56,601 - INFO - joeynmt.training - Example #0
2025-05-22 15:10:56,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:10:56,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:10:56,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', ',', 'die', '<unk>', 'met', '40', 'procent', '<unk>', 'is', '.', '</s>']
2025-05-22 15:10:56,602 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:10:56,602 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:10:56,602 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> de <unk> van de <unk> staten, die <unk> met 40 procent <unk> is.
2025-05-22 15:10:56,603 - INFO - joeynmt.training - Example #1
2025-05-22 15:10:56,603 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:10:56,603 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:10:56,603 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'sterk', 'genoeg', '<unk>', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2025-05-22 15:10:56,603 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:10:56,603 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:10:56,604 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg <unk> de <unk> van dit <unk> <unk>, want het is niet de <unk> van het <unk>.
2025-05-22 15:10:56,604 - INFO - joeynmt.training - Example #2
2025-05-22 15:10:56,604 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:10:56,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:10:56,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', 'hart', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:10:56,605 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:10:56,605 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:10:56,605 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het hart van ons <unk> <unk>.
2025-05-22 15:10:56,605 - INFO - joeynmt.training - Example #3
2025-05-22 15:10:56,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:10:56,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:10:56,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:10:56,606 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:10:56,606 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:10:56,606 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2025-05-22 15:10:56,606 - INFO - joeynmt.training - Example #4
2025-05-22 15:10:56,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:10:56,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:10:56,606 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:10:56,607 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:10:56,607 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:10:56,607 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> in de laatste 25 jaar.
2025-05-22 15:11:03,178 - INFO - joeynmt.training - Epoch   5, Step:    28100, Batch Loss:     1.627822, Batch Acc: 0.537540, Tokens per Sec:     9898, Lr: 0.000300
2025-05-22 15:11:09,874 - INFO - joeynmt.training - Epoch   5, Step:    28200, Batch Loss:     1.395753, Batch Acc: 0.536914, Tokens per Sec:     9950, Lr: 0.000300
2025-05-22 15:11:16,526 - INFO - joeynmt.training - Epoch   5, Step:    28300, Batch Loss:     1.543797, Batch Acc: 0.535876, Tokens per Sec:    10072, Lr: 0.000300
2025-05-22 15:11:23,193 - INFO - joeynmt.training - Epoch   5, Step:    28400, Batch Loss:     1.418199, Batch Acc: 0.541027, Tokens per Sec:    10020, Lr: 0.000300
2025-05-22 15:11:29,746 - INFO - joeynmt.training - Epoch   5, Step:    28500, Batch Loss:     1.511700, Batch Acc: 0.540574, Tokens per Sec:    10022, Lr: 0.000300
2025-05-22 15:11:29,746 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:11:29,746 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:11:36,635 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.24, acc:   0.50, generation: 6.8232[sec], evaluation: 0.0000[sec]
2025-05-22 15:11:36,636 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:11:36,769 - INFO - joeynmt.helpers - delete models/transformer_enit/23000.ckpt
2025-05-22 15:11:36,780 - INFO - joeynmt.training - Example #0
2025-05-22 15:11:36,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:11:36,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:11:36,780 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', 'had', '<unk>', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2025-05-22 15:11:36,781 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:11:36,781 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:11:36,781 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> <unk>, drie miljoen jaar de <unk> van de <unk> <unk> staten had <unk> om 40 procent te <unk>.
2025-05-22 15:11:36,781 - INFO - joeynmt.training - Example #1
2025-05-22 15:11:36,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:11:36,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:11:36,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'groot', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:11:36,782 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:11:36,782 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:11:36,782 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo groot genoeg om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 15:11:36,782 - INFO - joeynmt.training - Example #2
2025-05-22 15:11:36,783 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:11:36,783 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:11:36,783 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:11:36,783 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:11:36,783 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:11:36,783 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:11:36,784 - INFO - joeynmt.training - Example #3
2025-05-22 15:11:36,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:11:36,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:11:36,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:11:36,784 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:11:36,784 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:11:36,785 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:11:36,785 - INFO - joeynmt.training - Example #4
2025-05-22 15:11:36,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:11:36,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:11:36,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:11:36,785 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:11:36,786 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:11:36,786 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> van de laatste 25 jaar.
2025-05-22 15:11:42,826 - INFO - joeynmt.training - Epoch   5, Step:    28600, Batch Loss:     1.613895, Batch Acc: 0.538342, Tokens per Sec:    10723, Lr: 0.000300
2025-05-22 15:11:49,012 - INFO - joeynmt.training - Epoch   5, Step:    28700, Batch Loss:     1.424108, Batch Acc: 0.537748, Tokens per Sec:    10523, Lr: 0.000300
2025-05-22 15:11:55,334 - INFO - joeynmt.training - Epoch   5, Step:    28800, Batch Loss:     1.525753, Batch Acc: 0.534784, Tokens per Sec:    10120, Lr: 0.000300
2025-05-22 15:12:01,520 - INFO - joeynmt.training - Epoch   5, Step:    28900, Batch Loss:     1.492572, Batch Acc: 0.539976, Tokens per Sec:    10715, Lr: 0.000300
2025-05-22 15:12:08,624 - INFO - joeynmt.training - Epoch   5, Step:    29000, Batch Loss:     1.447465, Batch Acc: 0.535305, Tokens per Sec:     9217, Lr: 0.000300
2025-05-22 15:12:08,625 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:12:08,625 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:12:17,384 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.23, acc:   0.49, generation: 8.6608[sec], evaluation: 0.0000[sec]
2025-05-22 15:12:17,385 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:12:17,540 - INFO - joeynmt.helpers - delete models/transformer_enit/26500.ckpt
2025-05-22 15:12:17,552 - INFO - joeynmt.training - Example #0
2025-05-22 15:12:17,552 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:12:17,552 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:12:17,552 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']
2025-05-22 15:12:17,553 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:12:17,553 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:12:17,553 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> <unk>, die drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-22 15:12:17,554 - INFO - joeynmt.training - Example #1
2025-05-22 15:12:17,554 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:12:17,554 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:12:17,554 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:12:17,555 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:12:17,555 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:12:17,555 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 15:12:17,555 - INFO - joeynmt.training - Example #2
2025-05-22 15:12:17,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:12:17,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:12:17,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', 'hart', 'van', 'ons', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 15:12:17,556 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:12:17,556 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:12:17,557 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het hart van ons mondiale <unk>.
2025-05-22 15:12:17,557 - INFO - joeynmt.training - Example #3
2025-05-22 15:12:17,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:12:17,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:12:17,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:12:17,558 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:12:17,558 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:12:17,558 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:12:17,558 - INFO - joeynmt.training - Example #4
2025-05-22 15:12:17,558 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:12:17,559 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:12:17,559 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:12:17,559 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:12:17,559 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:12:17,560 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:12:25,041 - INFO - joeynmt.training - Epoch   5, Step:    29100, Batch Loss:     1.710241, Batch Acc: 0.532722, Tokens per Sec:     8608, Lr: 0.000300
2025-05-22 15:12:32,088 - INFO - joeynmt.training - Epoch   5, Step:    29200, Batch Loss:     1.520738, Batch Acc: 0.532851, Tokens per Sec:     9351, Lr: 0.000300
2025-05-22 15:12:39,005 - INFO - joeynmt.training - Epoch   5, Step:    29300, Batch Loss:     1.450098, Batch Acc: 0.534385, Tokens per Sec:     9575, Lr: 0.000300
2025-05-22 15:12:45,853 - INFO - joeynmt.training - Epoch   5, Step:    29400, Batch Loss:     1.436981, Batch Acc: 0.534275, Tokens per Sec:     9454, Lr: 0.000300
2025-05-22 15:12:52,577 - INFO - joeynmt.training - Epoch   5, Step:    29500, Batch Loss:     1.360751, Batch Acc: 0.537565, Tokens per Sec:    10010, Lr: 0.000300
2025-05-22 15:12:52,577 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:12:52,577 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:12:59,785 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.50, generation: 7.1478[sec], evaluation: 0.0000[sec]
2025-05-22 15:12:59,786 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:12:59,916 - INFO - joeynmt.helpers - delete models/transformer_enit/27000.ckpt
2025-05-22 15:12:59,927 - INFO - joeynmt.training - Example #0
2025-05-22 15:12:59,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:12:59,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:12:59,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '40', 'procent', '<unk>', '.', '</s>']
2025-05-22 15:12:59,928 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:12:59,928 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:12:59,928 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> <unk> <unk> <unk>, <unk> <unk>, 40 procent <unk>.
2025-05-22 15:12:59,928 - INFO - joeynmt.training - Example #1
2025-05-22 15:12:59,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:12:59,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:12:59,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'toont', '.', '</s>']
2025-05-22 15:12:59,928 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:12:59,928 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:12:59,928 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> toont.
2025-05-22 15:12:59,929 - INFO - joeynmt.training - Example #2
2025-05-22 15:12:59,929 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:12:59,929 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:12:59,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 15:12:59,929 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:12:59,929 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:12:59,929 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> het <unk> hart van ons mondiale <unk>.
2025-05-22 15:12:59,929 - INFO - joeynmt.training - Example #3
2025-05-22 15:12:59,929 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:12:59,929 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:12:59,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', 'zomer', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:12:59,930 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:12:59,930 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:12:59,930 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer en <unk> in de zomer.
2025-05-22 15:12:59,930 - INFO - joeynmt.training - Example #4
2025-05-22 15:12:59,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:12:59,930 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:12:59,930 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'zal', 'laten', 'zien', ',', 'is', 'een', '<unk>', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 15:12:59,930 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:12:59,931 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:12:59,931 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik zal laten zien, is een <unk> in de afgelopen 25 jaar.
2025-05-22 15:13:06,279 - INFO - joeynmt.training - Epoch   5, Step:    29600, Batch Loss:     1.708404, Batch Acc: 0.534114, Tokens per Sec:    10133, Lr: 0.000300
2025-05-22 15:13:12,330 - INFO - joeynmt.training - Epoch   5, Step:    29700, Batch Loss:     1.463731, Batch Acc: 0.534868, Tokens per Sec:    10665, Lr: 0.000300
2025-05-22 15:13:12,765 - INFO - joeynmt.training - Epoch   5: total training loss 8949.87
2025-05-22 15:13:12,766 - INFO - joeynmt.training - EPOCH 6
2025-05-22 15:13:18,499 - INFO - joeynmt.training - Epoch   6, Step:    29800, Batch Loss:     1.404565, Batch Acc: 0.552618, Tokens per Sec:    11052, Lr: 0.000300
2025-05-22 15:13:24,686 - INFO - joeynmt.training - Epoch   6, Step:    29900, Batch Loss:     1.298913, Batch Acc: 0.549385, Tokens per Sec:    10679, Lr: 0.000300
2025-05-22 15:13:31,346 - INFO - joeynmt.training - Epoch   6, Step:    30000, Batch Loss:     1.620832, Batch Acc: 0.548510, Tokens per Sec:     9894, Lr: 0.000300
2025-05-22 15:13:31,346 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:13:31,346 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:13:39,473 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.50, generation: 8.0423[sec], evaluation: 0.0000[sec]
2025-05-22 15:13:39,478 - INFO - joeynmt.training - Example #0
2025-05-22 15:13:39,478 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:13:39,478 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:13:39,478 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'dat', 'de', '<unk>', '<unk>', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'in', '<unk>', 'staten', '.', '</s>']
2025-05-22 15:13:39,479 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:13:39,480 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:13:39,480 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien dat de <unk> <unk> die <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> in <unk> staten.
2025-05-22 15:13:39,480 - INFO - joeynmt.training - Example #1
2025-05-22 15:13:39,480 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:13:39,480 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:13:39,480 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'sterk', 'genoeg', '<unk>', 'is', 'dat', 'het', '<unk>', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2025-05-22 15:13:39,480 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:13:39,481 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:13:39,481 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg <unk> is dat het <unk> <unk> van dit <unk> <unk>, want het is niet de <unk> van het <unk>.
2025-05-22 15:13:39,482 - INFO - joeynmt.training - Example #2
2025-05-22 15:13:39,482 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:13:39,482 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:13:39,482 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:13:39,482 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:13:39,482 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:13:39,483 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:13:39,483 - INFO - joeynmt.training - Example #3
2025-05-22 15:13:39,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:13:39,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:13:39,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:13:39,484 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:13:39,484 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:13:39,484 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:13:39,484 - INFO - joeynmt.training - Example #4
2025-05-22 15:13:39,484 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:13:39,484 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:13:39,484 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'zien', 'dat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:13:39,485 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:13:39,485 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:13:39,485 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> zien dat er in de laatste 25 jaar is gebeurd in de laatste 25 jaar.
2025-05-22 15:13:46,329 - INFO - joeynmt.training - Epoch   6, Step:    30100, Batch Loss:     1.477099, Batch Acc: 0.547803, Tokens per Sec:     9536, Lr: 0.000300
2025-05-22 15:13:53,278 - INFO - joeynmt.training - Epoch   6, Step:    30200, Batch Loss:     1.534769, Batch Acc: 0.546729, Tokens per Sec:     9384, Lr: 0.000300
2025-05-22 15:14:00,213 - INFO - joeynmt.training - Epoch   6, Step:    30300, Batch Loss:     1.492371, Batch Acc: 0.549263, Tokens per Sec:     9796, Lr: 0.000300
2025-05-22 15:14:07,164 - INFO - joeynmt.training - Epoch   6, Step:    30400, Batch Loss:     1.434819, Batch Acc: 0.548528, Tokens per Sec:     9650, Lr: 0.000300
2025-05-22 15:14:14,071 - INFO - joeynmt.training - Epoch   6, Step:    30500, Batch Loss:     1.395723, Batch Acc: 0.551658, Tokens per Sec:     9449, Lr: 0.000300
2025-05-22 15:14:14,071 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:14:14,071 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:14:21,869 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.50, generation: 7.7364[sec], evaluation: 0.0000[sec]
2025-05-22 15:14:21,999 - INFO - joeynmt.helpers - delete models/transformer_enit/27500.ckpt
2025-05-22 15:14:22,009 - INFO - joeynmt.training - Example #0
2025-05-22 15:14:22,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:14:22,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:14:22,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', ',', 'met', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', 'staten', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2025-05-22 15:14:22,010 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:14:22,010 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:14:22,010 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> <unk> <unk>, met de <unk> van de <unk> <unk> <unk> staten om 40 procent <unk> te <unk>.
2025-05-22 15:14:22,010 - INFO - joeynmt.training - Example #1
2025-05-22 15:14:22,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:14:22,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:14:22,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', '<unk>', 'genoeg', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', 'zo', '<unk>', '.', '</s>']
2025-05-22 15:14:22,011 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:14:22,011 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:14:22,011 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet <unk> genoeg <unk> van dit <unk> <unk>, want het is niet zo <unk>.
2025-05-22 15:14:22,011 - INFO - joeynmt.training - Example #2
2025-05-22 15:14:22,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:14:22,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:14:22,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 15:14:22,012 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:14:22,012 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:14:22,012 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons mondiale <unk>.
2025-05-22 15:14:22,012 - INFO - joeynmt.training - Example #3
2025-05-22 15:14:22,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:14:22,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:14:22,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:14:22,012 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:14:22,012 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:14:22,012 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:14:22,012 - INFO - joeynmt.training - Example #4
2025-05-22 15:14:22,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:14:22,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:14:22,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'zal', 'laten', 'zien', 'is', 'een', '<unk>', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 15:14:22,013 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:14:22,013 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:14:22,013 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie zal laten zien is een <unk> <unk> in de laatste 25 jaar is gebeurd.
2025-05-22 15:14:28,344 - INFO - joeynmt.training - Epoch   6, Step:    30600, Batch Loss:     1.588114, Batch Acc: 0.547939, Tokens per Sec:    10290, Lr: 0.000300
2025-05-22 15:14:34,723 - INFO - joeynmt.training - Epoch   6, Step:    30700, Batch Loss:     1.496599, Batch Acc: 0.546517, Tokens per Sec:    10187, Lr: 0.000300
2025-05-22 15:14:41,026 - INFO - joeynmt.training - Epoch   6, Step:    30800, Batch Loss:     1.509348, Batch Acc: 0.543327, Tokens per Sec:    10682, Lr: 0.000300
2025-05-22 15:14:47,230 - INFO - joeynmt.training - Epoch   6, Step:    30900, Batch Loss:     1.491481, Batch Acc: 0.545904, Tokens per Sec:    10590, Lr: 0.000300
2025-05-22 15:14:53,867 - INFO - joeynmt.training - Epoch   6, Step:    31000, Batch Loss:     1.369490, Batch Acc: 0.547342, Tokens per Sec:     9805, Lr: 0.000300
2025-05-22 15:14:53,868 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:14:53,868 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:15:01,628 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.50, generation: 7.6860[sec], evaluation: 0.0000[sec]
2025-05-22 15:15:01,629 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:15:01,770 - INFO - joeynmt.helpers - delete models/transformer_enit/28000.ckpt
2025-05-22 15:15:01,782 - INFO - joeynmt.training - Example #0
2025-05-22 15:15:01,782 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:15:01,783 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:15:01,783 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2025-05-22 15:15:01,783 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:15:01,783 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:15:01,783 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> de <unk> van de <unk> <unk> staten, om 40 procent <unk> te <unk>.
2025-05-22 15:15:01,784 - INFO - joeynmt.training - Example #1
2025-05-22 15:15:01,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:15:01,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:15:01,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'want', 'het', 'is', 'niet', '<unk>', '.', '</s>']
2025-05-22 15:15:01,784 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:15:01,785 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:15:01,785 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg <unk> van dit <unk> <unk>, want het is niet <unk>.
2025-05-22 15:15:01,785 - INFO - joeynmt.training - Example #2
2025-05-22 15:15:01,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:15:01,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:15:01,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 15:15:01,786 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:15:01,786 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:15:01,786 - INFO - joeynmt.training - 	Hypothesis: In <unk> zin is de <unk> <unk> het <unk> hart van ons mondiale <unk>.
2025-05-22 15:15:01,786 - INFO - joeynmt.training - Example #3
2025-05-22 15:15:01,786 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:15:01,786 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:15:01,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:15:01,786 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:15:01,786 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:15:01,787 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:15:01,787 - INFO - joeynmt.training - Example #4
2025-05-22 15:15:01,787 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:15:01,787 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:15:01,787 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:15:01,788 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:15:01,788 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:15:01,788 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> <unk> in de laatste 25 jaar.
2025-05-22 15:15:08,502 - INFO - joeynmt.training - Epoch   6, Step:    31100, Batch Loss:     1.507018, Batch Acc: 0.546438, Tokens per Sec:     9702, Lr: 0.000300
2025-05-22 15:15:15,168 - INFO - joeynmt.training - Epoch   6, Step:    31200, Batch Loss:     1.453816, Batch Acc: 0.543491, Tokens per Sec:    10145, Lr: 0.000300
2025-05-22 15:15:21,966 - INFO - joeynmt.training - Epoch   6, Step:    31300, Batch Loss:     1.415211, Batch Acc: 0.541677, Tokens per Sec:     9617, Lr: 0.000300
2025-05-22 15:15:28,833 - INFO - joeynmt.training - Epoch   6, Step:    31400, Batch Loss:     1.417203, Batch Acc: 0.546599, Tokens per Sec:     9420, Lr: 0.000300
2025-05-22 15:15:35,362 - INFO - joeynmt.training - Epoch   6, Step:    31500, Batch Loss:     1.634648, Batch Acc: 0.547074, Tokens per Sec:    10212, Lr: 0.000300
2025-05-22 15:15:35,363 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:15:35,363 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:15:41,599 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.24, acc:   0.50, generation: 6.1785[sec], evaluation: 0.0000[sec]
2025-05-22 15:15:41,604 - INFO - joeynmt.training - Example #0
2025-05-22 15:15:41,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:15:41,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:15:41,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', 'had', '<unk>', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2025-05-22 15:15:41,606 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:15:41,606 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:15:41,606 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> <unk>, drie miljoen jaar de <unk> van de <unk> staten had <unk> om 40 procent <unk> te <unk>.
2025-05-22 15:15:41,606 - INFO - joeynmt.training - Example #1
2025-05-22 15:15:41,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:15:41,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:15:41,606 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'is', '.', '</s>']
2025-05-22 15:15:41,607 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:15:41,608 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:15:41,608 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk> is.
2025-05-22 15:15:41,608 - INFO - joeynmt.training - Example #2
2025-05-22 15:15:41,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:15:41,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:15:41,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 15:15:41,608 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:15:41,608 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:15:41,608 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons mondiale <unk>.
2025-05-22 15:15:41,608 - INFO - joeynmt.training - Example #3
2025-05-22 15:15:41,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:15:41,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:15:41,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:15:41,609 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:15:41,609 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:15:41,609 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:15:41,610 - INFO - joeynmt.training - Example #4
2025-05-22 15:15:41,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:15:41,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:15:41,610 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'die', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 15:15:41,610 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:15:41,610 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:15:41,611 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> die de laatste 25 jaar is gebeurd.
2025-05-22 15:15:47,794 - INFO - joeynmt.training - Epoch   6, Step:    31600, Batch Loss:     1.467355, Batch Acc: 0.541600, Tokens per Sec:    10339, Lr: 0.000300
2025-05-22 15:15:53,991 - INFO - joeynmt.training - Epoch   6, Step:    31700, Batch Loss:     1.397385, Batch Acc: 0.548037, Tokens per Sec:    11047, Lr: 0.000300
2025-05-22 15:15:59,979 - INFO - joeynmt.training - Epoch   6, Step:    31800, Batch Loss:     1.505368, Batch Acc: 0.542411, Tokens per Sec:    11437, Lr: 0.000300
2025-05-22 15:16:06,169 - INFO - joeynmt.training - Epoch   6, Step:    31900, Batch Loss:     1.299435, Batch Acc: 0.542877, Tokens per Sec:    10827, Lr: 0.000300
2025-05-22 15:16:13,365 - INFO - joeynmt.training - Epoch   6, Step:    32000, Batch Loss:     1.526607, Batch Acc: 0.544536, Tokens per Sec:     9233, Lr: 0.000300
2025-05-22 15:16:13,366 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:16:13,366 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:16:21,121 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.50, generation: 7.6802[sec], evaluation: 0.0000[sec]
2025-05-22 15:16:21,263 - INFO - joeynmt.helpers - delete models/transformer_enit/28500.ckpt
2025-05-22 15:16:21,276 - INFO - joeynmt.training - Example #0
2025-05-22 15:16:21,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:16:21,277 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:16:21,277 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', ',', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2025-05-22 15:16:21,277 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:16:21,277 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:16:21,277 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien, om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk> <unk>, om 40 procent te <unk>.
2025-05-22 15:16:21,277 - INFO - joeynmt.training - Example #1
2025-05-22 15:16:21,277 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:16:21,277 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:16:21,277 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', 'is', 'dat', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:16:21,278 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:16:21,278 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:16:21,278 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg <unk> is dat <unk> <unk>, omdat het niet de <unk> van de <unk> <unk>.
2025-05-22 15:16:21,278 - INFO - joeynmt.training - Example #2
2025-05-22 15:16:21,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:16:21,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:16:21,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 15:16:21,279 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:16:21,279 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:16:21,279 - INFO - joeynmt.training - 	Hypothesis: In de <unk> is de <unk> <unk> het <unk> hart van ons mondiale <unk>.
2025-05-22 15:16:21,279 - INFO - joeynmt.training - Example #3
2025-05-22 15:16:21,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:16:21,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:16:21,279 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:16:21,279 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:16:21,279 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:16:21,279 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:16:21,280 - INFO - joeynmt.training - Example #4
2025-05-22 15:16:21,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:16:21,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:16:21,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 15:16:21,281 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:16:21,281 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:16:21,281 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> van wat er in de afgelopen 25 jaar is.
2025-05-22 15:16:27,843 - INFO - joeynmt.training - Epoch   6, Step:    32100, Batch Loss:     1.487622, Batch Acc: 0.545439, Tokens per Sec:     9696, Lr: 0.000300
2025-05-22 15:16:34,460 - INFO - joeynmt.training - Epoch   6, Step:    32200, Batch Loss:     1.430493, Batch Acc: 0.546125, Tokens per Sec:    10105, Lr: 0.000300
2025-05-22 15:16:41,204 - INFO - joeynmt.training - Epoch   6, Step:    32300, Batch Loss:     1.365326, Batch Acc: 0.544283, Tokens per Sec:    10105, Lr: 0.000300
2025-05-22 15:16:47,918 - INFO - joeynmt.training - Epoch   6, Step:    32400, Batch Loss:     1.438747, Batch Acc: 0.550113, Tokens per Sec:     9778, Lr: 0.000300
2025-05-22 15:16:54,848 - INFO - joeynmt.training - Epoch   6, Step:    32500, Batch Loss:     1.621531, Batch Acc: 0.544205, Tokens per Sec:     9609, Lr: 0.000300
2025-05-22 15:16:54,848 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:16:54,849 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:17:01,185 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.24, acc:   0.50, generation: 6.2756[sec], evaluation: 0.0000[sec]
2025-05-22 15:17:01,191 - INFO - joeynmt.training - Example #0
2025-05-22 15:17:01,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:17:01,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:17:01,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'om', '40', 'procent', 'te', '<unk>', 'is', '.', '</s>']
2025-05-22 15:17:01,192 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:17:01,192 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:17:01,192 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> <unk> van de <unk> <unk> staten, om 40 procent te <unk> is.
2025-05-22 15:17:01,192 - INFO - joeynmt.training - Example #1
2025-05-22 15:17:01,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:17:01,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:17:01,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'sterk', 'genoeg', '<unk>', 'genoeg', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:17:01,194 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:17:01,194 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:17:01,194 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg <unk> genoeg <unk> van deze <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:17:01,194 - INFO - joeynmt.training - Example #2
2025-05-22 15:17:01,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:17:01,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:17:01,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:17:01,195 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:17:01,195 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:17:01,195 - INFO - joeynmt.training - 	Hypothesis: In de <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:17:01,195 - INFO - joeynmt.training - Example #3
2025-05-22 15:17:01,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:17:01,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:17:01,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:17:01,196 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:17:01,196 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:17:01,196 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:17:01,196 - INFO - joeynmt.training - Example #4
2025-05-22 15:17:01,197 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:17:01,197 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:17:01,197 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:17:01,198 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:17:01,198 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:17:01,198 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> van de laatste 25 jaar.
2025-05-22 15:17:07,267 - INFO - joeynmt.training - Epoch   6, Step:    32600, Batch Loss:     1.401070, Batch Acc: 0.542956, Tokens per Sec:    10599, Lr: 0.000300
2025-05-22 15:17:13,449 - INFO - joeynmt.training - Epoch   6, Step:    32700, Batch Loss:     1.401616, Batch Acc: 0.546870, Tokens per Sec:    10582, Lr: 0.000300
2025-05-22 15:17:19,627 - INFO - joeynmt.training - Epoch   6, Step:    32800, Batch Loss:     1.643159, Batch Acc: 0.542324, Tokens per Sec:    10461, Lr: 0.000300
2025-05-22 15:17:25,869 - INFO - joeynmt.training - Epoch   6, Step:    32900, Batch Loss:     1.441729, Batch Acc: 0.545185, Tokens per Sec:    10476, Lr: 0.000300
2025-05-22 15:17:32,662 - INFO - joeynmt.training - Epoch   6, Step:    33000, Batch Loss:     1.620141, Batch Acc: 0.545486, Tokens per Sec:     9725, Lr: 0.000300
2025-05-22 15:17:32,663 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:17:32,663 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:17:40,523 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.21, acc:   0.50, generation: 7.7746[sec], evaluation: 0.0000[sec]
2025-05-22 15:17:40,524 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:17:40,673 - INFO - joeynmt.helpers - delete models/transformer_enit/29000.ckpt
2025-05-22 15:17:40,686 - INFO - joeynmt.training - Example #0
2025-05-22 15:17:40,687 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:17:40,687 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:17:40,687 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', ',', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', '40', 'procent', '<unk>', '.', '</s>']
2025-05-22 15:17:40,688 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:17:40,688 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:17:40,688 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien, om te <unk> dat de <unk> <unk>, die drie miljoen jaar de <unk> van de <unk> <unk> staten, 40 procent <unk>.
2025-05-22 15:17:40,688 - INFO - joeynmt.training - Example #1
2025-05-22 15:17:40,688 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:17:40,688 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:17:40,688 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', 'genoeg', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:17:40,689 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:17:40,689 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:17:40,690 - INFO - joeynmt.training - 	Hypothesis: Maar dit <unk> niet sterk genoeg <unk> genoeg <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:17:40,690 - INFO - joeynmt.training - Example #2
2025-05-22 15:17:40,690 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:17:40,690 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:17:40,690 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', '<unk>', '<unk>', '<unk>', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:17:40,691 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:17:40,691 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:17:40,691 - INFO - joeynmt.training - 	Hypothesis: In <unk> <unk> <unk> is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:17:40,691 - INFO - joeynmt.training - Example #3
2025-05-22 15:17:40,691 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:17:40,691 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:17:40,691 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:17:40,692 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:17:40,692 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:17:40,692 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:17:40,692 - INFO - joeynmt.training - Example #4
2025-05-22 15:17:40,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:17:40,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:17:40,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 15:17:40,693 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:17:40,693 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:17:40,694 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> wat in de laatste 25 jaar is.
2025-05-22 15:17:47,475 - INFO - joeynmt.training - Epoch   6, Step:    33100, Batch Loss:     1.439660, Batch Acc: 0.543997, Tokens per Sec:     9671, Lr: 0.000300
2025-05-22 15:17:54,530 - INFO - joeynmt.training - Epoch   6, Step:    33200, Batch Loss:     1.464967, Batch Acc: 0.544680, Tokens per Sec:     9416, Lr: 0.000300
2025-05-22 15:18:01,555 - INFO - joeynmt.training - Epoch   6, Step:    33300, Batch Loss:     1.443956, Batch Acc: 0.538752, Tokens per Sec:     9343, Lr: 0.000300
2025-05-22 15:18:08,306 - INFO - joeynmt.training - Epoch   6, Step:    33400, Batch Loss:     1.470985, Batch Acc: 0.542576, Tokens per Sec:     9647, Lr: 0.000300
2025-05-22 15:18:14,932 - INFO - joeynmt.training - Epoch   6, Step:    33500, Batch Loss:     1.521982, Batch Acc: 0.539646, Tokens per Sec:     9903, Lr: 0.000300
2025-05-22 15:18:14,932 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:18:14,932 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:18:22,229 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.21, acc:   0.50, generation: 7.2161[sec], evaluation: 0.0000[sec]
2025-05-22 15:18:22,374 - INFO - joeynmt.helpers - delete models/transformer_enit/30500.ckpt
2025-05-22 15:18:22,385 - INFO - joeynmt.training - Example #0
2025-05-22 15:18:22,385 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:18:22,385 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:18:22,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', 'staten', 'had', '<unk>', 'om', '40', 'procent', '<unk>', 'te', 'zijn', '.', '</s>']
2025-05-22 15:18:22,386 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:18:22,386 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:18:22,386 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die voor <unk> drie miljoen jaar de <unk> van de <unk> staten had <unk> om 40 procent <unk> te zijn.
2025-05-22 15:18:22,386 - INFO - joeynmt.training - Example #1
2025-05-22 15:18:22,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:18:22,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:18:22,386 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', 'zien', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:18:22,386 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:18:22,386 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:18:22,386 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg om dit <unk> <unk> te zien, omdat het niet de <unk> van de <unk>.
2025-05-22 15:18:22,387 - INFO - joeynmt.training - Example #2
2025-05-22 15:18:22,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:18:22,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:18:22,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:18:22,387 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:18:22,387 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:18:22,387 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:18:22,387 - INFO - joeynmt.training - Example #3
2025-05-22 15:18:22,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:18:22,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:18:22,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:18:22,388 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:18:22,389 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:18:22,389 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:18:22,389 - INFO - joeynmt.training - Example #4
2025-05-22 15:18:22,389 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:18:22,389 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:18:22,389 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:18:22,390 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:18:22,390 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:18:22,390 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:18:28,527 - INFO - joeynmt.training - Epoch   6, Step:    33600, Batch Loss:     1.546755, Batch Acc: 0.540387, Tokens per Sec:    10265, Lr: 0.000300
2025-05-22 15:18:34,592 - INFO - joeynmt.training - Epoch   6, Step:    33700, Batch Loss:     1.322576, Batch Acc: 0.544745, Tokens per Sec:    10930, Lr: 0.000300
2025-05-22 15:18:40,602 - INFO - joeynmt.training - Epoch   6, Step:    33800, Batch Loss:     1.748204, Batch Acc: 0.541307, Tokens per Sec:    11224, Lr: 0.000300
2025-05-22 15:18:46,841 - INFO - joeynmt.training - Epoch   6, Step:    33900, Batch Loss:     1.564243, Batch Acc: 0.542516, Tokens per Sec:    10776, Lr: 0.000300
2025-05-22 15:18:53,523 - INFO - joeynmt.training - Epoch   6, Step:    34000, Batch Loss:     1.314475, Batch Acc: 0.538500, Tokens per Sec:     9828, Lr: 0.000300
2025-05-22 15:18:53,523 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:18:53,523 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:19:01,470 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.20, acc:   0.50, generation: 7.8509[sec], evaluation: 0.0000[sec]
2025-05-22 15:19:01,471 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:19:01,609 - INFO - joeynmt.helpers - delete models/transformer_enit/32000.ckpt
2025-05-22 15:19:01,621 - INFO - joeynmt.training - Example #0
2025-05-22 15:19:01,621 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:19:01,621 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:19:01,621 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', 'om', '40', 'procent', '<unk>', 'te', 'zijn', '.', '</s>']
2025-05-22 15:19:01,622 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:19:01,622 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:19:01,622 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> <unk> van de <unk> <unk> staten om 40 procent <unk> te zijn.
2025-05-22 15:19:01,622 - INFO - joeynmt.training - Example #1
2025-05-22 15:19:01,622 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:19:01,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:19:01,622 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'sterk', 'genoeg', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'toont', '.', '</s>']
2025-05-22 15:19:01,622 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:19:01,622 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:19:01,623 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de <unk> van deze <unk> <unk>, omdat het niet de <unk> van de <unk> toont.
2025-05-22 15:19:01,623 - INFO - joeynmt.training - Example #2
2025-05-22 15:19:01,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:19:01,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:19:01,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:19:01,623 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:19:01,623 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:19:01,624 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:19:01,624 - INFO - joeynmt.training - Example #3
2025-05-22 15:19:01,624 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:19:01,624 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:19:01,624 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:19:01,625 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:19:01,625 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:19:01,625 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:19:01,625 - INFO - joeynmt.training - Example #4
2025-05-22 15:19:01,625 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:19:01,625 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:19:01,625 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:19:01,626 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:19:01,626 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:19:01,626 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:19:08,228 - INFO - joeynmt.training - Epoch   6, Step:    34100, Batch Loss:     1.425488, Batch Acc: 0.544319, Tokens per Sec:     9893, Lr: 0.000300
2025-05-22 15:19:14,982 - INFO - joeynmt.training - Epoch   6, Step:    34200, Batch Loss:     1.504031, Batch Acc: 0.540468, Tokens per Sec:     9743, Lr: 0.000300
2025-05-22 15:19:21,686 - INFO - joeynmt.training - Epoch   6, Step:    34300, Batch Loss:     1.607470, Batch Acc: 0.540533, Tokens per Sec:     9650, Lr: 0.000300
2025-05-22 15:19:28,328 - INFO - joeynmt.training - Epoch   6, Step:    34400, Batch Loss:     1.583988, Batch Acc: 0.542165, Tokens per Sec:    10033, Lr: 0.000300
2025-05-22 15:19:34,934 - INFO - joeynmt.training - Epoch   6, Step:    34500, Batch Loss:     1.514247, Batch Acc: 0.541874, Tokens per Sec:    10232, Lr: 0.000300
2025-05-22 15:19:34,935 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:19:34,935 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:19:41,997 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.17, acc:   0.50, generation: 6.9931[sec], evaluation: 0.0000[sec]
2025-05-22 15:19:41,998 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:19:42,125 - INFO - joeynmt.helpers - delete models/transformer_enit/29500.ckpt
2025-05-22 15:19:42,136 - INFO - joeynmt.training - Example #0
2025-05-22 15:19:42,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:19:42,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:19:42,138 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', '<unk>', '<unk>', '<unk>', ',', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2025-05-22 15:19:42,138 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:19:42,138 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:19:42,139 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> van de <unk> <unk> staten, <unk> <unk> <unk>, om 40 procent te <unk>.
2025-05-22 15:19:42,139 - INFO - joeynmt.training - Example #1
2025-05-22 15:19:42,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:19:42,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:19:42,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'om', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', '<unk>', 'is', '.', '</s>']
2025-05-22 15:19:42,139 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:19:42,140 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:19:42,140 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg om de <unk> van dit <unk> <unk>, omdat het niet <unk> is.
2025-05-22 15:19:42,140 - INFO - joeynmt.training - Example #2
2025-05-22 15:19:42,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:19:42,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:19:42,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:19:42,141 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:19:42,141 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:19:42,141 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:19:42,141 - INFO - joeynmt.training - Example #3
2025-05-22 15:19:42,141 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:19:42,141 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:19:42,141 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:19:42,142 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:19:42,142 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:19:42,142 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:19:42,142 - INFO - joeynmt.training - Example #4
2025-05-22 15:19:42,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:19:42,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:19:42,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'die', 'de', 'laatste', '25', 'jaar', '<unk>', '.', '</s>']
2025-05-22 15:19:42,143 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:19:42,143 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:19:42,143 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> die de laatste 25 jaar <unk>.
2025-05-22 15:19:48,206 - INFO - joeynmt.training - Epoch   6, Step:    34600, Batch Loss:     1.546924, Batch Acc: 0.538852, Tokens per Sec:    10498, Lr: 0.000300
2025-05-22 15:19:54,217 - INFO - joeynmt.training - Epoch   6, Step:    34700, Batch Loss:     1.511407, Batch Acc: 0.539352, Tokens per Sec:    10883, Lr: 0.000300
2025-05-22 15:20:00,213 - INFO - joeynmt.training - Epoch   6, Step:    34800, Batch Loss:     1.394617, Batch Acc: 0.541450, Tokens per Sec:    10860, Lr: 0.000300
2025-05-22 15:20:06,454 - INFO - joeynmt.training - Epoch   6, Step:    34900, Batch Loss:     1.508800, Batch Acc: 0.544504, Tokens per Sec:    10683, Lr: 0.000300
2025-05-22 15:20:13,157 - INFO - joeynmt.training - Epoch   6, Step:    35000, Batch Loss:     1.368331, Batch Acc: 0.545713, Tokens per Sec:     9804, Lr: 0.000300
2025-05-22 15:20:13,157 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:20:13,157 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:20:21,258 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.18, acc:   0.50, generation: 8.0156[sec], evaluation: 0.0000[sec]
2025-05-22 15:20:21,402 - INFO - joeynmt.helpers - delete models/transformer_enit/31000.ckpt
2025-05-22 15:20:21,414 - INFO - joeynmt.training - Example #0
2025-05-22 15:20:21,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:20:21,414 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:20:21,414 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:20:21,417 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:20:21,417 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:20:21,417 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, drie miljoen jaar de <unk> van de <unk> <unk> <unk>, <unk> <unk>, <unk> <unk> <unk>, <unk> <unk> <unk>.
2025-05-22 15:20:21,417 - INFO - joeynmt.training - Example #1
2025-05-22 15:20:21,417 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:20:21,417 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:20:21,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'om', 'dit', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', '<unk>', 'is', '.', '</s>']
2025-05-22 15:20:21,418 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:20:21,418 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:20:21,418 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg om dit <unk> te <unk>, omdat het niet <unk> is.
2025-05-22 15:20:21,418 - INFO - joeynmt.training - Example #2
2025-05-22 15:20:21,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:20:21,419 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:20:21,419 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:20:21,419 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:20:21,419 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:20:21,419 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:20:21,419 - INFO - joeynmt.training - Example #3
2025-05-22 15:20:21,419 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:20:21,419 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:20:21,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:20:21,420 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:20:21,420 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:20:21,420 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2025-05-22 15:20:21,420 - INFO - joeynmt.training - Example #4
2025-05-22 15:20:21,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:20:21,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:20:21,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:20:21,421 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:20:21,421 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:20:21,421 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:20:28,588 - INFO - joeynmt.training - Epoch   6, Step:    35100, Batch Loss:     1.664371, Batch Acc: 0.544340, Tokens per Sec:     8791, Lr: 0.000300
2025-05-22 15:20:35,262 - INFO - joeynmt.training - Epoch   6, Step:    35200, Batch Loss:     1.494656, Batch Acc: 0.545995, Tokens per Sec:    10034, Lr: 0.000300
2025-05-22 15:20:41,900 - INFO - joeynmt.training - Epoch   6, Step:    35300, Batch Loss:     1.350154, Batch Acc: 0.545234, Tokens per Sec:     9984, Lr: 0.000300
2025-05-22 15:20:48,681 - INFO - joeynmt.training - Epoch   6, Step:    35400, Batch Loss:     1.473643, Batch Acc: 0.539238, Tokens per Sec:     9597, Lr: 0.000300
2025-05-22 15:20:55,444 - INFO - joeynmt.training - Epoch   6, Step:    35500, Batch Loss:     1.515276, Batch Acc: 0.537350, Tokens per Sec:     9724, Lr: 0.000300
2025-05-22 15:20:55,444 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:20:55,445 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:21:02,724 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.15, acc:   0.50, generation: 7.2110[sec], evaluation: 0.0000[sec]
2025-05-22 15:21:02,725 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:21:02,856 - INFO - joeynmt.helpers - delete models/transformer_enit/33500.ckpt
2025-05-22 15:21:02,866 - INFO - joeynmt.training - Example #0
2025-05-22 15:21:02,866 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:21:02,866 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:21:02,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', ',', 'dat', 'de', '<unk>', '<unk>', ',', 'die', '<unk>', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', 'is', '.', '</s>']
2025-05-22 15:21:02,867 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:21:02,867 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:21:02,867 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien, dat de <unk> <unk>, die <unk> <unk> <unk>, drie miljoen jaar de <unk> van de <unk> <unk> <unk>, <unk> <unk> <unk> is.
2025-05-22 15:21:02,867 - INFO - joeynmt.training - Example #1
2025-05-22 15:21:02,867 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:21:02,867 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:21:02,867 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'erg', 'genoeg', '<unk>', 'is', 'dat', '<unk>', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:21:02,867 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:21:02,867 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:21:02,867 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet erg genoeg <unk> is dat <unk> <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 15:21:02,867 - INFO - joeynmt.training - Example #2
2025-05-22 15:21:02,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:21:02,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:21:02,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:21:02,868 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:21:02,868 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:21:02,868 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:21:02,868 - INFO - joeynmt.training - Example #3
2025-05-22 15:21:02,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:21:02,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:21:02,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:21:02,869 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:21:02,869 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:21:02,869 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:21:02,869 - INFO - joeynmt.training - Example #4
2025-05-22 15:21:02,869 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:21:02,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:21:02,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:21:02,869 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:21:02,870 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:21:02,870 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> <unk> in de laatste 25 jaar.
2025-05-22 15:21:08,905 - INFO - joeynmt.training - Epoch   6, Step:    35600, Batch Loss:     1.503294, Batch Acc: 0.540171, Tokens per Sec:    10802, Lr: 0.000300
2025-05-22 15:21:11,711 - INFO - joeynmt.training - Epoch   6: total training loss 8761.84
2025-05-22 15:21:11,711 - INFO - joeynmt.training - EPOCH 7
2025-05-22 15:21:14,899 - INFO - joeynmt.training - Epoch   7, Step:    35700, Batch Loss:     1.396881, Batch Acc: 0.560218, Tokens per Sec:    10781, Lr: 0.000300
2025-05-22 15:21:20,867 - INFO - joeynmt.training - Epoch   7, Step:    35800, Batch Loss:     1.376827, Batch Acc: 0.556455, Tokens per Sec:    10936, Lr: 0.000300
2025-05-22 15:21:27,024 - INFO - joeynmt.training - Epoch   7, Step:    35900, Batch Loss:     1.467160, Batch Acc: 0.559196, Tokens per Sec:    10757, Lr: 0.000300
2025-05-22 15:21:33,918 - INFO - joeynmt.training - Epoch   7, Step:    36000, Batch Loss:     1.418132, Batch Acc: 0.553025, Tokens per Sec:     9528, Lr: 0.000300
2025-05-22 15:21:33,919 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:21:33,919 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:21:41,353 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.20, acc:   0.50, generation: 7.3481[sec], evaluation: 0.0000[sec]
2025-05-22 15:21:41,497 - INFO - joeynmt.helpers - delete models/transformer_enit/33000.ckpt
2025-05-22 15:21:41,510 - INFO - joeynmt.training - Example #0
2025-05-22 15:21:41,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:21:41,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:21:41,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', 'staten', ',', '<unk>', '<unk>', ',', 'met', '40', 'procent', '.', '</s>']
2025-05-22 15:21:41,511 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:21:41,511 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:21:41,511 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> <unk> van de <unk> staten, <unk> <unk>, met 40 procent.
2025-05-22 15:21:41,511 - INFO - joeynmt.training - Example #1
2025-05-22 15:21:41,511 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:21:41,511 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:21:41,511 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', 'is', 'dat', 'het', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:21:41,511 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:21:41,511 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:21:41,511 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg <unk> is dat het <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:21:41,511 - INFO - joeynmt.training - Example #2
2025-05-22 15:21:41,512 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:21:41,512 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:21:41,512 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:21:41,512 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:21:41,512 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:21:41,512 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk> <unk>.
2025-05-22 15:21:41,512 - INFO - joeynmt.training - Example #3
2025-05-22 15:21:41,512 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:21:41,512 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:21:41,512 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'het', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:21:41,513 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:21:41,513 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:21:41,513 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het <unk> en <unk> in de zomer.
2025-05-22 15:21:41,513 - INFO - joeynmt.training - Example #4
2025-05-22 15:21:41,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:21:41,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:21:41,513 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:21:41,513 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:21:41,513 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:21:41,513 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:21:48,230 - INFO - joeynmt.training - Epoch   7, Step:    36100, Batch Loss:     1.402938, Batch Acc: 0.555828, Tokens per Sec:     9429, Lr: 0.000300
2025-05-22 15:21:54,719 - INFO - joeynmt.training - Epoch   7, Step:    36200, Batch Loss:     1.392213, Batch Acc: 0.556984, Tokens per Sec:     9979, Lr: 0.000300
2025-05-22 15:22:01,367 - INFO - joeynmt.training - Epoch   7, Step:    36300, Batch Loss:     1.390505, Batch Acc: 0.561756, Tokens per Sec:     9883, Lr: 0.000300
2025-05-22 15:22:07,989 - INFO - joeynmt.training - Epoch   7, Step:    36400, Batch Loss:     1.314315, Batch Acc: 0.558473, Tokens per Sec:    10018, Lr: 0.000300
2025-05-22 15:22:14,657 - INFO - joeynmt.training - Epoch   7, Step:    36500, Batch Loss:     1.484216, Batch Acc: 0.555888, Tokens per Sec:    10217, Lr: 0.000300
2025-05-22 15:22:14,657 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:22:14,657 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:22:21,819 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.18, acc:   0.50, generation: 7.0938[sec], evaluation: 0.0000[sec]
2025-05-22 15:22:21,948 - INFO - joeynmt.helpers - delete models/transformer_enit/36000.ckpt
2025-05-22 15:22:21,955 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit/36000.ckpt
2025-05-22 15:22:21,955 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit\36000.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit\\36000.ckpt')
2025-05-22 15:22:21,956 - INFO - joeynmt.training - Example #0
2025-05-22 15:22:21,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:22:21,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:22:21,957 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:22:21,957 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:22:21,957 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:22:21,957 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> <unk> voor <unk> drie miljoen jaar <unk> <unk>.
2025-05-22 15:22:21,957 - INFO - joeynmt.training - Example #1
2025-05-22 15:22:21,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:22:21,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:22:21,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:22:21,958 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:22:21,958 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:22:21,958 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg om dit <unk> <unk> te <unk>, omdat het niet <unk> van de <unk> laat zien.
2025-05-22 15:22:21,958 - INFO - joeynmt.training - Example #2
2025-05-22 15:22:21,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:22:21,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:22:21,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:22:21,959 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:22:21,959 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:22:21,959 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:22:21,959 - INFO - joeynmt.training - Example #3
2025-05-22 15:22:21,959 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:22:21,959 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:22:21,959 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:22:21,959 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:22:21,959 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:22:21,959 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:22:21,960 - INFO - joeynmt.training - Example #4
2025-05-22 15:22:21,960 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:22:21,960 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:22:21,960 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', '<unk>', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 15:22:21,960 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:22:21,960 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:22:21,960 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> <unk> in de afgelopen 25 jaar.
2025-05-22 15:22:28,109 - INFO - joeynmt.training - Epoch   7, Step:    36600, Batch Loss:     1.432310, Batch Acc: 0.557532, Tokens per Sec:    10067, Lr: 0.000300
2025-05-22 15:22:34,173 - INFO - joeynmt.training - Epoch   7, Step:    36700, Batch Loss:     1.553632, Batch Acc: 0.552840, Tokens per Sec:    10957, Lr: 0.000300
2025-05-22 15:22:41,130 - INFO - joeynmt.training - Epoch   7, Step:    36800, Batch Loss:     1.423751, Batch Acc: 0.545406, Tokens per Sec:     9495, Lr: 0.000300
2025-05-22 15:22:47,889 - INFO - joeynmt.training - Epoch   7, Step:    36900, Batch Loss:     1.668369, Batch Acc: 0.552501, Tokens per Sec:     9937, Lr: 0.000300
2025-05-22 15:22:54,589 - INFO - joeynmt.training - Epoch   7, Step:    37000, Batch Loss:     1.373231, Batch Acc: 0.551418, Tokens per Sec:    10016, Lr: 0.000300
2025-05-22 15:22:54,590 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:22:54,590 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:23:01,978 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.21, acc:   0.50, generation: 7.3024[sec], evaluation: 0.0000[sec]
2025-05-22 15:23:01,983 - INFO - joeynmt.training - Example #0
2025-05-22 15:23:01,983 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:23:01,984 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:23:01,984 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', ',', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2025-05-22 15:23:01,985 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:23:01,985 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:23:01,985 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien, om te <unk> dat de <unk> <unk>, die drie miljoen jaar de <unk> van de <unk> <unk> staten, om 40 procent <unk> te <unk>.
2025-05-22 15:23:01,986 - INFO - joeynmt.training - Example #1
2025-05-22 15:23:01,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:23:01,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:23:01,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', '<unk>', 'genoeg', '<unk>', 'van', 'het', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:23:01,987 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:23:01,987 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:23:01,987 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet <unk> genoeg <unk> van het <unk> <unk>, omdat het niet de <unk> van de <unk> <unk>.
2025-05-22 15:23:01,988 - INFO - joeynmt.training - Example #2
2025-05-22 15:23:01,988 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:23:01,988 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:23:01,988 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:23:01,989 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:23:01,989 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:23:01,989 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:23:01,989 - INFO - joeynmt.training - Example #3
2025-05-22 15:23:01,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:23:01,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:23:01,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:23:01,990 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:23:01,990 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:23:01,990 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:23:01,990 - INFO - joeynmt.training - Example #4
2025-05-22 15:23:01,990 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:23:01,991 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:23:01,991 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:23:01,991 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:23:01,992 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:23:01,992 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:23:08,657 - INFO - joeynmt.training - Epoch   7, Step:    37100, Batch Loss:     1.375926, Batch Acc: 0.548908, Tokens per Sec:    10090, Lr: 0.000300
2025-05-22 15:23:15,278 - INFO - joeynmt.training - Epoch   7, Step:    37200, Batch Loss:     1.470459, Batch Acc: 0.544966, Tokens per Sec:     9891, Lr: 0.000300
2025-05-22 15:23:21,936 - INFO - joeynmt.training - Epoch   7, Step:    37300, Batch Loss:     1.525753, Batch Acc: 0.552856, Tokens per Sec:    10058, Lr: 0.000300
2025-05-22 15:23:28,513 - INFO - joeynmt.training - Epoch   7, Step:    37400, Batch Loss:     1.387530, Batch Acc: 0.551512, Tokens per Sec:    10047, Lr: 0.000300
2025-05-22 15:23:34,892 - INFO - joeynmt.training - Epoch   7, Step:    37500, Batch Loss:     1.598892, Batch Acc: 0.554807, Tokens per Sec:    10185, Lr: 0.000300
2025-05-22 15:23:34,893 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:23:34,893 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:23:41,984 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.50, generation: 7.0316[sec], evaluation: 0.0000[sec]
2025-05-22 15:23:41,989 - INFO - joeynmt.training - Example #0
2025-05-22 15:23:41,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:23:41,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:23:41,990 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', ',', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', 'procent', '.', '</s>']
2025-05-22 15:23:41,991 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:23:41,991 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:23:41,991 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien, om te <unk> dat de <unk> <unk> <unk>, die drie miljoen jaar de <unk> van de <unk> <unk> staten, met <unk> procent.
2025-05-22 15:23:41,991 - INFO - joeynmt.training - Example #1
2025-05-22 15:23:41,991 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:23:41,991 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:23:41,991 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'erg', 'genoeg', '<unk>', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:23:41,992 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:23:41,992 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:23:41,992 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet erg genoeg <unk> <unk> <unk>, omdat het niet de <unk> van de <unk> van de <unk>.
2025-05-22 15:23:41,992 - INFO - joeynmt.training - Example #2
2025-05-22 15:23:41,992 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:23:41,992 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:23:41,992 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 15:23:41,993 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:23:41,993 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:23:41,993 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons mondiale <unk>.
2025-05-22 15:23:41,993 - INFO - joeynmt.training - Example #3
2025-05-22 15:23:41,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:23:41,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:23:41,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:23:41,994 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:23:41,994 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:23:41,995 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:23:41,995 - INFO - joeynmt.training - Example #4
2025-05-22 15:23:41,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:23:41,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:23:41,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', ',', 'is', 'een', '<unk>', '<unk>', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 15:23:41,995 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:23:41,996 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:23:41,996 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien, is een <unk> <unk> in de afgelopen 25 jaar.
2025-05-22 15:23:48,174 - INFO - joeynmt.training - Epoch   7, Step:    37600, Batch Loss:     1.570643, Batch Acc: 0.548174, Tokens per Sec:    10551, Lr: 0.000300
2025-05-22 15:23:54,249 - INFO - joeynmt.training - Epoch   7, Step:    37700, Batch Loss:     1.496059, Batch Acc: 0.547073, Tokens per Sec:    10588, Lr: 0.000300
2025-05-22 15:24:00,322 - INFO - joeynmt.training - Epoch   7, Step:    37800, Batch Loss:     1.536564, Batch Acc: 0.545914, Tokens per Sec:    10973, Lr: 0.000300
2025-05-22 15:24:06,895 - INFO - joeynmt.training - Epoch   7, Step:    37900, Batch Loss:     1.556882, Batch Acc: 0.554325, Tokens per Sec:    10211, Lr: 0.000300
2025-05-22 15:24:13,499 - INFO - joeynmt.training - Epoch   7, Step:    38000, Batch Loss:     1.474041, Batch Acc: 0.547180, Tokens per Sec:     9641, Lr: 0.000300
2025-05-22 15:24:13,499 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:24:13,499 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:24:21,480 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.20, acc:   0.50, generation: 7.9021[sec], evaluation: 0.0000[sec]
2025-05-22 15:24:21,485 - INFO - joeynmt.training - Example #0
2025-05-22 15:24:21,485 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:24:21,485 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:24:21,485 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '40', '%', '<unk>', '.', '</s>']
2025-05-22 15:24:21,487 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:24:21,487 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:24:21,487 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> de <unk> van de <unk> <unk> <unk>, 40% <unk>.
2025-05-22 15:24:21,487 - INFO - joeynmt.training - Example #1
2025-05-22 15:24:21,487 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:24:21,487 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:24:21,487 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', 'is', 'dat', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:24:21,488 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:24:21,488 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:24:21,489 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg <unk> is dat <unk> <unk>, omdat het niet de <unk> van de <unk> van de <unk>.
2025-05-22 15:24:21,489 - INFO - joeynmt.training - Example #2
2025-05-22 15:24:21,489 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:24:21,489 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:24:21,489 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:24:21,490 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:24:21,490 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:24:21,490 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:24:21,490 - INFO - joeynmt.training - Example #3
2025-05-22 15:24:21,491 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:24:21,491 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:24:21,491 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:24:21,491 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:24:21,491 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:24:21,492 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:24:21,492 - INFO - joeynmt.training - Example #4
2025-05-22 15:24:21,492 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:24:21,492 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:24:21,492 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'zien', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 15:24:21,492 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:24:21,493 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:24:21,493 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> zien wat er in de laatste 25 jaar is gebeurd.
2025-05-22 15:24:28,251 - INFO - joeynmt.training - Epoch   7, Step:    38100, Batch Loss:     1.480580, Batch Acc: 0.554615, Tokens per Sec:     9758, Lr: 0.000300
2025-05-22 15:24:35,040 - INFO - joeynmt.training - Epoch   7, Step:    38200, Batch Loss:     1.192829, Batch Acc: 0.550104, Tokens per Sec:     9778, Lr: 0.000300
2025-05-22 15:24:41,855 - INFO - joeynmt.training - Epoch   7, Step:    38300, Batch Loss:     1.393882, Batch Acc: 0.551177, Tokens per Sec:     9622, Lr: 0.000300
2025-05-22 15:24:48,526 - INFO - joeynmt.training - Epoch   7, Step:    38400, Batch Loss:     1.469789, Batch Acc: 0.551555, Tokens per Sec:     9963, Lr: 0.000300
2025-05-22 15:24:55,068 - INFO - joeynmt.training - Epoch   7, Step:    38500, Batch Loss:     1.507034, Batch Acc: 0.548137, Tokens per Sec:    10180, Lr: 0.000300
2025-05-22 15:24:55,069 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:24:55,069 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:25:02,241 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.18, acc:   0.50, generation: 7.1021[sec], evaluation: 0.0000[sec]
2025-05-22 15:25:02,380 - INFO - joeynmt.helpers - delete models/transformer_enit/34000.ckpt
2025-05-22 15:25:02,392 - INFO - joeynmt.training - Example #0
2025-05-22 15:25:02,392 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:25:02,392 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:25:02,392 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', 'met', '40', 'procent', '.', '</s>']
2025-05-22 15:25:02,393 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:25:02,393 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:25:02,393 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk>, met 40 procent.
2025-05-22 15:25:02,393 - INFO - joeynmt.training - Example #1
2025-05-22 15:25:02,393 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:25:02,393 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:25:02,393 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:25:02,394 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:25:02,394 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:25:02,394 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 15:25:02,394 - INFO - joeynmt.training - Example #2
2025-05-22 15:25:02,394 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:25:02,394 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:25:02,394 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 15:25:02,394 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:25:02,394 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:25:02,394 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons mondiale <unk>.
2025-05-22 15:25:02,395 - INFO - joeynmt.training - Example #3
2025-05-22 15:25:02,395 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:25:02,395 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:25:02,395 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:25:02,395 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:25:02,395 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:25:02,395 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:25:02,395 - INFO - joeynmt.training - Example #4
2025-05-22 15:25:02,395 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:25:02,395 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:25:02,395 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'zien', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'gebeurt', '.', '</s>']
2025-05-22 15:25:02,396 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:25:02,396 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:25:02,396 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> zien wat er in de laatste 25 jaar gebeurt.
2025-05-22 15:25:09,700 - INFO - joeynmt.training - Epoch   7, Step:    38600, Batch Loss:     1.590588, Batch Acc: 0.548574, Tokens per Sec:     8925, Lr: 0.000300
2025-05-22 15:25:17,736 - INFO - joeynmt.training - Epoch   7, Step:    38700, Batch Loss:     1.596252, Batch Acc: 0.550481, Tokens per Sec:     8153, Lr: 0.000300
2025-05-22 15:25:24,003 - INFO - joeynmt.training - Epoch   7, Step:    38800, Batch Loss:     1.481332, Batch Acc: 0.553508, Tokens per Sec:    10525, Lr: 0.000300
2025-05-22 15:25:30,785 - INFO - joeynmt.training - Epoch   7, Step:    38900, Batch Loss:     1.586353, Batch Acc: 0.543988, Tokens per Sec:     9872, Lr: 0.000300
2025-05-22 15:25:37,388 - INFO - joeynmt.training - Epoch   7, Step:    39000, Batch Loss:     1.344202, Batch Acc: 0.548119, Tokens per Sec:     9877, Lr: 0.000300
2025-05-22 15:25:37,388 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:25:37,389 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:25:44,871 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.20, acc:   0.50, generation: 7.4192[sec], evaluation: 0.0000[sec]
2025-05-22 15:25:44,877 - INFO - joeynmt.training - Example #0
2025-05-22 15:25:44,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:25:44,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:25:44,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'dat', 'de', '<unk>', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2025-05-22 15:25:44,878 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:25:44,879 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:25:44,879 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien dat de <unk> <unk> <unk>, die drie miljoen jaar de <unk> van de <unk> <unk> <unk> <unk> <unk> <unk> <unk> om 40 procent te <unk>.
2025-05-22 15:25:44,879 - INFO - joeynmt.training - Example #1
2025-05-22 15:25:44,879 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:25:44,879 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:25:44,879 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'veel', '<unk>', '<unk>', 'van', 'dit', '<unk>', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:25:44,880 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:25:44,880 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:25:44,880 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet veel <unk> <unk> van dit <unk> <unk> <unk>, omdat het niet de <unk> van de <unk> <unk>.
2025-05-22 15:25:44,880 - INFO - joeynmt.training - Example #2
2025-05-22 15:25:44,880 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:25:44,880 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:25:44,880 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 15:25:44,881 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:25:44,881 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:25:44,882 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons mondiale <unk>.
2025-05-22 15:25:44,882 - INFO - joeynmt.training - Example #3
2025-05-22 15:25:44,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:25:44,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:25:44,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:25:44,883 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:25:44,883 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:25:44,883 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:25:44,883 - INFO - joeynmt.training - Example #4
2025-05-22 15:25:44,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:25:44,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:25:44,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 15:25:44,884 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:25:44,884 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:25:44,885 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> van wat er in de laatste 25 jaar is gebeurd.
2025-05-22 15:25:51,614 - INFO - joeynmt.training - Epoch   7, Step:    39100, Batch Loss:     1.584639, Batch Acc: 0.552303, Tokens per Sec:     9798, Lr: 0.000300
2025-05-22 15:25:58,386 - INFO - joeynmt.training - Epoch   7, Step:    39200, Batch Loss:     1.531045, Batch Acc: 0.549004, Tokens per Sec:     9857, Lr: 0.000300
2025-05-22 15:26:05,051 - INFO - joeynmt.training - Epoch   7, Step:    39300, Batch Loss:     1.391468, Batch Acc: 0.552028, Tokens per Sec:     9660, Lr: 0.000300
2025-05-22 15:26:12,281 - INFO - joeynmt.training - Epoch   7, Step:    39400, Batch Loss:     1.404425, Batch Acc: 0.549654, Tokens per Sec:     8996, Lr: 0.000300
2025-05-22 15:26:18,427 - INFO - joeynmt.training - Epoch   7, Step:    39500, Batch Loss:     1.288462, Batch Acc: 0.551027, Tokens per Sec:    10914, Lr: 0.000300
2025-05-22 15:26:18,428 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:26:18,428 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:26:25,282 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.19, acc:   0.50, generation: 6.7847[sec], evaluation: 0.0000[sec]
2025-05-22 15:26:25,286 - INFO - joeynmt.training - Example #0
2025-05-22 15:26:25,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:26:25,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:26:25,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:26:25,288 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:26:25,288 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:26:25,288 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>.
2025-05-22 15:26:25,288 - INFO - joeynmt.training - Example #1
2025-05-22 15:26:25,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:26:25,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:26:25,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'sterk', 'genoeg', '<unk>', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'toont', '.', '</s>']
2025-05-22 15:26:25,289 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:26:25,290 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:26:25,290 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg <unk> de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> toont.
2025-05-22 15:26:25,290 - INFO - joeynmt.training - Example #2
2025-05-22 15:26:25,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:26:25,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:26:25,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:26:25,291 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:26:25,291 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:26:25,291 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:26:25,291 - INFO - joeynmt.training - Example #3
2025-05-22 15:26:25,291 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:26:25,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:26:25,292 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:26:25,292 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:26:25,292 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:26:25,292 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:26:25,293 - INFO - joeynmt.training - Example #4
2025-05-22 15:26:25,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:26:25,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:26:25,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'wat', 'er', 'gebeurt', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 15:26:25,294 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:26:25,294 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:26:25,294 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> wat er gebeurt in de afgelopen 25 jaar.
2025-05-22 15:26:31,301 - INFO - joeynmt.training - Epoch   7, Step:    39600, Batch Loss:     1.472021, Batch Acc: 0.552997, Tokens per Sec:    11034, Lr: 0.000300
2025-05-22 15:26:37,440 - INFO - joeynmt.training - Epoch   7, Step:    39700, Batch Loss:     1.419905, Batch Acc: 0.550579, Tokens per Sec:    10696, Lr: 0.000300
2025-05-22 15:26:43,608 - INFO - joeynmt.training - Epoch   7, Step:    39800, Batch Loss:     1.443552, Batch Acc: 0.546814, Tokens per Sec:    10717, Lr: 0.000300
2025-05-22 15:26:50,218 - INFO - joeynmt.training - Epoch   7, Step:    39900, Batch Loss:     1.381196, Batch Acc: 0.545320, Tokens per Sec:    10135, Lr: 0.000300
2025-05-22 15:26:56,970 - INFO - joeynmt.training - Epoch   7, Step:    40000, Batch Loss:     1.416740, Batch Acc: 0.547057, Tokens per Sec:     9756, Lr: 0.000300
2025-05-22 15:26:56,971 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:26:56,971 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:27:05,013 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.19, acc:   0.50, generation: 7.9460[sec], evaluation: 0.0000[sec]
2025-05-22 15:27:05,018 - INFO - joeynmt.training - Example #0
2025-05-22 15:27:05,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:27:05,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:27:05,019 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '40', '%', '.', '</s>']
2025-05-22 15:27:05,020 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:27:05,020 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:27:05,020 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien dat de <unk> <unk> die drie miljoen jaar <unk> <unk> <unk>, die drie miljoen jaar de <unk> van de <unk> <unk> <unk>, 40%.
2025-05-22 15:27:05,020 - INFO - joeynmt.training - Example #1
2025-05-22 15:27:05,020 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:27:05,021 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:27:05,021 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:27:05,021 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:27:05,022 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:27:05,022 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 15:27:05,022 - INFO - joeynmt.training - Example #2
2025-05-22 15:27:05,022 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:27:05,022 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:27:05,022 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:27:05,022 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:27:05,022 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:27:05,023 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:27:05,023 - INFO - joeynmt.training - Example #3
2025-05-22 15:27:05,023 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:27:05,023 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:27:05,023 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:27:05,024 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:27:05,024 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:27:05,024 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:27:05,024 - INFO - joeynmt.training - Example #4
2025-05-22 15:27:05,024 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:27:05,024 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:27:05,024 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:27:05,025 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:27:05,025 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:27:05,025 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> in de laatste 25 jaar.
2025-05-22 15:27:11,917 - INFO - joeynmt.training - Epoch   7, Step:    40100, Batch Loss:     1.419886, Batch Acc: 0.547554, Tokens per Sec:     9808, Lr: 0.000210
2025-05-22 15:27:18,864 - INFO - joeynmt.training - Epoch   7, Step:    40200, Batch Loss:     1.506286, Batch Acc: 0.550097, Tokens per Sec:     9475, Lr: 0.000210
2025-05-22 15:27:27,134 - INFO - joeynmt.training - Epoch   7, Step:    40300, Batch Loss:     1.436287, Batch Acc: 0.555054, Tokens per Sec:     7975, Lr: 0.000210
2025-05-22 15:27:34,308 - INFO - joeynmt.training - Epoch   7, Step:    40400, Batch Loss:     1.457281, Batch Acc: 0.547347, Tokens per Sec:     9357, Lr: 0.000210
2025-05-22 15:27:40,480 - INFO - joeynmt.training - Epoch   7, Step:    40500, Batch Loss:     1.507069, Batch Acc: 0.552346, Tokens per Sec:    10991, Lr: 0.000210
2025-05-22 15:27:40,481 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:27:40,481 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:27:48,052 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.08, acc:   0.50, generation: 7.4367[sec], evaluation: 0.0000[sec]
2025-05-22 15:27:48,053 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:27:48,244 - INFO - joeynmt.helpers - delete models/transformer_enit/38500.ckpt
2025-05-22 15:27:48,256 - INFO - joeynmt.training - Example #0
2025-05-22 15:27:48,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:27:48,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:27:48,256 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', ',', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:27:48,257 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:27:48,257 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:27:48,257 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien, om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> van de <unk> <unk> <unk>, <unk> <unk>, <unk> <unk>, <unk> <unk> <unk>.
2025-05-22 15:27:48,258 - INFO - joeynmt.training - Example #1
2025-05-22 15:27:48,258 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:27:48,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:27:48,258 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', '<unk>', 'genoeg', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:27:48,259 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:27:48,259 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:27:48,259 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet <unk> genoeg <unk> van dit <unk> <unk>, omdat het niet de <unk> van het <unk> <unk>.
2025-05-22 15:27:48,259 - INFO - joeynmt.training - Example #2
2025-05-22 15:27:48,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:27:48,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:27:48,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:27:48,260 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:27:48,260 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:27:48,260 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:27:48,260 - INFO - joeynmt.training - Example #3
2025-05-22 15:27:48,260 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:27:48,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:27:48,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:27:48,262 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:27:48,262 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:27:48,262 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:27:48,262 - INFO - joeynmt.training - Example #4
2025-05-22 15:27:48,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:27:48,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:27:48,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', ',', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:27:48,263 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:27:48,263 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:27:48,263 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien, is een <unk> in de laatste 25 jaar.
2025-05-22 15:27:54,377 - INFO - joeynmt.training - Epoch   7, Step:    40600, Batch Loss:     1.484175, Batch Acc: 0.548076, Tokens per Sec:    10530, Lr: 0.000210
2025-05-22 15:28:00,512 - INFO - joeynmt.training - Epoch   7, Step:    40700, Batch Loss:     1.451444, Batch Acc: 0.547579, Tokens per Sec:    10549, Lr: 0.000210
2025-05-22 15:28:06,694 - INFO - joeynmt.training - Epoch   7, Step:    40800, Batch Loss:     1.571862, Batch Acc: 0.555342, Tokens per Sec:    10861, Lr: 0.000210
2025-05-22 15:28:13,448 - INFO - joeynmt.training - Epoch   7, Step:    40900, Batch Loss:     1.322436, Batch Acc: 0.548552, Tokens per Sec:     9938, Lr: 0.000210
2025-05-22 15:28:20,008 - INFO - joeynmt.training - Epoch   7, Step:    41000, Batch Loss:     1.326552, Batch Acc: 0.556424, Tokens per Sec:    10084, Lr: 0.000210
2025-05-22 15:28:20,009 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:28:20,009 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:28:27,707 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.08, acc:   0.50, generation: 7.6081[sec], evaluation: 0.0000[sec]
2025-05-22 15:28:27,852 - INFO - joeynmt.helpers - delete models/transformer_enit/36500.ckpt
2025-05-22 15:28:27,862 - INFO - joeynmt.training - Example #0
2025-05-22 15:28:27,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:28:27,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:28:27,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '40', 'procent', '.', '</s>']
2025-05-22 15:28:27,863 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:28:27,863 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:28:27,864 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk>, <unk> <unk>, 40 procent.
2025-05-22 15:28:27,864 - INFO - joeynmt.training - Example #1
2025-05-22 15:28:27,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:28:27,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:28:27,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:28:27,864 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:28:27,865 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:28:27,865 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 15:28:27,865 - INFO - joeynmt.training - Example #2
2025-05-22 15:28:27,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:28:27,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:28:27,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:28:27,865 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:28:27,865 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:28:27,865 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:28:27,866 - INFO - joeynmt.training - Example #3
2025-05-22 15:28:27,866 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:28:27,866 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:28:27,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:28:27,866 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:28:27,866 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:28:27,866 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:28:27,866 - INFO - joeynmt.training - Example #4
2025-05-22 15:28:27,866 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:28:27,866 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:28:27,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:28:27,867 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:28:27,867 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:28:27,867 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:28:34,484 - INFO - joeynmt.training - Epoch   7, Step:    41100, Batch Loss:     1.357571, Batch Acc: 0.550563, Tokens per Sec:     9863, Lr: 0.000210
2025-05-22 15:28:41,145 - INFO - joeynmt.training - Epoch   7, Step:    41200, Batch Loss:     1.523789, Batch Acc: 0.550143, Tokens per Sec:     9718, Lr: 0.000210
2025-05-22 15:28:47,807 - INFO - joeynmt.training - Epoch   7, Step:    41300, Batch Loss:     1.434528, Batch Acc: 0.554873, Tokens per Sec:     9971, Lr: 0.000210
2025-05-22 15:28:54,504 - INFO - joeynmt.training - Epoch   7, Step:    41400, Batch Loss:     1.386540, Batch Acc: 0.551425, Tokens per Sec:     9978, Lr: 0.000210
2025-05-22 15:29:00,654 - INFO - joeynmt.training - Epoch   7, Step:    41500, Batch Loss:     1.380806, Batch Acc: 0.556012, Tokens per Sec:    10807, Lr: 0.000210
2025-05-22 15:29:00,654 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:29:00,655 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:29:07,277 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.07, acc:   0.51, generation: 6.5647[sec], evaluation: 0.0000[sec]
2025-05-22 15:29:07,278 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:29:07,416 - INFO - joeynmt.helpers - delete models/transformer_enit/35000.ckpt
2025-05-22 15:29:07,427 - INFO - joeynmt.training - Example #0
2025-05-22 15:29:07,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:29:07,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:29:07,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', 'met', '40', 'procent', '.', '</s>']
2025-05-22 15:29:07,428 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:29:07,428 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:29:07,428 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die drie miljoen jaar de <unk> van de <unk> <unk> <unk> <unk>, <unk> met 40 procent.
2025-05-22 15:29:07,428 - INFO - joeynmt.training - Example #1
2025-05-22 15:29:07,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:29:07,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:29:07,429 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', '<unk>', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:29:07,429 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:29:07,429 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:29:07,429 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet <unk> genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 15:29:07,429 - INFO - joeynmt.training - Example #2
2025-05-22 15:29:07,429 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:29:07,429 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:29:07,429 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:29:07,430 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:29:07,430 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:29:07,430 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:29:07,430 - INFO - joeynmt.training - Example #3
2025-05-22 15:29:07,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:29:07,430 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:29:07,430 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:29:07,430 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:29:07,430 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:29:07,430 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:29:07,431 - INFO - joeynmt.training - Example #4
2025-05-22 15:29:07,431 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:29:07,431 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:29:07,431 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:29:07,431 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:29:07,431 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:29:07,431 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:29:12,975 - INFO - joeynmt.training - Epoch   7: total training loss 8594.79
2025-05-22 15:29:12,975 - INFO - joeynmt.training - EPOCH 8
2025-05-22 15:29:13,609 - INFO - joeynmt.training - Epoch   8, Step:    41600, Batch Loss:     1.327494, Batch Acc: 0.561497, Tokens per Sec:    11234, Lr: 0.000210
2025-05-22 15:29:19,719 - INFO - joeynmt.training - Epoch   8, Step:    41700, Batch Loss:     1.487233, Batch Acc: 0.570388, Tokens per Sec:    10697, Lr: 0.000210
2025-05-22 15:29:25,935 - INFO - joeynmt.training - Epoch   8, Step:    41800, Batch Loss:     1.426128, Batch Acc: 0.571032, Tokens per Sec:    10669, Lr: 0.000210
2025-05-22 15:29:32,637 - INFO - joeynmt.training - Epoch   8, Step:    41900, Batch Loss:     1.379765, Batch Acc: 0.568954, Tokens per Sec:     9880, Lr: 0.000210
2025-05-22 15:29:39,380 - INFO - joeynmt.training - Epoch   8, Step:    42000, Batch Loss:     1.269307, Batch Acc: 0.574400, Tokens per Sec:     9880, Lr: 0.000210
2025-05-22 15:29:39,381 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:29:39,381 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:29:46,764 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.09, acc:   0.50, generation: 7.2922[sec], evaluation: 0.0000[sec]
2025-05-22 15:29:46,924 - INFO - joeynmt.helpers - delete models/transformer_enit/34500.ckpt
2025-05-22 15:29:46,934 - INFO - joeynmt.training - Example #0
2025-05-22 15:29:46,934 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:29:46,935 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:29:46,935 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', '<unk>', 'met', '40', 'procent', '.', '</s>']
2025-05-22 15:29:46,935 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:29:46,935 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:29:46,935 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die drie miljoen jaar de <unk> van de <unk> <unk> <unk> <unk>, <unk> met 40 procent.
2025-05-22 15:29:46,935 - INFO - joeynmt.training - Example #1
2025-05-22 15:29:46,935 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:29:46,935 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:29:46,935 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'genoeg', 'om', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:29:46,936 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:29:46,936 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:29:46,936 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet genoeg om de <unk> van deze <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:29:46,936 - INFO - joeynmt.training - Example #2
2025-05-22 15:29:46,936 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:29:46,936 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:29:46,936 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:29:46,937 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:29:46,937 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:29:46,937 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:29:46,937 - INFO - joeynmt.training - Example #3
2025-05-22 15:29:46,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:29:46,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:29:46,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:29:46,937 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:29:46,937 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:29:46,937 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:29:46,937 - INFO - joeynmt.training - Example #4
2025-05-22 15:29:46,938 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:29:46,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:29:46,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:29:46,938 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:29:46,938 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:29:46,938 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:29:53,563 - INFO - joeynmt.training - Epoch   8, Step:    42100, Batch Loss:     1.372945, Batch Acc: 0.568195, Tokens per Sec:     9408, Lr: 0.000210
2025-05-22 15:30:00,219 - INFO - joeynmt.training - Epoch   8, Step:    42200, Batch Loss:     1.430116, Batch Acc: 0.566890, Tokens per Sec:    10087, Lr: 0.000210
2025-05-22 15:30:07,109 - INFO - joeynmt.training - Epoch   8, Step:    42300, Batch Loss:     1.518952, Batch Acc: 0.565812, Tokens per Sec:     9242, Lr: 0.000210
2025-05-22 15:30:14,128 - INFO - joeynmt.training - Epoch   8, Step:    42400, Batch Loss:     1.307781, Batch Acc: 0.572030, Tokens per Sec:     9272, Lr: 0.000210
2025-05-22 15:30:20,233 - INFO - joeynmt.training - Epoch   8, Step:    42500, Batch Loss:     1.379813, Batch Acc: 0.565221, Tokens per Sec:    10556, Lr: 0.000210
2025-05-22 15:30:20,233 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:30:20,233 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:30:27,033 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.12, acc:   0.50, generation: 6.7285[sec], evaluation: 0.0000[sec]
2025-05-22 15:30:27,169 - INFO - joeynmt.helpers - delete models/transformer_enit/35500.ckpt
2025-05-22 15:30:27,179 - INFO - joeynmt.training - Example #0
2025-05-22 15:30:27,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:30:27,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:30:27,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'voor', '<unk>', 'drie', 'miljoen', 'jaar', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', 'om', 'de', '<unk>', 'te', '<unk>', '.', '</s>']
2025-05-22 15:30:27,180 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:30:27,180 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:30:27,180 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien dat de <unk> <unk> die drie miljoen jaar <unk> <unk> voor <unk> drie miljoen jaar <unk> van de <unk> <unk> staten om de <unk> te <unk>.
2025-05-22 15:30:27,180 - INFO - joeynmt.training - Example #1
2025-05-22 15:30:27,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:30:27,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:30:27,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', '<unk>', 'genoeg', 'om', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', 'te', 'zien', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:30:27,181 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:30:27,181 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:30:27,181 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet <unk> genoeg om de <unk> van dit <unk> <unk> te zien, omdat het niet de <unk> van de <unk> van de <unk>.
2025-05-22 15:30:27,181 - INFO - joeynmt.training - Example #2
2025-05-22 15:30:27,181 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:30:27,181 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:30:27,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:30:27,182 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:30:27,182 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:30:27,182 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk> <unk>.
2025-05-22 15:30:27,182 - INFO - joeynmt.training - Example #3
2025-05-22 15:30:27,182 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:30:27,182 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:30:27,182 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:30:27,182 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:30:27,182 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:30:27,182 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:30:27,183 - INFO - joeynmt.training - Example #4
2025-05-22 15:30:27,183 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:30:27,183 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:30:27,183 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:30:27,184 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:30:27,184 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:30:27,184 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> <unk> in de laatste 25 jaar.
2025-05-22 15:30:33,319 - INFO - joeynmt.training - Epoch   8, Step:    42600, Batch Loss:     1.281093, Batch Acc: 0.565526, Tokens per Sec:    10548, Lr: 0.000210
2025-05-22 15:30:39,318 - INFO - joeynmt.training - Epoch   8, Step:    42700, Batch Loss:     1.429717, Batch Acc: 0.568903, Tokens per Sec:    11508, Lr: 0.000210
2025-05-22 15:30:45,503 - INFO - joeynmt.training - Epoch   8, Step:    42800, Batch Loss:     1.386163, Batch Acc: 0.570361, Tokens per Sec:    10758, Lr: 0.000210
2025-05-22 15:30:52,215 - INFO - joeynmt.training - Epoch   8, Step:    42900, Batch Loss:     1.501956, Batch Acc: 0.569391, Tokens per Sec:     9913, Lr: 0.000210
2025-05-22 15:30:59,462 - INFO - joeynmt.training - Epoch   8, Step:    43000, Batch Loss:     1.367743, Batch Acc: 0.567964, Tokens per Sec:     9436, Lr: 0.000210
2025-05-22 15:30:59,463 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:30:59,463 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:31:09,058 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.10, acc:   0.50, generation: 9.5008[sec], evaluation: 0.0000[sec]
2025-05-22 15:31:09,193 - INFO - joeynmt.helpers - delete models/transformer_enit/42500.ckpt
2025-05-22 15:31:09,202 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit/42500.ckpt
2025-05-22 15:31:09,203 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit\42500.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit\\42500.ckpt')
2025-05-22 15:31:09,207 - INFO - joeynmt.training - Example #0
2025-05-22 15:31:09,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:31:09,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:31:09,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '40', 'procent', '.', '</s>']
2025-05-22 15:31:09,208 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:31:09,208 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:31:09,209 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> van de <unk> <unk> <unk>, 40 procent.
2025-05-22 15:31:09,209 - INFO - joeynmt.training - Example #1
2025-05-22 15:31:09,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:31:09,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:31:09,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'genoeg', 'om', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', 'te', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:31:09,210 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:31:09,210 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:31:09,210 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet genoeg om de <unk> van deze <unk> <unk> te <unk>, want het is niet de <unk> van de <unk>.
2025-05-22 15:31:09,210 - INFO - joeynmt.training - Example #2
2025-05-22 15:31:09,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:31:09,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:31:09,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:31:09,211 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:31:09,211 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:31:09,211 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:31:09,212 - INFO - joeynmt.training - Example #3
2025-05-22 15:31:09,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:31:09,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:31:09,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeien', 'in', 'de', 'zomer', 'in', 'de', '<unk>', 'en', '<unk>', '.', '</s>']
2025-05-22 15:31:09,213 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:31:09,213 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:31:09,213 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de zomer in de <unk> en <unk>.
2025-05-22 15:31:09,213 - INFO - joeynmt.training - Example #4
2025-05-22 15:31:09,213 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:31:09,213 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:31:09,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:31:09,214 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:31:09,215 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:31:09,215 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:31:15,807 - INFO - joeynmt.training - Epoch   8, Step:    43100, Batch Loss:     1.425403, Batch Acc: 0.566342, Tokens per Sec:     9929, Lr: 0.000210
2025-05-22 15:31:22,428 - INFO - joeynmt.training - Epoch   8, Step:    43200, Batch Loss:     1.323387, Batch Acc: 0.567969, Tokens per Sec:    10169, Lr: 0.000210
2025-05-22 15:31:29,175 - INFO - joeynmt.training - Epoch   8, Step:    43300, Batch Loss:     1.518469, Batch Acc: 0.562664, Tokens per Sec:     9891, Lr: 0.000210
2025-05-22 15:31:35,697 - INFO - joeynmt.training - Epoch   8, Step:    43400, Batch Loss:     1.219357, Batch Acc: 0.565447, Tokens per Sec:    10146, Lr: 0.000210
2025-05-22 15:31:41,730 - INFO - joeynmt.training - Epoch   8, Step:    43500, Batch Loss:     1.303086, Batch Acc: 0.565594, Tokens per Sec:    11043, Lr: 0.000210
2025-05-22 15:31:41,732 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:31:41,732 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:31:47,778 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.10, acc:   0.50, generation: 5.9850[sec], evaluation: 0.0000[sec]
2025-05-22 15:31:47,908 - INFO - joeynmt.helpers - delete models/transformer_enit/43000.ckpt
2025-05-22 15:31:47,915 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit/43000.ckpt
2025-05-22 15:31:47,916 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit\43000.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit\\43000.ckpt')
2025-05-22 15:31:47,919 - INFO - joeynmt.training - Example #0
2025-05-22 15:31:47,919 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:31:47,919 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:31:47,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:31:47,920 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:31:47,920 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:31:47,920 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> van de <unk> <unk> staten, met <unk>.
2025-05-22 15:31:47,920 - INFO - joeynmt.training - Example #1
2025-05-22 15:31:47,921 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:31:47,921 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:31:47,921 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', '<unk>', 'genoeg', '<unk>', 'van', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', '<unk>', 'is', '.', '</s>']
2025-05-22 15:31:47,921 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:31:47,922 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:31:47,922 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet <unk> genoeg <unk> van de <unk> van deze <unk> <unk>, omdat het niet <unk> is.
2025-05-22 15:31:47,922 - INFO - joeynmt.training - Example #2
2025-05-22 15:31:47,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:31:47,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:31:47,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:31:47,923 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:31:47,923 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:31:47,923 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:31:47,923 - INFO - joeynmt.training - Example #3
2025-05-22 15:31:47,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:31:47,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:31:47,924 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:31:47,924 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:31:47,924 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:31:47,924 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:31:47,924 - INFO - joeynmt.training - Example #4
2025-05-22 15:31:47,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:31:47,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:31:47,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', '<unk>', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'gebeurt', '.', '</s>']
2025-05-22 15:31:47,925 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:31:47,925 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:31:47,925 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> <unk> wat er in de afgelopen 25 jaar gebeurt.
2025-05-22 15:31:54,047 - INFO - joeynmt.training - Epoch   8, Step:    43600, Batch Loss:     1.421933, Batch Acc: 0.562744, Tokens per Sec:    10771, Lr: 0.000210
2025-05-22 15:32:00,252 - INFO - joeynmt.training - Epoch   8, Step:    43700, Batch Loss:     1.476292, Batch Acc: 0.568041, Tokens per Sec:    10693, Lr: 0.000210
2025-05-22 15:32:06,401 - INFO - joeynmt.training - Epoch   8, Step:    43800, Batch Loss:     1.343055, Batch Acc: 0.564730, Tokens per Sec:    10900, Lr: 0.000210
2025-05-22 15:32:12,970 - INFO - joeynmt.training - Epoch   8, Step:    43900, Batch Loss:     1.344440, Batch Acc: 0.563511, Tokens per Sec:    10109, Lr: 0.000210
2025-05-22 15:32:19,675 - INFO - joeynmt.training - Epoch   8, Step:    44000, Batch Loss:     1.396531, Batch Acc: 0.563947, Tokens per Sec:     9799, Lr: 0.000210
2025-05-22 15:32:19,676 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:32:19,676 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:32:27,385 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.09, acc:   0.51, generation: 7.6331[sec], evaluation: 0.0000[sec]
2025-05-22 15:32:27,526 - INFO - joeynmt.helpers - delete models/transformer_enit/43500.ckpt
2025-05-22 15:32:27,533 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit/43500.ckpt
2025-05-22 15:32:27,534 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit\43500.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit\\43500.ckpt')
2025-05-22 15:32:27,537 - INFO - joeynmt.training - Example #0
2025-05-22 15:32:27,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:32:27,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:32:27,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', 'met', '40', 'procent', '<unk>', '.', '</s>']
2025-05-22 15:32:27,538 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:32:27,538 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:32:27,538 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk>, met 40 procent <unk>.
2025-05-22 15:32:27,538 - INFO - joeynmt.training - Example #1
2025-05-22 15:32:27,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:32:27,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:32:27,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', '<unk>', 'genoeg', '<unk>', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:32:27,538 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:32:27,538 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:32:27,539 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet <unk> genoeg <unk> de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:32:27,539 - INFO - joeynmt.training - Example #2
2025-05-22 15:32:27,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:32:27,539 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:32:27,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:32:27,539 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:32:27,539 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:32:27,539 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:32:27,539 - INFO - joeynmt.training - Example #3
2025-05-22 15:32:27,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:32:27,540 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:32:27,540 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:32:27,540 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:32:27,540 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:32:27,540 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:32:27,540 - INFO - joeynmt.training - Example #4
2025-05-22 15:32:27,540 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:32:27,540 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:32:27,541 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', '<unk>', ',', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 15:32:27,541 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:32:27,541 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:32:27,541 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> <unk>, wat er in de afgelopen 25 jaar is gebeurd.
2025-05-22 15:32:34,218 - INFO - joeynmt.training - Epoch   8, Step:    44100, Batch Loss:     1.369871, Batch Acc: 0.562740, Tokens per Sec:     9617, Lr: 0.000210
2025-05-22 15:32:40,909 - INFO - joeynmt.training - Epoch   8, Step:    44200, Batch Loss:     1.368159, Batch Acc: 0.564580, Tokens per Sec:     9753, Lr: 0.000210
2025-05-22 15:32:47,470 - INFO - joeynmt.training - Epoch   8, Step:    44300, Batch Loss:     1.394165, Batch Acc: 0.564478, Tokens per Sec:     9813, Lr: 0.000210
2025-05-22 15:32:54,119 - INFO - joeynmt.training - Epoch   8, Step:    44400, Batch Loss:     1.458418, Batch Acc: 0.563742, Tokens per Sec:     9819, Lr: 0.000210
2025-05-22 15:33:00,255 - INFO - joeynmt.training - Epoch   8, Step:    44500, Batch Loss:     1.457174, Batch Acc: 0.563964, Tokens per Sec:    10768, Lr: 0.000210
2025-05-22 15:33:00,255 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:33:00,255 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:33:07,520 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.10, acc:   0.50, generation: 7.1801[sec], evaluation: 0.0000[sec]
2025-05-22 15:33:07,524 - INFO - joeynmt.training - Example #0
2025-05-22 15:33:07,524 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:33:07,524 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:33:07,524 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', '<unk>', 'is', '.', '</s>']
2025-05-22 15:33:07,525 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:33:07,526 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:33:07,526 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk>, <unk> <unk>, <unk> <unk>, <unk> <unk> is.
2025-05-22 15:33:07,526 - INFO - joeynmt.training - Example #1
2025-05-22 15:33:07,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:33:07,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:33:07,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', '<unk>', 'genoeg', '<unk>', 'is', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:33:07,526 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:33:07,526 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:33:07,526 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet <unk> genoeg <unk> is de <unk> van deze <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 15:33:07,526 - INFO - joeynmt.training - Example #2
2025-05-22 15:33:07,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:33:07,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:33:07,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:33:07,526 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:33:07,526 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:33:07,526 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk> <unk>.
2025-05-22 15:33:07,526 - INFO - joeynmt.training - Example #3
2025-05-22 15:33:07,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:33:07,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:33:07,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:33:07,529 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:33:07,529 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:33:07,529 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:33:07,529 - INFO - joeynmt.training - Example #4
2025-05-22 15:33:07,529 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:33:07,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:33:07,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 15:33:07,530 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:33:07,530 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:33:07,530 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> van wat er in de laatste 25 jaar is gebeurd.
2025-05-22 15:33:13,625 - INFO - joeynmt.training - Epoch   8, Step:    44600, Batch Loss:     1.352345, Batch Acc: 0.564268, Tokens per Sec:    11005, Lr: 0.000210
2025-05-22 15:33:19,643 - INFO - joeynmt.training - Epoch   8, Step:    44700, Batch Loss:     1.270286, Batch Acc: 0.562272, Tokens per Sec:    10909, Lr: 0.000210
2025-05-22 15:33:25,758 - INFO - joeynmt.training - Epoch   8, Step:    44800, Batch Loss:     1.352413, Batch Acc: 0.559090, Tokens per Sec:    10668, Lr: 0.000210
2025-05-22 15:33:32,423 - INFO - joeynmt.training - Epoch   8, Step:    44900, Batch Loss:     1.543316, Batch Acc: 0.560181, Tokens per Sec:     9890, Lr: 0.000210
2025-05-22 15:33:39,038 - INFO - joeynmt.training - Epoch   8, Step:    45000, Batch Loss:     1.460472, Batch Acc: 0.566333, Tokens per Sec:     9869, Lr: 0.000210
2025-05-22 15:33:39,039 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:33:39,039 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:33:46,946 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.11, acc:   0.50, generation: 7.8187[sec], evaluation: 0.0000[sec]
2025-05-22 15:33:46,952 - INFO - joeynmt.training - Example #0
2025-05-22 15:33:46,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:33:46,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:33:46,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'had', '<unk>', ',', 'met', '40', 'procent', '.', '</s>']
2025-05-22 15:33:46,953 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:33:46,953 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:33:46,953 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> van de <unk> <unk> staten, had <unk>, met 40 procent.
2025-05-22 15:33:46,953 - INFO - joeynmt.training - Example #1
2025-05-22 15:33:46,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:33:46,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:33:46,954 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', '<unk>', 'genoeg', 'om', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:33:46,954 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:33:46,955 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:33:46,955 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet <unk> genoeg om de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:33:46,955 - INFO - joeynmt.training - Example #2
2025-05-22 15:33:46,955 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:33:46,955 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:33:46,955 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:33:46,956 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:33:46,956 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:33:46,956 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:33:46,956 - INFO - joeynmt.training - Example #3
2025-05-22 15:33:46,956 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:33:46,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:33:46,957 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:33:46,957 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:33:46,957 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:33:46,957 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:33:46,958 - INFO - joeynmt.training - Example #4
2025-05-22 15:33:46,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:33:46,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:33:46,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 15:33:46,959 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:33:46,959 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:33:46,959 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> van wat er in de afgelopen 25 jaar is.
2025-05-22 15:33:53,645 - INFO - joeynmt.training - Epoch   8, Step:    45100, Batch Loss:     1.305116, Batch Acc: 0.563362, Tokens per Sec:    10033, Lr: 0.000210
2025-05-22 15:34:00,437 - INFO - joeynmt.training - Epoch   8, Step:    45200, Batch Loss:     1.391318, Batch Acc: 0.562209, Tokens per Sec:     9687, Lr: 0.000210
2025-05-22 15:34:07,224 - INFO - joeynmt.training - Epoch   8, Step:    45300, Batch Loss:     1.286509, Batch Acc: 0.560695, Tokens per Sec:     9721, Lr: 0.000210
2025-05-22 15:34:14,234 - INFO - joeynmt.training - Epoch   8, Step:    45400, Batch Loss:     1.379543, Batch Acc: 0.564040, Tokens per Sec:     9347, Lr: 0.000210
2025-05-22 15:34:21,295 - INFO - joeynmt.training - Epoch   8, Step:    45500, Batch Loss:     1.307920, Batch Acc: 0.565148, Tokens per Sec:     9187, Lr: 0.000210
2025-05-22 15:34:21,295 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:34:21,295 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:34:30,239 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.12, acc:   0.50, generation: 8.8592[sec], evaluation: 0.0000[sec]
2025-05-22 15:34:30,247 - INFO - joeynmt.training - Example #0
2025-05-22 15:34:30,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:34:30,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:34:30,248 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'om', '40', 'procent', '<unk>', 'te', '<unk>', '.', '</s>']
2025-05-22 15:34:30,248 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:34:30,248 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:34:30,248 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, drie miljoen jaar de <unk> van de <unk> <unk> staten, om 40 procent <unk> te <unk>.
2025-05-22 15:34:30,250 - INFO - joeynmt.training - Example #1
2025-05-22 15:34:30,250 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:34:30,250 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:34:30,250 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'om', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:34:30,251 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:34:30,251 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:34:30,251 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg om de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:34:30,251 - INFO - joeynmt.training - Example #2
2025-05-22 15:34:30,251 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:34:30,251 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:34:30,251 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:34:30,252 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:34:30,253 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:34:30,253 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:34:30,253 - INFO - joeynmt.training - Example #3
2025-05-22 15:34:30,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:34:30,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:34:30,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:34:30,254 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:34:30,254 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:34:30,254 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:34:30,254 - INFO - joeynmt.training - Example #4
2025-05-22 15:34:30,255 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:34:30,255 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:34:30,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 15:34:30,255 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:34:30,255 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:34:30,256 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> van wat er in de afgelopen 25 jaar is gebeurd.
2025-05-22 15:34:36,789 - INFO - joeynmt.training - Epoch   8, Step:    45600, Batch Loss:     1.481247, Batch Acc: 0.562783, Tokens per Sec:    10343, Lr: 0.000210
2025-05-22 15:34:42,969 - INFO - joeynmt.training - Epoch   8, Step:    45700, Batch Loss:     1.385653, Batch Acc: 0.563767, Tokens per Sec:    10362, Lr: 0.000210
2025-05-22 15:34:49,537 - INFO - joeynmt.training - Epoch   8, Step:    45800, Batch Loss:     1.497562, Batch Acc: 0.567097, Tokens per Sec:    10018, Lr: 0.000210
2025-05-22 15:34:56,285 - INFO - joeynmt.training - Epoch   8, Step:    45900, Batch Loss:     1.497638, Batch Acc: 0.564907, Tokens per Sec:     9728, Lr: 0.000210
2025-05-22 15:35:02,945 - INFO - joeynmt.training - Epoch   8, Step:    46000, Batch Loss:     1.482394, Batch Acc: 0.570409, Tokens per Sec:     9706, Lr: 0.000210
2025-05-22 15:35:02,945 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:35:02,945 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:35:10,869 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.07, acc:   0.50, generation: 7.8422[sec], evaluation: 0.0000[sec]
2025-05-22 15:35:11,001 - INFO - joeynmt.helpers - delete models/transformer_enit/42000.ckpt
2025-05-22 15:35:11,009 - INFO - joeynmt.training - Example #0
2025-05-22 15:35:11,009 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:35:11,009 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:35:11,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '40', 'procent', '<unk>', 'is', '.', '</s>']
2025-05-22 15:35:11,010 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:35:11,010 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:35:11,010 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar de <unk> van de <unk> <unk> <unk>, 40 procent <unk> is.
2025-05-22 15:35:11,010 - INFO - joeynmt.training - Example #1
2025-05-22 15:35:11,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:35:11,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:35:11,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', '<unk>', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:35:11,011 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:35:11,011 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:35:11,011 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg <unk> om dit <unk> <unk> te <unk>, want het is niet de <unk> van de <unk>.
2025-05-22 15:35:11,011 - INFO - joeynmt.training - Example #2
2025-05-22 15:35:11,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:35:11,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:35:11,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 15:35:11,011 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:35:11,011 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:35:11,011 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons mondiale <unk>.
2025-05-22 15:35:11,011 - INFO - joeynmt.training - Example #3
2025-05-22 15:35:11,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:35:11,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:35:11,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:35:11,012 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:35:11,012 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:35:11,012 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:35:11,012 - INFO - joeynmt.training - Example #4
2025-05-22 15:35:11,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:35:11,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:35:11,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 15:35:11,013 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:35:11,013 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:35:11,013 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> van wat er in de laatste 25 jaar is gebeurd.
2025-05-22 15:35:17,415 - INFO - joeynmt.training - Epoch   8, Step:    46100, Batch Loss:     1.250301, Batch Acc: 0.560824, Tokens per Sec:    10180, Lr: 0.000147
2025-05-22 15:35:24,059 - INFO - joeynmt.training - Epoch   8, Step:    46200, Batch Loss:     1.396009, Batch Acc: 0.566950, Tokens per Sec:    10100, Lr: 0.000147
2025-05-22 15:35:30,735 - INFO - joeynmt.training - Epoch   8, Step:    46300, Batch Loss:     1.567265, Batch Acc: 0.567542, Tokens per Sec:     9838, Lr: 0.000147
2025-05-22 15:35:37,023 - INFO - joeynmt.training - Epoch   8, Step:    46400, Batch Loss:     1.372584, Batch Acc: 0.567375, Tokens per Sec:    10604, Lr: 0.000147
2025-05-22 15:35:43,145 - INFO - joeynmt.training - Epoch   8, Step:    46500, Batch Loss:     1.479044, Batch Acc: 0.563256, Tokens per Sec:    10841, Lr: 0.000147
2025-05-22 15:35:43,145 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:35:43,145 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:35:49,430 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.00, acc:   0.50, generation: 6.2233[sec], evaluation: 0.0000[sec]
2025-05-22 15:35:49,431 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:35:49,564 - INFO - joeynmt.helpers - delete models/transformer_enit/44000.ckpt
2025-05-22 15:35:49,579 - INFO - joeynmt.training - Example #0
2025-05-22 15:35:49,579 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:35:49,579 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:35:49,579 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', 'met', '40', 'procent', '.', '</s>']
2025-05-22 15:35:49,579 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:35:49,579 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:35:49,580 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk>, <unk> <unk>, met 40 procent.
2025-05-22 15:35:49,580 - INFO - joeynmt.training - Example #1
2025-05-22 15:35:49,580 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:35:49,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:35:49,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', '<unk>', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:35:49,580 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:35:49,580 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:35:49,580 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg <unk> de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 15:35:49,580 - INFO - joeynmt.training - Example #2
2025-05-22 15:35:49,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:35:49,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:35:49,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:35:49,581 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:35:49,581 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:35:49,581 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:35:49,581 - INFO - joeynmt.training - Example #3
2025-05-22 15:35:49,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:35:49,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:35:49,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:35:49,582 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:35:49,582 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:35:49,582 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:35:49,582 - INFO - joeynmt.training - Example #4
2025-05-22 15:35:49,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:35:49,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:35:49,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:35:49,583 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:35:49,583 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:35:49,583 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:35:55,618 - INFO - joeynmt.training - Epoch   8, Step:    46600, Batch Loss:     1.352934, Batch Acc: 0.572617, Tokens per Sec:    10432, Lr: 0.000147
2025-05-22 15:36:01,671 - INFO - joeynmt.training - Epoch   8, Step:    46700, Batch Loss:     1.449781, Batch Acc: 0.565737, Tokens per Sec:    10870, Lr: 0.000147
2025-05-22 15:36:08,162 - INFO - joeynmt.training - Epoch   8, Step:    46800, Batch Loss:     1.503201, Batch Acc: 0.562239, Tokens per Sec:    10100, Lr: 0.000147
2025-05-22 15:36:15,616 - INFO - joeynmt.training - Epoch   8, Step:    46900, Batch Loss:     1.400512, Batch Acc: 0.566740, Tokens per Sec:     8878, Lr: 0.000147
2025-05-22 15:36:22,387 - INFO - joeynmt.training - Epoch   8, Step:    47000, Batch Loss:     1.422487, Batch Acc: 0.568065, Tokens per Sec:     9782, Lr: 0.000147
2025-05-22 15:36:22,387 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:36:22,387 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:36:29,661 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.01, acc:   0.51, generation: 7.1979[sec], evaluation: 0.0000[sec]
2025-05-22 15:36:29,801 - INFO - joeynmt.helpers - delete models/transformer_enit/41000.ckpt
2025-05-22 15:36:29,814 - INFO - joeynmt.training - Example #0
2025-05-22 15:36:29,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:36:29,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:36:29,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:36:29,815 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:36:29,815 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:36:29,816 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> van de <unk> <unk> staten, met <unk>.
2025-05-22 15:36:29,816 - INFO - joeynmt.training - Example #1
2025-05-22 15:36:29,816 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:36:29,816 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:36:29,816 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', 'is', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:36:29,817 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:36:29,817 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:36:29,817 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg is de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> <unk>.
2025-05-22 15:36:29,817 - INFO - joeynmt.training - Example #2
2025-05-22 15:36:29,817 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:36:29,817 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:36:29,817 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 15:36:29,818 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:36:29,818 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:36:29,818 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons mondiale <unk>.
2025-05-22 15:36:29,818 - INFO - joeynmt.training - Example #3
2025-05-22 15:36:29,819 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:36:29,819 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:36:29,819 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:36:29,819 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:36:29,819 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:36:29,820 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:36:29,820 - INFO - joeynmt.training - Example #4
2025-05-22 15:36:29,820 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:36:29,820 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:36:29,820 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:36:29,820 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:36:29,821 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:36:29,821 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:36:36,483 - INFO - joeynmt.training - Epoch   8, Step:    47100, Batch Loss:     1.495395, Batch Acc: 0.567620, Tokens per Sec:     9738, Lr: 0.000147
2025-05-22 15:36:42,993 - INFO - joeynmt.training - Epoch   8, Step:    47200, Batch Loss:     1.440594, Batch Acc: 0.564511, Tokens per Sec:     9950, Lr: 0.000147
2025-05-22 15:36:49,586 - INFO - joeynmt.training - Epoch   8, Step:    47300, Batch Loss:     1.417023, Batch Acc: 0.562798, Tokens per Sec:    10160, Lr: 0.000147
2025-05-22 15:36:56,135 - INFO - joeynmt.training - Epoch   8, Step:    47400, Batch Loss:     1.318910, Batch Acc: 0.568701, Tokens per Sec:    10226, Lr: 0.000147
2025-05-22 15:37:02,191 - INFO - joeynmt.training - Epoch   8, Step:    47500, Batch Loss:     1.339319, Batch Acc: 0.565019, Tokens per Sec:    10695, Lr: 0.000147
2025-05-22 15:37:02,192 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:37:02,192 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:37:08,886 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.00, acc:   0.51, generation: 6.6284[sec], evaluation: 0.0000[sec]
2025-05-22 15:37:08,887 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:37:09,016 - INFO - joeynmt.helpers - delete models/transformer_enit/40500.ckpt
2025-05-22 15:37:09,027 - INFO - joeynmt.training - Example #0
2025-05-22 15:37:09,028 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:37:09,028 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:37:09,028 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:37:09,028 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:37:09,029 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:37:09,029 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> <unk> van de <unk> <unk> staten, met <unk>.
2025-05-22 15:37:09,029 - INFO - joeynmt.training - Example #1
2025-05-22 15:37:09,029 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:37:09,029 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:37:09,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:37:09,030 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:37:09,030 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:37:09,030 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:37:09,030 - INFO - joeynmt.training - Example #2
2025-05-22 15:37:09,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:37:09,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:37:09,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:37:09,031 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:37:09,031 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:37:09,031 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:37:09,031 - INFO - joeynmt.training - Example #3
2025-05-22 15:37:09,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:37:09,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:37:09,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:37:09,032 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:37:09,032 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:37:09,032 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:37:09,032 - INFO - joeynmt.training - Example #4
2025-05-22 15:37:09,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:37:09,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:37:09,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:37:09,033 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:37:09,033 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:37:09,033 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:37:11,275 - INFO - joeynmt.training - Epoch   8: total training loss 8292.49
2025-05-22 15:37:11,275 - INFO - joeynmt.training - EPOCH 9
2025-05-22 15:37:15,111 - INFO - joeynmt.training - Epoch   9, Step:    47600, Batch Loss:     1.343121, Batch Acc: 0.583169, Tokens per Sec:    10975, Lr: 0.000147
2025-05-22 15:37:22,337 - INFO - joeynmt.training - Epoch   9, Step:    47700, Batch Loss:     1.320950, Batch Acc: 0.582158, Tokens per Sec:     8980, Lr: 0.000147
2025-05-22 15:37:30,429 - INFO - joeynmt.training - Epoch   9, Step:    47800, Batch Loss:     1.306027, Batch Acc: 0.582549, Tokens per Sec:     8204, Lr: 0.000147
2025-05-22 15:37:37,119 - INFO - joeynmt.training - Epoch   9, Step:    47900, Batch Loss:     1.194303, Batch Acc: 0.583421, Tokens per Sec:     9670, Lr: 0.000147
2025-05-22 15:37:44,171 - INFO - joeynmt.training - Epoch   9, Step:    48000, Batch Loss:     1.373335, Batch Acc: 0.586052, Tokens per Sec:     9314, Lr: 0.000147
2025-05-22 15:37:44,172 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:37:44,172 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:37:51,742 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.04, acc:   0.51, generation: 7.4767[sec], evaluation: 0.0000[sec]
2025-05-22 15:37:51,891 - INFO - joeynmt.helpers - delete models/transformer_enit/46000.ckpt
2025-05-22 15:37:51,903 - INFO - joeynmt.training - Example #0
2025-05-22 15:37:51,903 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:37:51,903 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:37:51,903 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:37:51,903 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:37:51,903 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:37:51,903 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, drie miljoen jaar de <unk> van de <unk> <unk> staten, met <unk>.
2025-05-22 15:37:51,903 - INFO - joeynmt.training - Example #1
2025-05-22 15:37:51,903 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:37:51,904 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:37:51,904 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', 'is', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:37:51,904 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:37:51,904 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:37:51,904 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg is om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:37:51,904 - INFO - joeynmt.training - Example #2
2025-05-22 15:37:51,904 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:37:51,904 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:37:51,904 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:37:51,905 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:37:51,905 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:37:51,905 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:37:51,905 - INFO - joeynmt.training - Example #3
2025-05-22 15:37:51,905 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:37:51,905 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:37:51,905 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:37:51,905 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:37:51,905 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:37:51,905 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:37:51,905 - INFO - joeynmt.training - Example #4
2025-05-22 15:37:51,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:37:51,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:37:51,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:37:51,907 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:37:51,908 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:37:51,908 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:37:58,668 - INFO - joeynmt.training - Epoch   9, Step:    48100, Batch Loss:     1.358942, Batch Acc: 0.585728, Tokens per Sec:     9404, Lr: 0.000147
2025-05-22 15:38:05,289 - INFO - joeynmt.training - Epoch   9, Step:    48200, Batch Loss:     1.321366, Batch Acc: 0.582982, Tokens per Sec:    10381, Lr: 0.000147
2025-05-22 15:38:11,920 - INFO - joeynmt.training - Epoch   9, Step:    48300, Batch Loss:     1.465396, Batch Acc: 0.580830, Tokens per Sec:     9977, Lr: 0.000147
2025-05-22 15:38:18,265 - INFO - joeynmt.training - Epoch   9, Step:    48400, Batch Loss:     1.176681, Batch Acc: 0.583845, Tokens per Sec:    10526, Lr: 0.000147
2025-05-22 15:38:24,443 - INFO - joeynmt.training - Epoch   9, Step:    48500, Batch Loss:     1.253408, Batch Acc: 0.580595, Tokens per Sec:    10673, Lr: 0.000147
2025-05-22 15:38:24,443 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:38:24,444 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:38:30,954 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.05, acc:   0.51, generation: 6.4419[sec], evaluation: 0.0000[sec]
2025-05-22 15:38:31,083 - INFO - joeynmt.helpers - delete models/transformer_enit/41500.ckpt
2025-05-22 15:38:31,093 - INFO - joeynmt.training - Example #0
2025-05-22 15:38:31,093 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:38:31,093 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:38:31,093 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', '<unk>', ',', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', '<unk>', ',', 'met', '40', 'procent', '.', '</s>']
2025-05-22 15:38:31,094 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:38:31,094 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:38:31,094 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, drie miljoen jaar <unk>, de <unk> van de <unk> <unk> <unk> <unk>, met 40 procent.
2025-05-22 15:38:31,094 - INFO - joeynmt.training - Example #1
2025-05-22 15:38:31,094 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:38:31,094 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:38:31,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'om', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:38:31,094 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:38:31,094 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:38:31,095 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg om de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:38:31,095 - INFO - joeynmt.training - Example #2
2025-05-22 15:38:31,095 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:38:31,095 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:38:31,095 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:38:31,095 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:38:31,095 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:38:31,095 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:38:31,095 - INFO - joeynmt.training - Example #3
2025-05-22 15:38:31,095 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:38:31,095 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:38:31,095 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:38:31,096 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:38:31,096 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:38:31,096 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:38:31,096 - INFO - joeynmt.training - Example #4
2025-05-22 15:38:31,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:38:31,096 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:38:31,096 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 15:38:31,097 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:38:31,097 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:38:31,097 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> in de afgelopen 25 jaar.
2025-05-22 15:38:37,145 - INFO - joeynmt.training - Epoch   9, Step:    48600, Batch Loss:     1.384912, Batch Acc: 0.583339, Tokens per Sec:    10360, Lr: 0.000147
2025-05-22 15:38:43,275 - INFO - joeynmt.training - Epoch   9, Step:    48700, Batch Loss:     1.352122, Batch Acc: 0.580597, Tokens per Sec:    10682, Lr: 0.000147
2025-05-22 15:38:49,729 - INFO - joeynmt.training - Epoch   9, Step:    48800, Batch Loss:     1.331001, Batch Acc: 0.579211, Tokens per Sec:    10150, Lr: 0.000147
2025-05-22 15:38:56,488 - INFO - joeynmt.training - Epoch   9, Step:    48900, Batch Loss:     1.444157, Batch Acc: 0.575860, Tokens per Sec:     9726, Lr: 0.000147
2025-05-22 15:39:03,357 - INFO - joeynmt.training - Epoch   9, Step:    49000, Batch Loss:     1.315633, Batch Acc: 0.579201, Tokens per Sec:     9774, Lr: 0.000147
2025-05-22 15:39:03,358 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:39:03,358 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:39:10,550 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.50, generation: 7.1075[sec], evaluation: 0.0000[sec]
2025-05-22 15:39:10,556 - INFO - joeynmt.training - Example #0
2025-05-22 15:39:10,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:39:10,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:39:10,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', 'met', '40', 'procent', '.', '</s>']
2025-05-22 15:39:10,557 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:39:10,559 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:39:10,559 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk> die drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk>, met 40 procent.
2025-05-22 15:39:10,559 - INFO - joeynmt.training - Example #1
2025-05-22 15:39:10,559 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:39:10,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:39:10,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', 'is', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'want', 'het', 'is', 'niet', 'de', '<unk>', 'van', 'het', '<unk>', '.', '</s>']
2025-05-22 15:39:10,560 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:39:10,560 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:39:10,560 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg <unk> is om dit <unk> <unk> te <unk>, want het is niet de <unk> van het <unk>.
2025-05-22 15:39:10,560 - INFO - joeynmt.training - Example #2
2025-05-22 15:39:10,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:39:10,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:39:10,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:39:10,561 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:39:10,561 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:39:10,561 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:39:10,561 - INFO - joeynmt.training - Example #3
2025-05-22 15:39:10,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:39:10,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:39:10,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:39:10,563 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:39:10,563 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:39:10,563 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:39:10,563 - INFO - joeynmt.training - Example #4
2025-05-22 15:39:10,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:39:10,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:39:10,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laat', 'zien', 'is', 'een', '<unk>', '<unk>', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 15:39:10,564 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:39:10,564 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:39:10,564 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laat zien is een <unk> <unk> in de afgelopen 25 jaar.
2025-05-22 15:39:17,583 - INFO - joeynmt.training - Epoch   9, Step:    49100, Batch Loss:     1.356273, Batch Acc: 0.581711, Tokens per Sec:     9539, Lr: 0.000147
2025-05-22 15:39:24,195 - INFO - joeynmt.training - Epoch   9, Step:    49200, Batch Loss:     1.326670, Batch Acc: 0.575989, Tokens per Sec:    10045, Lr: 0.000147
2025-05-22 15:39:30,830 - INFO - joeynmt.training - Epoch   9, Step:    49300, Batch Loss:     1.186915, Batch Acc: 0.577853, Tokens per Sec:    10061, Lr: 0.000147
2025-05-22 15:39:37,105 - INFO - joeynmt.training - Epoch   9, Step:    49400, Batch Loss:     1.441773, Batch Acc: 0.578259, Tokens per Sec:    10435, Lr: 0.000147
2025-05-22 15:39:43,150 - INFO - joeynmt.training - Epoch   9, Step:    49500, Batch Loss:     1.364209, Batch Acc: 0.580680, Tokens per Sec:    10933, Lr: 0.000147
2025-05-22 15:39:43,151 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:39:43,151 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:39:49,988 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.05, acc:   0.50, generation: 6.7730[sec], evaluation: 0.0000[sec]
2025-05-22 15:39:49,992 - INFO - joeynmt.training - Example #0
2025-05-22 15:39:49,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:39:49,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:39:49,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', '<unk>', ',', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', 'met', '40', 'procent', '.', '</s>']
2025-05-22 15:39:49,994 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:39:49,994 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:39:49,994 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, drie miljoen jaar <unk>, de <unk> van de <unk> <unk> <unk>, met 40 procent.
2025-05-22 15:39:49,994 - INFO - joeynmt.training - Example #1
2025-05-22 15:39:49,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:39:49,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:39:49,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'om', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', 'te', 'zien', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:39:49,994 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:39:49,994 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:39:49,994 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg om de <unk> van deze <unk> <unk> te zien, omdat het niet de <unk> van de <unk>.
2025-05-22 15:39:49,995 - INFO - joeynmt.training - Example #2
2025-05-22 15:39:49,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:39:49,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:39:49,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:39:49,995 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:39:49,996 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:39:49,996 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:39:49,996 - INFO - joeynmt.training - Example #3
2025-05-22 15:39:49,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:39:49,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:39:49,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:39:49,997 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:39:49,997 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:39:49,997 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:39:49,997 - INFO - joeynmt.training - Example #4
2025-05-22 15:39:49,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:39:49,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:39:49,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:39:49,998 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:39:49,998 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:39:49,998 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:39:56,062 - INFO - joeynmt.training - Epoch   9, Step:    49600, Batch Loss:     1.390487, Batch Acc: 0.581962, Tokens per Sec:    10912, Lr: 0.000147
2025-05-22 15:40:02,128 - INFO - joeynmt.training - Epoch   9, Step:    49700, Batch Loss:     1.296673, Batch Acc: 0.580501, Tokens per Sec:    10931, Lr: 0.000147
2025-05-22 15:40:08,532 - INFO - joeynmt.training - Epoch   9, Step:    49800, Batch Loss:     1.238512, Batch Acc: 0.583195, Tokens per Sec:    10347, Lr: 0.000147
2025-05-22 15:40:15,175 - INFO - joeynmt.training - Epoch   9, Step:    49900, Batch Loss:     1.376627, Batch Acc: 0.570461, Tokens per Sec:     9909, Lr: 0.000147
2025-05-22 15:40:21,789 - INFO - joeynmt.training - Epoch   9, Step:    50000, Batch Loss:     1.348337, Batch Acc: 0.576262, Tokens per Sec:    10073, Lr: 0.000147
2025-05-22 15:40:21,790 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:40:21,790 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:40:28,879 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.51, generation: 7.0145[sec], evaluation: 0.0000[sec]
2025-05-22 15:40:28,886 - INFO - joeynmt.training - Example #0
2025-05-22 15:40:28,886 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:40:28,886 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:40:28,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', ',', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:40:28,887 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:40:28,887 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:40:28,887 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk>, de <unk> van de <unk> <unk> staten, met <unk>.
2025-05-22 15:40:28,887 - INFO - joeynmt.training - Example #1
2025-05-22 15:40:28,887 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:40:28,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:40:28,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'om', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:40:28,887 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:40:28,887 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:40:28,887 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg om de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:40:28,887 - INFO - joeynmt.training - Example #2
2025-05-22 15:40:28,887 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:40:28,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:40:28,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:40:28,887 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:40:28,891 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:40:28,891 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:40:28,891 - INFO - joeynmt.training - Example #3
2025-05-22 15:40:28,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:40:28,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:40:28,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:40:28,892 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:40:28,892 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:40:28,892 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:40:28,892 - INFO - joeynmt.training - Example #4
2025-05-22 15:40:28,892 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:40:28,892 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:40:28,892 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:40:28,893 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:40:28,893 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:40:28,893 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:40:35,651 - INFO - joeynmt.training - Epoch   9, Step:    50100, Batch Loss:     1.411747, Batch Acc: 0.577949, Tokens per Sec:    10234, Lr: 0.000147
2025-05-22 15:40:42,168 - INFO - joeynmt.training - Epoch   9, Step:    50200, Batch Loss:     1.266455, Batch Acc: 0.581821, Tokens per Sec:    10380, Lr: 0.000147
2025-05-22 15:40:48,783 - INFO - joeynmt.training - Epoch   9, Step:    50300, Batch Loss:     1.364529, Batch Acc: 0.577589, Tokens per Sec:    10271, Lr: 0.000147
2025-05-22 15:40:55,267 - INFO - joeynmt.training - Epoch   9, Step:    50400, Batch Loss:     1.427670, Batch Acc: 0.579752, Tokens per Sec:    10340, Lr: 0.000147
2025-05-22 15:41:02,244 - INFO - joeynmt.training - Epoch   9, Step:    50500, Batch Loss:     1.200458, Batch Acc: 0.575893, Tokens per Sec:     9363, Lr: 0.000147
2025-05-22 15:41:02,244 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:41:02,244 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:41:08,987 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.07, acc:   0.51, generation: 6.6816[sec], evaluation: 0.0000[sec]
2025-05-22 15:41:08,992 - INFO - joeynmt.training - Example #0
2025-05-22 15:41:08,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:41:08,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:41:08,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'om', '40', 'procent', '<unk>', 'te', 'zijn', '.', '</s>']
2025-05-22 15:41:08,994 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:41:08,994 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:41:08,994 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar de <unk> van de <unk> <unk> staten, om 40 procent <unk> te zijn.
2025-05-22 15:41:08,995 - INFO - joeynmt.training - Example #1
2025-05-22 15:41:08,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:41:08,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:41:08,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:41:08,996 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:41:08,996 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:41:08,996 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg de <unk> van deze <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 15:41:08,996 - INFO - joeynmt.training - Example #2
2025-05-22 15:41:08,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:41:08,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:41:08,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:41:08,997 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:41:08,998 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:41:08,998 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:41:08,998 - INFO - joeynmt.training - Example #3
2025-05-22 15:41:08,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:41:08,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:41:08,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:41:08,999 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:41:08,999 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:41:08,999 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:41:08,999 - INFO - joeynmt.training - Example #4
2025-05-22 15:41:08,999 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:41:08,999 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:41:08,999 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:41:09,000 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:41:09,000 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:41:09,000 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:41:15,007 - INFO - joeynmt.training - Epoch   9, Step:    50600, Batch Loss:     1.305213, Batch Acc: 0.576581, Tokens per Sec:    11430, Lr: 0.000147
2025-05-22 15:41:20,942 - INFO - joeynmt.training - Epoch   9, Step:    50700, Batch Loss:     1.330479, Batch Acc: 0.577275, Tokens per Sec:    11110, Lr: 0.000147
2025-05-22 15:41:27,402 - INFO - joeynmt.training - Epoch   9, Step:    50800, Batch Loss:     1.131239, Batch Acc: 0.574638, Tokens per Sec:    10300, Lr: 0.000147
2025-05-22 15:41:33,947 - INFO - joeynmt.training - Epoch   9, Step:    50900, Batch Loss:     1.340627, Batch Acc: 0.577100, Tokens per Sec:    10257, Lr: 0.000147
2025-05-22 15:41:40,435 - INFO - joeynmt.training - Epoch   9, Step:    51000, Batch Loss:     1.383666, Batch Acc: 0.576637, Tokens per Sec:    10243, Lr: 0.000147
2025-05-22 15:41:40,435 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:41:40,436 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:41:47,513 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.04, acc:   0.51, generation: 6.9974[sec], evaluation: 0.0000[sec]
2025-05-22 15:41:47,648 - INFO - joeynmt.helpers - delete models/transformer_enit/48500.ckpt
2025-05-22 15:41:47,658 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit/48500.ckpt
2025-05-22 15:41:47,659 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit\48500.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit\\48500.ckpt')
2025-05-22 15:41:47,662 - INFO - joeynmt.training - Example #0
2025-05-22 15:41:47,662 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:41:47,662 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:41:47,662 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', '<unk>', 'met', '<unk>', 'van', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:41:47,663 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:41:47,663 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:41:47,663 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> <unk>, <unk> <unk>, <unk> met <unk> van <unk> staten, met <unk>.
2025-05-22 15:41:47,663 - INFO - joeynmt.training - Example #1
2025-05-22 15:41:47,663 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:41:47,663 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:41:47,663 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', '<unk>', 'genoeg', 'is', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:41:47,664 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:41:47,664 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:41:47,664 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet <unk> genoeg is om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:41:47,664 - INFO - joeynmt.training - Example #2
2025-05-22 15:41:47,664 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:41:47,664 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:41:47,664 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:41:47,664 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:41:47,664 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:41:47,665 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:41:47,665 - INFO - joeynmt.training - Example #3
2025-05-22 15:41:47,665 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:41:47,665 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:41:47,665 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:41:47,665 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:41:47,665 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:41:47,665 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:41:47,665 - INFO - joeynmt.training - Example #4
2025-05-22 15:41:47,665 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:41:47,666 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:41:47,666 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:41:47,667 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:41:47,667 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:41:47,667 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:41:54,331 - INFO - joeynmt.training - Epoch   9, Step:    51100, Batch Loss:     1.343037, Batch Acc: 0.574096, Tokens per Sec:     9835, Lr: 0.000147
2025-05-22 15:42:00,870 - INFO - joeynmt.training - Epoch   9, Step:    51200, Batch Loss:     1.522328, Batch Acc: 0.576039, Tokens per Sec:    10109, Lr: 0.000147
2025-05-22 15:42:07,328 - INFO - joeynmt.training - Epoch   9, Step:    51300, Batch Loss:     1.306615, Batch Acc: 0.576286, Tokens per Sec:    10328, Lr: 0.000147
2025-05-22 15:42:13,595 - INFO - joeynmt.training - Epoch   9, Step:    51400, Batch Loss:     1.428407, Batch Acc: 0.572809, Tokens per Sec:    10536, Lr: 0.000147
2025-05-22 15:42:19,874 - INFO - joeynmt.training - Epoch   9, Step:    51500, Batch Loss:     1.420382, Batch Acc: 0.573610, Tokens per Sec:    11195, Lr: 0.000147
2025-05-22 15:42:19,874 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:42:19,875 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:42:26,918 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.04, acc:   0.51, generation: 6.9805[sec], evaluation: 0.0000[sec]
2025-05-22 15:42:27,047 - INFO - joeynmt.helpers - delete models/transformer_enit/48000.ckpt
2025-05-22 15:42:27,056 - INFO - joeynmt.training - Example #0
2025-05-22 15:42:27,056 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:42:27,057 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:42:27,057 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:42:27,058 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:42:27,058 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:42:27,058 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> van de <unk> <unk> staten, met <unk>.
2025-05-22 15:42:27,059 - INFO - joeynmt.training - Example #1
2025-05-22 15:42:27,059 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:42:27,059 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:42:27,059 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'om', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:42:27,060 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:42:27,060 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:42:27,060 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg om de <unk> van deze <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:42:27,060 - INFO - joeynmt.training - Example #2
2025-05-22 15:42:27,060 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:42:27,060 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:42:27,060 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'mondiale', '<unk>', '.', '</s>']
2025-05-22 15:42:27,061 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:42:27,061 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:42:27,061 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons mondiale <unk>.
2025-05-22 15:42:27,061 - INFO - joeynmt.training - Example #3
2025-05-22 15:42:27,061 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:42:27,061 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:42:27,061 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', 'zomer', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:42:27,063 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:42:27,063 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:42:27,063 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de zomer en <unk> in de zomer.
2025-05-22 15:42:27,063 - INFO - joeynmt.training - Example #4
2025-05-22 15:42:27,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:42:27,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:42:27,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:42:27,064 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:42:27,064 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:42:27,064 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:42:33,003 - INFO - joeynmt.training - Epoch   9, Step:    51600, Batch Loss:     1.324666, Batch Acc: 0.575156, Tokens per Sec:    10933, Lr: 0.000147
2025-05-22 15:42:38,836 - INFO - joeynmt.training - Epoch   9, Step:    51700, Batch Loss:     1.432017, Batch Acc: 0.577754, Tokens per Sec:    11395, Lr: 0.000147
2025-05-22 15:42:45,231 - INFO - joeynmt.training - Epoch   9, Step:    51800, Batch Loss:     1.199993, Batch Acc: 0.577365, Tokens per Sec:    10149, Lr: 0.000147
2025-05-22 15:42:51,632 - INFO - joeynmt.training - Epoch   9, Step:    51900, Batch Loss:     1.352102, Batch Acc: 0.573571, Tokens per Sec:     9729, Lr: 0.000147
2025-05-22 15:42:58,034 - INFO - joeynmt.training - Epoch   9, Step:    52000, Batch Loss:     1.413801, Batch Acc: 0.578216, Tokens per Sec:    10402, Lr: 0.000147
2025-05-22 15:42:58,035 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:42:58,035 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:43:05,549 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.50, generation: 7.4333[sec], evaluation: 0.0000[sec]
2025-05-22 15:43:05,554 - INFO - joeynmt.training - Example #0
2025-05-22 15:43:05,554 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:43:05,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:43:05,555 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', '<unk>', ',', '40', 'procent', '.', '</s>']
2025-05-22 15:43:05,556 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:43:05,556 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:43:05,556 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> van de <unk> <unk> <unk>, 40 procent.
2025-05-22 15:43:05,556 - INFO - joeynmt.training - Example #1
2025-05-22 15:43:05,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:43:05,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:43:05,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', 'is', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:43:05,557 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:43:05,557 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:43:05,558 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg <unk> is de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> <unk>.
2025-05-22 15:43:05,558 - INFO - joeynmt.training - Example #2
2025-05-22 15:43:05,558 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:43:05,558 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:43:05,558 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:43:05,559 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:43:05,559 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:43:05,559 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:43:05,559 - INFO - joeynmt.training - Example #3
2025-05-22 15:43:05,559 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:43:05,559 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:43:05,559 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:43:05,560 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:43:05,560 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:43:05,560 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:43:05,560 - INFO - joeynmt.training - Example #4
2025-05-22 15:43:05,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:43:05,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:43:05,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'laatste', '25', 'jaar', 'is', '.', '</s>']
2025-05-22 15:43:05,561 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:43:05,561 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:43:05,561 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> <unk> van wat er in de laatste 25 jaar is.
2025-05-22 15:43:12,239 - INFO - joeynmt.training - Epoch   9, Step:    52100, Batch Loss:     1.331629, Batch Acc: 0.577907, Tokens per Sec:    10016, Lr: 0.000103
2025-05-22 15:43:18,747 - INFO - joeynmt.training - Epoch   9, Step:    52200, Batch Loss:     1.329844, Batch Acc: 0.576027, Tokens per Sec:    10056, Lr: 0.000103
2025-05-22 15:43:25,332 - INFO - joeynmt.training - Epoch   9, Step:    52300, Batch Loss:     1.204605, Batch Acc: 0.577867, Tokens per Sec:    10103, Lr: 0.000103
2025-05-22 15:43:31,416 - INFO - joeynmt.training - Epoch   9, Step:    52400, Batch Loss:     1.384718, Batch Acc: 0.575890, Tokens per Sec:    10816, Lr: 0.000103
2025-05-22 15:43:37,317 - INFO - joeynmt.training - Epoch   9, Step:    52500, Batch Loss:     1.330185, Batch Acc: 0.586309, Tokens per Sec:    11286, Lr: 0.000103
2025-05-22 15:43:37,318 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:43:37,318 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:43:43,480 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.02, acc:   0.51, generation: 6.0902[sec], evaluation: 0.0000[sec]
2025-05-22 15:43:43,614 - INFO - joeynmt.helpers - delete models/transformer_enit/51500.ckpt
2025-05-22 15:43:43,622 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit/51500.ckpt
2025-05-22 15:43:43,623 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit\51500.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit\\51500.ckpt')
2025-05-22 15:43:43,627 - INFO - joeynmt.training - Example #0
2025-05-22 15:43:43,627 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:43:43,627 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:43:43,627 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'in', 'de', '<unk>', 'van', '<unk>', 'staten', ',', 'om', '40', 'procent', 'te', '<unk>', '.', '</s>']
2025-05-22 15:43:43,628 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:43:43,628 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:43:43,628 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> in de <unk> van <unk> staten, om 40 procent te <unk>.
2025-05-22 15:43:43,628 - INFO - joeynmt.training - Example #1
2025-05-22 15:43:43,628 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:43:43,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:43:43,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', '<unk>', 'genoeg', '<unk>', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:43:43,629 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:43:43,629 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:43:43,630 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet <unk> genoeg <unk> om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:43:43,630 - INFO - joeynmt.training - Example #2
2025-05-22 15:43:43,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:43:43,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:43:43,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:43:43,631 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:43:43,631 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:43:43,631 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:43:43,631 - INFO - joeynmt.training - Example #3
2025-05-22 15:43:43,631 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:43:43,631 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:43:43,631 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:43:43,632 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:43:43,632 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:43:43,632 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:43:43,632 - INFO - joeynmt.training - Example #4
2025-05-22 15:43:43,632 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:43:43,632 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:43:43,632 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:43:43,633 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:43:43,633 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:43:43,633 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:43:49,519 - INFO - joeynmt.training - Epoch   9, Step:    52600, Batch Loss:     1.415717, Batch Acc: 0.575621, Tokens per Sec:    10935, Lr: 0.000103
2025-05-22 15:43:55,382 - INFO - joeynmt.training - Epoch   9, Step:    52700, Batch Loss:     1.528191, Batch Acc: 0.579287, Tokens per Sec:    11332, Lr: 0.000103
2025-05-22 15:44:01,583 - INFO - joeynmt.training - Epoch   9, Step:    52800, Batch Loss:     1.203619, Batch Acc: 0.580120, Tokens per Sec:    10772, Lr: 0.000103
2025-05-22 15:44:08,137 - INFO - joeynmt.training - Epoch   9, Step:    52900, Batch Loss:     1.385324, Batch Acc: 0.573939, Tokens per Sec:     9961, Lr: 0.000103
2025-05-22 15:44:14,618 - INFO - joeynmt.training - Epoch   9, Step:    53000, Batch Loss:     1.439402, Batch Acc: 0.573194, Tokens per Sec:    10211, Lr: 0.000103
2025-05-22 15:44:14,619 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:44:14,619 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:44:21,904 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.00, acc:   0.51, generation: 7.2146[sec], evaluation: 0.0000[sec]
2025-05-22 15:44:21,905 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-22 15:44:22,048 - INFO - joeynmt.helpers - delete models/transformer_enit/51000.ckpt
2025-05-22 15:44:22,059 - INFO - joeynmt.training - Example #0
2025-05-22 15:44:22,059 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:44:22,060 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:44:22,060 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', 'van', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:44:22,060 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:44:22,061 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:44:22,061 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> van de <unk> van de <unk> <unk> staten, met <unk>.
2025-05-22 15:44:22,061 - INFO - joeynmt.training - Example #1
2025-05-22 15:44:22,061 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:44:22,061 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:44:22,061 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', 'is', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:44:22,061 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:44:22,061 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:44:22,061 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg <unk> is de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 15:44:22,061 - INFO - joeynmt.training - Example #2
2025-05-22 15:44:22,062 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:44:22,062 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:44:22,062 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:44:22,062 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:44:22,062 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:44:22,062 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk> <unk>.
2025-05-22 15:44:22,062 - INFO - joeynmt.training - Example #3
2025-05-22 15:44:22,062 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:44:22,062 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:44:22,062 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:44:22,063 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:44:22,063 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:44:22,063 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:44:22,063 - INFO - joeynmt.training - Example #4
2025-05-22 15:44:22,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:44:22,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:44:22,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:44:22,063 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:44:22,063 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:44:22,063 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:44:28,414 - INFO - joeynmt.training - Epoch   9, Step:    53100, Batch Loss:     1.358761, Batch Acc: 0.577456, Tokens per Sec:    10281, Lr: 0.000103
2025-05-22 15:44:35,036 - INFO - joeynmt.training - Epoch   9, Step:    53200, Batch Loss:     1.570087, Batch Acc: 0.574316, Tokens per Sec:    10178, Lr: 0.000103
2025-05-22 15:44:41,591 - INFO - joeynmt.training - Epoch   9, Step:    53300, Batch Loss:     1.337535, Batch Acc: 0.578654, Tokens per Sec:    10121, Lr: 0.000103
2025-05-22 15:44:47,972 - INFO - joeynmt.training - Epoch   9, Step:    53400, Batch Loss:     1.297793, Batch Acc: 0.573983, Tokens per Sec:    10247, Lr: 0.000103
2025-05-22 15:44:51,532 - INFO - joeynmt.training - Epoch   9: total training loss 7985.84
2025-05-22 15:44:51,532 - INFO - joeynmt.training - EPOCH 10
2025-05-22 15:44:54,225 - INFO - joeynmt.training - Epoch  10, Step:    53500, Batch Loss:     1.246089, Batch Acc: 0.600360, Tokens per Sec:    10936, Lr: 0.000103
2025-05-22 15:44:54,226 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:44:54,226 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:45:00,517 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.03, acc:   0.51, generation: 6.2267[sec], evaluation: 0.0000[sec]
2025-05-22 15:45:00,521 - INFO - joeynmt.training - Example #0
2025-05-22 15:45:00,521 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:45:00,521 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:45:00,521 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:45:00,522 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:45:00,522 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:45:00,522 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, drie miljoen jaar de <unk> van de <unk> <unk> staten, met <unk>.
2025-05-22 15:45:00,522 - INFO - joeynmt.training - Example #1
2025-05-22 15:45:00,522 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:45:00,522 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:45:00,522 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', '<unk>', 'niet', 'sterk', 'genoeg', '<unk>', 'is', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:45:00,524 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:45:00,524 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:45:00,524 - INFO - joeynmt.training - 	Hypothesis: Maar dat <unk> niet sterk genoeg <unk> is de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 15:45:00,524 - INFO - joeynmt.training - Example #2
2025-05-22 15:45:00,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:45:00,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:45:00,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:45:00,525 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:45:00,526 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:45:00,526 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:45:00,526 - INFO - joeynmt.training - Example #3
2025-05-22 15:45:00,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:45:00,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:45:00,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:45:00,527 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:45:00,527 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:45:00,527 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:45:00,527 - INFO - joeynmt.training - Example #4
2025-05-22 15:45:00,527 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:45:00,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:45:00,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'van', 'wat', 'er', 'in', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.', '</s>']
2025-05-22 15:45:00,528 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:45:00,528 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:45:00,528 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> van wat er in de afgelopen 25 jaar is gebeurd.
2025-05-22 15:45:06,613 - INFO - joeynmt.training - Epoch  10, Step:    53600, Batch Loss:     1.250715, Batch Acc: 0.591920, Tokens per Sec:    11075, Lr: 0.000103
2025-05-22 15:45:14,708 - INFO - joeynmt.training - Epoch  10, Step:    53700, Batch Loss:     1.266763, Batch Acc: 0.594328, Tokens per Sec:     8065, Lr: 0.000103
2025-05-22 15:45:21,937 - INFO - joeynmt.training - Epoch  10, Step:    53800, Batch Loss:     1.322525, Batch Acc: 0.595386, Tokens per Sec:     9099, Lr: 0.000103
2025-05-22 15:45:29,263 - INFO - joeynmt.training - Epoch  10, Step:    53900, Batch Loss:     1.151486, Batch Acc: 0.597341, Tokens per Sec:     9160, Lr: 0.000103
2025-05-22 15:45:36,700 - INFO - joeynmt.training - Epoch  10, Step:    54000, Batch Loss:     1.313404, Batch Acc: 0.594753, Tokens per Sec:     8817, Lr: 0.000103
2025-05-22 15:45:36,700 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:45:36,700 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:45:44,600 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.51, generation: 7.8216[sec], evaluation: 0.0000[sec]
2025-05-22 15:45:44,605 - INFO - joeynmt.training - Example #0
2025-05-22 15:45:44,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:45:44,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:45:44,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', '<unk>', ',', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:45:44,606 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:45:44,606 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:45:44,606 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, drie miljoen jaar <unk>, de <unk> van de <unk> <unk> staten, met <unk> <unk>.
2025-05-22 15:45:44,606 - INFO - joeynmt.training - Example #1
2025-05-22 15:45:44,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:45:44,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:45:44,607 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'om', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:45:44,607 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:45:44,607 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:45:44,607 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg om de <unk> van dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:45:44,608 - INFO - joeynmt.training - Example #2
2025-05-22 15:45:44,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:45:44,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:45:44,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:45:44,609 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:45:44,609 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:45:44,609 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:45:44,609 - INFO - joeynmt.training - Example #3
2025-05-22 15:45:44,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:45:44,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:45:44,610 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:45:44,610 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:45:44,610 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:45:44,610 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:45:44,611 - INFO - joeynmt.training - Example #4
2025-05-22 15:45:44,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:45:44,611 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:45:44,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:45:44,612 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:45:44,612 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:45:44,612 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:45:51,277 - INFO - joeynmt.training - Epoch  10, Step:    54100, Batch Loss:     1.216712, Batch Acc: 0.591615, Tokens per Sec:     9724, Lr: 0.000103
2025-05-22 15:45:57,683 - INFO - joeynmt.training - Epoch  10, Step:    54200, Batch Loss:     1.337956, Batch Acc: 0.591434, Tokens per Sec:    10743, Lr: 0.000103
2025-05-22 15:46:04,928 - INFO - joeynmt.training - Epoch  10, Step:    54300, Batch Loss:     1.465736, Batch Acc: 0.590340, Tokens per Sec:     8965, Lr: 0.000103
2025-05-22 15:46:12,848 - INFO - joeynmt.training - Epoch  10, Step:    54400, Batch Loss:     1.443833, Batch Acc: 0.598324, Tokens per Sec:     8453, Lr: 0.000103
2025-05-22 15:46:20,078 - INFO - joeynmt.training - Epoch  10, Step:    54500, Batch Loss:     1.170537, Batch Acc: 0.593080, Tokens per Sec:     9183, Lr: 0.000103
2025-05-22 15:46:20,078 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:46:20,078 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:46:26,820 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.51, generation: 6.6773[sec], evaluation: 0.0000[sec]
2025-05-22 15:46:26,824 - INFO - joeynmt.training - Example #0
2025-05-22 15:46:26,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:46:26,825 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:46:26,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:46:26,826 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:46:26,826 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:46:26,826 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, drie miljoen jaar de <unk> van de <unk> <unk> staten, met <unk>.
2025-05-22 15:46:26,826 - INFO - joeynmt.training - Example #1
2025-05-22 15:46:26,826 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:46:26,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:46:26,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'zo', 'sterk', 'genoeg', '<unk>', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:46:26,828 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:46:26,828 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:46:26,828 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet zo sterk genoeg <unk> de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:46:26,828 - INFO - joeynmt.training - Example #2
2025-05-22 15:46:26,828 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:46:26,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:46:26,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:46:26,829 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:46:26,829 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:46:26,829 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:46:26,829 - INFO - joeynmt.training - Example #3
2025-05-22 15:46:26,829 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:46:26,829 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:46:26,829 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:46:26,830 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:46:26,830 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:46:26,830 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:46:26,830 - INFO - joeynmt.training - Example #4
2025-05-22 15:46:26,830 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:46:26,831 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:46:26,831 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:46:26,831 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:46:26,831 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:46:26,831 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> <unk> in de laatste 25 jaar.
2025-05-22 15:46:33,737 - INFO - joeynmt.training - Epoch  10, Step:    54600, Batch Loss:     1.185666, Batch Acc: 0.588642, Tokens per Sec:     9226, Lr: 0.000103
2025-05-22 15:46:40,479 - INFO - joeynmt.training - Epoch  10, Step:    54700, Batch Loss:     1.191021, Batch Acc: 0.591777, Tokens per Sec:     9582, Lr: 0.000103
2025-05-22 15:46:47,502 - INFO - joeynmt.training - Epoch  10, Step:    54800, Batch Loss:     1.162168, Batch Acc: 0.593814, Tokens per Sec:     9364, Lr: 0.000103
2025-05-22 15:46:54,782 - INFO - joeynmt.training - Epoch  10, Step:    54900, Batch Loss:     1.314082, Batch Acc: 0.592312, Tokens per Sec:     9080, Lr: 0.000103
2025-05-22 15:47:01,946 - INFO - joeynmt.training - Epoch  10, Step:    55000, Batch Loss:     1.278155, Batch Acc: 0.589397, Tokens per Sec:     9418, Lr: 0.000103
2025-05-22 15:47:01,947 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:47:01,947 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:47:09,737 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.51, generation: 7.7079[sec], evaluation: 0.0000[sec]
2025-05-22 15:47:09,743 - INFO - joeynmt.training - Example #0
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:47:09,743 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:47:09,743 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:47:09,743 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> de <unk> van de <unk> <unk> staten, met <unk>.
2025-05-22 15:47:09,743 - INFO - joeynmt.training - Example #1
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:47:09,743 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:47:09,743 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:47:09,743 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> <unk>.
2025-05-22 15:47:09,743 - INFO - joeynmt.training - Example #2
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:47:09,743 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:47:09,743 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:47:09,743 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:47:09,743 - INFO - joeynmt.training - Example #3
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:47:09,743 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:47:09,743 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:47:09,743 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:47:09,743 - INFO - joeynmt.training - Example #4
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:47:09,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:47:09,743 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:47:09,752 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:47:09,752 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:47:16,420 - INFO - joeynmt.training - Epoch  10, Step:    55100, Batch Loss:     1.382592, Batch Acc: 0.595667, Tokens per Sec:    10036, Lr: 0.000103
2025-05-22 15:47:23,004 - INFO - joeynmt.training - Epoch  10, Step:    55200, Batch Loss:     1.174186, Batch Acc: 0.593212, Tokens per Sec:     9745, Lr: 0.000103
2025-05-22 15:47:30,163 - INFO - joeynmt.training - Epoch  10, Step:    55300, Batch Loss:     1.439693, Batch Acc: 0.584262, Tokens per Sec:     9225, Lr: 0.000103
2025-05-22 15:47:36,586 - INFO - joeynmt.training - Epoch  10, Step:    55400, Batch Loss:     1.309142, Batch Acc: 0.590281, Tokens per Sec:    10444, Lr: 0.000103
2025-05-22 15:47:43,852 - INFO - joeynmt.training - Epoch  10, Step:    55500, Batch Loss:     1.192533, Batch Acc: 0.594793, Tokens per Sec:     9220, Lr: 0.000103
2025-05-22 15:47:43,853 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:47:43,853 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:47:51,162 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.05, acc:   0.51, generation: 7.2402[sec], evaluation: 0.0000[sec]
2025-05-22 15:47:51,166 - INFO - joeynmt.training - Example #0
2025-05-22 15:47:51,167 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:47:51,167 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:47:51,167 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', ',', 'de', '<unk>', 'van', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:47:51,168 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:47:51,168 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:47:51,168 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk>, de <unk> van <unk> staten, met <unk>.
2025-05-22 15:47:51,168 - INFO - joeynmt.training - Example #1
2025-05-22 15:47:51,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:47:51,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:47:51,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', '<unk>', 'genoeg', '<unk>', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:47:51,169 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:47:51,169 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:47:51,169 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet <unk> genoeg <unk> de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:47:51,169 - INFO - joeynmt.training - Example #2
2025-05-22 15:47:51,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:47:51,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:47:51,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:47:51,170 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:47:51,170 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:47:51,170 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:47:51,171 - INFO - joeynmt.training - Example #3
2025-05-22 15:47:51,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:47:51,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:47:51,172 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:47:51,172 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:47:51,172 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:47:51,172 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:47:51,172 - INFO - joeynmt.training - Example #4
2025-05-22 15:47:51,172 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:47:51,172 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:47:51,172 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', ',', 'is', 'een', '<unk>', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 15:47:51,173 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:47:51,173 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:47:51,173 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien, is een <unk> in de afgelopen 25 jaar.
2025-05-22 15:47:57,660 - INFO - joeynmt.training - Epoch  10, Step:    55600, Batch Loss:     1.299588, Batch Acc: 0.589274, Tokens per Sec:    10320, Lr: 0.000103
2025-05-22 15:48:03,948 - INFO - joeynmt.training - Epoch  10, Step:    55700, Batch Loss:     1.259399, Batch Acc: 0.588353, Tokens per Sec:    10761, Lr: 0.000103
2025-05-22 15:48:10,792 - INFO - joeynmt.training - Epoch  10, Step:    55800, Batch Loss:     1.346104, Batch Acc: 0.585256, Tokens per Sec:     9743, Lr: 0.000103
2025-05-22 15:48:17,858 - INFO - joeynmt.training - Epoch  10, Step:    55900, Batch Loss:     1.214636, Batch Acc: 0.590482, Tokens per Sec:     9409, Lr: 0.000103
2025-05-22 15:48:24,604 - INFO - joeynmt.training - Epoch  10, Step:    56000, Batch Loss:     1.161800, Batch Acc: 0.594754, Tokens per Sec:     9834, Lr: 0.000103
2025-05-22 15:48:24,604 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:48:24,604 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:48:33,281 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.07, acc:   0.50, generation: 8.5865[sec], evaluation: 0.0000[sec]
2025-05-22 15:48:33,286 - INFO - joeynmt.training - Example #0
2025-05-22 15:48:33,286 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:48:33,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:48:33,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', ',', 'de', '<unk>', 'van', '<unk>', 'staten', ',', 'met', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:48:33,288 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:48:33,288 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:48:33,288 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk>, de <unk> van <unk> staten, met <unk> <unk>.
2025-05-22 15:48:33,288 - INFO - joeynmt.training - Example #1
2025-05-22 15:48:33,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:48:33,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:48:33,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'sterk', 'genoeg', '<unk>', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:48:33,289 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:48:33,289 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:48:33,289 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg <unk> de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:48:33,289 - INFO - joeynmt.training - Example #2
2025-05-22 15:48:33,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:48:33,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:48:33,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:48:33,290 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:48:33,291 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:48:33,291 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:48:33,291 - INFO - joeynmt.training - Example #3
2025-05-22 15:48:33,291 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:48:33,291 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:48:33,291 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:48:33,292 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:48:33,292 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:48:33,292 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:48:33,292 - INFO - joeynmt.training - Example #4
2025-05-22 15:48:33,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:48:33,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:48:33,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:48:33,293 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:48:33,293 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:48:33,294 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> <unk> in de laatste 25 jaar.
2025-05-22 15:48:40,813 - INFO - joeynmt.training - Epoch  10, Step:    56100, Batch Loss:     1.223074, Batch Acc: 0.589136, Tokens per Sec:     8691, Lr: 0.000103
2025-05-22 15:48:48,002 - INFO - joeynmt.training - Epoch  10, Step:    56200, Batch Loss:     1.168761, Batch Acc: 0.593398, Tokens per Sec:     9098, Lr: 0.000103
2025-05-22 15:48:54,777 - INFO - joeynmt.training - Epoch  10, Step:    56300, Batch Loss:     1.258226, Batch Acc: 0.591421, Tokens per Sec:     9785, Lr: 0.000103
2025-05-22 15:49:01,050 - INFO - joeynmt.training - Epoch  10, Step:    56400, Batch Loss:     1.306432, Batch Acc: 0.591138, Tokens per Sec:    10857, Lr: 0.000103
2025-05-22 15:49:07,217 - INFO - joeynmt.training - Epoch  10, Step:    56500, Batch Loss:     1.430423, Batch Acc: 0.585621, Tokens per Sec:    10855, Lr: 0.000103
2025-05-22 15:49:07,217 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:49:07,217 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:49:13,802 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.08, acc:   0.51, generation: 6.5212[sec], evaluation: 0.0000[sec]
2025-05-22 15:49:13,806 - INFO - joeynmt.training - Example #0
2025-05-22 15:49:13,806 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:49:13,807 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:49:13,807 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '40', 'procent', '<unk>', '.', '</s>']
2025-05-22 15:49:13,807 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:49:13,807 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:49:13,808 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> <unk> van de <unk> <unk> staten, met 40 procent <unk>.
2025-05-22 15:49:13,808 - INFO - joeynmt.training - Example #1
2025-05-22 15:49:13,808 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:49:13,808 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:49:13,808 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'sterk', 'genoeg', '<unk>', 'om', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:49:13,809 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:49:13,809 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:49:13,809 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg <unk> om de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:49:13,810 - INFO - joeynmt.training - Example #2
2025-05-22 15:49:13,810 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:49:13,810 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:49:13,810 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:49:13,811 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:49:13,811 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:49:13,811 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:49:13,811 - INFO - joeynmt.training - Example #3
2025-05-22 15:49:13,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:49:13,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:49:13,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:49:13,812 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:49:13,812 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:49:13,812 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:49:13,812 - INFO - joeynmt.training - Example #4
2025-05-22 15:49:13,812 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:49:13,812 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:49:13,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:49:13,813 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:49:13,813 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:49:13,813 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik jullie laten zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:49:19,847 - INFO - joeynmt.training - Epoch  10, Step:    56600, Batch Loss:     1.349804, Batch Acc: 0.587793, Tokens per Sec:    11003, Lr: 0.000103
2025-05-22 15:49:25,915 - INFO - joeynmt.training - Epoch  10, Step:    56700, Batch Loss:     1.248569, Batch Acc: 0.588005, Tokens per Sec:    11103, Lr: 0.000103
2025-05-22 15:49:32,500 - INFO - joeynmt.training - Epoch  10, Step:    56800, Batch Loss:     1.226342, Batch Acc: 0.590291, Tokens per Sec:     9767, Lr: 0.000103
2025-05-22 15:49:39,091 - INFO - joeynmt.training - Epoch  10, Step:    56900, Batch Loss:     1.350690, Batch Acc: 0.591510, Tokens per Sec:    10058, Lr: 0.000103
2025-05-22 15:49:45,694 - INFO - joeynmt.training - Epoch  10, Step:    57000, Batch Loss:     1.511373, Batch Acc: 0.585271, Tokens per Sec:     9995, Lr: 0.000103
2025-05-22 15:49:45,695 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:49:45,695 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:49:53,101 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.50, generation: 7.3280[sec], evaluation: 0.0000[sec]
2025-05-22 15:49:53,105 - INFO - joeynmt.training - Example #0
2025-05-22 15:49:53,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:49:53,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:49:53,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:49:53,107 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:49:53,107 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:49:53,107 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, drie miljoen jaar de <unk> van de <unk> <unk> staten, met <unk> <unk>.
2025-05-22 15:49:53,107 - INFO - joeynmt.training - Example #1
2025-05-22 15:49:53,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:49:53,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:49:53,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'om', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:49:53,109 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:49:53,109 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:49:53,109 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg om de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:49:53,109 - INFO - joeynmt.training - Example #2
2025-05-22 15:49:53,109 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:49:53,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:49:53,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', 'wereldwijde', '<unk>', '.', '</s>']
2025-05-22 15:49:53,110 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:49:53,110 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:49:53,110 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons wereldwijde <unk>.
2025-05-22 15:49:53,110 - INFO - joeynmt.training - Example #3
2025-05-22 15:49:53,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:49:53,111 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:49:53,111 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:49:53,112 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:49:53,112 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:49:53,112 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:49:53,112 - INFO - joeynmt.training - Example #4
2025-05-22 15:49:53,112 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:49:53,112 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:49:53,112 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'afgelopen', '25', 'jaar', '.', '</s>']
2025-05-22 15:49:53,113 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:49:53,113 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:49:53,113 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de afgelopen 25 jaar.
2025-05-22 15:50:00,544 - INFO - joeynmt.training - Epoch  10, Step:    57100, Batch Loss:     1.409389, Batch Acc: 0.585682, Tokens per Sec:     8783, Lr: 0.000103
2025-05-22 15:50:07,323 - INFO - joeynmt.training - Epoch  10, Step:    57200, Batch Loss:     1.380291, Batch Acc: 0.585712, Tokens per Sec:     9577, Lr: 0.000103
2025-05-22 15:50:13,780 - INFO - joeynmt.training - Epoch  10, Step:    57300, Batch Loss:     1.292552, Batch Acc: 0.590708, Tokens per Sec:    10378, Lr: 0.000103
2025-05-22 15:50:19,912 - INFO - joeynmt.training - Epoch  10, Step:    57400, Batch Loss:     1.324129, Batch Acc: 0.592839, Tokens per Sec:    10533, Lr: 0.000103
2025-05-22 15:50:25,819 - INFO - joeynmt.training - Epoch  10, Step:    57500, Batch Loss:     1.440346, Batch Acc: 0.583172, Tokens per Sec:    11175, Lr: 0.000103
2025-05-22 15:50:25,820 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:50:25,820 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:50:32,114 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.05, acc:   0.51, generation: 6.2273[sec], evaluation: 0.0000[sec]
2025-05-22 15:50:32,119 - INFO - joeynmt.training - Example #0
2025-05-22 15:50:32,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:50:32,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:50:32,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:50:32,120 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:50:32,120 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:50:32,120 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, die drie miljoen jaar de <unk> van de <unk> <unk> staten, met <unk>.
2025-05-22 15:50:32,120 - INFO - joeynmt.training - Example #1
2025-05-22 15:50:32,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:50:32,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:50:32,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'sterk', 'genoeg', '<unk>', 'om', 'dit', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:50:32,121 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:50:32,121 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:50:32,121 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg <unk> om dit <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:50:32,121 - INFO - joeynmt.training - Example #2
2025-05-22 15:50:32,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:50:32,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:50:32,122 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:50:32,122 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:50:32,122 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:50:32,122 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:50:32,122 - INFO - joeynmt.training - Example #3
2025-05-22 15:50:32,123 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:50:32,123 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:50:32,123 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:50:32,123 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:50:32,123 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:50:32,123 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:50:32,123 - INFO - joeynmt.training - Example #4
2025-05-22 15:50:32,123 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:50:32,123 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:50:32,123 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:50:32,124 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:50:32,124 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:50:32,124 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:50:38,040 - INFO - joeynmt.training - Epoch  10, Step:    57600, Batch Loss:     1.233368, Batch Acc: 0.587895, Tokens per Sec:    11166, Lr: 0.000072
2025-05-22 15:50:43,966 - INFO - joeynmt.training - Epoch  10, Step:    57700, Batch Loss:     1.409093, Batch Acc: 0.587870, Tokens per Sec:    10905, Lr: 0.000072
2025-05-22 15:50:50,346 - INFO - joeynmt.training - Epoch  10, Step:    57800, Batch Loss:     1.293872, Batch Acc: 0.588343, Tokens per Sec:    10384, Lr: 0.000072
2025-05-22 15:50:56,928 - INFO - joeynmt.training - Epoch  10, Step:    57900, Batch Loss:     1.421848, Batch Acc: 0.585206, Tokens per Sec:    10160, Lr: 0.000072
2025-05-22 15:51:03,440 - INFO - joeynmt.training - Epoch  10, Step:    58000, Batch Loss:     1.332995, Batch Acc: 0.585363, Tokens per Sec:    10208, Lr: 0.000072
2025-05-22 15:51:03,441 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:51:03,441 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:51:10,139 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.03, acc:   0.51, generation: 6.6203[sec], evaluation: 0.0000[sec]
2025-05-22 15:51:10,145 - INFO - joeynmt.training - Example #0
2025-05-22 15:51:10,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:51:10,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:51:10,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', 'laten', 'zien', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:51:10,145 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:51:10,145 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:51:10,145 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> laten zien om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> de <unk> van de <unk> <unk> staten, met <unk>.
2025-05-22 15:51:10,145 - INFO - joeynmt.training - Example #1
2025-05-22 15:51:10,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:51:10,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:51:10,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'om', 'de', '<unk>', 'van', 'dit', '<unk>', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', 'laat', 'zien', '.', '</s>']
2025-05-22 15:51:10,145 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:51:10,149 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:51:10,149 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg om de <unk> van dit <unk> <unk>, omdat het niet de <unk> van de <unk> laat zien.
2025-05-22 15:51:10,149 - INFO - joeynmt.training - Example #2
2025-05-22 15:51:10,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:51:10,149 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:51:10,149 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:51:10,150 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:51:10,150 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:51:10,150 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:51:10,150 - INFO - joeynmt.training - Example #3
2025-05-22 15:51:10,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:51:10,151 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:51:10,151 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:51:10,151 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:51:10,151 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:51:10,151 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:51:10,152 - INFO - joeynmt.training - Example #4
2025-05-22 15:51:10,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:51:10,152 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:51:10,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:51:10,152 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:51:10,152 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:51:10,152 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:51:16,603 - INFO - joeynmt.training - Epoch  10, Step:    58100, Batch Loss:     1.288602, Batch Acc: 0.588728, Tokens per Sec:    10267, Lr: 0.000072
2025-05-22 15:51:23,129 - INFO - joeynmt.training - Epoch  10, Step:    58200, Batch Loss:     1.327658, Batch Acc: 0.590039, Tokens per Sec:    10069, Lr: 0.000072
2025-05-22 15:51:29,612 - INFO - joeynmt.training - Epoch  10, Step:    58300, Batch Loss:     1.393263, Batch Acc: 0.586831, Tokens per Sec:    10243, Lr: 0.000072
2025-05-22 15:51:35,745 - INFO - joeynmt.training - Epoch  10, Step:    58400, Batch Loss:     1.331730, Batch Acc: 0.585610, Tokens per Sec:    10674, Lr: 0.000072
2025-05-22 15:51:41,646 - INFO - joeynmt.training - Epoch  10, Step:    58500, Batch Loss:     1.095729, Batch Acc: 0.592304, Tokens per Sec:    11336, Lr: 0.000072
2025-05-22 15:51:41,646 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:51:41,647 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:51:47,921 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.05, acc:   0.51, generation: 6.2032[sec], evaluation: 0.0000[sec]
2025-05-22 15:51:47,925 - INFO - joeynmt.training - Example #0
2025-05-22 15:51:47,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:51:47,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:51:47,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '.', '</s>']
2025-05-22 15:51:47,926 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:51:47,926 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:51:47,926 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk> de <unk> van de <unk> <unk> staten, met <unk>.
2025-05-22 15:51:47,927 - INFO - joeynmt.training - Example #1
2025-05-22 15:51:47,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:51:47,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:51:47,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'om', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '.', '</s>']
2025-05-22 15:51:47,927 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:51:47,927 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:51:47,927 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg om de <unk> van deze <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk>.
2025-05-22 15:51:47,928 - INFO - joeynmt.training - Example #2
2025-05-22 15:51:47,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:51:47,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:51:47,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:51:47,929 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:51:47,929 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:51:47,929 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:51:47,929 - INFO - joeynmt.training - Example #3
2025-05-22 15:51:47,929 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:51:47,929 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:51:47,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:51:47,930 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:51:47,930 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:51:47,930 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:51:47,930 - INFO - joeynmt.training - Example #4
2025-05-22 15:51:47,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:51:47,931 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:51:47,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:51:47,931 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:51:47,931 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:51:47,931 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:51:53,908 - INFO - joeynmt.training - Epoch  10, Step:    58600, Batch Loss:     1.287000, Batch Acc: 0.584841, Tokens per Sec:    11162, Lr: 0.000072
2025-05-22 15:52:00,015 - INFO - joeynmt.training - Epoch  10, Step:    58700, Batch Loss:     1.357266, Batch Acc: 0.586395, Tokens per Sec:    10893, Lr: 0.000072
2025-05-22 15:52:07,745 - INFO - joeynmt.training - Epoch  10, Step:    58800, Batch Loss:     1.325796, Batch Acc: 0.587084, Tokens per Sec:     8435, Lr: 0.000072
2025-05-22 15:52:14,437 - INFO - joeynmt.training - Epoch  10, Step:    58900, Batch Loss:     1.333979, Batch Acc: 0.585971, Tokens per Sec:    10202, Lr: 0.000072
2025-05-22 15:52:23,209 - INFO - joeynmt.training - Epoch  10, Step:    59000, Batch Loss:     1.450840, Batch Acc: 0.587209, Tokens per Sec:     7626, Lr: 0.000072
2025-05-22 15:52:23,210 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:52:23,210 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:52:32,146 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.03, acc:   0.51, generation: 8.8344[sec], evaluation: 0.0000[sec]
2025-05-22 15:52:32,152 - INFO - joeynmt.training - Example #0
2025-05-22 15:52:32,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt', ',', 'um', 'zu', 'veranschaulichen', ',', 'dass', 'die', 'arktische', 'Eiskappe', ',', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte', ',', 'um', '40', 'Prozent', 'geschrumpft', 'ist', '.']
2025-05-22 15:52:32,153 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', 'dia', '&apos;', 's', 'zien', 'om', 'aan', 'te', 'tonen', 'dat', 'de', 'poolijskap', ',', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS', ',', 'met', '40', '%', 'gekrompen', 'was', '.']
2025-05-22 15:52:32,153 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'jaar', 'heb', 'ik', 'deze', 'twee', '<unk>', '<unk>', 'om', 'te', '<unk>', 'dat', 'de', '<unk>', '<unk>', ',', 'die', 'drie', 'miljoen', 'jaar', '<unk>', ',', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', 'staten', ',', 'met', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:52:32,154 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt , um zu veranschaulichen , dass die arktische Eiskappe , die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte , um 40 Prozent geschrumpft ist .
2025-05-22 15:52:32,154 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia &apos; s zien om aan te tonen dat de poolijskap , die de afgelopen drie miljoen jaar ongeveer de grootte had van het vasteland van de VS , met 40 % gekrompen was .
2025-05-22 15:52:32,155 - INFO - joeynmt.training - 	Hypothesis: <unk> jaar heb ik deze twee <unk> <unk> om te <unk> dat de <unk> <unk>, die drie miljoen jaar <unk>, de <unk> van de <unk> <unk> staten, met <unk> <unk>.
2025-05-22 15:52:32,155 - INFO - joeynmt.training - Example #1
2025-05-22 15:52:32,155 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus', ',', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt', '.']
2025-05-22 15:52:32,156 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien', '.']
2025-05-22 15:52:32,156 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'erg', 'genoeg', 'om', 'de', '<unk>', 'van', 'deze', '<unk>', '<unk>', 'te', '<unk>', ',', 'omdat', 'het', 'niet', 'de', '<unk>', 'van', 'de', '<unk>', '<unk>', '.', '</s>']
2025-05-22 15:52:32,156 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus , da es nicht die Dicke des Eises zeigt .
2025-05-22 15:52:32,157 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem omdat het niet de dikte van het ijs laat zien .
2025-05-22 15:52:32,157 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet erg genoeg om de <unk> van deze <unk> <unk> te <unk>, omdat het niet de <unk> van de <unk> <unk>.
2025-05-22 15:52:32,157 - INFO - joeynmt.training - Example #2
2025-05-22 15:52:32,157 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems', '.']
2025-05-22 15:52:32,157 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem', '.']
2025-05-22 15:52:32,157 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'zekere', 'zin', 'is', 'de', '<unk>', '<unk>', 'het', '<unk>', 'hart', 'van', 'ons', '<unk>', '.', '</s>']
2025-05-22 15:52:32,158 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems .
2025-05-22 15:52:32,159 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin het kloppend hart van ons globaal klimaatsysteem .
2025-05-22 15:52:32,160 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de <unk> <unk> het <unk> hart van ons <unk>.
2025-05-22 15:52:32,160 - INFO - joeynmt.training - Example #3
2025-05-22 15:52:32,160 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer', '.']
2025-05-22 15:52:32,160 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer', '.']
2025-05-22 15:52:32,160 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'groeit', 'in', 'de', '<unk>', 'en', '<unk>', 'in', 'de', 'zomer', '.', '</s>']
2025-05-22 15:52:32,161 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer .
2025-05-22 15:52:32,161 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer .
2025-05-22 15:52:32,161 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de <unk> en <unk> in de zomer.
2025-05-22 15:52:32,162 - INFO - joeynmt.training - Example #4
2025-05-22 15:52:32,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Folie', ',', 'die', 'ich', 'Ihnen', 'zeige', ',', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist', '.']
2025-05-22 15:52:32,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd', '.']
2025-05-22 15:52:32,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'volgende', '<unk>', 'die', 'ik', 'je', 'laat', 'zien', 'is', 'een', '<unk>', 'in', 'de', 'laatste', '25', 'jaar', '.', '</s>']
2025-05-22 15:52:32,163 - INFO - joeynmt.training - 	Source:     Die nächste Folie , die ich Ihnen zeige , ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist .
2025-05-22 15:52:32,163 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd .
2025-05-22 15:52:32,163 - INFO - joeynmt.training - 	Hypothesis: De volgende <unk> die ik je laat zien is een <unk> in de laatste 25 jaar.
2025-05-22 15:52:39,434 - INFO - joeynmt.training - Epoch  10, Step:    59100, Batch Loss:     1.199352, Batch Acc: 0.587861, Tokens per Sec:     9139, Lr: 0.000072
2025-05-22 15:52:46,112 - INFO - joeynmt.training - Epoch  10, Step:    59200, Batch Loss:     1.343579, Batch Acc: 0.587535, Tokens per Sec:     9617, Lr: 0.000072
2025-05-22 15:52:53,587 - INFO - joeynmt.training - Epoch  10, Step:    59300, Batch Loss:     1.299140, Batch Acc: 0.589175, Tokens per Sec:     9182, Lr: 0.000072
2025-05-22 15:52:59,719 - INFO - joeynmt.training - Epoch  10: total training loss 7789.00
2025-05-22 15:52:59,720 - INFO - joeynmt.training - Training ended after  10 epochs.
2025-05-22 15:52:59,720 - INFO - joeynmt.training - Best validation result (greedy) at step    53000:   5.00 ppl.
2025-05-22 15:52:59,815 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-22 15:52:59,974 - INFO - joeynmt.model - Enc-dec model built.
2025-05-22 15:53:00,192 - INFO - joeynmt.helpers - Load model from C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit\53000.ckpt.
2025-05-22 15:53:00,253 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=None)
2025-05-22 15:53:00,275 - INFO - joeynmt.prediction - Decoding on dev set...
2025-05-22 15:53:00,276 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:53:00,276 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Beam search with beam_size=3, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:53:11,645 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 11.3072[sec], evaluation: 0.0000[sec]
2025-05-22 15:53:11,652 - INFO - joeynmt.prediction - Translations saved to: C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit\00053000.hyps.dev.
2025-05-22 15:53:11,652 - INFO - joeynmt.prediction - Decoding on test set...
2025-05-22 15:53:11,652 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-22 15:53:11,653 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=3, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-22 15:53:27,413 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 15.6423[sec], evaluation: 0.0000[sec]
2025-05-22 15:53:27,421 - INFO - joeynmt.prediction - Translations saved to: C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit\00053000.hyps.test.
