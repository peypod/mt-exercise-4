2025-05-29 18:11:37,967 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-29 18:11:37,967 - INFO - joeynmt.helpers -                           cfg.name : transformer_enit_config
2025-05-29 18:11:37,968 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-29 18:11:37,968 - INFO - joeynmt.helpers -                     cfg.data.train : data/train.de-nl
2025-05-29 18:11:37,968 - INFO - joeynmt.helpers -                       cfg.data.dev : data/dev.de-nl
2025-05-29 18:11:37,968 - INFO - joeynmt.helpers -                      cfg.data.test : data/test.de-nl
2025-05-29 18:11:37,969 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-29 18:11:37,969 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2025-05-29 18:11:37,970 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-29 18:11:37,970 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-29 18:11:37,970 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-29 18:11:37,970 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : data/bpe_vocab.de
2025-05-29 18:11:37,970 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-29 18:11:37,971 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenizer : none
2025-05-29 18:11:37,971 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.num_merges : 2000
2025-05-29 18:11:37,971 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data/codes.bpe
2025-05-29 18:11:37,971 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : nl
2025-05-29 18:11:37,971 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-29 18:11:37,971 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-29 18:11:37,971 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-29 18:11:37,971 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : data/bpe_vocab.nl
2025-05-29 18:11:37,972 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-29 18:11:37,972 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenizer : none
2025-05-29 18:11:37,972 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.num_merges : 2000
2025-05-29 18:11:37,972 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data/codes.bpe
2025-05-29 18:11:37,972 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 3
2025-05-29 18:11:37,972 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-29 18:11:37,972 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-29 18:11:37,973 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-29 18:11:37,973 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-29 18:11:37,973 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-29 18:11:37,973 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-29 18:11:37,973 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-29 18:11:37,973 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-29 18:11:37,973 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-29 18:11:37,973 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-29 18:11:37,974 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-29 18:11:37,974 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-29 18:11:37,974 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-29 18:11:37,974 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-29 18:11:37,974 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-29 18:11:37,974 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-29 18:11:37,974 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-29 18:11:37,974 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-29 18:11:37,974 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/transformer_enit_bpe
2025-05-29 18:11:37,974 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-29 18:11:37,975 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-29 18:11:37,975 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2025-05-29 18:11:37,975 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-29 18:11:37,975 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-29 18:11:37,975 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-29 18:11:37,975 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-29 18:11:37,975 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-29 18:11:37,975 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-29 18:11:37,976 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-29 18:11:37,976 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-29 18:11:37,976 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : False
2025-05-29 18:11:37,976 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-29 18:11:37,976 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-29 18:11:37,976 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-29 18:11:37,976 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-29 18:11:37,977 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-29 18:11:37,977 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-29 18:11:37,977 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-29 18:11:37,977 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-29 18:11:37,977 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-29 18:11:37,977 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-29 18:11:37,978 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-29 18:11:37,978 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-29 18:11:37,978 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-29 18:11:37,978 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-29 18:11:37,978 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-29 18:11:37,978 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-29 18:11:37,978 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-29 18:11:37,978 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-29 18:11:37,979 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-29 18:11:38,036 - INFO - joeynmt.data - Building tokenizer...
2025-05-29 18:11:38,048 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 18:11:38,048 - INFO - joeynmt.tokenizers - nl tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 18:11:38,049 - INFO - joeynmt.data - Loading train set...
2025-05-29 18:11:38,773 - INFO - joeynmt.data - Building vocabulary...
2025-05-29 18:11:38,839 - INFO - joeynmt.data - Loading dev set...
2025-05-29 18:11:38,845 - INFO - joeynmt.data - Loading test set...
2025-05-29 18:11:38,851 - INFO - joeynmt.data - Data loaded.
2025-05-29 18:11:38,851 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=216893, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2025-05-29 18:11:38,852 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1001, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2025-05-29 18:11:38,852 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1779, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2025-05-29 18:11:38,853 - INFO - joeynmt.data - First training example:
	[SRC] A@@ l G@@ or@@ e@@ : Die Ab@@ wen@@ dung der K@@ li@@ ma@@ k@@ at@@ ast@@ rop@@ he
	[TRG] A@@ l G@@ or@@ e over het af@@ wen@@ den van de kl@@ im@@ aat@@ c@@ r@@ is@@ is
2025-05-29 18:11:38,853 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) die (5) und (6) der (7) , (8) in (9) .
2025-05-29 18:11:38,853 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) en (6) een (7) het (8) van (9) dat
2025-05-29 18:11:38,853 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 1771
2025-05-29 18:11:38,853 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 1736
2025-05-29 18:11:38,866 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-29 18:11:38,982 - INFO - joeynmt.model - Enc-dec model built.
2025-05-29 18:11:38,995 - INFO - joeynmt.model - Total params: 3796992
2025-05-29 18:11:38,996 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2025-05-29 18:11:38,996 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=1771),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=1736),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-29 18:11:39,110 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2025-05-29 18:11:39,111 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2025-05-29 18:11:39,111 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2025-05-29 18:11:39,111 - INFO - joeynmt.training - EPOCH 1
2025-05-29 18:11:50,015 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.984273, Batch Acc: 0.038623, Tokens per Sec:     6497, Lr: 0.000300
2025-05-29 18:11:57,985 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     3.830878, Batch Acc: 0.064151, Tokens per Sec:     8571, Lr: 0.000300
2025-05-29 18:12:05,501 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.792732, Batch Acc: 0.076354, Tokens per Sec:     9050, Lr: 0.000300
2025-05-29 18:12:12,832 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.597126, Batch Acc: 0.085428, Tokens per Sec:     9538, Lr: 0.000300
2025-05-29 18:12:20,202 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.547873, Batch Acc: 0.091651, Tokens per Sec:     9313, Lr: 0.000300
2025-05-29 18:12:20,203 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:12:20,203 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:12:54,587 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.58, ppl:  35.71, acc:   0.09, generation: 34.3369[sec], evaluation: 0.0000[sec]
2025-05-29 18:12:54,588 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:12:54,745 - INFO - joeynmt.training - Example #0
2025-05-29 18:12:54,746 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:12:54,746 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:12:54,746 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['M@@', ':', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'dat', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'ik', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te', 'te']
2025-05-29 18:12:54,747 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:12:54,747 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:12:54,747 - INFO - joeynmt.training - 	Hypothesis: M: ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik dat ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik ik te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te te
2025-05-29 18:12:54,747 - INFO - joeynmt.training - Example #1
2025-05-29 18:12:54,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:12:54,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:12:54,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'niet', 'de', 're@@', 're@@', 're@@', 're@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'en.', '</s>']
2025-05-29 18:12:54,748 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:12:54,748 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:12:54,748 - INFO - joeynmt.training - 	Hypothesis: Maar niet de rererereccccccccccccccccccccccccccccen.
2025-05-29 18:12:54,750 - INFO - joeynmt.training - Example #2
2025-05-29 18:12:54,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:12:54,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:12:54,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'c@@', '-@@', 'v@@', '.', '</s>']
2025-05-29 18:12:54,750 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:12:54,750 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:12:54,750 - INFO - joeynmt.training - 	Hypothesis: In de verververververververververc-v.
2025-05-29 18:12:54,750 - INFO - joeynmt.training - Example #3
2025-05-29 18:12:54,751 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:12:54,751 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:12:54,751 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Je', 'zijn', 'een', 'ver@@', 'v@@', 'v@@', 'v@@', '.', '</s>']
2025-05-29 18:12:54,751 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:12:54,752 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:12:54,752 - INFO - joeynmt.training - 	Hypothesis: Je zijn een vervvv.
2025-05-29 18:12:54,752 - INFO - joeynmt.training - Example #4
2025-05-29 18:12:54,752 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:12:54,752 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:12:54,752 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'be@@', 'be@@', 'be@@', 'be@@', 'op@@', '-@@', 'c@@', ',', 'van', 'de', 'b@@', '-@@', 'c@@', '-@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', 'c@@', '.', '</s>']
2025-05-29 18:12:54,753 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:12:54,753 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:12:54,753 - INFO - joeynmt.training - 	Hypothesis: De bebebebeop-c, van de b-c-cccccccc.
2025-05-29 18:13:02,766 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.449321, Batch Acc: 0.100034, Tokens per Sec:     8595, Lr: 0.000300
2025-05-29 18:13:11,180 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.494998, Batch Acc: 0.107573, Tokens per Sec:     8245, Lr: 0.000300
2025-05-29 18:13:19,607 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.358339, Batch Acc: 0.114353, Tokens per Sec:     8245, Lr: 0.000300
2025-05-29 18:13:28,384 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.324902, Batch Acc: 0.120767, Tokens per Sec:     8234, Lr: 0.000300
2025-05-29 18:13:37,037 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.271391, Batch Acc: 0.131390, Tokens per Sec:     8162, Lr: 0.000300
2025-05-29 18:13:37,038 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:13:37,038 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:14:16,400 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.32, ppl:  27.61, acc:   0.13, generation: 39.2999[sec], evaluation: 0.0000[sec]
2025-05-29 18:14:16,401 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:14:16,565 - INFO - joeynmt.training - Example #0
2025-05-29 18:14:16,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:14:16,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:14:16,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'ij', 'ik', 'ik', 'ik', 'dat', 'ik', 'dat', 'de', 'eerste', 'eerste', 'eerste', 'eerste', 'eerste', 'eerste', 'eerste', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@']
2025-05-29 18:14:16,567 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:14:16,567 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:14:16,568 - INFO - joeynmt.training - 	Hypothesis: Vij ik ik ik dat ik dat de eerste eerste eerste eerste eerste eerste eerste ververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververver
2025-05-29 18:14:16,568 - INFO - joeynmt.training - Example #1
2025-05-29 18:14:16,568 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:14:16,568 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:14:16,568 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'is', 'dat', 'dat', 'dat', 'het', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet']
2025-05-29 18:14:16,569 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:14:16,569 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:14:16,570 - INFO - joeynmt.training - 	Hypothesis: Maar het is dat dat dat het niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet
2025-05-29 18:14:16,570 - INFO - joeynmt.training - Example #2
2025-05-29 18:14:16,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:14:16,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:14:16,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'de', 'de', 'de', 'eerste', 'eerste', 'vol@@', 'f@@', 'en,', 'van', 'de', 'eerste', 'eerste', 'eerste', 'vol@@', 'k@@', 'k@@', 'k@@', 'el@@', 'de', 're@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@']
2025-05-29 18:14:16,571 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:14:16,571 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:14:16,572 - INFO - joeynmt.training - 	Hypothesis: In de de de de eerste eerste volfen, van de eerste eerste eerste volkkkelde reeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee
2025-05-29 18:14:16,572 - INFO - joeynmt.training - Example #3
2025-05-29 18:14:16,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:14:16,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:14:16,572 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'zijn', 'en', 'het', 'het', 'het', 'in', 'de', 're@@', 're@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', 'e@@', '.', '</s>']
2025-05-29 18:14:16,573 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:14:16,574 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:14:16,574 - INFO - joeynmt.training - 	Hypothesis: Ze zijn en het het het in de rereeeeeeeeeeeeeeeeeeeeeeeeeeeee.
2025-05-29 18:14:16,574 - INFO - joeynmt.training - Example #4
2025-05-29 18:14:16,574 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:14:16,574 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:14:16,574 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eerste', 'eerste', 'eerste', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@']
2025-05-29 18:14:16,575 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:14:16,575 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:14:16,575 - INFO - joeynmt.training - 	Hypothesis: De eerste eerste eerste ververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververververver
2025-05-29 18:14:24,809 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.187953, Batch Acc: 0.146611, Tokens per Sec:     8056, Lr: 0.000300
2025-05-29 18:14:33,412 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     3.060848, Batch Acc: 0.157395, Tokens per Sec:     8230, Lr: 0.000300
2025-05-29 18:14:42,227 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     3.028286, Batch Acc: 0.168514, Tokens per Sec:     7686, Lr: 0.000300
2025-05-29 18:14:51,458 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     2.931425, Batch Acc: 0.181702, Tokens per Sec:     7473, Lr: 0.000300
2025-05-29 18:15:00,048 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     2.822433, Batch Acc: 0.189977, Tokens per Sec:     8174, Lr: 0.000300
2025-05-29 18:15:00,049 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:15:00,049 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:15:52,135 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.01, ppl:  20.36, acc:   0.18, generation: 52.0255[sec], evaluation: 0.0000[sec]
2025-05-29 18:15:52,136 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:15:52,354 - INFO - joeynmt.training - Example #0
2025-05-29 18:15:52,354 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:15:52,355 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:15:52,355 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'ik', 'heb', 'ik', 'een', 'paar', 'van', 'de', 'wereld', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'den', 'van', 'de', 'mensen', 'die', 'de', 'mensen', 'die', 'de', 'mensen', 'van', 'de', 'mensen', 'van', 'de', 'mensen', 'van', 'de', 'mensen', 'van', 'de', 'mensen', 'van', 'de', 'mensen', 'van', 'de', 'wereld', 'van', 'de', 'wereld', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'cht@@', 'ige', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'c@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@', 'ontro@@']
2025-05-29 18:15:52,356 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:15:52,356 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:15:52,356 - INFO - joeynmt.training - 	Hypothesis: Ik heb ik heb ik een paar van de wereld van de rest van de rest van de rest van de reden van de mensen die de mensen die de mensen van de mensen van de mensen van de mensen van de mensen van de mensen van de wereld van de wereld van de reden van de rest van de rechtige van de rest van de reden van de recontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontroontro
2025-05-29 18:15:52,356 - INFO - joeynmt.training - Example #1
2025-05-29 18:15:52,357 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:15:52,357 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:15:52,357 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'de', 're@@', 'st', 'niet', 'de', 'de', 're@@', 'st', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'cht', 'van', 'de', 're@@', 'cht', 'van', 'de', 're@@', 'cht', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 'cht@@', 'cht@@', 'ige', 're@@', 'st', 'van', 'de', 're@@', 'st', 'van', 'de', 're@@', 's@@', 's@@', 's@@', 's@@', 's@@', 'ult@@', 'ijn@@', 'ijn@@', 'ijn@@', 'lijk', 'ge@@', 'ge@@', 'ge@@', 'ge@@', 'gev@@', 'en.', '</s>']
2025-05-29 18:15:52,358 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:15:52,358 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:15:52,358 - INFO - joeynmt.training - 	Hypothesis: Maar de rest niet de de rest van de rest van de rest van de rest van de rest van de rest van de rest van de recht van de recht van de recht van de rest van de rest van de rest van de rest van de rest van de rechtchtige rest van de rest van de resssssultijnijnijnlijk gegegegegeven.
2025-05-29 18:15:52,359 - INFO - joeynmt.training - Example #2
2025-05-29 18:15:52,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:15:52,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:15:52,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 're@@', 'st', 'de', 'is', 'de', 're@@', 'st', 'van', 'de', 're@@', 's@@', 'ult@@', 'ult@@', 'at@@', 'ie.', '</s>']
2025-05-29 18:15:52,360 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:15:52,360 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:15:52,360 - INFO - joeynmt.training - 	Hypothesis: In de rest de is de rest van de resultultatie.
2025-05-29 18:15:52,360 - INFO - joeynmt.training - Example #3
2025-05-29 18:15:52,361 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:15:52,361 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:15:52,361 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'ver@@', 'z@@', 'it', 'in', 'de', 'de', 'en', 'en', 'en', 'en', 'en', 'in', 'de', 're@@', 'cht', 'in', 'de', 're@@', 'st', 'in', 'de', 're@@', 'st', 'in', 'de', 'wereld', 'in', 'de', 'wereld', 'in', 'de', 're@@', 'ch@@', 'ch@@', 'ch@@', 'ch@@', 'ch@@', 'ten.', '</s>']
2025-05-29 18:15:52,362 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:15:52,362 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:15:52,362 - INFO - joeynmt.training - 	Hypothesis: Ze verzit in de de en en en en en in de recht in de rest in de rest in de wereld in de wereld in de rechchchchchten.
2025-05-29 18:15:52,362 - INFO - joeynmt.training - Example #4
2025-05-29 18:15:52,363 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:15:52,363 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:15:52,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 're@@', 'den', 'de', 'de', 'de', 're@@', 'st', 'is', 'een', 'paar', 'paar', 'paar', 'paar', 'van', 'de', 'mensen', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'ik', 'hebben', 'hebben', 'hebben', 'hebben', 'hebben', 'hebben', 'hebben', 'hebben', 'hebben']
2025-05-29 18:15:52,364 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:15:52,364 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:15:52,364 - INFO - joeynmt.training - 	Hypothesis: De reden de de de rest is een paar paar paar paar van de mensen die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die die ik hebben hebben hebben hebben hebben hebben hebben hebben hebben
2025-05-29 18:16:02,079 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     2.914353, Batch Acc: 0.199335, Tokens per Sec:     7287, Lr: 0.000300
2025-05-29 18:16:12,182 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     2.812516, Batch Acc: 0.208323, Tokens per Sec:     6910, Lr: 0.000300
2025-05-29 18:16:22,067 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.907981, Batch Acc: 0.212659, Tokens per Sec:     7217, Lr: 0.000300
2025-05-29 18:16:31,615 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     3.050738, Batch Acc: 0.220819, Tokens per Sec:     7242, Lr: 0.000300
2025-05-29 18:16:43,085 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.653439, Batch Acc: 0.225430, Tokens per Sec:     6051, Lr: 0.000300
2025-05-29 18:16:43,086 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:16:43,086 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:17:24,745 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.82, ppl:  16.75, acc:   0.21, generation: 41.6074[sec], evaluation: 0.0000[sec]
2025-05-29 18:17:24,746 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:17:24,945 - INFO - joeynmt.training - Example #0
2025-05-29 18:17:24,946 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:17:24,946 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:17:24,946 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'ik', 'een', 'paar', 'jaar', 'gele@@', 'den', 'van', 'de', 'eerste', 'be@@', 'sl@@', 'im@@', 'p@@', 'el@@', 'ing', 'van', 'de', 're@@', 'c@@', 'ar@@', 'ar@@', 'en', 'de', 'b@@', 'inn@@', 'en@@', 'te', 'ver@@', 'hal@@', 'en', 'de', 'de', 'de', 'van', 'de', 'k@@', 'ol@@', 'en', 'de', 'van', 'de', '1@@', '00', 'jaar', 'van', 'de', '1@@', '00', 'proc@@', 'ent', 'van', 'de', 'van', 'de', 'van', 'de', 'mee@@', 'st', 'van', 'de', 'k@@', 'eu@@', 'w@@', 'aaro@@', 'p', 'van', 'de', 're@@', 'cht@@', 'ing', 'van', 'de', 'mee@@', 'st', 'van', 'de', '1@@', '00', 'jaar', 'voor', 'de', 'k@@', 'oo@@', 'g', 'van', 'de', 'k@@', 'ken.', '</s>']
2025-05-29 18:17:24,947 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:17:24,947 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:17:24,947 - INFO - joeynmt.training - 	Hypothesis: Ik heb ik een paar jaar geleden van de eerste beslimpeling van de recararen de binnente verhalen de de de van de kolen de van de 100 jaar van de 100 procent van de van de van de meest van de keuwaarop van de rechting van de meest van de 100 jaar voor de koog van de kken.
2025-05-29 18:17:24,947 - INFO - joeynmt.training - Example #1
2025-05-29 18:17:24,948 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:17:24,948 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:17:24,948 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'is', 'niet', 'ge@@', 'maakt', 'dat', 'de', 're@@', 'cht@@', 's@@', 'ult@@', 'aat', 'de', 're@@', 'cht@@', 's@@', 'ult@@', 'aat', 'niet', 'over', 'de', 're@@', 'cht@@', 's@@', 'ult@@', 'aat', 'de', 're@@', 'cht@@', 's@@', 'ult@@', 'aat', 'niet', 'de', 're@@', 'cht@@', 's@@', 'ult@@', 'aat', 'niet', 'de', 'mo@@', 'eil@@', 'ijk@@', '.', '</s>']
2025-05-29 18:17:24,949 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:17:24,949 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:17:24,949 - INFO - joeynmt.training - 	Hypothesis: Maar het is niet gemaakt dat de rechtsultaat de rechtsultaat niet over de rechtsultaat de rechtsultaat niet de rechtsultaat niet de moeilijk.
2025-05-29 18:17:24,949 - INFO - joeynmt.training - Example #2
2025-05-29 18:17:24,950 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:17:24,950 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:17:24,950 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'b@@', 'la@@', 'st@@', 'aan', 'de', 'b@@', 'aar@@', 't', 'de', 'c@@', 'ar@@', 'ar@@', 'ar@@', 'en', 'het', 'is', 'het', 'het', 'van', 'de', 'k@@', 'eu@@', 'w@@', ',', 'de', 'c@@', 'r@@', 'is@@', 'is@@', 'is@@', 'kun@@', 'st@@', 'aan', 'de', 'c@@', 'r@@', 'ond', 'de', 'b@@', 'ijn@@', '.', '</s>']
2025-05-29 18:17:24,951 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:17:24,951 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:17:24,951 - INFO - joeynmt.training - 	Hypothesis: In de blastaan de baart de carararen het is het het van de keuw, de crisisiskunstaan de crond de bijn.
2025-05-29 18:17:24,951 - INFO - joeynmt.training - Example #3
2025-05-29 18:17:24,951 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:17:24,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:17:24,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'ver@@', 'der', 'en', 'en', 'en', 'en', 'en', 'het', 'ver@@', '.', '</s>']
2025-05-29 18:17:24,953 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:17:24,953 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:17:24,953 - INFO - joeynmt.training - 	Hypothesis: Ze verder en en en en en het ver.
2025-05-29 18:17:24,953 - INFO - joeynmt.training - Example #4
2025-05-29 18:17:24,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:17:24,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:17:24,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eerste', 'eerste', 'eerste', 'de', 'ik', 'de', 'eerste', 'eerste', 'is', 'een', 'paar', 'paar', 'paar', 'jaar', 'is', 'wat', 'ik', 'in', 'de', 'eerste', 'eerste', 'jaar', 'gele@@', 'den', 'van', 'de', 'eerste', 'jaar', 'gele@@', 'den', 'van', 'de', 'eerste', 'eerste', 'eerste', 'eerste', 'eerste', 'eerste', 'eerste', 'eerste', 'eerste', 'eerste', 'eerste', 'eerste', 'jaar', 'gele@@', 'den', 'van', 'de', 'eerste', 'eerste', 'jaar', 'gele@@', 'den', 'van', 'de', 'mee@@', 'st', 'van', 'de', 'mee@@', 'st', 'van', 'de', 'mee@@', 'st', 'van', 'de', 're@@', 'cht@@', 'cht@@', 'cht@@', 'ige', 'van', 'de', 're@@', 'cht@@', 'cht@@', 'ige', 'van', 'de', 'v@@', 'lie@@', 'f@@', 'de', 'ik', 'van', 'de', 'de', 'de', 'de', 'mee@@', 'ste', 'van', 'de', 'mee@@', 'ste', 'ste', 'ste', 'ste', 'ste', 'ste', 'ste', 'ste', 'van', 'de', 'de', 'de', 'de', 'de', 'mee@@', 'st', 'van', 'de', 'mee@@', 'st']
2025-05-29 18:17:24,954 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:17:24,954 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:17:24,954 - INFO - joeynmt.training - 	Hypothesis: De eerste eerste eerste de ik de eerste eerste is een paar paar paar jaar is wat ik in de eerste eerste jaar geleden van de eerste jaar geleden van de eerste eerste eerste eerste eerste eerste eerste eerste eerste eerste eerste eerste jaar geleden van de eerste eerste jaar geleden van de meest van de meest van de meest van de rechtchtchtige van de rechtchtige van de vliefde ik van de de de de meeste van de meeste ste ste ste ste ste ste ste van de de de de de meest van de meest
2025-05-29 18:17:34,790 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.795116, Batch Acc: 0.233935, Tokens per Sec:     6870, Lr: 0.000300
2025-05-29 18:17:44,332 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.748978, Batch Acc: 0.236283, Tokens per Sec:     7406, Lr: 0.000300
2025-05-29 18:17:54,168 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.771734, Batch Acc: 0.241084, Tokens per Sec:     7225, Lr: 0.000300
2025-05-29 18:18:04,086 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.629986, Batch Acc: 0.247749, Tokens per Sec:     7098, Lr: 0.000300
2025-05-29 18:18:13,915 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.634676, Batch Acc: 0.253034, Tokens per Sec:     7278, Lr: 0.000300
2025-05-29 18:18:13,915 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:18:13,915 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:18:56,227 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.70, ppl:  14.82, acc:   0.24, generation: 42.2739[sec], evaluation: 0.0000[sec]
2025-05-29 18:18:56,228 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:18:56,414 - INFO - joeynmt.training - Example #0
2025-05-29 18:18:56,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:18:56,415 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:18:56,415 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'jaar', 'gele@@', 'den', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'ver@@', 'antwoor@@', 'den', 'dat', 'de', 'ver@@', 'wa@@', 'cht@@', 'ing', 'van', 'de', 'E@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', ',', 'voor', 'drie', 'miljo@@', 'en', 'van', 'de', 'mensen', 'die', 'die', 'die', 'die', 'die', 'die', 'die', 'jaar', 'gele@@', 'den', 'van', 'de', 'V@@', 'S', 'van', 'de', 'V@@', 'S', 'van', 'de', 'V@@', 'S', 'van', 'de', 'mee@@', 'st', 'van', 'de', '4@@', '0', 'miljo@@', 'en', 'van', 'de', 'mee@@', 'st', 'van', 'de', '1@@', '0@@', '.', '</s>']
2025-05-29 18:18:56,416 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:18:56,416 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:18:56,416 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze jaar geleden die die die die die die die verantwoorden dat de verwachting van de Euuuuuu, voor drie miljoen van de mensen die die die die die die die jaar geleden van de VS van de VS van de VS van de meest van de 40 miljoen van de meest van de 10.
2025-05-29 18:18:56,416 - INFO - joeynmt.training - Example #1
2025-05-29 18:18:56,417 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:18:56,417 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:18:56,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'is', 'niet', 'aan', 'het', 'ver@@', 'sp@@', 'rei@@', 'd', 'van', 'het', 'proble@@', 'em', 'van', 'het', 'proble@@', 'em', 'van', 'het', 'proble@@', 'em', 'niet', 'alleen', 'van', 'het', 'proble@@', 'em', 'van', 'het', 'e@@', 'conom@@', 'ie', 'van', 'het', 'e@@', 'conom@@', 'ie', 'van', 'het', 'e@@', 'conom@@', 'ie', 'van', 'het', 'e@@', 'conom@@', 'ie', 'van', 'het', 'e@@', 'conom@@', 'ie', 'van', 'het', 'proble@@', 'em', 'van', 'het', 'proble@@', 'em@@', '.', '</s>']
2025-05-29 18:18:56,418 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:18:56,418 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:18:56,418 - INFO - joeynmt.training - 	Hypothesis: Maar het is niet aan het verspreid van het probleem van het probleem van het probleem niet alleen van het probleem van het economie van het economie van het economie van het economie van het economie van het probleem van het probleem.
2025-05-29 18:18:56,418 - INFO - joeynmt.training - Example #2
2025-05-29 18:18:56,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:18:56,419 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:18:56,419 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'z@@', 'it', 'de', 'van', 'de', 'c@@', 'ar@@', 'ar@@', 'ch@@', 'ter', 'is', 'de', 'e@@', 'conom@@', 'ie', 'van', 'ons', 'k@@', 'eu@@', 'w@@', 's', 'van', 'ons', 'k@@', 'eu@@', 'w@@', 's', 'van', 'de', 'k@@', 'eu@@', 'w@@', '.', '</s>']
2025-05-29 18:18:56,420 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:18:56,420 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:18:56,420 - INFO - joeynmt.training - 	Hypothesis: In de zit de van de cararchter is de economie van ons keuws van ons keuws van de keuw.
2025-05-29 18:18:56,420 - INFO - joeynmt.training - Example #3
2025-05-29 18:18:56,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:18:56,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:18:56,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'st@@', 'aan', 'het', 'ver@@', 'st@@', 'ij@@', 'f', 'en', 'en', 'in', 'de', 'b@@', 'om@@', 'om@@', '.', '</s>']
2025-05-29 18:18:56,421 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:18:56,421 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:18:56,422 - INFO - joeynmt.training - 	Hypothesis: Ze staan het verstijf en en in de bomom.
2025-05-29 18:18:56,422 - INFO - joeynmt.training - Example #4
2025-05-29 18:18:56,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:18:56,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:18:56,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'aak', 'die', 'ik', 'wil', 'jullie', 'een', 'paar', 'jaar', 'is', 'een', 'paar', 'jaar', 'gele@@', 'den', 'van', 'de', '2@@', '5', 'jaar', 'gele@@', 'den', 'van', 'de', '2@@', '5', 'jaar', 'gele@@', 'den', 'van', '1@@', '5', 'jaar', 'gele@@', 'den', 'in', 'de', 'v@@', 'rij@@', 'd', 'is.', '</s>']
2025-05-29 18:18:56,424 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:18:56,424 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:18:56,424 - INFO - joeynmt.training - 	Hypothesis: De volgende vaak die ik wil jullie een paar jaar is een paar jaar geleden van de 25 jaar geleden van de 25 jaar geleden van 15 jaar geleden in de vrijd is.
2025-05-29 18:19:05,489 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.618041, Batch Acc: 0.255463, Tokens per Sec:     7511, Lr: 0.000300
2025-05-29 18:19:15,380 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.623910, Batch Acc: 0.265621, Tokens per Sec:     7274, Lr: 0.000300
2025-05-29 18:19:25,859 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.843275, Batch Acc: 0.270974, Tokens per Sec:     6496, Lr: 0.000300
2025-05-29 18:19:36,446 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.679047, Batch Acc: 0.279391, Tokens per Sec:     6609, Lr: 0.000300
2025-05-29 18:19:46,931 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.564787, Batch Acc: 0.283910, Tokens per Sec:     6881, Lr: 0.000300
2025-05-29 18:19:46,935 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:19:46,935 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:20:36,440 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.59, ppl:  13.32, acc:   0.27, generation: 49.4475[sec], evaluation: 0.0000[sec]
2025-05-29 18:20:36,441 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:20:36,648 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/500.ckpt
2025-05-29 18:20:36,666 - INFO - joeynmt.training - Example #0
2025-05-29 18:20:36,667 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:20:36,667 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:20:36,667 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'ik', 'heb', 'ik', 'deze', 'v@@', 'ij@@', 'f', 'jaar', 'gele@@', 'den', 'van', 'de', 'V@@', 'ol@@', 'gens', 'van', 'de', 'V@@', 'an@@', 'da@@', 'da@@', 'g@@', 'ingen', 'van', 'de', 'E@@', 'u@@', 'u@@', 'u@@', 'u@@', 'rop@@', 'e@@', 'se', 'jaar', 'gele@@', 'den', 'die', 'drie', 'jaar', 'gele@@', 'den', 'van', 'de', 'V@@', 'S', 'die', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'V@@', 'S', 'van', 'de', 'V@@', 'S', 'van', 'de', 'V@@', 'S', 'van', 'de', 'lan@@', 'd.', '</s>']
2025-05-29 18:20:36,668 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:20:36,668 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:20:36,669 - INFO - joeynmt.training - 	Hypothesis: Laten ik heb ik deze vijf jaar geleden van de Volgens van de Vandadagingen van de Euuuuropese jaar geleden die drie jaar geleden van de VS die 40 procent van de VS van de VS van de VS van de land.
2025-05-29 18:20:36,669 - INFO - joeynmt.training - Example #1
2025-05-29 18:20:36,669 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:20:36,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:20:36,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 're@@', 'cht', 'van', 'de', 're@@', 'st', 'van', 'het', 'proble@@', 'em', 'van', 'het', 'proble@@', 'em', 'van', 'het', 'proble@@', 'em', 'van', 'het', 'proble@@', 'em', 'van', 'het', 'e@@', 'conom@@', 'ie', 'van', 'het', 'E@@', 'g@@', 'g@@', 'aa@@', 't.', '</s>']
2025-05-29 18:20:36,670 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:20:36,671 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:20:36,671 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de recht van de rest van het probleem van het probleem van het probleem van het probleem van het economie van het Eggaat.
2025-05-29 18:20:36,671 - INFO - joeynmt.training - Example #2
2025-05-29 18:20:36,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:20:36,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:20:36,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'z@@', 'ich@@', 'zelf', 'is', 'de', 're@@', 'act@@', 'ie', 'van', 'de', 'E@@', 'u@@', 'rop@@', 'e@@', 'se', 'e@@', 'c@@', 'r@@', 'r@@', 'ond', 'het', 'is', 'van', 'de', 'c@@', 'entr@@', 'ale', 'c@@', 'ul@@', 'a@@', 'ir@@', 'e', 'van', 'de', 'c@@', 'ontro@@', 'le@@', 's.', '</s>']
2025-05-29 18:20:36,672 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:20:36,672 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:20:36,673 - INFO - joeynmt.training - 	Hypothesis: In de zichzelf is de reactie van de Europese ecrrond het is van de centrale culaire van de controles.
2025-05-29 18:20:36,673 - INFO - joeynmt.training - Example #3
2025-05-29 18:20:36,673 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:20:36,673 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:20:36,673 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'aaro@@', 'p', 'in', 'de', 'in@@', 'di@@', 'vi@@', 'du@@', 'iz@@', 'enden', 'en', 'in', 'de', 'z@@', 'om@@', '.', '</s>']
2025-05-29 18:20:36,674 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:20:36,674 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:20:36,674 - INFO - joeynmt.training - 	Hypothesis: Ze waarop in de individuizenden en in de zom.
2025-05-29 18:20:36,675 - INFO - joeynmt.training - Example #4
2025-05-29 18:20:36,675 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:20:36,675 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:20:36,675 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ij@@', 'f', 'ik', 'jullie', 'jullie', 'jullie', 'jullie', 'een', 'paar', 'jaar', 'gele@@', 'den', 'van', 'de', 'laat@@', 'ste', 'jaar', 'gele@@', 'den', 'van', 'de', 'laat@@', 'ste', 'jaar', 'gele@@', 'den', 'is.', '</s>']
2025-05-29 18:20:36,676 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:20:36,676 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:20:36,676 - INFO - joeynmt.training - 	Hypothesis: De volgende vijf ik jullie jullie jullie jullie een paar jaar geleden van de laatste jaar geleden van de laatste jaar geleden is.
2025-05-29 18:20:48,798 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.560766, Batch Acc: 0.286307, Tokens per Sec:     5674, Lr: 0.000300
2025-05-29 18:21:00,974 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.454555, Batch Acc: 0.293808, Tokens per Sec:     5616, Lr: 0.000300
2025-05-29 18:21:11,980 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.560236, Batch Acc: 0.293182, Tokens per Sec:     6289, Lr: 0.000300
2025-05-29 18:21:22,346 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.505803, Batch Acc: 0.298203, Tokens per Sec:     6759, Lr: 0.000300
2025-05-29 18:21:32,061 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.536649, Batch Acc: 0.302396, Tokens per Sec:     6975, Lr: 0.000300
2025-05-29 18:21:32,061 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:21:32,062 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:22:18,592 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.51, ppl:  12.28, acc:   0.29, generation: 46.4796[sec], evaluation: 0.0000[sec]
2025-05-29 18:22:18,594 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:22:18,792 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/1000.ckpt
2025-05-29 18:22:18,812 - INFO - joeynmt.training - Example #0
2025-05-29 18:22:18,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:22:18,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:22:18,813 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'we', 'deze', 'v@@', 'lo@@', 'ei@@', 'ten', 'van', 'de', 'v@@', 'lo@@', 'ei@@', 'ende', 'k@@', 'aar@@', 't', 'dat', 'de', 'be@@', 'ste', 'van', 'de', 'V@@', 'an@@', 'da@@', 'g@@', 'g@@', 'ingen', 'van', 'drie', 'jaar', 'voor', 'drie', 'jaar', 'gele@@', 'den', 'voor', 'drie', 'jaar', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'St@@', 'aten', 'van', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'St@@', 'aten', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'Ver@@', 'en@@', 'en@@', 'en@@', 'ig@@', 'de', 'St@@', 'aten', 'is.', '</s>']
2025-05-29 18:22:18,814 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:22:18,815 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:22:18,815 - INFO - joeynmt.training - 	Hypothesis: Laten we deze vloeiten van de vloeiende kaart dat de beste van de Vandaggingen van drie jaar voor drie jaar geleden voor drie jaar de Verenigde Staten van de Verenigde Staten van 40 procent van 40 procent van 40 procent van de Verenenenigde Staten is.
2025-05-29 18:22:18,815 - INFO - joeynmt.training - Example #1
2025-05-29 18:22:18,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:22:18,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:22:18,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'genoe@@', 'g', 'van', 'de', 're@@', 'c@@', 'ult@@', 'aat', 'de', 're@@', 'c@@', 'ult@@', 'ur@@', 'ele', 'proble@@', 'men', 'van', 'dit', 'proble@@', 'men', 'niet', 'de', 'in@@', 'du@@', 'du@@', 'c@@', 'e', 'e@@', 'eu@@', 'w@@', '.', '</s>']
2025-05-29 18:22:18,816 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:22:18,817 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:22:18,817 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet genoeg van de recultaat de reculturele problemen van dit problemen niet de induduce eeuw.
2025-05-29 18:22:18,817 - INFO - joeynmt.training - Example #2
2025-05-29 18:22:18,817 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:22:18,817 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:22:18,817 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'z@@', 'it', 'de', 'z@@', 'ich@@', 'zelf', 'is', 'de', 'E@@', 'u@@', 'ist@@', 'e', 'van', 'onze', 'E@@', 'u@@', 'g@@', 'le@@', 'u@@', 'u@@', 's,', 'onze', 'c@@', 'ul@@', 'a@@', 'ir@@', 'e', 'c@@', 'r@@', 'ond', 'de', 'c@@', 'r@@', 'ond', 'van', 'onze', 'c@@', 'ul@@', 'a@@', 'ir@@', 'e', 'c@@', 'r@@', 'ond', 'de', 'E@@', 'u@@', 'g@@', 'le@@', 'ef@@', 't.', '</s>']
2025-05-29 18:22:18,818 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:22:18,819 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:22:18,819 - INFO - joeynmt.training - 	Hypothesis: In de zit de zichzelf is de Euiste van onze Eugleuus, onze culaire crond de crond van onze culaire crond de Eugleeft.
2025-05-29 18:22:18,819 - INFO - joeynmt.training - Example #3
2025-05-29 18:22:18,819 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:22:18,819 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:22:18,819 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'st@@', 'op@@', 't', 'en', 'in', 'de', 'in@@', 'v@@', 'l@@', 'oe@@', 'g', 'in', 'het', 'S@@', 'om@@', 'om@@', '.', '</s>']
2025-05-29 18:22:18,820 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:22:18,820 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:22:18,821 - INFO - joeynmt.training - 	Hypothesis: Ze stopt en in de invloeg in het Somom.
2025-05-29 18:22:18,821 - INFO - joeynmt.training - Example #4
2025-05-29 18:22:18,821 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:22:18,821 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:22:18,821 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ond', 'ik', 'jullie', 'de', 'laat@@', 'ste', 'tijd', 'is', 'een', 'tijd', 'dat', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 18:22:18,822 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:22:18,822 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:22:18,823 - INFO - joeynmt.training - 	Hypothesis: De volgende vond ik jullie de laatste tijd is een tijd dat de laatste 25 jaar is.
2025-05-29 18:22:29,101 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     2.375623, Batch Acc: 0.313707, Tokens per Sec:     6973, Lr: 0.000300
2025-05-29 18:22:39,301 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.426140, Batch Acc: 0.313600, Tokens per Sec:     6786, Lr: 0.000300
2025-05-29 18:22:49,849 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.368430, Batch Acc: 0.321651, Tokens per Sec:     6783, Lr: 0.000300
2025-05-29 18:23:01,011 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.359607, Batch Acc: 0.326418, Tokens per Sec:     6340, Lr: 0.000300
2025-05-29 18:23:11,507 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     2.541247, Batch Acc: 0.329484, Tokens per Sec:     6806, Lr: 0.000300
2025-05-29 18:23:11,508 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:23:11,508 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:23:57,035 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.43, ppl:  11.31, acc:   0.31, generation: 45.4732[sec], evaluation: 0.0000[sec]
2025-05-29 18:23:57,036 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:23:57,244 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/1500.ckpt
2025-05-29 18:23:57,262 - INFO - joeynmt.training - Example #0
2025-05-29 18:23:57,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:23:57,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:23:57,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', 'dat', 'ik', 'deze', 'v@@', 'ol@@', 'ie@@', 'ën', 'om', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'dat', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'gele@@', 'den', 'van', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'St@@', 'aten', 'die', 'jaar', 'gele@@', 'den', 'van', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'St@@', 'aten', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'St@@', 'at@@', 'en.', '</s>']
2025-05-29 18:23:57,265 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:23:57,265 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:23:57,265 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden dat ik deze volieën om de Verenigde dat de drie miljoen jaar geleden van de Verenigde Staten die jaar geleden van de Verenigde Staten van 40 procent van 40 procent van 40 procent van de Verenigde Staten.
2025-05-29 18:23:57,265 - INFO - joeynmt.training - Example #1
2025-05-29 18:23:57,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:23:57,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:23:57,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 'ver@@', 'wa@@', 'cht@@', 'ing', 'van', 'de', 'aar@@', 'de', 'de', 'ver@@', 'wa@@', 'cht@@', 'ing', 'van', 'de', 're@@', 'c@@', 'ellen', 'van', 'de', 'di@@', 're@@', 'c@@', 'e', 'e@@', 'cht@@', 'ige', 'e@@', 'ven', 'van', 'de', 'di@@', 're@@', 'c@@', 'e', 'e@@', 'ch@@', 'ter', 'van', 'de', 're@@', 'c@@', 'or@@', 'r@@', 'is@@', 'ic@@', 'o@@', '.', '</s>']
2025-05-29 18:23:57,267 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:23:57,267 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:23:57,267 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de verwachting van de aarde de verwachting van de recellen van de direce echtige even van de direce echter van de recorrisico.
2025-05-29 18:23:57,267 - INFO - joeynmt.training - Example #2
2025-05-29 18:23:57,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:23:57,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:23:57,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'z@@', 'it', 'S@@', 'te@@', 'm@@', 'heid', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'u@@', 'g@@', 'oo@@', 'p', 'van', 'ons', 'op@@', 'lo@@', 'g@@', 'ale', 'k@@', 'ale', 'e@@', 'conom@@', 'ische', 'k@@', 'eu@@', 'm@@', 'oo@@', 'i', 'van', 'de', 'ar@@', 'ch@@', 'ter@@', 's.', '</s>']
2025-05-29 18:23:57,269 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:23:57,269 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:23:57,269 - INFO - joeynmt.training - 	Hypothesis: In de zit Stemheid is de artische Eugoop van ons oplogale kale economische keumooi van de archters.
2025-05-29 18:23:57,269 - INFO - joeynmt.training - Example #3
2025-05-29 18:23:57,270 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:23:57,270 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:23:57,270 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'de', 'w@@', 'in@@', 'st@@', 'ond', 'en', 'de', 'z@@', 'om@@', 'om@@', '.', '</s>']
2025-05-29 18:23:57,271 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:23:57,271 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:23:57,271 - INFO - joeynmt.training - 	Hypothesis: Ze wist de winstond en de zomom.
2025-05-29 18:23:57,271 - INFO - joeynmt.training - Example #4
2025-05-29 18:23:57,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:23:57,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:23:57,272 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ond', 'ik', 'jullie', 'die', 'ik', 'wil', 'wil', 'de', 'laat@@', 'ste', 'van', 'de', 'laat@@', 'ste', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'in', 'de', '2@@', '5', 'jaar', 'gele@@', 'den', 'van', '2@@', '5', 'jaar', 'gele@@', 'den', 'in', 'de', '2@@', '5', 'jaar', 'gele@@', 'den', 'van', 'de', '2@@', '5', 'jaar', 'gele@@', 'den', 'van', 'de', '2@@', '5', 'jaar', 'gele@@', 'den', 'van', 'de', '2@@', '5', 'jaar', 'gele@@', 'den', 'van', 'de', '2@@', '5', 'jaar', 'gele@@', 'den', 'van', 'de', 'laat@@', 'ste', 'v@@', 'ier@@', '.', '</s>']
2025-05-29 18:23:57,273 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:23:57,273 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:23:57,273 - INFO - joeynmt.training - 	Hypothesis: De volgende vond ik jullie die ik wil wil de laatste van de laatste ste 25 jaar geleden in de 25 jaar geleden van 25 jaar geleden in de 25 jaar geleden van de 25 jaar geleden van de 25 jaar geleden van de 25 jaar geleden van de 25 jaar geleden van de laatste vier.
2025-05-29 18:24:07,939 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     2.417661, Batch Acc: 0.340098, Tokens per Sec:     6521, Lr: 0.000300
2025-05-29 18:24:19,114 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     2.408043, Batch Acc: 0.338639, Tokens per Sec:     6282, Lr: 0.000300
2025-05-29 18:24:29,553 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     2.366748, Batch Acc: 0.342882, Tokens per Sec:     6653, Lr: 0.000300
2025-05-29 18:24:39,937 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:     2.254440, Batch Acc: 0.352078, Tokens per Sec:     6778, Lr: 0.000300
2025-05-29 18:24:50,012 - INFO - joeynmt.training - Epoch   1, Step:     4500, Batch Loss:     2.177052, Batch Acc: 0.352336, Tokens per Sec:     7085, Lr: 0.000300
2025-05-29 18:24:50,013 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:24:50,013 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:25:34,343 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.34, ppl:  10.34, acc:   0.34, generation: 44.2818[sec], evaluation: 0.0000[sec]
2025-05-29 18:25:34,344 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:25:34,559 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/2000.ckpt
2025-05-29 18:25:34,578 - INFO - joeynmt.training - Example #0
2025-05-29 18:25:34,579 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:25:34,579 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:25:34,579 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', 'dat', 'ik', 'deze', 'deze', 't@@', 'on@@', 'en', 'om', 'te', 'ver@@', 'hal@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'c@@', 'a', 'te', 'k@@', 'oo@@', 'k,', 'de', 'n@@', 'u@@', 'ch@@', 'o@@', 'k', 'van', 'de', 'V@@', 'S', 'die', '4@@', '8', 'miljo@@', 'en', 'jaar', 'van', '4@@', '8', 'proc@@', 'ent', 'van', '4@@', '8', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'V@@', 'S', 'was', 'was', 'was', 'ik', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'V@@', 'S', 'en', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '8', 'proc@@', 'ent', 'van', 'de', 'V@@', 'S', 'om', '4@@', '8', 'miljo@@', 'en', 'jaar', 'van', 'de', 'V@@', 'S', 'te', 'ver@@']
2025-05-29 18:25:34,580 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:25:34,581 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:25:34,581 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden dat ik deze deze tonen om te verhalen dat de artica te kook, de nuchok van de VS die 48 miljoen jaar van 48 procent van 48 procent van 40 procent van 40 procent van 40 procent van de VS was was was ik 40 procent van de VS en 40 procent van 40 procent van 48 procent van de VS om 48 miljoen jaar van de VS te ver
2025-05-29 18:25:34,581 - INFO - joeynmt.training - Example #1
2025-05-29 18:25:34,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:25:34,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:25:34,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'als', 'je', 'niet', 'ver@@', 'tel@@', 't', 'dat', 'het', 'niet', 'de', 're@@', 's@@', 'ult@@', 'aten', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'u@@', 's,', 'het', 'niet', 'de', 'di@@', 'c@@', 'e', 'van', 'het', 'v@@', 'aak', 'van', 'het', 'v@@', 'aak', 'van', 'het', 'be@@', 'et@@', 'je', 'het', 'niet', 'de', 'v@@', 'aak', 'van', 'het', 'be@@', 'et@@', 'je', 'dat', 'het', 'niet', 'de', 'be@@', 'ste', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'het', 'so@@', 'ci@@', 'ale', 'proble@@', 'em', 'niet', 'als', 'het', 'niet', 'de', 'v@@', 'aak', 'van', 'de', 'v@@', 'aak', 'van', 'de', 'v@@', 'aak', 'van', 'het', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'is', 'het', 'niet', 'de', 'c@@', 'ellen', 'van', 'het', 'ge@@', 'zien', 'van', 'het', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'is', 'het', 'niet']
2025-05-29 18:25:34,583 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:25:34,583 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:25:34,583 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet als je niet vertelt dat het niet de resultaten van het specifieus, het niet de dice van het vaak van het vaak van het beetje het niet de vaak van het beetje dat het niet de beste van het specifiek van het sociale probleem niet als het niet de vaak van de vaak van de vaak van het speciale probleem is het niet de cellen van het gezien van het speciale probleem is het niet
2025-05-29 18:25:34,584 - INFO - joeynmt.training - Example #2
2025-05-29 18:25:34,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:25:34,585 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:25:34,585 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'v@@', 'al', 'van', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'u@@', 'is@@', 'c@@', 'e', 'E@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'e', 'van', 'onze', 'op@@', 'en@@', 'bare', 'k@@', 'wal@@', 'it@@', 'ei@@', 't.', '</s>']
2025-05-29 18:25:34,586 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:25:34,586 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:25:34,586 - INFO - joeynmt.training - 	Hypothesis: In de val van de artische Eiscuisce Eiscusse van onze openbare kwaliteit.
2025-05-29 18:25:34,586 - INFO - joeynmt.training - Example #3
2025-05-29 18:25:34,587 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:25:34,587 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:25:34,587 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'het', 'in', 'het', 'w@@', 'aaro@@', 'p', 'je', 'in', 'de', 'z@@', 'om@@', 'gev@@', 'ing.', '</s>']
2025-05-29 18:25:34,588 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:25:34,588 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:25:34,588 - INFO - joeynmt.training - 	Hypothesis: Ze wist het in het waarop je in de zomgeving.
2025-05-29 18:25:34,589 - INFO - joeynmt.training - Example #4
2025-05-29 18:25:34,589 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:25:34,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:25:34,589 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'al@@', 'so@@', 'f', 'ik', 'jullie', 'jullie', 'zien', 'wat', 'ik', 'jullie', 'zien', 'wat', 'er', 'gebeur@@', 't', 'is.', '</s>']
2025-05-29 18:25:34,590 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:25:34,590 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:25:34,591 - INFO - joeynmt.training - 	Hypothesis: De volgende valsof ik jullie jullie zien wat ik jullie zien wat er gebeurt is.
2025-05-29 18:25:46,382 - INFO - joeynmt.training - Epoch   1, Step:     4600, Batch Loss:     2.309164, Batch Acc: 0.357713, Tokens per Sec:     5914, Lr: 0.000300
2025-05-29 18:25:57,852 - INFO - joeynmt.training - Epoch   1, Step:     4700, Batch Loss:     2.429115, Batch Acc: 0.364233, Tokens per Sec:     6275, Lr: 0.000300
2025-05-29 18:26:09,201 - INFO - joeynmt.training - Epoch   1, Step:     4800, Batch Loss:     2.156848, Batch Acc: 0.369440, Tokens per Sec:     6248, Lr: 0.000300
2025-05-29 18:26:19,854 - INFO - joeynmt.training - Epoch   1, Step:     4900, Batch Loss:     2.275475, Batch Acc: 0.374070, Tokens per Sec:     6562, Lr: 0.000300
2025-05-29 18:26:29,724 - INFO - joeynmt.training - Epoch   1, Step:     5000, Batch Loss:     2.272270, Batch Acc: 0.370217, Tokens per Sec:     6834, Lr: 0.000300
2025-05-29 18:26:29,725 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:26:29,725 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:27:23,347 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.28, ppl:   9.80, acc:   0.35, generation: 53.5547[sec], evaluation: 0.0000[sec]
2025-05-29 18:27:23,349 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:27:23,637 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/2500.ckpt
2025-05-29 18:27:23,657 - INFO - joeynmt.training - Example #0
2025-05-29 18:27:23,659 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:27:23,659 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:27:23,659 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'ik', 'deze', 'twee', 'v@@', 'ol@@', 'en', 'ik', 'deze', 'twee', 'v@@', 'ol@@', 'en', 'ver@@', 'der', 'die', 'je', 'ver@@', 'der', 'ver@@', 'der', 'die', 'je', 'ver@@', 'der', 'voor', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'St@@', 'aten', 'voor', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'St@@', 'aten', 'van', 'de', 'V@@', 'S', 'die', 'de', 'St@@', 'aten', 'van', '4@@', '8', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '8', 'proc@@', 'ent', 'van', '4@@', '8', 'proc@@', 'ent', 'van', 'de', 'St@@', 'aten', 'is.', '</s>']
2025-05-29 18:27:23,660 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:27:23,660 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:27:23,661 - INFO - joeynmt.training - 	Hypothesis: Laten ik deze twee volen ik deze twee volen verder die je verder verder die je verder voor de Verenigde Staten voor de Verenigde Staten van de VS die de Staten van 48 procent van 40 procent van 48 procent van 48 procent van de Staten is.
2025-05-29 18:27:23,661 - INFO - joeynmt.training - Example #1
2025-05-29 18:27:23,661 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:27:23,662 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:27:23,662 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'soort', 'c@@', 'ontro@@', 'le@@', 'er@@', 'den', 'die', 'de', 're@@', 's@@', 'ult@@', 'aten', 'die', 'de', 're@@', 's@@', 'ult@@', 'aten', 'van', 'deze', 'spe@@', 'ci@@', 'ë@@', 'le', 'proble@@', 'men', 'van', 'de', 'E@@', 'is@@', 'c@@', 'u@@', 'ck@@', 'e', 'van', 'de', 'E@@', 'is@@', 'c@@', 'u@@', 'is@@', '.', '</s>']
2025-05-29 18:27:23,663 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:27:23,663 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:27:23,663 - INFO - joeynmt.training - 	Hypothesis: Maar dit soort controleerden die de resultaten die de resultaten van deze speciële problemen van de Eiscucke van de Eiscuis.
2025-05-29 18:27:23,663 - INFO - joeynmt.training - Example #2
2025-05-29 18:27:23,664 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:27:23,664 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:27:23,664 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'ar@@', 'ti@@', 'sche', 'sit@@', 'u@@', 'atie', 'is', 'de', 'ar@@', 'ti@@', 'ti@@', 'sche', 'E@@', 'en@@', 'ti@@', 'sche', 'E@@', 'u@@', 'rop@@', 'ale', 'c@@', 'ul@@', 'a@@', 'ir@@', 'e', 'kan@@', 't@@', 'on@@', 'on@@', 's@@', 'zelf', 'te', 'maken.', '</s>']
2025-05-29 18:27:23,665 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:27:23,665 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:27:23,666 - INFO - joeynmt.training - 	Hypothesis: In de artische situatie is de artitische Eentische Europale culaire kantononszelf te maken.
2025-05-29 18:27:23,666 - INFO - joeynmt.training - Example #3
2025-05-29 18:27:23,666 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:27:23,667 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:27:23,667 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'de', 'w@@', 'in@@', 'di@@', 'ver@@', '.', '</s>']
2025-05-29 18:27:23,668 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:27:23,668 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:27:23,668 - INFO - joeynmt.training - 	Hypothesis: Ze wist in de windiver.
2025-05-29 18:27:23,668 - INFO - joeynmt.training - Example #4
2025-05-29 18:27:23,669 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:27:23,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:27:23,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'al@@', 'so@@', 'f', 'ik', 'jullie', 'zien', 'wat', 'ik', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gele@@', 'den', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'die', 'ik', 'jullie', 'zien', 'wat', 'de', 'laat@@', 'ste', 'v@@', 'la@@', 'k@@', 'ken@@', 'de', 'ik', 'jullie', 'zien', 'van', 'de', 'laat@@', 'ste', 'k@@', 'eu@@', 'w@@', 'en', 'ik', 'jullie', 'zien', 'wat', 'ik', 'jullie', 'zien', 'zien', 'zien', 'van', 'de', 'laat@@', 'ste', 'k@@', 'we@@', 'er@@', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'die', 'ik', 'jullie', 'zien', 'zien', 'zien', 'zien', 'zien', 'van', 'de', 'laat@@']
2025-05-29 18:27:23,670 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:27:23,671 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:27:23,671 - INFO - joeynmt.training - 	Hypothesis: De volgende valsof ik jullie zien wat ik de laatste 25 jaar geleden in de laatste 25 jaar geleden in de afgelopen 25 jaar geleden in de laatste 25 jaar geleden die ik jullie zien wat de laatste vlakkende ik jullie zien van de laatste keuwen ik jullie zien wat ik jullie zien zien zien van de laatste kweervan de laatste 25 jaar geleden in de laatste 25 jaar geleden die ik jullie zien zien zien zien zien van de laat
2025-05-29 18:27:36,736 - INFO - joeynmt.training - Epoch   1, Step:     5100, Batch Loss:     2.260538, Batch Acc: 0.371596, Tokens per Sec:     5294, Lr: 0.000300
2025-05-29 18:27:49,924 - INFO - joeynmt.training - Epoch   1, Step:     5200, Batch Loss:     2.064732, Batch Acc: 0.378743, Tokens per Sec:     5184, Lr: 0.000300
2025-05-29 18:28:01,821 - INFO - joeynmt.training - Epoch   1, Step:     5300, Batch Loss:     2.285070, Batch Acc: 0.381677, Tokens per Sec:     5853, Lr: 0.000300
2025-05-29 18:28:13,227 - INFO - joeynmt.training - Epoch   1, Step:     5400, Batch Loss:     2.159529, Batch Acc: 0.382627, Tokens per Sec:     6092, Lr: 0.000300
2025-05-29 18:28:24,460 - INFO - joeynmt.training - Epoch   1, Step:     5500, Batch Loss:     2.114151, Batch Acc: 0.384926, Tokens per Sec:     6397, Lr: 0.000300
2025-05-29 18:28:24,461 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:28:24,461 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:29:14,129 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.21, ppl:   9.16, acc:   0.37, generation: 49.6122[sec], evaluation: 0.0000[sec]
2025-05-29 18:29:14,131 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:29:14,343 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/3000.ckpt
2025-05-29 18:29:14,361 - INFO - joeynmt.training - Example #0
2025-05-29 18:29:14,361 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:29:14,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:29:14,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', 'dat', 'de', 'dag', 'ge@@', 'zien', 'om', 'te', 'ver@@', 'sp@@', 'rei@@', 'ding', 'te', 'ver@@', 'anderen', 'dat', 'de', 'ar@@', 'ch@@', 'nie@@', 'k', 'van', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'en@@', '-@@', 'e@@', 'chte', 're@@', 'den', 'die', 'de', 'V@@', 'S', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'V@@', 'S', 'is', '4@@', '0', 'proc@@', 'ent', 'om', '4@@', '0', 'proc@@', 'ent', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'is', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'is', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'is.', '</s>']
2025-05-29 18:29:14,363 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:29:14,363 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:29:14,363 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden dat de dag gezien om te verspreiding te veranderen dat de archniek van de artische Een-echte reden die de VS de drie miljoen jaar de VS is 40 procent om 40 procent procent van 40 procent is 40 procent van 40 procent is 40 procent van 40 procent van 40 procent is.
2025-05-29 18:29:14,363 - INFO - joeynmt.training - Example #1
2025-05-29 18:29:14,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:29:14,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:29:14,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'der@@', 'de', 'niet', 'st@@', 'op@@', 't', 'in', 'de', 'aar@@', 'n@@', 'st@@', 'op@@', 't', 'van', 'dit', 'soort', 'proble@@', 'em', 'in', 'het', 'proble@@', 'em', 'van', 'het', 'ij@@', 'st', 'van', 'het', 'E@@', 'is@@', 'c@@', 'u@@', 'is@@', '.', '</s>']
2025-05-29 18:29:14,365 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:29:14,365 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:29:14,365 - INFO - joeynmt.training - 	Hypothesis: Maar dit derde niet stopt in de aarnstopt van dit soort probleem in het probleem van het ijst van het Eiscuis.
2025-05-29 18:29:14,366 - INFO - joeynmt.training - Example #2
2025-05-29 18:29:14,366 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:29:14,366 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:29:14,366 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'f@@', 'eite', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'c@@', 'c@@', 'l@@', 'aat', 'het', 'sch@@', 'a@@', 'cht', 'van', 'ons', 'on@@', 'gelu@@', 'i@@', 'd', 'van', 'ons', 'op@@', 'lo@@', 'b@@', 'ale', 'k@@', 'aar@@', 't', 'in', 'de', 'l@@', 'oo@@', 'p', 'van', 'de', 'ar@@', 'ti@@', 'sche', 'k@@', 'aar@@', 't', 'in', 'de', 'ar@@', 'ti@@', 'sche', 'vo@@', 'e@@', 'gen', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'vo@@', 'e@@', 'gen', 'van', 'de', 'ar@@', 'ti@@', 'sche', 'in@@', 'ti@@', 'sche', 'vo@@', 'ed@@', 'sel@@', '.', '</s>']
2025-05-29 18:29:14,367 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:29:14,367 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:29:14,367 - INFO - joeynmt.training - 	Hypothesis: In feite is de artische Eisccclaat het schacht van ons ongeluid van ons oplobale kaart in de loop van de artische kaart in de artische voegen is de artische voegen van de artische intische voedsel.
2025-05-29 18:29:14,367 - INFO - joeynmt.training - Example #3
2025-05-29 18:29:14,368 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:29:14,368 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:29:14,368 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'oe@@', 'k', 'in', 'de', 'w@@', 'in', 'de', 'z@@', 'in', 'de', 'z@@', 'om@@', 'aar', 'in', 'de', 'z@@', 'om@@', 'aar', 'in', 'de', 'z@@', 'om@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'om@@', 'er', 'en', 'sch@@', 'il@@', 'der@@', '.', '</s>']
2025-05-29 18:29:14,369 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:29:14,369 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:29:14,369 - INFO - joeynmt.training - 	Hypothesis: Ze woek in de win de zin de zomaar in de zomaar in de zomomer in de zomomer en schilder.
2025-05-29 18:29:14,370 - INFO - joeynmt.training - Example #4
2025-05-29 18:29:14,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:29:14,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:29:14,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'den@@', 's', 'wat', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de.', '</s>']
2025-05-29 18:29:14,371 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:29:14,372 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:29:14,372 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie tonen is een tijdens wat in de laatste 25 jaar gebeurde.
2025-05-29 18:29:25,118 - INFO - joeynmt.training - Epoch   1, Step:     5600, Batch Loss:     2.227195, Batch Acc: 0.386389, Tokens per Sec:     6390, Lr: 0.000300
2025-05-29 18:29:36,575 - INFO - joeynmt.training - Epoch   1, Step:     5700, Batch Loss:     2.134052, Batch Acc: 0.387873, Tokens per Sec:     6038, Lr: 0.000300
2025-05-29 18:29:49,379 - INFO - joeynmt.training - Epoch   1, Step:     5800, Batch Loss:     2.004780, Batch Acc: 0.394240, Tokens per Sec:     5451, Lr: 0.000300
2025-05-29 18:30:04,571 - INFO - joeynmt.training - Epoch   1, Step:     5900, Batch Loss:     2.204598, Batch Acc: 0.398453, Tokens per Sec:     4654, Lr: 0.000300
2025-05-29 18:30:19,447 - INFO - joeynmt.training - Epoch   1, Step:     6000, Batch Loss:     2.145465, Batch Acc: 0.396151, Tokens per Sec:     4666, Lr: 0.000300
2025-05-29 18:30:19,449 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:30:19,449 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:31:20,236 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.17, ppl:   8.74, acc:   0.38, generation: 60.7394[sec], evaluation: 0.0000[sec]
2025-05-29 18:31:20,237 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:31:20,426 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/3500.ckpt
2025-05-29 18:31:20,442 - INFO - joeynmt.training - Example #0
2025-05-29 18:31:20,443 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:31:20,443 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:31:20,443 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'een', 'jaar', 'gele@@', 'den', 'om', 'de', 'v@@', 'ol@@', 'i@@', 'f@@', 'ic@@', 't@@', 'ie', 'te', 'ver@@', 'sp@@', 'rei@@', 'd', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'ch@@', 'ter', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'chte', 're@@', 'den', 'voor', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'de', 're@@', 'den', 'van', '4@@', '8', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'is.', '</s>']
2025-05-29 18:31:20,444 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:31:20,445 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:31:20,445 - INFO - joeynmt.training - 	Hypothesis: Ik heb een jaar geleden om de volifictie te verspreid dat de artische echter voor de artische echte reden voor de drie miljoen jaar de reden van 48 procent van 40 procent van 40 procent van 40 procent is.
2025-05-29 18:31:20,445 - INFO - joeynmt.training - Example #1
2025-05-29 18:31:20,446 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:31:20,446 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:31:20,446 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'mom@@', 'ent', 'niet', 'ster@@', 'k', 'van', 'de', 'aar@@', 'n@@', 'u@@', ',', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'in', 'het', 'zie@@', 'kte', 'van', 'het', 'E@@', 'is@@', 'c@@', 'is@@', 'es', 'van', 'het', 'E@@', 'is@@', 'c@@', 'is@@', 'es', 'van', 'het', 'E@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', 'van', 'het', 'E@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', 'van', 'het', 'E@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', 'van', 'het', 'e@@', 'chte', 'proble@@', 'em', 'niet', 'de', 'di@@', 'k@@', 'n@@', 'u@@', 'il@@', 'le@@', 's.', '</s>']
2025-05-29 18:31:20,447 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:31:20,447 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:31:20,447 - INFO - joeynmt.training - 	Hypothesis: Maar dit moment niet sterk van de aarnu, dit speciale probleem van dit speciale probleem in het ziekte van het Eiscises van het Eiscises van het Eiscussie van het Eiscussie van het Eiscussie van het echte probleem niet de diknuilles.
2025-05-29 18:31:20,447 - INFO - joeynmt.training - Example #2
2025-05-29 18:31:20,447 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:31:20,448 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:31:20,448 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'f@@', 'eite', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'conom@@', 'ische', 'e@@', 'ch@@', 'ter', 'de', 'sch@@', 'rij@@', 'v@@', 'en,', 'de', 'kl@@', 'im@@', 'aat@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'de', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 's@@', 'k@@', 'aar@@', 't.', '</s>']
2025-05-29 18:31:20,448 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:31:20,449 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:31:20,449 - INFO - joeynmt.training - 	Hypothesis: In feite is de artische economische echter de schrijven, de klimaatskaart van de lobale klimaatskaart.
2025-05-29 18:31:20,449 - INFO - joeynmt.training - Example #3
2025-05-29 18:31:20,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:31:20,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:31:20,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'w@@', 'w@@', 'ist', 'in', 'de', 'w@@', 'in@@', 'der', 'en', 'sch@@', 'il@@', 'der@@', '.', '</s>']
2025-05-29 18:31:20,450 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:31:20,451 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:31:20,451 - INFO - joeynmt.training - 	Hypothesis: Ze wwwist in de winder en schilder.
2025-05-29 18:31:20,451 - INFO - joeynmt.training - Example #4
2025-05-29 18:31:20,451 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:31:20,451 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:31:20,452 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ol@@', 'ie,', 'die', 'ik', 'jullie', 'zien', 'wat', 'ik', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'is.', '</s>']
2025-05-29 18:31:20,452 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:31:20,453 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:31:20,453 - INFO - joeynmt.training - 	Hypothesis: De volgende volie, die ik jullie zien wat ik in de laatste 25 jaar geleden in de laatste 25 jaar geleden in de laatste 25 jaar geleden is.
2025-05-29 18:31:30,464 - INFO - joeynmt.training - Epoch   1, Step:     6100, Batch Loss:     1.981745, Batch Acc: 0.399163, Tokens per Sec:     6753, Lr: 0.000300
2025-05-29 18:31:40,359 - INFO - joeynmt.training - Epoch   1, Step:     6200, Batch Loss:     2.115489, Batch Acc: 0.403438, Tokens per Sec:     7108, Lr: 0.000300
2025-05-29 18:31:49,634 - INFO - joeynmt.training - Epoch   1, Step:     6300, Batch Loss:     2.080024, Batch Acc: 0.402405, Tokens per Sec:     7593, Lr: 0.000300
2025-05-29 18:31:58,392 - INFO - joeynmt.training - Epoch   1, Step:     6400, Batch Loss:     1.998108, Batch Acc: 0.407392, Tokens per Sec:     7899, Lr: 0.000300
2025-05-29 18:32:07,241 - INFO - joeynmt.training - Epoch   1, Step:     6500, Batch Loss:     2.215583, Batch Acc: 0.402838, Tokens per Sec:     7504, Lr: 0.000300
2025-05-29 18:32:07,242 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:32:07,242 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:32:51,637 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.15, ppl:   8.62, acc:   0.39, generation: 44.3504[sec], evaluation: 0.0000[sec]
2025-05-29 18:32:51,638 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:32:51,858 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/4000.ckpt
2025-05-29 18:32:51,890 - INFO - joeynmt.training - Example #0
2025-05-29 18:32:51,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:32:51,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:32:51,892 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'de', 'jaar', 'gele@@', 'den', 'om', 'deze', 'twee', 'v@@', 'ol@@', 'ie@@', 'ën', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'ch@@', 'ter', 'voor', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'van', 'drie', 'miljo@@', 'en', 'jaar', 'van', 'drie', 'miljo@@', 'en', 'jaar', 'van', '4@@', '8', 'proc@@', 'ent', 'van', '4@@', '8', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '8', 'proc@@', 'ent', 'is.', '</s>']
2025-05-29 18:32:51,893 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:32:51,893 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:32:51,893 - INFO - joeynmt.training - 	Hypothesis: Ik heb de jaar geleden om deze twee volieën te verzamelen, dat de artische echter voor de drie miljoen jaar de drie miljoen jaar van drie miljoen jaar van drie miljoen jaar van 48 procent van 48 procent van 40 procent van 48 procent is.
2025-05-29 18:32:51,893 - INFO - joeynmt.training - Example #1
2025-05-29 18:32:51,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:32:51,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:32:51,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'der@@', 'de', 'niet', 'de', 'ver@@', 'n@@', 'u@@', 'st', 'de', 're@@', 's@@', 'ult@@', 'aat', 'van', 'dit', 'soort', 'proble@@', 'em', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ale', 'proble@@', 'men', 'van', 'het', 'E@@', 'is@@', 'es', 'van', 'het', 'E@@', 'is@@', 'es', 'van', 'het', 'E@@', 'is@@', 'es', 'van', 'het', 'E@@', 'is@@', 'es', 'van', 'het', 'E@@', 'is@@', 'es', 'van', 'het', 'E@@', 'is@@', 'es', 'van', 'het', 'E@@', 'is@@', 'es', 'van', 'het', 'e@@', 'chte', 'proble@@', 'em', 'van', 'het', 'e@@', 'ven@@', 'w@@', 'aa@@', 'st', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'E@@', 'is@@', 'ci@@', 'ë@@', 'le', 'proble@@', 'em', 'em', 'is', 'het', 'di@@', 'k@@', 'ie@@', 'k', 'van', 'het', 'E@@', 'is@@', 'c@@', 'el', 'van', 'het', 'E@@', 'is@@', 'ci@@', 'ë@@', 'le', 'proble@@', 'em@@', '.', '</s>']
2025-05-29 18:32:51,895 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:32:51,895 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:32:51,895 - INFO - joeynmt.training - 	Hypothesis: Maar dit derde niet de vernust de resultaat van dit soort probleem is het niet de dikale problemen van het Eises van het Eises van het Eises van het Eises van het Eises van het Eises van het Eises van het echte probleem van het evenwaast niet de dicke van het Eisciële probleem em is het dikiek van het Eiscel van het Eisciële probleem.
2025-05-29 18:32:51,896 - INFO - joeynmt.training - Example #2
2025-05-29 18:32:51,896 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:32:51,896 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:32:51,896 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'is@@', 'kun@@', 'de', 'van', 'de', 'c@@', 'li@@', 'p', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ie@@', '-@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:32:51,897 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:32:51,897 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:32:51,898 - INFO - joeynmt.training - 	Hypothesis: In wiskunde van de clip is de artische ijskie-systeem.
2025-05-29 18:32:51,898 - INFO - joeynmt.training - Example #3
2025-05-29 18:32:51,898 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:32:51,898 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:32:51,898 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'et', 'het', 'w@@', 'ein@@', 'ig', 'en', 'het', 'sch@@', 'il@@', 'der@@', '.', '</s>']
2025-05-29 18:32:51,899 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:32:51,900 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:32:51,900 - INFO - joeynmt.training - 	Hypothesis: Ze wet het weinig en het schilder.
2025-05-29 18:32:51,900 - INFO - joeynmt.training - Example #4
2025-05-29 18:32:51,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:32:51,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:32:51,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'zien', 'is', 'een', 'tijd', 'dat', 'ik', 'een', 'tij@@', 'den@@', 's', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', 'is.', '</s>']
2025-05-29 18:32:51,902 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:32:51,902 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:32:51,902 - INFO - joeynmt.training - 	Hypothesis: De volgende volie die ik jullie zien is een tijd dat ik een tijdens van de laatste 25 jaar gebeurt is.
2025-05-29 18:33:03,067 - INFO - joeynmt.training - Epoch   1, Step:     6600, Batch Loss:     2.079365, Batch Acc: 0.406093, Tokens per Sec:     6118, Lr: 0.000300
2025-05-29 18:33:13,013 - INFO - joeynmt.training - Epoch   1, Step:     6700, Batch Loss:     2.242442, Batch Acc: 0.412752, Tokens per Sec:     7211, Lr: 0.000300
2025-05-29 18:33:23,017 - INFO - joeynmt.training - Epoch   1, Step:     6800, Batch Loss:     2.100522, Batch Acc: 0.420222, Tokens per Sec:     6887, Lr: 0.000300
2025-05-29 18:33:33,113 - INFO - joeynmt.training - Epoch   1, Step:     6900, Batch Loss:     1.951683, Batch Acc: 0.413615, Tokens per Sec:     7050, Lr: 0.000300
2025-05-29 18:33:43,520 - INFO - joeynmt.training - Epoch   1, Step:     7000, Batch Loss:     2.089611, Batch Acc: 0.413885, Tokens per Sec:     6785, Lr: 0.000300
2025-05-29 18:33:43,521 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:33:43,521 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:34:26,955 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.10, ppl:   8.18, acc:   0.40, generation: 43.3917[sec], evaluation: 0.0000[sec]
2025-05-29 18:34:26,956 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:34:27,147 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/4500.ckpt
2025-05-29 18:34:27,165 - INFO - joeynmt.training - Example #0
2025-05-29 18:34:27,166 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:34:27,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:34:27,167 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', 'die', 'twee', 'f@@', 'ol@@', 'ie@@', 'ven', 'hebben', 'om', 'te', 'ver@@', 'anderen', 'die', 'die', 'de', 'ar@@', 'ti@@', 'kel', 'voor', 'de', 'ar@@', 'ti@@', 'kel', 'voor', 'de', 're@@', 'den', 'die', 'voor', 'de', 're@@', 'den', 'drie', 'miljo@@', 'en', 'jaar', 'die', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'gebeur@@', 'de', 'de', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'gebeur@@', 'de', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'is.', '</s>']
2025-05-29 18:34:27,168 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:34:27,168 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:34:27,168 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden die twee folieven hebben om te veranderen die die de artikel voor de artikel voor de reden die voor de reden drie miljoen jaar die de reden van 40 procent van 40 procent gebeurde de 40 procent van 40 procent gebeurde 40 procent van 40 procent is.
2025-05-29 18:34:27,169 - INFO - joeynmt.training - Example #1
2025-05-29 18:34:27,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:34:27,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:34:27,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'dr@@', 'a', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 're@@', 's@@', 'ult@@', 'aten', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'is', 'dat', 'niet', 'de', 'di@@', 'k@@', 'n@@', 'i@@', 've@@', 'au', 'van', 'de', 'ij@@', 's@@', 'k@@', 'we@@', 'er', 'van', 'de', 'ij@@', 's@@', 'k@@', 'te.', '</s>']
2025-05-29 18:34:27,170 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:34:27,170 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:34:27,170 - INFO - joeynmt.training - 	Hypothesis: Maar dit dra niet sterk genoeg de resultaten van dit speciale probleem is dat niet de dikniveau van de ijskweer van de ijskte.
2025-05-29 18:34:27,170 - INFO - joeynmt.training - Example #2
2025-05-29 18:34:27,170 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:34:27,170 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:34:27,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'c@@', 'u@@', 'ss@@', 'a', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'sch@@', 'ap', 'van', 'de', 'kl@@', 'im@@', 'aat@@', 'sch@@', 'ap', 'van', 'de', 'kl@@', 'im@@', 'aat@@', 'sch@@', 'ap@@', '.', '</s>']
2025-05-29 18:34:27,171 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:34:27,171 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:34:27,171 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische Eisccussa van ons globale klimaatschap van de klimaatschap van de klimaatschap.
2025-05-29 18:34:27,172 - INFO - joeynmt.training - Example #3
2025-05-29 18:34:27,172 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:34:27,172 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:34:27,172 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'w@@', 'ist', 'in', 'het', 'W@@', 'in@@', 'der', 'en', 'sch@@', 'ro@@', 'mp@@', 'el@@', 'en.', '</s>']
2025-05-29 18:34:27,173 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:34:27,173 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:34:27,173 - INFO - joeynmt.training - 	Hypothesis: Ze wwist in het Winder en schrompelen.
2025-05-29 18:34:27,173 - INFO - joeynmt.training - Example #4
2025-05-29 18:34:27,174 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:34:27,174 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:34:27,174 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ou@@', 't', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', '2@@', '5', 'jaar', 'gele@@', 'den', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 18:34:27,174 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:34:27,175 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:34:27,175 - INFO - joeynmt.training - 	Hypothesis: De volgende fout die ik jullie laten zien is een tijdje in de laatste 25 jaar geleden 25 jaar geleden 25 jaar is.
2025-05-29 18:34:36,776 - INFO - joeynmt.training - Epoch   1, Step:     7100, Batch Loss:     1.968315, Batch Acc: 0.411636, Tokens per Sec:     7188, Lr: 0.000300
2025-05-29 18:34:46,426 - INFO - joeynmt.training - Epoch   1, Step:     7200, Batch Loss:     1.942824, Batch Acc: 0.420096, Tokens per Sec:     7592, Lr: 0.000300
2025-05-29 18:34:56,475 - INFO - joeynmt.training - Epoch   1, Step:     7300, Batch Loss:     1.981071, Batch Acc: 0.415597, Tokens per Sec:     7086, Lr: 0.000300
2025-05-29 18:35:06,777 - INFO - joeynmt.training - Epoch   1, Step:     7400, Batch Loss:     1.945478, Batch Acc: 0.419660, Tokens per Sec:     6668, Lr: 0.000300
2025-05-29 18:35:16,805 - INFO - joeynmt.training - Epoch   1, Step:     7500, Batch Loss:     2.185712, Batch Acc: 0.421116, Tokens per Sec:     7086, Lr: 0.000300
2025-05-29 18:35:16,807 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:35:16,807 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:36:11,384 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.08, ppl:   8.00, acc:   0.40, generation: 54.5121[sec], evaluation: 0.0000[sec]
2025-05-29 18:36:11,386 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:36:11,586 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/5000.ckpt
2025-05-29 18:36:11,604 - INFO - joeynmt.training - Example #0
2025-05-29 18:36:11,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:36:11,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:36:11,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', 'van', 'de', 'gev@@', 'allen', 'van', 'de', 'gev@@', 'allen', 'van', 'de', 'ar@@', 'ti@@', 'sche', 'vo@@', 'ed@@', 's@@', 'el', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'vo@@', 'ed@@', 's@@', 'el', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'werel@@', 'd,', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'oor@@', 'z@@', 'aa@@', 'kt', 'is.', '</s>']
2025-05-29 18:36:11,606 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:36:11,606 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:36:11,607 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden van de gevallen van de gevallen van de artische voedsel dat de artische voedsel van de reden van de reden van de reden van de wereld, om 40 procent te veroorzaakt is.
2025-05-29 18:36:11,607 - INFO - joeynmt.training - Example #1
2025-05-29 18:36:11,607 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:36:11,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:36:11,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'ver@@', 'n@@', 'u@@', 'st', 'de', 'ver@@', 'nie@@', 'tig@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'de', 'E@@', 'is@@', 'es', 'van', 'de', 'ij@@', 's@@', 'k@@', 'we@@', 'er', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'de', 'ij@@', 's@@', 'b@@', 'uit@@', 'en@@', 'd.', '</s>']
2025-05-29 18:36:11,609 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:36:11,609 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:36:11,609 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de vernust de vernietiging van dit specifiek van de Eises van de ijskweer niet de dicke van de ijsbuitend.
2025-05-29 18:36:11,609 - INFO - joeynmt.training - Example #2
2025-05-29 18:36:11,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:36:11,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:36:11,610 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'f@@', 'eite', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'vo@@', 'ed@@', 's@@', 'el', 'van', 'de', 'ar@@', 'ti@@', 'sche', 'vo@@', 'ed@@', 'sel@@', ',', 'de', 'be@@', 'ste', 'van', 'ons', 'het', 'kl@@', 'im@@', 'aat@@', 's@@', 'k@@', 'i@@', 've@@', 'au', 'van', 'de', 'kl@@', 'im@@', 'aat@@', 's@@', 'k@@', 'we@@', 'z@@', 'en@@', 'd.', '</s>']
2025-05-29 18:36:11,611 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:36:11,612 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:36:11,612 - INFO - joeynmt.training - 	Hypothesis: In feite is de artische voedsel van de artische voedsel, de beste van ons het klimaatskiveau van de klimaatskwezend.
2025-05-29 18:36:11,613 - INFO - joeynmt.training - Example #3
2025-05-29 18:36:11,614 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:36:11,614 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:36:11,614 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'aaro@@', 'p', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'o@@', 'on@@', '.', '</s>']
2025-05-29 18:36:11,615 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:36:11,615 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:36:11,616 - INFO - joeynmt.training - 	Hypothesis: Ze waarop in de winter en schoon.
2025-05-29 18:36:11,616 - INFO - joeynmt.training - Example #4
2025-05-29 18:36:11,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:36:11,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:36:11,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'den@@', 's', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', 'is.', '</s>']
2025-05-29 18:36:11,618 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:36:11,618 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:36:11,618 - INFO - joeynmt.training - 	Hypothesis: De volgende volie die ik jullie laten zien is een tijdens van de laatste 25 jaar gebeurt is.
2025-05-29 18:36:21,887 - INFO - joeynmt.training - Epoch   1, Step:     7600, Batch Loss:     2.041435, Batch Acc: 0.425927, Tokens per Sec:     6847, Lr: 0.000300
2025-05-29 18:36:32,396 - INFO - joeynmt.training - Epoch   1, Step:     7700, Batch Loss:     1.872585, Batch Acc: 0.420749, Tokens per Sec:     6665, Lr: 0.000300
2025-05-29 18:36:42,794 - INFO - joeynmt.training - Epoch   1, Step:     7800, Batch Loss:     1.881984, Batch Acc: 0.423854, Tokens per Sec:     6752, Lr: 0.000300
2025-05-29 18:36:52,162 - INFO - joeynmt.training - Epoch   1, Step:     7900, Batch Loss:     1.940729, Batch Acc: 0.428624, Tokens per Sec:     7263, Lr: 0.000300
2025-05-29 18:37:01,380 - INFO - joeynmt.training - Epoch   1, Step:     8000, Batch Loss:     1.921742, Batch Acc: 0.430051, Tokens per Sec:     7689, Lr: 0.000300
2025-05-29 18:37:01,380 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:37:01,381 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:37:44,567 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.06, ppl:   7.85, acc:   0.41, generation: 43.1397[sec], evaluation: 0.0000[sec]
2025-05-29 18:37:44,568 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:37:44,787 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/5500.ckpt
2025-05-29 18:37:44,803 - INFO - joeynmt.training - Example #0
2025-05-29 18:37:44,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:37:44,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:37:44,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', 'ge@@', 'to@@', 'on@@', 't', 'om', 'te', 'ver@@', 'der', 'te', 'ver@@', 'der', 'te', 'ver@@', 'der', 'te', 'zien', 'dat', 'de', 'ar@@', 'ct@@', 'ie', 'van', 'de', 'A@@', 'ct@@', 'ie', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'e@@', 'eu@@', 'eu@@', 'w@@', 'en', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'gebeur@@', 'd.', '</s>']
2025-05-29 18:37:44,805 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:37:44,806 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:37:44,806 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden getoont om te verder te verder te verder te zien dat de arctie van de Actie van de reden van de reden van de eeueuwen 40 procent van 40 procent gebeurd.
2025-05-29 18:37:44,807 - INFO - joeynmt.training - Example #1
2025-05-29 18:37:44,807 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:37:44,807 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:37:44,807 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'uit@@', 'z@@', 'onder@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'van', 'de', 'E@@', 'is@@', 'es', 'van', 'de', 'ij@@', 's@@', 'k@@', 'eu@@', 'ze', 'to@@', 'on@@', '.', '</s>']
2025-05-29 18:37:44,808 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:37:44,808 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:37:44,808 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de uitzondering van dit speciale problemen van dit speciale problemen van de Eises van de ijskeuze toon.
2025-05-29 18:37:44,809 - INFO - joeynmt.training - Example #2
2025-05-29 18:37:44,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:37:44,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:37:44,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'is@@', 'sel@@', 'ing', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'E@@', 'is@@', 'c@@', 'c@@', 'c@@', 'li@@', 'ma@@', 'ss@@', 'a', 'van', 'onze', 'g@@', 'lo@@', 'b@@', 'ale', 'c@@', 'li@@', 'ma@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:37:44,810 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:37:44,810 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:37:44,811 - INFO - joeynmt.training - 	Hypothesis: In wisseling is de artische Eisccclimassa van onze globale climasysteem.
2025-05-29 18:37:44,811 - INFO - joeynmt.training - Example #3
2025-05-29 18:37:44,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:37:44,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:37:44,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'm@@', 'ing', 'in', 'de', 'z@@', 'om@@', 'mer@@', '.', '</s>']
2025-05-29 18:37:44,812 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:37:44,812 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:37:44,813 - INFO - joeynmt.training - 	Hypothesis: Ze wist in de winter en schruming in de zommer.
2025-05-29 18:37:44,813 - INFO - joeynmt.training - Example #4
2025-05-29 18:37:44,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:37:44,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:37:44,813 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'fo@@', 'to@@', "'s", 'is', 'een', 'tij@@', 'd@@', 'je', 'die', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', 'is.', '</s>']
2025-05-29 18:37:44,814 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:37:44,814 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:37:44,815 - INFO - joeynmt.training - 	Hypothesis: De volgende foto's is een tijdje die een tijdje in de laatste 25 jaar gebeurt is.
2025-05-29 18:37:54,950 - INFO - joeynmt.training - Epoch   1, Step:     8100, Batch Loss:     1.896316, Batch Acc: 0.428044, Tokens per Sec:     6787, Lr: 0.000300
2025-05-29 18:38:05,175 - INFO - joeynmt.training - Epoch   1, Step:     8200, Batch Loss:     1.851419, Batch Acc: 0.425145, Tokens per Sec:     6741, Lr: 0.000300
2025-05-29 18:38:15,491 - INFO - joeynmt.training - Epoch   1, Step:     8300, Batch Loss:     2.065002, Batch Acc: 0.435435, Tokens per Sec:     6844, Lr: 0.000300
2025-05-29 18:38:25,718 - INFO - joeynmt.training - Epoch   1, Step:     8400, Batch Loss:     1.977516, Batch Acc: 0.432788, Tokens per Sec:     6785, Lr: 0.000300
2025-05-29 18:38:34,966 - INFO - joeynmt.training - Epoch   1, Step:     8500, Batch Loss:     2.055477, Batch Acc: 0.431910, Tokens per Sec:     7496, Lr: 0.000300
2025-05-29 18:38:34,968 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:38:34,968 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:39:13,730 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.04, ppl:   7.67, acc:   0.41, generation: 38.7160[sec], evaluation: 0.0000[sec]
2025-05-29 18:39:13,731 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:39:13,919 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/6000.ckpt
2025-05-29 18:39:13,937 - INFO - joeynmt.training - Example #0
2025-05-29 18:39:13,938 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:39:13,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:39:13,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'heb', 'deze', 'twee', 'v@@', 'al@@', 'ge@@', 'to@@', 'on@@', 't', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'n@@', 'her@@', 'sen@@', 'en', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'werel@@', 'd@@', 'wij@@', 'd', 'drie', 'miljo@@', 'en', 'jaar', 'van', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'k@@', 'eer@@', 'd.', '</s>']
2025-05-29 18:39:13,939 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:39:13,939 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:39:13,939 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb deze twee valgetoont om te verbeteren dat de artische ijsknhersenen die voor de reden van de wereldwijd drie miljoen jaar van 40 procent gekeerd.
2025-05-29 18:39:13,939 - INFO - joeynmt.training - Example #1
2025-05-29 18:39:13,940 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:39:13,940 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:39:13,940 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 're@@', 's@@', 'ult@@', 'aat', 'de', 're@@', 's@@', 'ult@@', 'aten', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', '.', '</s>']
2025-05-29 18:39:13,941 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:39:13,941 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:39:13,941 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de resultaat de resultaten van dit speciale probleem.
2025-05-29 18:39:13,942 - INFO - joeynmt.training - Example #2
2025-05-29 18:39:13,942 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:39:13,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:39:13,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'f@@', 'eite', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ort', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', '-@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:39:13,943 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:39:13,944 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:39:13,944 - INFO - joeynmt.training - 	Hypothesis: In feite is de artische ijskort dat de artische ijs-systeem.
2025-05-29 18:39:13,944 - INFO - joeynmt.training - Example #3
2025-05-29 18:39:13,944 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:39:13,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:39:13,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'u@@', 'i@@', 'v@@', 'en.', '</s>']
2025-05-29 18:39:13,945 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:39:13,946 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:39:13,946 - INFO - joeynmt.training - 	Hypothesis: Ze wist in het winter en schuiven.
2025-05-29 18:39:13,946 - INFO - joeynmt.training - Example #4
2025-05-29 18:39:13,946 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:39:13,946 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:39:13,946 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ol@@', 'ie,', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'dat', 'ik', 'jullie', 'zien', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't.', '</s>']
2025-05-29 18:39:13,947 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:39:13,948 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:39:13,948 - INFO - joeynmt.training - 	Hypothesis: De volgende volie, die ik jullie tonen dat ik jullie zien wat er in de laatste 25 jaar gebeurt.
2025-05-29 18:39:23,190 - INFO - joeynmt.training - Epoch   1, Step:     8600, Batch Loss:     1.965162, Batch Acc: 0.434103, Tokens per Sec:     7234, Lr: 0.000300
2025-05-29 18:39:32,245 - INFO - joeynmt.training - Epoch   1, Step:     8700, Batch Loss:     1.991958, Batch Acc: 0.431052, Tokens per Sec:     7530, Lr: 0.000300
2025-05-29 18:39:41,571 - INFO - joeynmt.training - Epoch   1, Step:     8800, Batch Loss:     1.867631, Batch Acc: 0.433470, Tokens per Sec:     7352, Lr: 0.000300
2025-05-29 18:39:51,911 - INFO - joeynmt.training - Epoch   1, Step:     8900, Batch Loss:     1.904654, Batch Acc: 0.434533, Tokens per Sec:     6844, Lr: 0.000300
2025-05-29 18:40:02,154 - INFO - joeynmt.training - Epoch   1, Step:     9000, Batch Loss:     2.067490, Batch Acc: 0.438028, Tokens per Sec:     6897, Lr: 0.000300
2025-05-29 18:40:02,155 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:40:02,155 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:40:50,557 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.02, ppl:   7.53, acc:   0.42, generation: 48.3489[sec], evaluation: 0.0000[sec]
2025-05-29 18:40:50,558 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:40:50,759 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/6500.ckpt
2025-05-29 18:40:50,777 - INFO - joeynmt.training - Example #0
2025-05-29 18:40:50,778 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:40:50,778 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:40:50,778 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'we', 'deze', 'twee', 'v@@', 'ij@@', 'f', 'ik', 'deze', 'twee', 'v@@', 'ol@@', 'ie@@', 'ën', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'werel@@', 'd,', 'en', 'de', 're@@', 'den', 'van', 'de', 'V@@', 'S', 'hadden', 'ge@@', 'ï@@', 'n@@', 'v@@', 'l@@', 'oe@@', 'd', 'in', 'de', 'V@@', 'S', 'van', '4@@', '0', 'proc@@', 'ent', 'gebeur@@', 't.', '</s>']
2025-05-29 18:40:50,779 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:40:50,779 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:40:50,780 - INFO - joeynmt.training - 	Hypothesis: Laten we deze twee vijf ik deze twee volieën om te verbeteren dat de artische ijskaart van de reden van de reden van de wereld, en de reden van de VS hadden geïnvloed in de VS van 40 procent gebeurt.
2025-05-29 18:40:50,780 - INFO - joeynmt.training - Example #1
2025-05-29 18:40:50,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:40:50,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:40:50,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 're@@', 's@@', 'ult@@', 'aat', 'de', 're@@', 's@@', 'ult@@', 'aat', 'van', 'deze', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'proble@@', 'em@@', '.', '</s>']
2025-05-29 18:40:50,781 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:40:50,782 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:40:50,782 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de resultaat de resultaat van deze specifiek probleem.
2025-05-29 18:40:50,782 - INFO - joeynmt.training - Example #2
2025-05-29 18:40:50,782 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:40:50,782 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:40:50,783 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'f@@', 'eite', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'sch@@', 'aa@@', 'm@@', 's@@', 'el', 'van', 'onze', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:40:50,784 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:40:50,784 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:40:50,784 - INFO - joeynmt.training - 	Hypothesis: In feite is de artische ijskaart het schaamsel van onze globale klimaatsysteem.
2025-05-29 18:40:50,784 - INFO - joeynmt.training - Example #3
2025-05-29 18:40:50,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:40:50,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:40:50,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'm@@', 'p', 'in', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', '.', '</s>']
2025-05-29 18:40:50,785 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:40:50,786 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:40:50,786 - INFO - joeynmt.training - 	Hypothesis: Ze wist in de winter en schrump in de zomer in de zomer in de zomer in de winter en schroep.
2025-05-29 18:40:50,786 - INFO - joeynmt.training - Example #4
2025-05-29 18:40:50,786 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:40:50,786 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:40:50,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ol@@', 'ie,', 'is', 'een', 'tijd', 'die', 'ik', 'jullie', 'zien', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', 'is.', '</s>']
2025-05-29 18:40:50,787 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:40:50,788 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:40:50,788 - INFO - joeynmt.training - 	Hypothesis: De volgende folie, is een tijd die ik jullie zien wat er in de laatste 25 jaar gebeurt is.
2025-05-29 18:41:01,235 - INFO - joeynmt.training - Epoch   1, Step:     9100, Batch Loss:     2.017584, Batch Acc: 0.444922, Tokens per Sec:     6780, Lr: 0.000300
2025-05-29 18:41:11,452 - INFO - joeynmt.training - Epoch   1, Step:     9200, Batch Loss:     1.850408, Batch Acc: 0.436137, Tokens per Sec:     7066, Lr: 0.000300
2025-05-29 18:41:14,273 - INFO - joeynmt.training - Epoch   1: total training loss 22679.90
2025-05-29 18:41:14,274 - INFO - joeynmt.training - EPOCH 2
2025-05-29 18:41:22,362 - INFO - joeynmt.training - Epoch   2, Step:     9300, Batch Loss:     1.838480, Batch Acc: 0.448391, Tokens per Sec:     6435, Lr: 0.000300
2025-05-29 18:41:32,418 - INFO - joeynmt.training - Epoch   2, Step:     9400, Batch Loss:     1.781982, Batch Acc: 0.446953, Tokens per Sec:     6917, Lr: 0.000300
2025-05-29 18:41:41,476 - INFO - joeynmt.training - Epoch   2, Step:     9500, Batch Loss:     1.825531, Batch Acc: 0.453064, Tokens per Sec:     7799, Lr: 0.000300
2025-05-29 18:41:41,477 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:41:41,477 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:42:20,350 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.41, acc:   0.43, generation: 38.8209[sec], evaluation: 0.0000[sec]
2025-05-29 18:42:20,351 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:42:20,535 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/7000.ckpt
2025-05-29 18:42:20,550 - INFO - joeynmt.training - Example #0
2025-05-29 18:42:20,551 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:42:20,552 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:42:20,552 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', 'om', 'te', 'ver@@', 'anderen', 'om', 'te', 'ver@@', 'anderen', 'te', 'ver@@', 'anderen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'c@@', 'ap@@', 'ac@@', 'iteit', 'die', 'voor', 'de', 'A@@', 'zi@@', 'ë', 'die', 'voor', 'de', 'A@@', 'zi@@', 'ë', 'die', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste@@', 'un@@', 'en', 'van', '4@@', '8', 'proc@@', 'ent', 'gebeur@@', 'de.', '</s>']
2025-05-29 18:42:20,552 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:42:20,553 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:42:20,553 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden om te veranderen om te veranderen te veranderen dat de artische eisccapaciteit die voor de Azië die voor de Azië die de reden van de ondersteunen van 48 procent gebeurde.
2025-05-29 18:42:20,553 - INFO - joeynmt.training - Example #1
2025-05-29 18:42:20,553 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:42:20,553 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:42:20,553 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'du@@', 'i@@', 'delijk', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'uit@@', 'kom@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'proble@@', 'em', 'dat', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'ij@@', 's@@', 'k@@', 'n@@', 'aa@@', 't.', '</s>']
2025-05-29 18:42:20,554 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:42:20,554 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:42:20,554 - INFO - joeynmt.training - 	Hypothesis: Maar dit duidelijk niet sterk genoeg de uitkomst van dit specifiek probleem dat niet de dicke van het ijsknaat.
2025-05-29 18:42:20,554 - INFO - joeynmt.training - Example #2
2025-05-29 18:42:20,554 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:42:20,554 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:42:20,554 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'gew@@', 'on@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'ti@@', 'sche', 'e@@', 'is@@', 'c@@', 'c@@', 'am@@', 'es', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:42:20,555 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:42:20,555 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:42:20,555 - INFO - joeynmt.training - 	Hypothesis: In gewone zin is de artitische eisccames van onze wereldwijd van ons globale klimaatsysteem.
2025-05-29 18:42:20,555 - INFO - joeynmt.training - Example #3
2025-05-29 18:42:20,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:42:20,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:42:20,555 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Je', 'w@@', 'ist', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'm@@', 't', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 18:42:20,556 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:42:20,557 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:42:20,557 - INFO - joeynmt.training - 	Hypothesis: Je wist in de winter en schrumt in het zomers.
2025-05-29 18:42:20,557 - INFO - joeynmt.training - Example #4
2025-05-29 18:42:20,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:42:20,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:42:20,558 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ol@@', 'ie,', 'die', 'ik', 'jullie', 'laten', 'zien', 'dat', 'ik', 'jullie', 'laten', 'zien', 'wat', 'er', 'gebeur@@', 't', 'is.', '</s>']
2025-05-29 18:42:20,558 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:42:20,559 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:42:20,559 - INFO - joeynmt.training - 	Hypothesis: De volgende volie, die ik jullie laten zien dat ik jullie laten zien wat er gebeurt is.
2025-05-29 18:42:30,366 - INFO - joeynmt.training - Epoch   2, Step:     9600, Batch Loss:     2.033394, Batch Acc: 0.445325, Tokens per Sec:     6712, Lr: 0.000300
2025-05-29 18:42:40,092 - INFO - joeynmt.training - Epoch   2, Step:     9700, Batch Loss:     2.061495, Batch Acc: 0.447685, Tokens per Sec:     7325, Lr: 0.000300
2025-05-29 18:42:50,000 - INFO - joeynmt.training - Epoch   2, Step:     9800, Batch Loss:     1.869039, Batch Acc: 0.448554, Tokens per Sec:     7114, Lr: 0.000300
2025-05-29 18:42:59,963 - INFO - joeynmt.training - Epoch   2, Step:     9900, Batch Loss:     2.033296, Batch Acc: 0.456811, Tokens per Sec:     7061, Lr: 0.000300
2025-05-29 18:43:09,718 - INFO - joeynmt.training - Epoch   2, Step:    10000, Batch Loss:     1.836577, Batch Acc: 0.455060, Tokens per Sec:     7353, Lr: 0.000300
2025-05-29 18:43:09,724 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:43:09,724 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:43:52,289 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.26, acc:   0.43, generation: 42.5193[sec], evaluation: 0.0000[sec]
2025-05-29 18:43:52,290 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:43:52,491 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/7500.ckpt
2025-05-29 18:43:52,512 - INFO - joeynmt.training - Example #0
2025-05-29 18:43:52,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:43:52,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:43:52,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'ik', 'deze', 'twee', 'jaar', 'heb', 'ik', 'deze', 'twee', 'f@@', 'ol@@', 'i@@', 'ë', 'om', 'te', 'ver@@', 'anderen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'e@@', 'den', 'van', 'de', 'hele', 'wereld', 'te', 'ver@@', 'oor@@', 'z@@', 'aa@@', 'kt', 'om', '4@@', '8', 'proc@@', 'ent', 'te', 'ver@@', 'oor@@', 'z@@', 'aa@@', 'kt', 'te', 'ver@@', 'oor@@', 'z@@', 'aa@@', 'kt', 'te', 'ver@@', 'anderen', 'en', 'van', '4@@', '8', 'proc@@', 'ent', 'gebeur@@', 't.', '</s>']
2025-05-29 18:43:52,516 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:43:52,516 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:43:52,516 - INFO - joeynmt.training - 	Hypothesis: Laten ik deze twee jaar heb ik deze twee folië om te veranderen dat de artische ijskappen die voor de reden van de reden van de reden van de eden van de hele wereld te veroorzaakt om 48 procent te veroorzaakt te veroorzaakt te veranderen en van 48 procent gebeurt.
2025-05-29 18:43:52,516 - INFO - joeynmt.training - Example #1
2025-05-29 18:43:52,517 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:43:52,517 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:43:52,517 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'de@@', 'ed', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'ver@@', 'n@@', 'aar@@', 'n@@', 'st@@', 'rij@@', 'd', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ken.', '</s>']
2025-05-29 18:43:52,518 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:43:52,518 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:43:52,518 - INFO - joeynmt.training - 	Hypothesis: Maar dit deed niet sterk genoeg de vernaarnstrijd van dit speciale probleem, omdat het niet de dikken.
2025-05-29 18:43:52,519 - INFO - joeynmt.training - Example #2
2025-05-29 18:43:52,519 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:43:52,519 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:43:52,519 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'f@@', 'eite', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'kl@@', 'im@@', 'aat@@', 's@@', 'k@@', 'ap@@', 'it@@', 'ei@@', 't.', '</s>']
2025-05-29 18:43:52,520 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:43:52,520 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:43:52,520 - INFO - joeynmt.training - 	Hypothesis: In feite is de artische ijskappe ijskappe klimaatskapiteit.
2025-05-29 18:43:52,521 - INFO - joeynmt.training - Example #3
2025-05-29 18:43:52,521 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:43:52,521 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:43:52,521 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'w@@', 'ist', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'm@@', 'ing', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 18:43:52,522 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:43:52,522 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:43:52,522 - INFO - joeynmt.training - 	Hypothesis: Ze wwist in de winter en schruming in de zomers.
2025-05-29 18:43:52,523 - INFO - joeynmt.training - Example #4
2025-05-29 18:43:52,523 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:43:52,523 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:43:52,523 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', 'wat', 'ik', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't.', '</s>']
2025-05-29 18:43:52,524 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:43:52,524 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:43:52,525 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien wat ik in de laatste 25 jaar gebeurt.
2025-05-29 18:44:02,340 - INFO - joeynmt.training - Epoch   2, Step:    10100, Batch Loss:     1.979329, Batch Acc: 0.449725, Tokens per Sec:     7104, Lr: 0.000300
2025-05-29 18:44:10,923 - INFO - joeynmt.training - Epoch   2, Step:    10200, Batch Loss:     1.828686, Batch Acc: 0.453913, Tokens per Sec:     8261, Lr: 0.000300
2025-05-29 18:44:19,465 - INFO - joeynmt.training - Epoch   2, Step:    10300, Batch Loss:     1.791625, Batch Acc: 0.454707, Tokens per Sec:     8260, Lr: 0.000300
2025-05-29 18:44:28,515 - INFO - joeynmt.training - Epoch   2, Step:    10400, Batch Loss:     1.853099, Batch Acc: 0.451534, Tokens per Sec:     7762, Lr: 0.000300
2025-05-29 18:44:37,087 - INFO - joeynmt.training - Epoch   2, Step:    10500, Batch Loss:     1.863533, Batch Acc: 0.459357, Tokens per Sec:     8388, Lr: 0.000300
2025-05-29 18:44:37,088 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:44:37,088 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:45:20,075 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.24, acc:   0.43, generation: 42.9415[sec], evaluation: 0.0000[sec]
2025-05-29 18:45:20,077 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:45:20,267 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/8000.ckpt
2025-05-29 18:45:20,282 - INFO - joeynmt.training - Example #0
2025-05-29 18:45:20,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:45:20,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:45:20,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'heb', 'deze', 'twee', 'v@@', 'ol@@', 'ies', 'om', 'te', 'ver@@', 'anderen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'de', 're@@', 'den', 'van', '4@@', '8', 'uur', 'van', 'de', 'onder@@', 'ste@@', 'un@@', 'en', 'van', '4@@', '8', 'proc@@', 'ent', 'van', '4@@', '8', 'proc@@', 'ent', 'gebeur@@', 'de', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'eft', '4@@', '8', 'proc@@', 'ent', 'ge@@', 'deel@@', 'de', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den']
2025-05-29 18:45:20,284 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:45:20,284 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:45:20,285 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb deze twee volies om te veranderen dat de artische ijskappen, dat de artische ijskaart van de reden van 48 uur van de ondersteunen van 48 procent van 48 procent gebeurde 40 procent van 40 procent van 40 procent van 40 procent van 40 procent van 40 procent van 40 procent van 40 procent geeft 48 procent gedeelde 40 procent van de reden
2025-05-29 18:45:20,285 - INFO - joeynmt.training - Example #1
2025-05-29 18:45:20,285 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:45:20,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:45:20,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'het', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'uit@@', 'gan@@', 'g@@', 'sp@@', 'el@@', 'heid', 'van', 'deze', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'van', 'het', 'ij@@', 's@@', 'k@@', 'we@@', 'z@@', 'ig@@', 'heid', 'van', 'de', 'ij@@', 's@@', 'k@@', 'we@@', 'z@@', 'en@@', 'd.', '</s>']
2025-05-29 18:45:20,287 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:45:20,287 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:45:20,287 - INFO - joeynmt.training - 	Hypothesis: Maar dit is het niet sterk genoeg de uitgangspelheid van deze speciale problemen van het ijskwezigheid van de ijskwezend.
2025-05-29 18:45:20,287 - INFO - joeynmt.training - Example #2
2025-05-29 18:45:20,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:45:20,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:45:20,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'f@@', 'eite', 'is', 'de', 'ar@@', 'ti@@', 'c@@', 'a', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'van', 'onze', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:45:20,289 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:45:20,289 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:45:20,289 - INFO - joeynmt.training - 	Hypothesis: In feite is de artica is de artische ijskappe van onze globale klimaatsysteem.
2025-05-29 18:45:20,289 - INFO - joeynmt.training - Example #3
2025-05-29 18:45:20,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:45:20,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:45:20,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'ik@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', '.', '</s>']
2025-05-29 18:45:20,291 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:45:20,291 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:45:20,291 - INFO - joeynmt.training - 	Hypothesis: Ze wist in de winter en schruikt in de zomer en schroep.
2025-05-29 18:45:20,291 - INFO - joeynmt.training - Example #4
2025-05-29 18:45:20,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:45:20,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:45:20,292 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ol@@', 'ie,', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't', 'is.', '</s>']
2025-05-29 18:45:20,293 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:45:20,293 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:45:20,293 - INFO - joeynmt.training - 	Hypothesis: De volgende volie, die ik jullie laten zien is een tijdperk in de laatste 25 jaar gebeurt is.
2025-05-29 18:45:29,748 - INFO - joeynmt.training - Epoch   2, Step:    10600, Batch Loss:     1.782543, Batch Acc: 0.448693, Tokens per Sec:     7141, Lr: 0.000300
2025-05-29 18:45:39,390 - INFO - joeynmt.training - Epoch   2, Step:    10700, Batch Loss:     1.891695, Batch Acc: 0.455699, Tokens per Sec:     7439, Lr: 0.000300
2025-05-29 18:45:48,843 - INFO - joeynmt.training - Epoch   2, Step:    10800, Batch Loss:     1.961358, Batch Acc: 0.452511, Tokens per Sec:     7592, Lr: 0.000300
2025-05-29 18:45:58,413 - INFO - joeynmt.training - Epoch   2, Step:    10900, Batch Loss:     1.888664, Batch Acc: 0.456203, Tokens per Sec:     7051, Lr: 0.000300
2025-05-29 18:46:07,976 - INFO - joeynmt.training - Epoch   2, Step:    11000, Batch Loss:     2.097728, Batch Acc: 0.453233, Tokens per Sec:     7361, Lr: 0.000300
2025-05-29 18:46:07,976 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:46:07,976 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:46:48,362 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.96, ppl:   7.12, acc:   0.44, generation: 40.3430[sec], evaluation: 0.0000[sec]
2025-05-29 18:46:48,364 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:46:48,545 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/8500.ckpt
2025-05-29 18:46:48,562 - INFO - joeynmt.training - Example #0
2025-05-29 18:46:48,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:46:48,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:46:48,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'heb', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 't', 'om', 'te', 'ver@@', 'beel@@', 'den', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'aat', 'voor', 'de', 'onder@@', 'delen', 'van', 'de', 'onder@@', 'delen', 'van', 'de', 'onder@@', 'delen', 'van', 'de', 'onder@@', 'delen', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'V@@', 'S', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'eft', '4@@', '8', 'uur', 'van', 'de', 'werel@@', 'd.', '</s>']
2025-05-29 18:46:48,564 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:46:48,564 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:46:48,565 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb deze twee getoont om te verbeelden dat de artische ijskappartische ijskapparaat voor de onderdelen van de onderdelen van de onderdelen van de onderdelen van 40 procent van 40 procent van 40 procent van 40 procent van 40 procent van 40 procent van de VS van 40 procent van 40 procent van 40 procent geeft 48 uur van de wereld.
2025-05-29 18:46:48,565 - INFO - joeynmt.training - Example #1
2025-05-29 18:46:48,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:46:48,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:46:48,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'aar@@', 'n@@', 'aar@@', 'n@@', 'st@@', 'af@@', 'aar@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'aal', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'e@@', 'is@@', 'es', 'laten', 'zien.', '</s>']
2025-05-29 18:46:48,566 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:46:48,567 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:46:48,567 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aarnaarnstafaarheid van dit speciaal probleem, omdat het niet de dikke eises laten zien.
2025-05-29 18:46:48,567 - INFO - joeynmt.training - Example #2
2025-05-29 18:46:48,567 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:46:48,567 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:46:48,567 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'f@@', 'eite', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'het', 'sch@@', 'aa@@', 'm@@', 'te', 'het', 'mo@@', 'eil@@', 'ijk', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:46:48,568 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:46:48,568 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:46:48,569 - INFO - joeynmt.training - 	Hypothesis: In feite is de artische ijskappels het schaamte het moeilijk van ons globale klimaatsysteem.
2025-05-29 18:46:48,569 - INFO - joeynmt.training - Example #3
2025-05-29 18:46:48,569 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:46:48,569 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:46:48,569 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'm@@', 't', 'in', 'het', 'z@@', 'om@@', 'er', 'in', 'het', 'z@@', 'om@@', 'er', 'in', 'het', 'z@@', 'om@@', '.', '</s>']
2025-05-29 18:46:48,569 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:46:48,570 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:46:48,570 - INFO - joeynmt.training - 	Hypothesis: Ze wist in het winter en schrumt in het zomer in het zomer in het zom.
2025-05-29 18:46:48,570 - INFO - joeynmt.training - Example #4
2025-05-29 18:46:48,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:46:48,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:46:48,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'fo@@', 'to@@', "'s", 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'oo@@', 'l', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't.', '</s>']
2025-05-29 18:46:48,571 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:46:48,571 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:46:48,571 - INFO - joeynmt.training - 	Hypothesis: De volgende foto's die ik jullie laten zien is een tijdschool in de laatste 25 jaar gebeurt.
2025-05-29 18:46:57,051 - INFO - joeynmt.training - Epoch   2, Step:    11100, Batch Loss:     1.853041, Batch Acc: 0.461598, Tokens per Sec:     8239, Lr: 0.000300
2025-05-29 18:47:06,318 - INFO - joeynmt.training - Epoch   2, Step:    11200, Batch Loss:     1.861831, Batch Acc: 0.455705, Tokens per Sec:     7365, Lr: 0.000300
2025-05-29 18:47:15,551 - INFO - joeynmt.training - Epoch   2, Step:    11300, Batch Loss:     1.750007, Batch Acc: 0.460567, Tokens per Sec:     7410, Lr: 0.000300
2025-05-29 18:47:25,345 - INFO - joeynmt.training - Epoch   2, Step:    11400, Batch Loss:     1.741737, Batch Acc: 0.458065, Tokens per Sec:     7113, Lr: 0.000300
2025-05-29 18:47:34,672 - INFO - joeynmt.training - Epoch   2, Step:    11500, Batch Loss:     1.876056, Batch Acc: 0.460142, Tokens per Sec:     7474, Lr: 0.000300
2025-05-29 18:47:34,672 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:47:34,673 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:48:15,636 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.04, acc:   0.44, generation: 40.9216[sec], evaluation: 0.0000[sec]
2025-05-29 18:48:15,638 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:48:15,840 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/9000.ckpt
2025-05-29 18:48:15,857 - INFO - joeynmt.training - Example #0
2025-05-29 18:48:15,857 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:48:15,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:48:15,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', 'hebben', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'wij@@', 'der@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'at@@', 'uur', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', '4@@', '8', 'uur', 'van', '4@@', '8', 'proc@@', 'ent', 'gebeur@@', 'd.', '</s>']
2025-05-29 18:48:15,859 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:48:15,859 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:48:15,859 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden hebben getoond om te verwijderen dat de artische ijskapparatuur van de reden van de reden van de reden van de reden van de reden van 48 uur van 48 procent gebeurd.
2025-05-29 18:48:15,859 - INFO - joeynmt.training - Example #1
2025-05-29 18:48:15,860 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:48:15,860 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:48:15,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'op@@', 'en@@', 'st@@', 'aa@@', 't,', 'is', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ijk', 'van', 'de', 'ij@@', 's@@', 'es', 'van', 'de', 'ij@@', 's@@', 'es', 'van', 'de', 'ij@@', 's@@', 'k@@', 'n@@', 'i@@', 've@@', 'au', 'van', 'de', 'ij@@', 's@@', 'k@@', 'n@@', 'i@@', 've@@', 'au', 'van', 'de', 'ij@@', 's@@', 'k@@', 'n@@', 'i@@', 've@@', 'au', 'van', 'het', 'ij@@', 's@@', 'heid', 'van', 'het', 'ij@@', 's@@', 'k@@', 'n@@', 'i@@', 've@@', 'au', 'van', 'het', 'ij@@', 's@@', 'k@@', 'n@@', 'i@@', 've@@', 'au', 'van', 'het', 'ij@@', 'g@@', 'aa@@', 't.', '</s>']
2025-05-29 18:48:15,861 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:48:15,861 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:48:15,861 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de openstaat, is het specifiek van dit specifiek van de ijskijk van de ijses van de ijses van de ijskniveau van de ijskniveau van de ijskniveau van het ijsheid van het ijskniveau van het ijskniveau van het ijgaat.
2025-05-29 18:48:15,862 - INFO - joeynmt.training - Example #2
2025-05-29 18:48:15,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:48:15,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:48:15,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'gew@@', 'ij@@', 'd', 'S@@', 'in@@', 'e', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'at@@', 'uur', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:48:15,864 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:48:15,864 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:48:15,864 - INFO - joeynmt.training - 	Hypothesis: In gewijd Sine is de artische ijskapparatuur van ons globale klimaatsysteem.
2025-05-29 18:48:15,864 - INFO - joeynmt.training - Example #3
2025-05-29 18:48:15,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:48:15,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:48:15,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'm@@', 'p@@', '.', '</s>']
2025-05-29 18:48:15,866 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:48:15,866 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:48:15,866 - INFO - joeynmt.training - 	Hypothesis: Ze wist in de winter en schrump.
2025-05-29 18:48:15,867 - INFO - joeynmt.training - Example #4
2025-05-29 18:48:15,867 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:48:15,867 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:48:15,867 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'gebeur@@', 'd', 'is.', '</s>']
2025-05-29 18:48:15,868 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:48:15,869 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:48:15,869 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien is een tijdperk van wat er gebeurd is.
2025-05-29 18:48:25,245 - INFO - joeynmt.training - Epoch   2, Step:    11600, Batch Loss:     1.882145, Batch Acc: 0.465268, Tokens per Sec:     7257, Lr: 0.000300
2025-05-29 18:48:34,842 - INFO - joeynmt.training - Epoch   2, Step:    11700, Batch Loss:     1.879251, Batch Acc: 0.462259, Tokens per Sec:     7276, Lr: 0.000300
2025-05-29 18:48:44,625 - INFO - joeynmt.training - Epoch   2, Step:    11800, Batch Loss:     1.657660, Batch Acc: 0.456666, Tokens per Sec:     7193, Lr: 0.000300
2025-05-29 18:48:53,978 - INFO - joeynmt.training - Epoch   2, Step:    11900, Batch Loss:     1.910862, Batch Acc: 0.457970, Tokens per Sec:     7551, Lr: 0.000300
2025-05-29 18:49:02,495 - INFO - joeynmt.training - Epoch   2, Step:    12000, Batch Loss:     1.825112, Batch Acc: 0.458537, Tokens per Sec:     8283, Lr: 0.000300
2025-05-29 18:49:02,496 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:49:02,496 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:49:40,266 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.95, acc:   0.44, generation: 37.7279[sec], evaluation: 0.0000[sec]
2025-05-29 18:49:40,267 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:49:40,479 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/9500.ckpt
2025-05-29 18:49:40,497 - INFO - joeynmt.training - Example #0
2025-05-29 18:49:40,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:49:40,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:49:40,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', 'dat', 'de', 'eerste', 'jaar', 'gele@@', 'den', 'van', 'de', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'drie', 'miljo@@', 'en', 'jaar', 'de', 're@@', 'den', 'van', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste@@', 'un@@', 'en.', '</s>']
2025-05-29 18:49:40,500 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:49:40,500 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:49:40,500 - INFO - joeynmt.training - 	Hypothesis: Het is dat de eerste jaar geleden van de folië getoond van de reden van de reden van de reden van drie miljoen jaar de reden van de drie miljoen jaar de reden van de ondersteunen.
2025-05-29 18:49:40,500 - INFO - joeynmt.training - Example #1
2025-05-29 18:49:40,501 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:49:40,501 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:49:40,501 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'op@@', 'st@@', 'ro@@', 'om@@', ',', 'dat', 'is', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em@@', ',', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'oo@@', 'p', 'van', 'de', 'ij@@', 's@@', 'k@@', 'n@@', 'i@@', 've@@', 'au', 'van', 'de', 'ij@@', 's@@', 'k@@', 'oo@@', 'p', 'van', 'de', 'ij@@', 's@@', 'k@@', 'oo@@', 'p@@', '.', '</s>']
2025-05-29 18:49:40,502 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:49:40,502 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:49:40,502 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de opstroom, dat is het specifieke probleem, dat het niet de dikke van de ijskoop van de ijskniveau van de ijskoop van de ijskoop.
2025-05-29 18:49:40,502 - INFO - joeynmt.training - Example #2
2025-05-29 18:49:40,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:49:40,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:49:40,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', 'e', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'van', 'onze', 'op@@', 'lo@@', 'ss@@', 'ende', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:49:40,504 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:49:40,504 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:49:40,504 - INFO - joeynmt.training - 	Hypothesis: In zekere zine is de artische ijskappe van onze oplossende klimaatsysteem.
2025-05-29 18:49:40,504 - INFO - joeynmt.training - Example #3
2025-05-29 18:49:40,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:49:40,505 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:49:40,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'mp@@', 'jes', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 18:49:40,506 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:49:40,506 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:49:40,506 - INFO - joeynmt.training - 	Hypothesis: Ze wist in de winter en schrompjes in de zomers.
2025-05-29 18:49:40,506 - INFO - joeynmt.training - Example #4
2025-05-29 18:49:40,507 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:49:40,507 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:49:40,507 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'gebeur@@', 't.', '</s>']
2025-05-29 18:49:40,508 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:49:40,508 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:49:40,508 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien is een tijdperk van wat er gebeurt.
2025-05-29 18:49:50,038 - INFO - joeynmt.training - Epoch   2, Step:    12100, Batch Loss:     1.737133, Batch Acc: 0.464054, Tokens per Sec:     7198, Lr: 0.000300
2025-05-29 18:49:59,323 - INFO - joeynmt.training - Epoch   2, Step:    12200, Batch Loss:     1.861490, Batch Acc: 0.461958, Tokens per Sec:     7286, Lr: 0.000300
2025-05-29 18:50:08,606 - INFO - joeynmt.training - Epoch   2, Step:    12300, Batch Loss:     1.940106, Batch Acc: 0.463476, Tokens per Sec:     7597, Lr: 0.000300
2025-05-29 18:50:18,242 - INFO - joeynmt.training - Epoch   2, Step:    12400, Batch Loss:     1.958801, Batch Acc: 0.469123, Tokens per Sec:     7325, Lr: 0.000300
2025-05-29 18:50:27,557 - INFO - joeynmt.training - Epoch   2, Step:    12500, Batch Loss:     1.928998, Batch Acc: 0.461277, Tokens per Sec:     7482, Lr: 0.000300
2025-05-29 18:50:27,560 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:50:27,560 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:51:14,272 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.90, acc:   0.45, generation: 46.6674[sec], evaluation: 0.0000[sec]
2025-05-29 18:51:14,273 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:51:14,456 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/10000.ckpt
2025-05-29 18:51:14,474 - INFO - joeynmt.training - Example #0
2025-05-29 18:51:14,474 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:51:14,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:51:14,475 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'm@@', 'inder@@', 'en', 'van', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'aat', 'drie', 'miljo@@', 'en', 'jaar', 'de', 're@@', 'den', 'van', '4@@', '8', 'proc@@', 'ent', 'gebeur@@', 'de.', '</s>']
2025-05-29 18:51:14,476 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:51:14,476 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:51:14,476 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee folië getoond om te verminderen van de artische ijskappen, die voor de artische ijskapparaat drie miljoen jaar de reden van 48 procent gebeurde.
2025-05-29 18:51:14,476 - INFO - joeynmt.training - Example #1
2025-05-29 18:51:14,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:51:14,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:51:14,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'een', 'be@@', 'et@@', 'je', 'van', 'de', 'aar@@', 'n@@', 'st@@', 'ig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'we@@', 'g.', '</s>']
2025-05-29 18:51:14,478 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:51:14,478 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:51:14,478 - INFO - joeynmt.training - 	Hypothesis: Maar dat is een beetje van de aarnstigheid van dit speciale probleem, omdat het niet de dikweg.
2025-05-29 18:51:14,479 - INFO - joeynmt.training - Example #2
2025-05-29 18:51:14,479 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:51:14,479 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:51:14,479 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'dat', 'we', 'het', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:51:14,480 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:51:14,480 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:51:14,481 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe dat we het globale klimaatsysteem.
2025-05-29 18:51:14,481 - INFO - joeynmt.training - Example #3
2025-05-29 18:51:14,481 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:51:14,481 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:51:14,481 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 18:51:14,482 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:51:14,482 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:51:14,483 - INFO - joeynmt.training - 	Hypothesis: Ze wist in de winter en schroept in de zomers.
2025-05-29 18:51:14,483 - INFO - joeynmt.training - Example #4
2025-05-29 18:51:14,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:51:14,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:51:14,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'dra@@', 'ff@@', 'er@@', 's@@', ':', 'wat', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 18:51:14,484 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:51:14,484 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:51:14,484 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien is een tijddraffers: wat in de laatste 25 jaar gebeurd.
2025-05-29 18:51:23,421 - INFO - joeynmt.training - Epoch   2, Step:    12600, Batch Loss:     1.967257, Batch Acc: 0.469218, Tokens per Sec:     7856, Lr: 0.000300
2025-05-29 18:51:32,109 - INFO - joeynmt.training - Epoch   2, Step:    12700, Batch Loss:     1.911320, Batch Acc: 0.462365, Tokens per Sec:     8434, Lr: 0.000300
2025-05-29 18:51:40,667 - INFO - joeynmt.training - Epoch   2, Step:    12800, Batch Loss:     1.916346, Batch Acc: 0.464780, Tokens per Sec:     8404, Lr: 0.000300
2025-05-29 18:51:49,400 - INFO - joeynmt.training - Epoch   2, Step:    12900, Batch Loss:     1.787794, Batch Acc: 0.461223, Tokens per Sec:     7740, Lr: 0.000300
2025-05-29 18:51:58,920 - INFO - joeynmt.training - Epoch   2, Step:    13000, Batch Loss:     1.740240, Batch Acc: 0.468930, Tokens per Sec:     7307, Lr: 0.000300
2025-05-29 18:51:58,920 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:51:58,923 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:52:51,184 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.81, acc:   0.45, generation: 52.2180[sec], evaluation: 0.0000[sec]
2025-05-29 18:52:51,185 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:52:51,402 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/10500.ckpt
2025-05-29 18:52:51,422 - INFO - joeynmt.training - Example #0
2025-05-29 18:52:51,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:52:51,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:52:51,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'de', 'twee', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'groot@@', 'te', 'van', '4@@', '0', 'proc@@', 'ent', 'gebeur@@', 'de.', '</s>']
2025-05-29 18:52:51,424 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:52:51,424 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:52:51,425 - INFO - joeynmt.training - 	Hypothesis: Ik heb de twee folië getoond, om te verbeteren dat de artische ijskappen, die de reden van de reden van de reden van de grootte van de grootte van de grootte van 40 procent gebeurde.
2025-05-29 18:52:51,425 - INFO - joeynmt.training - Example #1
2025-05-29 18:52:51,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:52:51,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:52:51,425 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'aar@@', 'n@@', 'aar@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'van', 'de', 'ij@@', 's@@', 'k@@', 'oo@@', 'p', 'van', 'de', 'ij@@', 's@@', 'k@@', 'oo@@', 'p', 'van', 'de', 'ij@@', 's@@', 'k@@', 'n@@', 'i@@', 've@@', 'au', 'van', 'de', 'ij@@', 's@@', 'k@@', 'n@@', 'ip@@', 'per@@', '.', '</s>']
2025-05-29 18:52:51,427 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:52:51,427 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:52:51,427 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aarnaarheid van dit speciale probleemheid van dit speciale problemen van de ijskoop van de ijskoop van de ijskniveau van de ijsknipper.
2025-05-29 18:52:51,427 - INFO - joeynmt.training - Example #2
2025-05-29 18:52:51,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:52:51,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:52:51,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', 'e', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'p@@', 'la@@', 'gen@@', 'aa@@', 'm@@', 'd', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:52:51,429 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:52:51,429 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:52:51,429 - INFO - joeynmt.training - 	Hypothesis: In zekere zine is de artische ijskappe het plagenaamd van ons wereldwijde klimaatsysteem.
2025-05-29 18:52:51,429 - INFO - joeynmt.training - Example #3
2025-05-29 18:52:51,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:52:51,430 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:52:51,430 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'aa@@', 'st', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'pen', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 18:52:51,431 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:52:51,431 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:52:51,431 - INFO - joeynmt.training - 	Hypothesis: Ze waast in het winter en schrompen in het zomers.
2025-05-29 18:52:51,432 - INFO - joeynmt.training - Example #4
2025-05-29 18:52:51,432 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:52:51,432 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:52:51,432 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', 'wat', 'er', 'gebeur@@', 'd', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'is', 'een', 'paar', 'jaar', 'gele@@', 'den', 'is', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'is', 'een', 'tij@@', 'd@@', 'je', 'die', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'is', 'een', 'tij@@', 'd@@', 'je', 'die', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gele@@', 'den', 'is', 'een', 'tij@@', 'd@@', 'je', 'die', 'ik', 'jullie', 'jullie', 'laten', 'zien', 'wat', 'er', 'gebeur@@', 't.', '</s>']
2025-05-29 18:52:51,433 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:52:51,433 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:52:51,434 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien wat er gebeurd is een tijdje in de laatste 25 jaar geleden is een paar jaar geleden is in de laatste 25 jaar geleden is een tijdje die in de laatste 25 jaar geleden is een tijdje die in de laatste 25 jaar geleden is een tijdje die ik jullie jullie laten zien wat er gebeurt.
2025-05-29 18:53:00,837 - INFO - joeynmt.training - Epoch   2, Step:    13100, Batch Loss:     2.126150, Batch Acc: 0.457251, Tokens per Sec:     7106, Lr: 0.000300
2025-05-29 18:53:10,096 - INFO - joeynmt.training - Epoch   2, Step:    13200, Batch Loss:     1.723696, Batch Acc: 0.467585, Tokens per Sec:     7556, Lr: 0.000300
2025-05-29 18:53:19,353 - INFO - joeynmt.training - Epoch   2, Step:    13300, Batch Loss:     1.836314, Batch Acc: 0.461252, Tokens per Sec:     7292, Lr: 0.000300
2025-05-29 18:53:28,133 - INFO - joeynmt.training - Epoch   2, Step:    13400, Batch Loss:     1.790543, Batch Acc: 0.469335, Tokens per Sec:     8073, Lr: 0.000300
2025-05-29 18:53:37,565 - INFO - joeynmt.training - Epoch   2, Step:    13500, Batch Loss:     1.895517, Batch Acc: 0.465343, Tokens per Sec:     7734, Lr: 0.000300
2025-05-29 18:53:37,565 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:53:37,565 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:54:10,931 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.71, acc:   0.45, generation: 33.3261[sec], evaluation: 0.0000[sec]
2025-05-29 18:54:10,932 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:54:11,114 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/11000.ckpt
2025-05-29 18:54:11,130 - INFO - joeynmt.training - Example #0
2025-05-29 18:54:11,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:54:11,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:54:11,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'gev@@', 'allen', 'die', 'twee', 'f@@', 'ol@@', 'ies', 'ge@@', 'to@@', 'on@@', 'de', 'de', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'ver@@', 'anderen', 'dat', 'de', 'ar@@', 'ct@@', 'ische', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'b@@', 'uit@@', 'en@@', 'kan@@', 't', 'van', '4@@', '0', 'proc@@', 'ent', 'gesch@@', 'ru@@', 'ik@@', 't', 'is.', '</s>']
2025-05-29 18:54:11,133 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:54:11,133 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:54:11,133 - INFO - joeynmt.training - 	Hypothesis: In de gevallen die twee folies getoonde de gevolgen om te veranderen dat de arctische ijskappen, die voor de reden van de reden van de reden van de reden van de buitenkant van 40 procent geschruikt is.
2025-05-29 18:54:11,133 - INFO - joeynmt.training - Example #1
2025-05-29 18:54:11,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:54:11,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:54:11,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'genoe@@', 'g', 'de', 'op@@', 'en@@', 'bare', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'want', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'n@@', 'ip@@', 'per@@', 't@@', 'on@@', '.', '</s>']
2025-05-29 18:54:11,135 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:54:11,135 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:54:11,135 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de openbare problemen van dit speciale probleem, want het niet de dikke van de ijsknipperton.
2025-05-29 18:54:11,136 - INFO - joeynmt.training - Example #2
2025-05-29 18:54:11,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:54:11,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:54:11,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'gew@@', 'iss@@', 'ig', 'z@@', 'in', 'is', 'de', 'ar@@', 'ct@@', 'ische', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'p@@', 'la@@', 'kt@@', 'ri@@', 'c@@', 'li@@', 'ma@@', 'ss@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:54:11,137 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:54:11,137 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:54:11,138 - INFO - joeynmt.training - 	Hypothesis: In gewissig zin is de arctische ijskappe is het plaktriclimassale klimaatsysteem.
2025-05-29 18:54:11,138 - INFO - joeynmt.training - Example #3
2025-05-29 18:54:11,138 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:54:11,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:54:11,138 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'is@@', 'sel@@', 'ing', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'ik@@', 't', 'in', 'het', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 18:54:11,139 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:54:11,139 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:54:11,140 - INFO - joeynmt.training - 	Hypothesis: Ze wisseling in de winter en schruikt in het zomer.
2025-05-29 18:54:11,140 - INFO - joeynmt.training - Example #4
2025-05-29 18:54:11,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:54:11,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:54:11,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', 'wat', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't.', '</s>']
2025-05-29 18:54:11,141 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:54:11,142 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:54:11,142 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien wat in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurt.
2025-05-29 18:54:19,669 - INFO - joeynmt.training - Epoch   2, Step:    13600, Batch Loss:     1.837563, Batch Acc: 0.469205, Tokens per Sec:     7913, Lr: 0.000300
2025-05-29 18:54:29,479 - INFO - joeynmt.training - Epoch   2, Step:    13700, Batch Loss:     2.056913, Batch Acc: 0.465257, Tokens per Sec:     7027, Lr: 0.000300
2025-05-29 18:54:39,065 - INFO - joeynmt.training - Epoch   2, Step:    13800, Batch Loss:     1.853235, Batch Acc: 0.466906, Tokens per Sec:     7274, Lr: 0.000300
2025-05-29 18:54:48,514 - INFO - joeynmt.training - Epoch   2, Step:    13900, Batch Loss:     1.879977, Batch Acc: 0.470000, Tokens per Sec:     7306, Lr: 0.000300
2025-05-29 18:54:58,135 - INFO - joeynmt.training - Epoch   2, Step:    14000, Batch Loss:     1.800905, Batch Acc: 0.470293, Tokens per Sec:     7190, Lr: 0.000300
2025-05-29 18:54:58,135 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:54:58,136 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:55:39,513 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.68, acc:   0.45, generation: 41.3417[sec], evaluation: 0.0000[sec]
2025-05-29 18:55:39,515 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:55:39,715 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/11500.ckpt
2025-05-29 18:55:39,732 - INFO - joeynmt.training - Example #0
2025-05-29 18:55:39,734 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:55:39,734 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:55:39,734 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'de', 'twee', 'jaar', 'heb', 'ik', 'deze', 'twee', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'de', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'sen', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'b@@', 'ro@@', 'n', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'gel@@', 's', 'is.', '</s>']
2025-05-29 18:55:39,735 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:55:39,735 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:55:39,735 - INFO - joeynmt.training - 	Hypothesis: Ik heb de twee jaar heb ik deze twee folië getoonde dat de artische ijskappen, dat de artische ijskappen, die de reden van de grondsen van 40 procent van 40 procent van 40 procent van de bron van 40 procent van de regels is.
2025-05-29 18:55:39,736 - INFO - joeynmt.training - Example #1
2025-05-29 18:55:39,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:55:39,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:55:39,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'op@@', 'en@@', 'bare', 'proble@@', 'em@@', ',', 'want', 'het', 'is', 'een', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'is', 'dat', 'er', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'oo@@', 'p@@', 't.', '</s>']
2025-05-29 18:55:39,737 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:55:39,737 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:55:39,738 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de openbare probleem, want het is een specifiek van de dikke probleem is dat er niet de dikke van de ijskoopt.
2025-05-29 18:55:39,738 - INFO - joeynmt.training - Example #2
2025-05-29 18:55:39,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:55:39,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:55:39,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'f@@', 'eite', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'de', 'ar@@', 'ti@@', 'c@@', 'a', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:55:39,739 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:55:39,739 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:55:39,740 - INFO - joeynmt.training - 	Hypothesis: In feite is de artische ijskappe is de artica van onze wereldwijde klimaatsysteem.
2025-05-29 18:55:39,740 - INFO - joeynmt.training - Example #3
2025-05-29 18:55:39,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:55:39,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:55:39,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'ik@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 18:55:39,741 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:55:39,741 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:55:39,742 - INFO - joeynmt.training - 	Hypothesis: Ze wist in de winter en schruikt in de zomers.
2025-05-29 18:55:39,742 - INFO - joeynmt.training - Example #4
2025-05-29 18:55:39,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:55:39,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:55:39,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ol@@', 'ie,', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 't.', '</s>']
2025-05-29 18:55:39,743 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:55:39,744 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:55:39,744 - INFO - joeynmt.training - 	Hypothesis: De volgende folie, die ik jullie tonen, is een tijdperk van wat er in de laatste 25 jaar gebeurt.
2025-05-29 18:55:49,140 - INFO - joeynmt.training - Epoch   2, Step:    14100, Batch Loss:     1.910670, Batch Acc: 0.470489, Tokens per Sec:     7172, Lr: 0.000300
2025-05-29 18:55:58,589 - INFO - joeynmt.training - Epoch   2, Step:    14200, Batch Loss:     1.767983, Batch Acc: 0.469413, Tokens per Sec:     7499, Lr: 0.000300
2025-05-29 18:56:07,923 - INFO - joeynmt.training - Epoch   2, Step:    14300, Batch Loss:     1.978983, Batch Acc: 0.462049, Tokens per Sec:     7615, Lr: 0.000300
2025-05-29 18:56:17,595 - INFO - joeynmt.training - Epoch   2, Step:    14400, Batch Loss:     1.685174, Batch Acc: 0.477941, Tokens per Sec:     7260, Lr: 0.000300
2025-05-29 18:56:26,593 - INFO - joeynmt.training - Epoch   2, Step:    14500, Batch Loss:     1.875120, Batch Acc: 0.477667, Tokens per Sec:     7680, Lr: 0.000300
2025-05-29 18:56:26,593 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:56:26,594 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:57:05,851 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.67, acc:   0.45, generation: 39.2124[sec], evaluation: 0.0000[sec]
2025-05-29 18:57:05,852 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:57:06,056 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/12000.ckpt
2025-05-29 18:57:06,073 - INFO - joeynmt.training - Example #0
2025-05-29 18:57:06,073 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:57:06,074 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:57:06,074 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'het', 'jaar', 'gele@@', 'den', 'ge@@', 'to@@', 'ond', 'om', 'deze', 'twee', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'ond', 'te', 'ver@@', 'anderen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'at@@', 'uur', 'die', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'st@@', 'aten', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'was', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'maakt', 'is.', '</s>']
2025-05-29 18:57:06,075 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:57:06,075 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:57:06,075 - INFO - joeynmt.training - 	Hypothesis: Ik heb het jaar geleden getoond om deze twee folië getoond te veranderen dat de artische ijskapparatuur die de reden van de reden van de reden van 40 procent van 40 procent van 40 procent van de staten van 40 procent van de reden van 40 procent van de reden van de reden van 40 procent van 40 procent was 40 procent gemaakt is.
2025-05-29 18:57:06,075 - INFO - joeynmt.training - Example #1
2025-05-29 18:57:06,076 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:57:06,076 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:57:06,076 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'op@@', 'kom@@', 'st', 'van', 'deze', 'op@@', 'en@@', 'baar', 'proble@@', 'em@@', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'eu@@', 'ze', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 18:57:06,077 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:57:06,077 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:57:06,077 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de opkomst van deze openbaar probleem, want het is het niet de dikke ijskeuze toont.
2025-05-29 18:57:06,077 - INFO - joeynmt.training - Example #2
2025-05-29 18:57:06,078 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:57:06,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:57:06,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'en', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:57:06,079 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:57:06,079 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:57:06,079 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen van onze wereldwijd en onze wereldwijd van onze wereldwijde klimaatsysteem.
2025-05-29 18:57:06,080 - INFO - joeynmt.training - Example #3
2025-05-29 18:57:06,080 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:57:06,080 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:57:06,080 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'mp@@', 'el@@', 'en.', '</s>']
2025-05-29 18:57:06,081 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:57:06,081 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:57:06,081 - INFO - joeynmt.training - 	Hypothesis: Ze wist in het winter en schrumpelen.
2025-05-29 18:57:06,082 - INFO - joeynmt.training - Example #4
2025-05-29 18:57:06,082 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:57:06,082 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:57:06,082 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', 'wat', 'ik', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 18:57:06,083 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:57:06,083 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:57:06,084 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien wat ik in de laatste 25 jaar gebeurd.
2025-05-29 18:57:15,738 - INFO - joeynmt.training - Epoch   2, Step:    14600, Batch Loss:     1.949824, Batch Acc: 0.473768, Tokens per Sec:     7090, Lr: 0.000300
2025-05-29 18:57:25,316 - INFO - joeynmt.training - Epoch   2, Step:    14700, Batch Loss:     1.703771, Batch Acc: 0.478976, Tokens per Sec:     7373, Lr: 0.000300
2025-05-29 18:57:34,935 - INFO - joeynmt.training - Epoch   2, Step:    14800, Batch Loss:     1.773850, Batch Acc: 0.473818, Tokens per Sec:     7210, Lr: 0.000300
2025-05-29 18:57:44,487 - INFO - joeynmt.training - Epoch   2, Step:    14900, Batch Loss:     1.711107, Batch Acc: 0.476480, Tokens per Sec:     7206, Lr: 0.000300
2025-05-29 18:57:54,116 - INFO - joeynmt.training - Epoch   2, Step:    15000, Batch Loss:     1.790653, Batch Acc: 0.468878, Tokens per Sec:     7401, Lr: 0.000300
2025-05-29 18:57:54,119 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:57:54,120 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:58:35,223 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.57, acc:   0.46, generation: 41.0611[sec], evaluation: 0.0000[sec]
2025-05-29 18:58:35,224 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:58:35,411 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/12500.ckpt
2025-05-29 18:58:35,427 - INFO - joeynmt.training - Example #0
2025-05-29 18:58:35,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 18:58:35,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 18:58:35,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'beel@@', 'den', 'om', 'te', 'ver@@', 'm@@', 'inder@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'w@@', 'on@@', 'en', '4@@', '8', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'gebeur@@', 'de.', '</s>']
2025-05-29 18:58:35,429 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:58:35,429 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 18:58:35,429 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden getoond om te verbeelden om te verminderen dat de artische ijskappen die voor de reden van de reden van de grondwonen 48 procent van 40 procent van 40 procent van 40 procent gebeurde.
2025-05-29 18:58:35,430 - INFO - joeynmt.training - Example #1
2025-05-29 18:58:35,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 18:58:35,430 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 18:58:35,430 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'genoe@@', 'g', 'de', 'aar@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em@@', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ker@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 18:58:35,431 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:58:35,431 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 18:58:35,432 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de aarde van dit specifieke probleem, want het is niet de dikke van de ijskkers toont.
2025-05-29 18:58:35,432 - INFO - joeynmt.training - Example #2
2025-05-29 18:58:35,432 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 18:58:35,432 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 18:58:35,432 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'm@@', 'in', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 18:58:35,434 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:58:35,434 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 18:58:35,435 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het min onze wereldwijde klimaatsysteem.
2025-05-29 18:58:35,435 - INFO - joeynmt.training - Example #3
2025-05-29 18:58:35,435 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 18:58:35,435 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 18:58:35,435 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'mp@@', '.', '</s>']
2025-05-29 18:58:35,436 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:58:35,436 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 18:58:35,437 - INFO - joeynmt.training - 	Hypothesis: Ze wist in de winter en schrump.
2025-05-29 18:58:35,437 - INFO - joeynmt.training - Example #4
2025-05-29 18:58:35,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 18:58:35,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 18:58:35,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de.', '</s>']
2025-05-29 18:58:35,438 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:58:35,438 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 18:58:35,438 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien wat er in de laatste 25 jaar gebeurde.
2025-05-29 18:58:45,072 - INFO - joeynmt.training - Epoch   2, Step:    15100, Batch Loss:     1.787331, Batch Acc: 0.474123, Tokens per Sec:     7095, Lr: 0.000300
2025-05-29 18:58:54,165 - INFO - joeynmt.training - Epoch   2, Step:    15200, Batch Loss:     1.739321, Batch Acc: 0.474459, Tokens per Sec:     7777, Lr: 0.000300
2025-05-29 18:59:02,563 - INFO - joeynmt.training - Epoch   2, Step:    15300, Batch Loss:     2.043188, Batch Acc: 0.476773, Tokens per Sec:     8316, Lr: 0.000300
2025-05-29 18:59:10,883 - INFO - joeynmt.training - Epoch   2, Step:    15400, Batch Loss:     1.829140, Batch Acc: 0.472183, Tokens per Sec:     8505, Lr: 0.000300
2025-05-29 18:59:19,288 - INFO - joeynmt.training - Epoch   2, Step:    15500, Batch Loss:     1.811250, Batch Acc: 0.474124, Tokens per Sec:     8225, Lr: 0.000300
2025-05-29 18:59:19,288 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 18:59:19,288 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:00:00,871 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.57, acc:   0.46, generation: 41.5440[sec], evaluation: 0.0000[sec]
2025-05-29 19:00:00,873 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:00:01,056 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/13000.ckpt
2025-05-29 19:00:01,075 - INFO - joeynmt.training - Example #0
2025-05-29 19:00:01,076 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:00:01,076 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:00:01,076 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'en', 'jaar', 'heb', 'ik', 'deze', 'twee', 'c@@', 'ol@@', 'ië@@', 'n', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'antwoor@@', 'del@@', 'ijk@@', 'heid', 'te', 'ver@@', 'antwoor@@', 'del@@', 'ijk@@', 'heid', 'te', 'ver@@', 'anderen', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'w@@', 'ijn@@', 'en.', '</s>']
2025-05-29 19:00:01,076 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:00:01,077 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:00:01,077 - INFO - joeynmt.training - 	Hypothesis: Ten jaar heb ik deze twee coliën getoond om te verantwoordelijkheid te verantwoordelijkheid te veranderen die voor de reden van de reden van de reden van de grondwijnen.
2025-05-29 19:00:01,077 - INFO - joeynmt.training - Example #1
2025-05-29 19:00:01,077 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:00:01,077 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:00:01,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'op@@', 'te', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'het', 'ij@@', 's@@', 'k@@', 'il@@', 'om@@', 'et@@', 'er', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ap@@', '.', '</s>']
2025-05-29 19:00:01,079 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:00:01,079 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:00:01,079 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste stopte van dit speciale problemen van dit speciale probleem van het ijskilometer van de ijskap.
2025-05-29 19:00:01,079 - INFO - joeynmt.training - Example #2
2025-05-29 19:00:01,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:00:01,080 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:00:01,080 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:00:01,081 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:00:01,081 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:00:01,081 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen van onze wereldwijde klimaatsysteem.
2025-05-29 19:00:01,081 - INFO - joeynmt.training - Example #3
2025-05-29 19:00:01,081 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:00:01,082 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:00:01,082 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'mp@@', '.', '</s>']
2025-05-29 19:00:01,083 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:00:01,083 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:00:01,083 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en schrump.
2025-05-29 19:00:01,083 - INFO - joeynmt.training - Example #4
2025-05-29 19:00:01,084 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:00:01,084 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:00:01,084 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'c@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de.', '</s>']
2025-05-29 19:00:01,085 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:00:01,085 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:00:01,085 - INFO - joeynmt.training - 	Hypothesis: De volgende colie die ik jullie laten zien wat er in de laatste 25 jaar gebeurde.
2025-05-29 19:00:10,736 - INFO - joeynmt.training - Epoch   2, Step:    15600, Batch Loss:     1.687336, Batch Acc: 0.474841, Tokens per Sec:     7179, Lr: 0.000300
2025-05-29 19:00:20,521 - INFO - joeynmt.training - Epoch   2, Step:    15700, Batch Loss:     1.803547, Batch Acc: 0.474937, Tokens per Sec:     6949, Lr: 0.000300
2025-05-29 19:00:30,053 - INFO - joeynmt.training - Epoch   2, Step:    15800, Batch Loss:     1.691380, Batch Acc: 0.479314, Tokens per Sec:     7432, Lr: 0.000300
2025-05-29 19:00:39,766 - INFO - joeynmt.training - Epoch   2, Step:    15900, Batch Loss:     1.815947, Batch Acc: 0.481364, Tokens per Sec:     7373, Lr: 0.000300
2025-05-29 19:00:49,049 - INFO - joeynmt.training - Epoch   2, Step:    16000, Batch Loss:     1.902473, Batch Acc: 0.475684, Tokens per Sec:     7158, Lr: 0.000300
2025-05-29 19:00:49,050 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:00:49,050 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:01:27,268 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.53, acc:   0.46, generation: 38.1800[sec], evaluation: 0.0000[sec]
2025-05-29 19:01:27,269 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:01:27,739 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/13500.ckpt
2025-05-29 19:01:27,756 - INFO - joeynmt.training - Example #0
2025-05-29 19:01:27,757 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:01:27,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:01:27,757 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'f@@', 'ei@@', 'ten', 'ge@@', 'to@@', 'on@@', 'de', 'ge@@', 'to@@', 'on@@', 'de', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', '4@@', '8', 'uur', 'van', 'de', '1@@', '0@@', '%', 'van', 'de', '1@@', '0@@', '%', 'gebeur@@', 'de.', '</s>']
2025-05-29 19:01:27,758 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:01:27,758 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:01:27,758 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee feiten getoonde getoonde dat de artische ijskappen, dat de artische ijskappen, die voor de reden van de reden van 48 uur van de 10% van de 10% gebeurde.
2025-05-29 19:01:27,758 - INFO - joeynmt.training - Example #1
2025-05-29 19:01:27,759 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:01:27,759 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:01:27,759 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'is', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'het', 'ij@@', 's@@', 'k@@', 'n@@', 'i@@', 've@@', 'au', 'van', 'de', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'het', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'het', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ie@@', 'ke', 'proble@@', 'em@@', '.', '</s>']
2025-05-29 19:01:27,760 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:01:27,760 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:01:27,760 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste eerste is dat het speciale probleem, omdat het niet de dikwestie van het ijskniveau van de ijskwestie van de ijskappen van de ijskappen van het ijskwestie van het ijskwestie van het ijskieke probleem.
2025-05-29 19:01:27,760 - INFO - joeynmt.training - Example #2
2025-05-29 19:01:27,761 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:01:27,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:01:27,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'd', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:01:27,762 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:01:27,762 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:01:27,762 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen van onze wereldwijd van ons wereldwijd systeem.
2025-05-29 19:01:27,762 - INFO - joeynmt.training - Example #3
2025-05-29 19:01:27,762 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:01:27,763 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:01:27,763 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'm@@', 't', 'in', 'het', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 19:01:27,763 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:01:27,764 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:01:27,764 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en schrumt in het zomer.
2025-05-29 19:01:27,764 - INFO - joeynmt.training - Example #4
2025-05-29 19:01:27,764 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:01:27,764 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:01:27,764 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'v@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'laten', 'zien', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:01:27,765 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:01:27,765 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:01:27,766 - INFO - joeynmt.training - 	Hypothesis: De volgende volie die ik jullie laten zien wat er in de laatste 25 jaar gebeurd.
2025-05-29 19:01:36,461 - INFO - joeynmt.training - Epoch   2, Step:    16100, Batch Loss:     1.849212, Batch Acc: 0.478021, Tokens per Sec:     7306, Lr: 0.000300
2025-05-29 19:01:44,849 - INFO - joeynmt.training - Epoch   2, Step:    16200, Batch Loss:     1.792705, Batch Acc: 0.478883, Tokens per Sec:     8494, Lr: 0.000300
2025-05-29 19:01:53,552 - INFO - joeynmt.training - Epoch   2, Step:    16300, Batch Loss:     1.869338, Batch Acc: 0.479082, Tokens per Sec:     7978, Lr: 0.000300
2025-05-29 19:02:02,837 - INFO - joeynmt.training - Epoch   2, Step:    16400, Batch Loss:     1.759997, Batch Acc: 0.480287, Tokens per Sec:     7723, Lr: 0.000300
2025-05-29 19:02:12,558 - INFO - joeynmt.training - Epoch   2, Step:    16500, Batch Loss:     1.764666, Batch Acc: 0.486319, Tokens per Sec:     7519, Lr: 0.000300
2025-05-29 19:02:12,559 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:02:12,559 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:02:58,128 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.43, acc:   0.46, generation: 45.5352[sec], evaluation: 0.0000[sec]
2025-05-29 19:02:58,129 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:02:58,305 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/14000.ckpt
2025-05-29 19:02:58,327 - INFO - joeynmt.training - Example #0
2025-05-29 19:02:58,328 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:02:58,328 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:02:58,328 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'enen', 'ge@@', 'to@@', 'on@@', 'd', 'ge@@', 'to@@', 'on@@', 't', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'on@@', 'd@@', 'se', 'ij@@', 's', 'van', '4@@', '8', 'proc@@', 'ent', 'van', '4@@', '8', 'proc@@', 'ent', 'ge@@', 'dur@@', 'ende', '4@@', '8', 'proc@@', 'ent', 'van', '4@@', '8', 'proc@@', 'ent', 'ge@@', 'g@@', 'aan.', '</s>']
2025-05-29 19:02:58,329 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:02:58,329 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:02:58,329 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dienen getoond getoont om te verbeteren dat de artische ijskappen, die voor de reden van de drie miljoen jaar de grondse ijs van 48 procent van 48 procent gedurende 48 procent van 48 procent gegaan.
2025-05-29 19:02:58,330 - INFO - joeynmt.training - Example #1
2025-05-29 19:02:58,330 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:02:58,330 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:02:58,330 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'is', 'het', 'ver@@', 'v@@', 'u@@', 'il@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'ij@@', 's@@', 'je', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 19:02:58,331 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:02:58,331 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:02:58,332 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste eerste is het vervuiling van dit speciale probleem, omdat het niet de dicke van het ijsje toont.
2025-05-29 19:02:58,332 - INFO - joeynmt.training - Example #2
2025-05-29 19:02:58,332 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:02:58,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:02:58,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'p@@', 'la@@', 'k@@', 'ken,', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:02:58,334 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:02:58,334 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:02:58,334 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het plakken, het hart van onze wereldwijde klimaatsysteem.
2025-05-29 19:02:58,334 - INFO - joeynmt.training - Example #3
2025-05-29 19:02:58,334 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:02:58,334 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:02:58,335 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', '.', '</s>']
2025-05-29 19:02:58,335 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:02:58,338 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:02:58,338 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schroep.
2025-05-29 19:02:58,338 - INFO - joeynmt.training - Example #4
2025-05-29 19:02:58,339 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:02:58,339 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:02:58,339 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'o', 'die', 'ik', 'jullie', 'laten', 'zien', 'wat', 'ik', 'jullie', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'gebeur@@', 't.', '</s>']
2025-05-29 19:02:58,340 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:02:58,340 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:02:58,340 - INFO - joeynmt.training - 	Hypothesis: De volgende dio die ik jullie laten zien wat ik jullie een tijdschriften wat er gebeurt.
2025-05-29 19:03:07,995 - INFO - joeynmt.training - Epoch   2, Step:    16600, Batch Loss:     1.837948, Batch Acc: 0.475615, Tokens per Sec:     7135, Lr: 0.000300
2025-05-29 19:03:17,511 - INFO - joeynmt.training - Epoch   2, Step:    16700, Batch Loss:     1.923789, Batch Acc: 0.482785, Tokens per Sec:     7167, Lr: 0.000300
2025-05-29 19:03:27,083 - INFO - joeynmt.training - Epoch   2, Step:    16800, Batch Loss:     1.729088, Batch Acc: 0.475458, Tokens per Sec:     7100, Lr: 0.000300
2025-05-29 19:03:36,419 - INFO - joeynmt.training - Epoch   2, Step:    16900, Batch Loss:     1.855530, Batch Acc: 0.476902, Tokens per Sec:     7464, Lr: 0.000300
2025-05-29 19:03:45,886 - INFO - joeynmt.training - Epoch   2, Step:    17000, Batch Loss:     2.085448, Batch Acc: 0.485404, Tokens per Sec:     7430, Lr: 0.000300
2025-05-29 19:03:45,886 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:03:45,886 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:04:21,751 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.37, acc:   0.46, generation: 35.8251[sec], evaluation: 0.0000[sec]
2025-05-29 19:04:21,752 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:04:21,934 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/14500.ckpt
2025-05-29 19:04:21,950 - INFO - joeynmt.training - Example #0
2025-05-29 19:04:21,950 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:04:21,951 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:04:21,951 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'beel@@', 'den', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'de', 're@@', 'den', 'van', '4@@', '8', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'el@@', 'ijke', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', '4@@', '8', 'proc@@', 'ent', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:04:21,951 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:04:21,951 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:04:21,952 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee folië getoond om te verbeelden dat de artische ijskappe ijskappe die voor de reden van de drie miljoen jaar de reden van 48 miljoen jaar de grondstoelijke ijskwestie van 48 procent gebeurd.
2025-05-29 19:04:21,952 - INFO - joeynmt.training - Example #1
2025-05-29 19:04:21,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:04:21,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:04:21,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'is', 'dat', 'het', 'op@@', 'en@@', 'baar', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'de', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'de', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'het', 'ij@@', 's@@', 'be@@', 'l', 'van', 'het', 'ij@@', 's@@', 'k@@', 'eer@@', 't', 'van', 'het', 'ij@@', 's@@', 'k@@', 'eer@@', 't', 'dat', 'het', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'is', 'om', 'het', 'te', 'be@@', 'stu@@', 'ur@@', 'en.', '</s>']
2025-05-29 19:04:21,953 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:04:21,954 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:04:21,954 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste eerste is dat het openbaar is dat het niet de dikke van het ijsje van het ijsje van de ijskwestie van de ijskwestie van het ijsbel van het ijskeert van het ijskeert dat het niet sterk genoeg is om het te bestuuren.
2025-05-29 19:04:21,954 - INFO - joeynmt.training - Example #2
2025-05-29 19:04:21,954 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:04:21,954 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:04:21,954 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'p@@', 'la@@', 'st@@', 'ige', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:04:21,956 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:04:21,956 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:04:21,956 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het plastige hart van onze wereldwijde klimaatsysteem.
2025-05-29 19:04:21,956 - INFO - joeynmt.training - Example #3
2025-05-29 19:04:21,956 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:04:21,956 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:04:21,956 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'mp@@', 'je', 'in', 'het', 'z@@', 'om@@', 'er', 'in', 'het', 'z@@', 'om@@', 'er', 'en', 'sch@@', 'o@@', 'on@@', '.', '</s>']
2025-05-29 19:04:21,957 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:04:21,957 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:04:21,958 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en schrumpje in het zomer in het zomer en schoon.
2025-05-29 19:04:21,958 - INFO - joeynmt.training - Example #4
2025-05-29 19:04:21,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:04:21,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:04:21,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:04:21,959 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:04:21,959 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:04:21,960 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie is een tijdschriften wat er gebeurt in de laatste 25 jaar gebeurd.
2025-05-29 19:04:31,080 - INFO - joeynmt.training - Epoch   2, Step:    17100, Batch Loss:     1.881106, Batch Acc: 0.479389, Tokens per Sec:     7507, Lr: 0.000300
2025-05-29 19:04:40,549 - INFO - joeynmt.training - Epoch   2, Step:    17200, Batch Loss:     1.797192, Batch Acc: 0.490279, Tokens per Sec:     7426, Lr: 0.000300
2025-05-29 19:04:49,878 - INFO - joeynmt.training - Epoch   2, Step:    17300, Batch Loss:     1.928818, Batch Acc: 0.478268, Tokens per Sec:     7478, Lr: 0.000300
2025-05-29 19:04:59,229 - INFO - joeynmt.training - Epoch   2, Step:    17400, Batch Loss:     1.813664, Batch Acc: 0.489880, Tokens per Sec:     7541, Lr: 0.000300
2025-05-29 19:05:08,813 - INFO - joeynmt.training - Epoch   2, Step:    17500, Batch Loss:     1.876013, Batch Acc: 0.479288, Tokens per Sec:     7253, Lr: 0.000300
2025-05-29 19:05:08,813 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:05:08,814 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:05:48,762 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.31, acc:   0.47, generation: 39.9090[sec], evaluation: 0.0000[sec]
2025-05-29 19:05:48,763 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:05:48,945 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/15000.ckpt
2025-05-29 19:05:48,962 - INFO - joeynmt.training - Example #0
2025-05-29 19:05:48,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:05:48,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:05:48,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'de', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'de', 'dat', 'de', 'ar@@', 'ti@@', 'c@@', 'a', 'van', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e,', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'A@@', 'f@@', ',', 'de', 're@@', 'den', 'van', '4@@', '8', 'uur', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'proc@@', 'ent', 'gebeur@@', 't.', '</s>']
2025-05-29 19:05:48,964 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:05:48,964 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:05:48,964 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee getoonde twee dia getoonde dat de artica van de artische ijskape, die voor de reden van de Af, de reden van 48 uur van de onderste 48 procent gebeurt.
2025-05-29 19:05:48,965 - INFO - joeynmt.training - Example #1
2025-05-29 19:05:48,965 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:05:48,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:05:48,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ier@@', 'k', 'genoe@@', 'g', 'de', 'aar@@', 'de', 'is', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'ij@@', 's@@', 'je', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 19:05:48,966 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:05:48,966 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:05:48,966 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet stierk genoeg de aarde is van dit speciale probleem dat het niet de dicke van het ijsje toont.
2025-05-29 19:05:48,966 - INFO - joeynmt.training - Example #2
2025-05-29 19:05:48,967 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:05:48,967 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:05:48,967 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'p@@', 'la@@', 'st@@', 'i@@', 'c', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:05:48,968 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:05:48,968 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:05:48,968 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het plastic systeem.
2025-05-29 19:05:48,968 - INFO - joeynmt.training - Example #3
2025-05-29 19:05:48,969 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:05:48,969 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:05:48,969 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'mp@@', 'je', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:05:48,970 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:05:48,970 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:05:48,970 - INFO - joeynmt.training - 	Hypothesis: Ze groeide in de winter en schrumpje in de zomers.
2025-05-29 19:05:48,970 - INFO - joeynmt.training - Example #4
2025-05-29 19:05:48,970 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:05:48,970 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:05:48,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'vol@@', 'gende', 'di@@', 're@@', 'c@@', 'te@@', 'er@@', 't,', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:05:48,971 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:05:48,971 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:05:48,971 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende directeert, is een tijdperk van wat er gebeurt in de laatste 25 jaar gebeurd.
2025-05-29 19:05:58,922 - INFO - joeynmt.training - Epoch   2, Step:    17600, Batch Loss:     1.916222, Batch Acc: 0.484083, Tokens per Sec:     6884, Lr: 0.000300
2025-05-29 19:06:08,725 - INFO - joeynmt.training - Epoch   2, Step:    17700, Batch Loss:     1.708161, Batch Acc: 0.482321, Tokens per Sec:     6928, Lr: 0.000300
2025-05-29 19:06:18,896 - INFO - joeynmt.training - Epoch   2, Step:    17800, Batch Loss:     1.763332, Batch Acc: 0.476679, Tokens per Sec:     6762, Lr: 0.000300
2025-05-29 19:06:28,514 - INFO - joeynmt.training - Epoch   2, Step:    17900, Batch Loss:     1.769786, Batch Acc: 0.487122, Tokens per Sec:     7226, Lr: 0.000300
2025-05-29 19:06:37,134 - INFO - joeynmt.training - Epoch   2, Step:    18000, Batch Loss:     1.675352, Batch Acc: 0.481732, Tokens per Sec:     7986, Lr: 0.000300
2025-05-29 19:06:37,135 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:06:37,135 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:07:12,217 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.32, acc:   0.47, generation: 35.0402[sec], evaluation: 0.0000[sec]
2025-05-29 19:07:12,401 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/15500.ckpt
2025-05-29 19:07:12,419 - INFO - joeynmt.training - Example #0
2025-05-29 19:07:12,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:07:12,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:07:12,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'eerste', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 't', 'om', 'te', 'ver@@', 'plaat@@', 'sen', 'te', 'ver@@', 'plaat@@', 'sen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'on@@', 'd@@', 'se', 'ij@@', 'nen', '4@@', '8', 'uur', 'van', '4@@', '0', 'proc@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 't.', '</s>']
2025-05-29 19:07:12,421 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:07:12,421 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:07:12,422 - INFO - joeynmt.training - 	Hypothesis: In de eerste jaar heb ik deze twee getoont om te verplaatsen te verplaatsen dat de artische ijskappen, die voor de reden van de drie miljoen jaar de grondse ijnen 48 uur van 40 procent geschrumpt.
2025-05-29 19:07:12,422 - INFO - joeynmt.training - Example #1
2025-05-29 19:07:12,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:07:12,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:07:12,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ier@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'het', 'ij@@', 's@@', 'be@@', 'd@@', 'rei@@', 'g@@', 'd', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'de', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'de', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'het', 'ij@@', 's@@', 'k@@', 'su@@', 'ele', 'proble@@', 'em', 'dat', 'is', 'dat', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'niet', 'st@@', 'ier@@', '.', '</s>']
2025-05-29 19:07:12,423 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:07:12,424 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:07:12,424 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet stierk genoeg de eerste is van dit specifiek van dit specifiek van het ijsbedreigd van de ijskappen van de ijskaart van de ijskaart van het ijskappen van het ijsksuele probleem dat is dat niet de dikke van de ijskwestie niet stier.
2025-05-29 19:07:12,424 - INFO - joeynmt.training - Example #2
2025-05-29 19:07:12,424 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:07:12,424 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:07:12,424 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'dat', 'we', 'het', 'l@@', 'aat', 'l@@', 'aa@@', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:07:12,425 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:07:12,425 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:07:12,425 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe dat we het laat laaglobale klimaatsysteem.
2025-05-29 19:07:12,426 - INFO - joeynmt.training - Example #3
2025-05-29 19:07:12,426 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:07:12,426 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:07:12,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'm@@', 'ing', 'in', 'het', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 19:07:12,427 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:07:12,427 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:07:12,427 - INFO - joeynmt.training - 	Hypothesis: Ze groeide in de winter en schruming in het zomer.
2025-05-29 19:07:12,428 - INFO - joeynmt.training - Example #4
2025-05-29 19:07:12,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:07:12,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:07:12,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'ge@@', 'vol@@', 'g@@', 'd', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 19:07:12,429 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:07:12,429 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:07:12,429 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolgd die ik jullie laten zien, is een tijdschrift van de afgelopen 25 jaar is in de afgelopen 25 jaar is.
2025-05-29 19:07:21,686 - INFO - joeynmt.training - Epoch   2, Step:    18100, Batch Loss:     1.743273, Batch Acc: 0.488040, Tokens per Sec:     7404, Lr: 0.000300
2025-05-29 19:07:30,957 - INFO - joeynmt.training - Epoch   2, Step:    18200, Batch Loss:     1.879698, Batch Acc: 0.483253, Tokens per Sec:     7486, Lr: 0.000300
2025-05-29 19:07:40,162 - INFO - joeynmt.training - Epoch   2, Step:    18300, Batch Loss:     1.770123, Batch Acc: 0.484795, Tokens per Sec:     7664, Lr: 0.000300
2025-05-29 19:07:49,387 - INFO - joeynmt.training - Epoch   2, Step:    18400, Batch Loss:     1.840909, Batch Acc: 0.485970, Tokens per Sec:     7650, Lr: 0.000300
2025-05-29 19:07:55,901 - INFO - joeynmt.training - Epoch   2: total training loss 16976.94
2025-05-29 19:07:55,901 - INFO - joeynmt.training - EPOCH 3
2025-05-29 19:07:58,936 - INFO - joeynmt.training - Epoch   3, Step:    18500, Batch Loss:     1.459831, Batch Acc: 0.512792, Tokens per Sec:     7204, Lr: 0.000300
2025-05-29 19:07:58,938 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:07:58,938 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:08:39,406 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.29, acc:   0.47, generation: 40.4278[sec], evaluation: 0.0000[sec]
2025-05-29 19:08:39,407 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:08:39,582 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/16000.ckpt
2025-05-29 19:08:39,600 - INFO - joeynmt.training - Example #0
2025-05-29 19:08:39,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:08:39,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:08:39,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'de', 'ge@@', 'to@@', 'on@@', 'de', 'de', 'ge@@', 'to@@', 'on@@', 'de', 'om', 'te', 'ver@@', 'anderen', 'om', 'te', 'ver@@', 'anderen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'se', 'ij@@', 'zen', 'van', 'de', 'onder@@', 'en', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'c@@', 'ru@@', 'mp@@', 'en.', '</s>']
2025-05-29 19:08:39,602 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:08:39,602 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:08:39,602 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar de getoonde de getoonde om te veranderen om te veranderen dat de artische ijskappen, die voor de reden van de grondse ijzen van de onderen 40 procent gecrumpen.
2025-05-29 19:08:39,602 - INFO - joeynmt.training - Example #1
2025-05-29 19:08:39,604 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:08:39,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:08:39,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'n@@', 'aa@@', 'st', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em@@', ',', 'dat', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ker', 'van', 'de', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie.', '</s>']
2025-05-29 19:08:39,605 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:08:39,605 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:08:39,605 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste naast het specifieke probleem, dat is niet de dikke van het ijskker van de ijskwestie.
2025-05-29 19:08:39,605 - INFO - joeynmt.training - Example #2
2025-05-29 19:08:39,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:08:39,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:08:39,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'p@@', 'ub@@', 'lie@@', 'ke', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:08:39,606 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:08:39,606 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:08:39,606 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het publieke klimaatsysteem.
2025-05-29 19:08:39,607 - INFO - joeynmt.training - Example #3
2025-05-29 19:08:39,607 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:08:39,607 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:08:39,607 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'ist', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p', 'in', 'het', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 19:08:39,608 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:08:39,608 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:08:39,608 - INFO - joeynmt.training - 	Hypothesis: Ze wist in de winter en schromp in het zomer.
2025-05-29 19:08:39,608 - INFO - joeynmt.training - Example #4
2025-05-29 19:08:39,609 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:08:39,609 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:08:39,609 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 're@@', 'ct', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 19:08:39,609 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:08:39,610 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:08:39,610 - INFO - joeynmt.training - 	Hypothesis: De volgende direct die ik jullie laat zien wat er in de laatste 25 jaar in de laatste 25 jaar.
2025-05-29 19:08:50,094 - INFO - joeynmt.training - Epoch   3, Step:    18600, Batch Loss:     1.635968, Batch Acc: 0.493400, Tokens per Sec:     6557, Lr: 0.000300
2025-05-29 19:08:59,801 - INFO - joeynmt.training - Epoch   3, Step:    18700, Batch Loss:     1.655217, Batch Acc: 0.494133, Tokens per Sec:     7270, Lr: 0.000300
2025-05-29 19:09:08,806 - INFO - joeynmt.training - Epoch   3, Step:    18800, Batch Loss:     1.811642, Batch Acc: 0.502580, Tokens per Sec:     7705, Lr: 0.000300
2025-05-29 19:09:18,610 - INFO - joeynmt.training - Epoch   3, Step:    18900, Batch Loss:     1.657320, Batch Acc: 0.497343, Tokens per Sec:     7120, Lr: 0.000300
2025-05-29 19:09:28,437 - INFO - joeynmt.training - Epoch   3, Step:    19000, Batch Loss:     1.684288, Batch Acc: 0.496688, Tokens per Sec:     7084, Lr: 0.000300
2025-05-29 19:09:28,437 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:09:28,437 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:10:13,564 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.23, acc:   0.47, generation: 45.0850[sec], evaluation: 0.0000[sec]
2025-05-29 19:10:13,565 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:10:13,768 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/16500.ckpt
2025-05-29 19:10:13,788 - INFO - joeynmt.training - Example #0
2025-05-29 19:10:13,788 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:10:13,789 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:10:13,789 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'plaat@@', 'sen', 'te', 'ver@@', 'plaat@@', 'sen', 'om', 'te', 'ver@@', 'plaat@@', 'sen', 'te', 'ver@@', 'plaat@@', 'sen', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 're@@', 'eu@@', 'ze', 'voor', 'de', 'gro@@', 'ter@@', 'e', 'van', 'de', 'gro@@', 'ter@@', 'e', 'van', 'de', 'gro@@', 'ter@@', 'e', 'van', '4@@', '0', 'proc@@', 'ent', 'gebeur@@', 't.', '</s>']
2025-05-29 19:10:13,790 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:10:13,790 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:10:13,790 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee folië getoond om te verplaatsen te verplaatsen om te verplaatsen te verplaatsen die voor de reden van de reeuze voor de grotere van de grotere van de grotere van 40 procent gebeurt.
2025-05-29 19:10:13,790 - INFO - joeynmt.training - Example #1
2025-05-29 19:10:13,791 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:10:13,791 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:10:13,791 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em@@', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'k@@', 'ijk', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 19:10:13,792 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:10:13,792 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:10:13,792 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste kwestie van dit specifieke probleem, want het is het niet de dikke van het ijskkijk toont.
2025-05-29 19:10:13,793 - INFO - joeynmt.training - Example #2
2025-05-29 19:10:13,793 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:10:13,793 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:10:13,793 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', ',', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'l@@', 'aa@@', 'g', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:10:13,795 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:10:13,795 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:10:13,795 - INFO - joeynmt.training - 	Hypothesis: In zekere zin, is de artische ijskappe het laag van onze wereldwijde klimaatsysteem.
2025-05-29 19:10:13,795 - INFO - joeynmt.training - Example #3
2025-05-29 19:10:13,796 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:10:13,796 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:10:13,796 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'm@@', 'p', 'in', 'het', 'z@@', 'om@@', 'er', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:10:13,797 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:10:13,797 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:10:13,798 - INFO - joeynmt.training - 	Hypothesis: Ze groeide in het winter en schrump in het zomer in het zomers.
2025-05-29 19:10:13,798 - INFO - joeynmt.training - Example #4
2025-05-29 19:10:13,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:10:13,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:10:13,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:10:13,799 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:10:13,799 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:10:13,800 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdje van de laatste 25 jaar gebeurd.
2025-05-29 19:10:23,587 - INFO - joeynmt.training - Epoch   3, Step:    19100, Batch Loss:     1.959502, Batch Acc: 0.491194, Tokens per Sec:     6900, Lr: 0.000300
2025-05-29 19:10:33,807 - INFO - joeynmt.training - Epoch   3, Step:    19200, Batch Loss:     1.873240, Batch Acc: 0.498406, Tokens per Sec:     7062, Lr: 0.000300
2025-05-29 19:10:43,743 - INFO - joeynmt.training - Epoch   3, Step:    19300, Batch Loss:     1.889132, Batch Acc: 0.499850, Tokens per Sec:     7025, Lr: 0.000300
2025-05-29 19:10:54,361 - INFO - joeynmt.training - Epoch   3, Step:    19400, Batch Loss:     1.592113, Batch Acc: 0.494110, Tokens per Sec:     6453, Lr: 0.000300
2025-05-29 19:11:04,007 - INFO - joeynmt.training - Epoch   3, Step:    19500, Batch Loss:     1.693723, Batch Acc: 0.494243, Tokens per Sec:     7312, Lr: 0.000300
2025-05-29 19:11:04,007 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:11:04,007 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:11:43,954 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.25, acc:   0.47, generation: 39.9020[sec], evaluation: 0.0000[sec]
2025-05-29 19:11:44,141 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/17000.ckpt
2025-05-29 19:11:44,158 - INFO - joeynmt.training - Example #0
2025-05-29 19:11:44,159 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:11:44,160 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:11:44,160 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'to@@', 'on@@', 'de', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 're@@', 'den', 'voor', 'de', 're@@', 'eu@@', 'w@@', 'en', 'de', 're@@', 'eu@@', 'ze', 'die', 'de', 'gr@@', 'on@@', 'd@@', 'heid', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'heid', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'heid', 'van', '4@@', '0', 'proc@@', 'ent', 'gesch@@', 're@@', 'cht', 'is.', '</s>']
2025-05-29 19:11:44,161 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:11:44,161 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:11:44,161 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee folië getoond om te vertoonde dat de artische ijskappen, die de reden voor de reeuwen de reeuze die de grondheid van de grondheid van de grondheid van 40 procent geschrecht is.
2025-05-29 19:11:44,161 - INFO - joeynmt.training - Example #1
2025-05-29 19:11:44,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:11:44,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:11:44,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'n@@', 'aa@@', 't.', '</s>']
2025-05-29 19:11:44,163 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:11:44,163 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:11:44,163 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste eerste problemen van dit speciale probleem, omdat het niet de dikke van de ijsknaat.
2025-05-29 19:11:44,163 - INFO - joeynmt.training - Example #2
2025-05-29 19:11:44,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:11:44,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:11:44,164 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:11:44,165 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:11:44,165 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:11:44,165 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen dat de artische ijskappen van onze wereldwijde klimaatsysteem.
2025-05-29 19:11:44,165 - INFO - joeynmt.training - Example #3
2025-05-29 19:11:44,166 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:11:44,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:11:44,166 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'u@@', 'i@@', 'v@@', 'en,', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:11:44,167 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:11:44,167 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:11:44,167 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schuiven, in de zomers.
2025-05-29 19:11:44,167 - INFO - joeynmt.training - Example #4
2025-05-29 19:11:44,167 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:11:44,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:11:44,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 're@@', 'c@@', 'te@@', 'ur@@', 's', 'die', 'ik', 'jullie', 'laten', 'zien', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:11:44,169 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:11:44,169 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:11:44,169 - INFO - joeynmt.training - 	Hypothesis: De volgende directeurs die ik jullie laten zien wat er gebeurt in de laatste 25 jaar gebeurd.
2025-05-29 19:11:53,419 - INFO - joeynmt.training - Epoch   3, Step:    19600, Batch Loss:     1.810220, Batch Acc: 0.496966, Tokens per Sec:     6982, Lr: 0.000300
2025-05-29 19:12:03,689 - INFO - joeynmt.training - Epoch   3, Step:    19700, Batch Loss:     1.710299, Batch Acc: 0.493298, Tokens per Sec:     6712, Lr: 0.000300
2025-05-29 19:12:12,908 - INFO - joeynmt.training - Epoch   3, Step:    19800, Batch Loss:     1.620584, Batch Acc: 0.494169, Tokens per Sec:     7629, Lr: 0.000300
2025-05-29 19:12:22,479 - INFO - joeynmt.training - Epoch   3, Step:    19900, Batch Loss:     1.878154, Batch Acc: 0.501186, Tokens per Sec:     7180, Lr: 0.000300
2025-05-29 19:12:32,060 - INFO - joeynmt.training - Epoch   3, Step:    20000, Batch Loss:     1.721871, Batch Acc: 0.494418, Tokens per Sec:     7555, Lr: 0.000300
2025-05-29 19:12:32,061 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:12:32,062 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:13:16,861 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.17, acc:   0.47, generation: 44.7554[sec], evaluation: 0.0000[sec]
2025-05-29 19:13:16,862 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:13:17,050 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/18000.ckpt
2025-05-29 19:13:17,068 - INFO - joeynmt.training - Example #0
2025-05-29 19:13:17,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:13:17,069 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:13:17,069 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', 'heb', 'ik', 'deze', 'twee', 'di@@', 'enen', 'jaar', 'om', 'te', 'ver@@', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 're@@', 'den', 'voor', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'uur', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'uur', 'van', 'de', '4@@', '0', 'proc@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'en.', '</s>']
2025-05-29 19:13:17,070 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:13:17,070 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:13:17,070 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden heb ik deze twee dienen jaar om te verzien dat de artische ijskappen, die voor de reden voor de reden van de reden van de onderste 48 uur van de onderste 48 uur van de 40 procent geschrumpen.
2025-05-29 19:13:17,070 - INFO - joeynmt.training - Example #1
2025-05-29 19:13:17,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:13:17,071 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:13:17,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'op@@', 'en@@', 'bare', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'be@@', 'l', 'van', 'het', 'ij@@', 's@@', 'be@@', 'l', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'be@@', 'l', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ijk', 'is', 'van', 'het', 'ij@@', 's@@', 'k@@', 'n@@', 'ip@@', '.', '</s>']
2025-05-29 19:13:17,072 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:13:17,072 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:13:17,073 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de openbare problemen van dit specifieke probleem, omdat het niet de dikke van het ijsje van het ijsbel van het ijsbel van het ijsje van het ijsbel van het ijskijk is van het ijsknip.
2025-05-29 19:13:17,073 - INFO - joeynmt.training - Example #2
2025-05-29 19:13:17,073 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:13:17,073 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:13:17,073 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'ge@@', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:13:17,074 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:13:17,074 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:13:17,075 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het geglobale klimaatsysteem.
2025-05-29 19:13:17,075 - INFO - joeynmt.training - Example #3
2025-05-29 19:13:17,075 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:13:17,075 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:13:17,075 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'en', 'z@@', 'om@@', 'er@@', 's,', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:13:17,076 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:13:17,076 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:13:17,077 - INFO - joeynmt.training - 	Hypothesis: Ze groeide en zomers, en zomers.
2025-05-29 19:13:17,077 - INFO - joeynmt.training - Example #4
2025-05-29 19:13:17,077 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:13:17,077 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:13:17,077 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 're@@', 'c@@', 'te@@', 'ur', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:13:17,078 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:13:17,078 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:13:17,078 - INFO - joeynmt.training - 	Hypothesis: De volgende directeur die ik jullie tonen wat er in de laatste 25 jaar gebeurd.
2025-05-29 19:13:26,620 - INFO - joeynmt.training - Epoch   3, Step:    20100, Batch Loss:     1.856844, Batch Acc: 0.498834, Tokens per Sec:     7209, Lr: 0.000300
2025-05-29 19:13:36,034 - INFO - joeynmt.training - Epoch   3, Step:    20200, Batch Loss:     1.582040, Batch Acc: 0.496782, Tokens per Sec:     7511, Lr: 0.000300
2025-05-29 19:13:45,555 - INFO - joeynmt.training - Epoch   3, Step:    20300, Batch Loss:     1.717594, Batch Acc: 0.499659, Tokens per Sec:     7242, Lr: 0.000300
2025-05-29 19:13:55,090 - INFO - joeynmt.training - Epoch   3, Step:    20400, Batch Loss:     1.666504, Batch Acc: 0.493254, Tokens per Sec:     7238, Lr: 0.000300
2025-05-29 19:14:04,575 - INFO - joeynmt.training - Epoch   3, Step:    20500, Batch Loss:     1.796677, Batch Acc: 0.496328, Tokens per Sec:     7608, Lr: 0.000300
2025-05-29 19:14:04,576 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:14:04,576 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:14:40,163 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.16, acc:   0.47, generation: 35.5511[sec], evaluation: 0.0000[sec]
2025-05-29 19:14:40,164 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:14:40,346 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/17500.ckpt
2025-05-29 19:14:40,366 - INFO - joeynmt.training - Example #0
2025-05-29 19:14:40,366 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:14:40,367 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:14:40,367 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'we', 'nu', 'nu', 'deze', 'twee', 'di@@', 'enen', 'ge@@', 'to@@', 'on@@', 'de', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'st@@', 'rij@@', 'd', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aa@@', 't.', '</s>']
2025-05-29 19:14:40,368 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:14:40,368 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:14:40,368 - INFO - joeynmt.training - 	Hypothesis: Laten we nu nu deze twee dienen getoonde dat de artische ijskappen, die de artische ijskappen, die de reden van de grondstrijd van de onderste 48 staat.
2025-05-29 19:14:40,368 - INFO - joeynmt.training - Example #1
2025-05-29 19:14:40,369 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:14:40,369 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:14:40,369 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'du@@', 'i@@', 'delijk', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'van', 'het', 'ij@@', 's@@', 'k@@', 'oo@@', 'p@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'ge@@', 'eft', 'van', 'de', 'ij@@', 's@@', 'be@@', 'hoe@@', 'f@@', 'te', 'van', 'de', 'ij@@', 's@@', 'en.', '</s>']
2025-05-29 19:14:40,370 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:14:40,370 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:14:40,370 - INFO - joeynmt.training - 	Hypothesis: Maar dit is duidelijk genoeg de eerste eerste van het ijskoop, omdat het niet de dikke van het ijsgeeft van de ijsbehoefte van de ijsen.
2025-05-29 19:14:40,370 - INFO - joeynmt.training - Example #2
2025-05-29 19:14:40,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:14:40,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:14:40,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'kel', 'is', 'de', 'ar@@', 'ti@@', 'kel', 'dat', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:14:40,371 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:14:40,371 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:14:40,372 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artikel is de artikel dat klimaatsysteem.
2025-05-29 19:14:40,372 - INFO - joeynmt.training - Example #3
2025-05-29 19:14:40,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:14:40,372 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:14:40,372 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:14:40,373 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:14:40,373 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:14:40,373 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schromp in het zomers.
2025-05-29 19:14:40,373 - INFO - joeynmt.training - Example #4
2025-05-29 19:14:40,373 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:14:40,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:14:40,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 're@@', 'c@@', 'te@@', 'ur', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 19:14:40,375 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:14:40,375 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:14:40,375 - INFO - joeynmt.training - 	Hypothesis: De volgende directeur die ik jullie laten zien is een tijdje in de laatste 25 jaar.
2025-05-29 19:14:49,045 - INFO - joeynmt.training - Epoch   3, Step:    20600, Batch Loss:     1.738901, Batch Acc: 0.496208, Tokens per Sec:     7796, Lr: 0.000300
2025-05-29 19:14:59,469 - INFO - joeynmt.training - Epoch   3, Step:    20700, Batch Loss:     1.816365, Batch Acc: 0.501944, Tokens per Sec:     6787, Lr: 0.000300
2025-05-29 19:15:09,550 - INFO - joeynmt.training - Epoch   3, Step:    20800, Batch Loss:     1.713294, Batch Acc: 0.501544, Tokens per Sec:     6970, Lr: 0.000300
2025-05-29 19:15:18,994 - INFO - joeynmt.training - Epoch   3, Step:    20900, Batch Loss:     1.747563, Batch Acc: 0.498242, Tokens per Sec:     7261, Lr: 0.000300
2025-05-29 19:15:28,760 - INFO - joeynmt.training - Epoch   3, Step:    21000, Batch Loss:     1.703591, Batch Acc: 0.497962, Tokens per Sec:     7210, Lr: 0.000300
2025-05-29 19:15:28,761 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:15:28,761 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:16:09,938 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.13, acc:   0.47, generation: 41.1308[sec], evaluation: 0.0000[sec]
2025-05-29 19:16:09,939 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:16:10,163 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/18500.ckpt
2025-05-29 19:16:10,183 - INFO - joeynmt.training - Example #0
2025-05-29 19:16:10,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:16:10,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:16:10,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'kel', 'te', 'ver@@', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', '1@@', '4@@', '0', 'proc@@', 'ent', 'gesch@@', 're@@', 'ven', 'en', '4@@', '0', 'proc@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 't.', '</s>']
2025-05-29 19:16:10,185 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:16:10,186 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:16:10,186 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden getoond om te verzien dat de artikel te verzien dat de artische ijskappen die voor de reden van de onderste 48 staten van de 140 procent geschreven en 40 procent geschrumpt.
2025-05-29 19:16:10,186 - INFO - joeynmt.training - Example #1
2025-05-29 19:16:10,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:16:10,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:16:10,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'eerste', 'dat', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'men', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'z@@', 'er', 'is.', '</s>']
2025-05-29 19:16:10,188 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:16:10,188 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:16:10,188 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste eerste eerste dat specifieke problemen van dit specifieke problemen van het ijsje van het ijszer is.
2025-05-29 19:16:10,188 - INFO - joeynmt.training - Example #2
2025-05-29 19:16:10,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:16:10,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:16:10,190 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', 'tu@@', 'ig@@', 'ig@@', 'ing', 'is', 'de', 'ar@@', 'ti@@', 'kel', 'het', 'p@@', 'ub@@', 'lie@@', 'k', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:16:10,192 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:16:10,192 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:16:10,193 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigiging is de artikel het publiek van onze wereldwijde klimaatsysteem.
2025-05-29 19:16:10,193 - INFO - joeynmt.training - Example #3
2025-05-29 19:16:10,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:16:10,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:16:10,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'u@@', 'w', 'in', 'het', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 19:16:10,194 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:16:10,195 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:16:10,195 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schuw in het zomer.
2025-05-29 19:16:10,195 - INFO - joeynmt.training - Example #4
2025-05-29 19:16:10,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:16:10,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:16:10,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'vol@@', 'gende', 'vol@@', 'gende', 'vol@@', 'gende', 'vol@@', 'gende', 'ge@@', 'dra@@', 'g', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:16:10,196 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:16:10,197 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:16:10,197 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende volgende volgende volgende gedrag is een tijdschrift van de laatste 25 jaar is gebeurd.
2025-05-29 19:16:19,939 - INFO - joeynmt.training - Epoch   3, Step:    21100, Batch Loss:     1.748184, Batch Acc: 0.500984, Tokens per Sec:     6861, Lr: 0.000300
2025-05-29 19:16:29,677 - INFO - joeynmt.training - Epoch   3, Step:    21200, Batch Loss:     1.758616, Batch Acc: 0.501021, Tokens per Sec:     7043, Lr: 0.000300
2025-05-29 19:16:38,982 - INFO - joeynmt.training - Epoch   3, Step:    21300, Batch Loss:     1.708464, Batch Acc: 0.493612, Tokens per Sec:     7613, Lr: 0.000300
2025-05-29 19:16:48,252 - INFO - joeynmt.training - Epoch   3, Step:    21400, Batch Loss:     1.869206, Batch Acc: 0.489200, Tokens per Sec:     7528, Lr: 0.000300
2025-05-29 19:16:57,154 - INFO - joeynmt.training - Epoch   3, Step:    21500, Batch Loss:     1.612133, Batch Acc: 0.496526, Tokens per Sec:     8004, Lr: 0.000300
2025-05-29 19:16:57,154 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:16:57,154 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:17:31,043 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.11, acc:   0.47, generation: 33.8499[sec], evaluation: 0.0000[sec]
2025-05-29 19:17:31,044 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:17:31,306 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/19500.ckpt
2025-05-29 19:17:31,365 - INFO - joeynmt.training - Example #0
2025-05-29 19:17:31,366 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:17:31,366 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:17:31,367 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'to@@', 'on@@', 't', 'te', 'ver@@', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aa@@', 't,', 'en', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'gesch@@', 're@@', 'v@@', 'en.', '</s>']
2025-05-29 19:17:31,368 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:17:31,368 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:17:31,368 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee getoond om te vertoont te verzien dat de artische ijskappen die voor de reden van de reden van de reden van de onderste 48 staat, en 40 procent van de onderste 40 procent geschreven.
2025-05-29 19:17:31,368 - INFO - joeynmt.training - Example #1
2025-05-29 19:17:31,369 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:17:31,369 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:17:31,369 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'ij@@', 'l@@', ',', 'dat', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'je@@', 's.', '</s>']
2025-05-29 19:17:31,370 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:17:31,370 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:17:31,370 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste stijl, dat is het niet de dikke probleem dat het niet de dikke van het ijsjes.
2025-05-29 19:17:31,370 - INFO - joeynmt.training - Example #2
2025-05-29 19:17:31,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:17:31,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:17:31,371 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'kel', 'is', 'de', 'ar@@', 'ti@@', 'kel', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:17:31,371 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:17:31,372 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:17:31,372 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artikel is de artikel van onze wereldwijde klimaatsysteem.
2025-05-29 19:17:31,372 - INFO - joeynmt.training - Example #3
2025-05-29 19:17:31,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:17:31,372 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:17:31,372 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'm@@', 'p', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:17:31,374 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:17:31,374 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:17:31,374 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en schrump in het zomers.
2025-05-29 19:17:31,374 - INFO - joeynmt.training - Example #4
2025-05-29 19:17:31,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:17:31,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:17:31,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'o', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:17:31,375 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:17:31,376 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:17:31,376 - INFO - joeynmt.training - 	Hypothesis: De volgende dio die ik jullie laten zien is een tijdschrift van wat er in de laatste 25 jaar is gebeurd.
2025-05-29 19:17:40,925 - INFO - joeynmt.training - Epoch   3, Step:    21600, Batch Loss:     1.724255, Batch Acc: 0.496763, Tokens per Sec:     7238, Lr: 0.000300
2025-05-29 19:17:50,524 - INFO - joeynmt.training - Epoch   3, Step:    21700, Batch Loss:     1.711560, Batch Acc: 0.501979, Tokens per Sec:     7188, Lr: 0.000300
2025-05-29 19:18:00,494 - INFO - joeynmt.training - Epoch   3, Step:    21800, Batch Loss:     1.873215, Batch Acc: 0.499581, Tokens per Sec:     7069, Lr: 0.000300
2025-05-29 19:18:10,173 - INFO - joeynmt.training - Epoch   3, Step:    21900, Batch Loss:     1.775114, Batch Acc: 0.498206, Tokens per Sec:     7083, Lr: 0.000300
2025-05-29 19:18:19,699 - INFO - joeynmt.training - Epoch   3, Step:    22000, Batch Loss:     1.641788, Batch Acc: 0.505374, Tokens per Sec:     7404, Lr: 0.000300
2025-05-29 19:18:19,701 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:18:19,702 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:18:57,583 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.08, acc:   0.48, generation: 37.8445[sec], evaluation: 0.0000[sec]
2025-05-29 19:18:57,584 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:18:57,762 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/19000.ckpt
2025-05-29 19:18:57,780 - INFO - joeynmt.training - Example #0
2025-05-29 19:18:57,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:18:57,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:18:57,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', 'heb', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijk@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'uur', 'van', 'de', '1@@', '4@@', '8', 'uur', 'van', 'de', '1@@', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'maa@@', 'kt.', '</s>']
2025-05-29 19:18:57,782 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:18:57,782 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:18:57,782 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden heb deze twee getoond om te verkijken, dat de artische ijskappe die voor de reden van de reden van de onderste 48 uur van de 148 uur van de 140 procent gemaakt.
2025-05-29 19:18:57,782 - INFO - joeynmt.training - Example #1
2025-05-29 19:18:57,783 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:18:57,783 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:18:57,783 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'ap@@', 'pen', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'be@@', 'et@@', 'je', 'van', 'het', 'ij@@', 's@@', 'be@@', 'et@@', 'je', 'van', 'het', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 19:18:57,784 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:18:57,784 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:18:57,784 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste stappen van dit specifiek is dat het niet de dikke dikke van het ijsje van het ijsbeetje van het ijsbeetje van het ijsver.
2025-05-29 19:18:57,784 - INFO - joeynmt.training - Example #2
2025-05-29 19:18:57,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:18:57,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:18:57,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:18:57,786 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:18:57,786 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:18:57,786 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het hart van onze wereldwijde klimaatsysteem.
2025-05-29 19:18:57,786 - INFO - joeynmt.training - Example #3
2025-05-29 19:18:57,786 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:18:57,786 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:18:57,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:18:57,787 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:18:57,787 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:18:57,787 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schrumpt in de zomers.
2025-05-29 19:18:57,787 - INFO - joeynmt.training - Example #4
2025-05-29 19:18:57,787 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:18:57,788 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:18:57,788 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:18:57,788 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:18:57,788 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:18:57,788 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschrift van wat er in de laatste 25 jaar gebeurd.
2025-05-29 19:19:07,295 - INFO - joeynmt.training - Epoch   3, Step:    22100, Batch Loss:     1.809968, Batch Acc: 0.502244, Tokens per Sec:     7159, Lr: 0.000300
2025-05-29 19:19:16,636 - INFO - joeynmt.training - Epoch   3, Step:    22200, Batch Loss:     1.804234, Batch Acc: 0.499898, Tokens per Sec:     7352, Lr: 0.000300
2025-05-29 19:19:26,028 - INFO - joeynmt.training - Epoch   3, Step:    22300, Batch Loss:     1.845312, Batch Acc: 0.499915, Tokens per Sec:     7550, Lr: 0.000300
2025-05-29 19:19:35,381 - INFO - joeynmt.training - Epoch   3, Step:    22400, Batch Loss:     1.970955, Batch Acc: 0.496229, Tokens per Sec:     7614, Lr: 0.000300
2025-05-29 19:19:44,216 - INFO - joeynmt.training - Epoch   3, Step:    22500, Batch Loss:     1.748378, Batch Acc: 0.499422, Tokens per Sec:     7927, Lr: 0.000300
2025-05-29 19:19:44,216 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:19:44,217 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:20:19,773 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.06, acc:   0.48, generation: 35.5124[sec], evaluation: 0.0000[sec]
2025-05-29 19:20:19,775 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:20:19,972 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/20000.ckpt
2025-05-29 19:20:19,990 - INFO - joeynmt.training - Example #0
2025-05-29 19:20:19,991 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:20:19,991 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:20:19,991 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'so@@', 'or@@', 'ten', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'zor@@', 'gen', 'dat', 'de', 'ar@@', 'ct@@', 'ie@@', 'c@@', 'ap@@', 'e,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'se', 'be@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'A@@', 'f@@', 'gel@@', 'ei@@', 'd', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'c@@', 'en@@', 'te', 'te', 'te', 'van', 'de', 're@@', 'den', 'van', 'de', 'mee@@', 'ste', '4@@', '8', 'st@@', 'aa@@', 't,', 'om', 'de', 're@@', 'c@@', 'l@@', 'am@@', 'e', 'te', 'ver@@']
2025-05-29 19:20:19,992 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:20:19,992 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:20:19,993 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee soorten getoond om te verzorgen dat de arctiecape, die de artische ijskappe die voor de reden van de grondse beste 48 staten van de onderste 40 procent van de Afgeleid van 40 procent van de reden van de reden van 40 procent van de reden van de recente te te van de reden van de meeste 48 staat, om de reclame te ver
2025-05-29 19:20:19,993 - INFO - joeynmt.training - Example #1
2025-05-29 19:20:19,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:20:19,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:20:19,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'ver@@', 'n@@', 'u@@', ',', 'dat', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'men', 'van', 'het', 'ij@@', 's@@', 'be@@', 'l', 'van', 'het', 'ij@@', 's@@', 'be@@', 'l', 'van', 'het', 'ij@@', 's@@', 'be@@', 'l', 'van', 'het', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 19:20:19,994 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:20:19,995 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:20:19,995 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de vernu, dat specifieke problemen van dit specifieke problemen van het ijsbel van het ijsbel van het ijsbel van het ijsver.
2025-05-29 19:20:19,995 - INFO - joeynmt.training - Example #2
2025-05-29 19:20:19,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:20:19,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:20:19,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'p@@', 'la@@', 'k@@', 'n@@', 'ip@@', 'per@@', 'e', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:20:19,996 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:20:19,997 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:20:19,997 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het plaknippere klimaatsysteem.
2025-05-29 19:20:19,997 - INFO - joeynmt.training - Example #3
2025-05-29 19:20:19,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:20:19,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:20:19,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:20:19,998 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:20:19,999 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:20:19,999 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schrumpt in de zomers.
2025-05-29 19:20:19,999 - INFO - joeynmt.training - Example #4
2025-05-29 19:20:19,999 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:20:20,000 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:20:20,000 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'st@@', 'ri@@', 'p@@', 'ut@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:20:20,001 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:20:20,001 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:20:20,001 - INFO - joeynmt.training - 	Hypothesis: De volgende distriputie die ik jullie laat zien wat er in de laatste 25 jaar gebeurd.
2025-05-29 19:20:29,674 - INFO - joeynmt.training - Epoch   3, Step:    22600, Batch Loss:     1.610393, Batch Acc: 0.497133, Tokens per Sec:     7276, Lr: 0.000300
2025-05-29 19:20:39,390 - INFO - joeynmt.training - Epoch   3, Step:    22700, Batch Loss:     1.707120, Batch Acc: 0.501053, Tokens per Sec:     7232, Lr: 0.000300
2025-05-29 19:20:48,989 - INFO - joeynmt.training - Epoch   3, Step:    22800, Batch Loss:     1.764635, Batch Acc: 0.497034, Tokens per Sec:     7551, Lr: 0.000300
2025-05-29 19:20:58,866 - INFO - joeynmt.training - Epoch   3, Step:    22900, Batch Loss:     1.760317, Batch Acc: 0.500114, Tokens per Sec:     7119, Lr: 0.000300
2025-05-29 19:21:09,095 - INFO - joeynmt.training - Epoch   3, Step:    23000, Batch Loss:     1.726174, Batch Acc: 0.500753, Tokens per Sec:     6950, Lr: 0.000300
2025-05-29 19:21:09,096 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:21:09,096 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:21:51,208 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.04, acc:   0.48, generation: 42.0668[sec], evaluation: 0.0000[sec]
2025-05-29 19:21:51,209 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:21:51,411 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/20500.ckpt
2025-05-29 19:21:51,427 - INFO - joeynmt.training - Example #0
2025-05-29 19:21:51,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:21:51,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:21:51,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'f@@', 'ol@@', 'en', 'ge@@', 'to@@', 'on@@', 't', 'om', 'te', 'ver@@', 'der', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'St@@', 'aten', 'ha@@', 'd,', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'gebeur@@', 'en.', '</s>']
2025-05-29 19:21:51,429 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:21:51,430 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:21:51,430 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee folen getoont om te verder te zien dat de artische ijskappen, die voor de artische ijskappen, die voor de onderste 48 Staten had, om 40 procent te gebeuren.
2025-05-29 19:21:51,430 - INFO - joeynmt.training - Example #1
2025-05-29 19:21:51,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:21:51,431 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:21:51,431 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'genoe@@', 'g', 'de', 'op@@', 'kom@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'het', 'ij@@', 's@@', 'ver@@', 'lie@@', 't.', '</s>']
2025-05-29 19:21:51,431 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:21:51,432 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:21:51,432 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de opkomst van dit specifieke probleem omdat het niet de dikke van het ijskwestie van het ijsverliet.
2025-05-29 19:21:51,432 - INFO - joeynmt.training - Example #2
2025-05-29 19:21:51,432 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:21:51,433 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:21:51,433 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'la@@', 'st@@', 'i@@', 'ma@@', 'ss@@', 'y@@', 'ste@@', 'em', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:21:51,434 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:21:51,435 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:21:51,435 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het lastimassysteem van onze wereldwijde klimaatsysteem.
2025-05-29 19:21:51,435 - INFO - joeynmt.training - Example #3
2025-05-29 19:21:51,435 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:21:51,436 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:21:51,436 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'mp@@', 't', 'in', 'het', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 19:21:51,437 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:21:51,437 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:21:51,437 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en schrumpt in het zomer.
2025-05-29 19:21:51,437 - INFO - joeynmt.training - Example #4
2025-05-29 19:21:51,438 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:21:51,438 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:21:51,438 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'een', 'tij@@', 'd@@', 'je', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:21:51,438 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:21:51,438 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:21:51,439 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie een tijdje een tijdje in de laatste 25 jaar gebeurd.
2025-05-29 19:22:00,926 - INFO - joeynmt.training - Epoch   3, Step:    23100, Batch Loss:     1.688675, Batch Acc: 0.498968, Tokens per Sec:     7081, Lr: 0.000300
2025-05-29 19:22:10,078 - INFO - joeynmt.training - Epoch   3, Step:    23200, Batch Loss:     1.547385, Batch Acc: 0.500815, Tokens per Sec:     7510, Lr: 0.000300
2025-05-29 19:22:19,145 - INFO - joeynmt.training - Epoch   3, Step:    23300, Batch Loss:     1.592642, Batch Acc: 0.505531, Tokens per Sec:     7757, Lr: 0.000300
2025-05-29 19:22:27,595 - INFO - joeynmt.training - Epoch   3, Step:    23400, Batch Loss:     1.860007, Batch Acc: 0.493858, Tokens per Sec:     8114, Lr: 0.000300
2025-05-29 19:22:35,940 - INFO - joeynmt.training - Epoch   3, Step:    23500, Batch Loss:     1.686207, Batch Acc: 0.501487, Tokens per Sec:     8261, Lr: 0.000300
2025-05-29 19:22:35,941 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:22:35,941 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:23:16,712 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   5.99, acc:   0.48, generation: 40.7338[sec], evaluation: 0.0000[sec]
2025-05-29 19:23:16,713 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:23:16,912 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/21000.ckpt
2025-05-29 19:23:16,929 - INFO - joeynmt.training - Example #0
2025-05-29 19:23:16,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:23:16,930 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:23:16,930 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Op', 'dit', 'mom@@', 'ent', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'om', 'te', 'ver@@', 'tel@@', 't', 'te', 'ver@@', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', '1@@', '0@@', '%', 'van', 'de', '1@@', '0@@', '%', 'van', 'de', '4@@', '0', 'proc@@', 'ent', 'was', 'ge@@', 'ï@@', 'm@@', 'd.', '</s>']
2025-05-29 19:23:16,931 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:23:16,931 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:23:16,932 - INFO - joeynmt.training - 	Hypothesis: Op dit moment heb ik deze twee dia om te vertelt te verzien dat de artische ijskappe ijskappe die voor de reden van de onderste 48 staten van de 10% van de 10% van de 40 procent was geïmd.
2025-05-29 19:23:16,932 - INFO - joeynmt.training - Example #1
2025-05-29 19:23:16,932 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:23:16,932 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:23:16,932 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'eerste', 'is', 'dat', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'es', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 19:23:16,933 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:23:16,934 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:23:16,934 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste eerste eerste is dat speciale probleem van dit speciale probleem omdat het niet de dikke van het ijses toont.
2025-05-29 19:23:16,934 - INFO - joeynmt.training - Example #2
2025-05-29 19:23:16,934 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:23:16,934 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:23:16,934 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:23:16,935 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:23:16,935 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:23:16,936 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe klimaatsysteem.
2025-05-29 19:23:16,936 - INFO - joeynmt.training - Example #3
2025-05-29 19:23:16,936 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:23:16,936 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:23:16,936 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p', 'in', 'het', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 19:23:16,937 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:23:16,937 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:23:16,938 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schromp in het zomer.
2025-05-29 19:23:16,938 - INFO - joeynmt.training - Example #4
2025-05-29 19:23:16,938 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:23:16,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:23:16,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'oon', 'een', 'tij@@', 'd@@', 'je', 'van', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de.', '</s>']
2025-05-29 19:23:16,939 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:23:16,939 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:23:16,940 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik toon een tijdje van wat er in de laatste 25 jaar gebeurde.
2025-05-29 19:23:26,591 - INFO - joeynmt.training - Epoch   3, Step:    23600, Batch Loss:     1.872205, Batch Acc: 0.506943, Tokens per Sec:     7181, Lr: 0.000300
2025-05-29 19:23:36,021 - INFO - joeynmt.training - Epoch   3, Step:    23700, Batch Loss:     1.598206, Batch Acc: 0.508332, Tokens per Sec:     7637, Lr: 0.000300
2025-05-29 19:23:45,566 - INFO - joeynmt.training - Epoch   3, Step:    23800, Batch Loss:     1.730980, Batch Acc: 0.504113, Tokens per Sec:     7221, Lr: 0.000300
2025-05-29 19:23:55,046 - INFO - joeynmt.training - Epoch   3, Step:    23900, Batch Loss:     1.634235, Batch Acc: 0.499864, Tokens per Sec:     7374, Lr: 0.000300
2025-05-29 19:24:04,411 - INFO - joeynmt.training - Epoch   3, Step:    24000, Batch Loss:     1.553301, Batch Acc: 0.502701, Tokens per Sec:     7750, Lr: 0.000300
2025-05-29 19:24:04,412 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:24:04,412 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:24:46,056 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   5.99, acc:   0.48, generation: 41.6006[sec], evaluation: 0.0000[sec]
2025-05-29 19:24:46,057 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:24:46,256 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/21500.ckpt
2025-05-29 19:24:46,277 - INFO - joeynmt.training - Example #0
2025-05-29 19:24:46,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:24:46,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:24:46,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'de', 'ge@@', 'to@@', 'on@@', 'de', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'ge@@', 'vol@@', 'gen', 'van', 'de', 're@@', 'c@@', 'en@@', 'te', 'be@@', 'stu@@', 'der@@']
2025-05-29 19:24:46,279 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:24:46,279 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:24:46,279 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee getoonde getoonde dat de artische ijskappen, dat de artische ijskappen, die voor de reden van de onderste 48 staten van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de reden den van de reden van de onderste 40 procent van de reden van de onderkant van de gevolgen van de recente bestuder
2025-05-29 19:24:46,279 - INFO - joeynmt.training - Example #1
2025-05-29 19:24:46,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:24:46,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:24:46,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'is', 'dat', 'het', 'niet', 'zo', 'ge@@', 'spe@@', 'ci@@', 'alis@@', 'eerde', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ijk', 'l@@', 'aat', 'zien.', '</s>']
2025-05-29 19:24:46,281 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:24:46,281 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:24:46,281 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste eerste is dat het niet zo gespecialiseerde probleem omdat het niet de dicke van het ijskijk laat zien.
2025-05-29 19:24:46,282 - INFO - joeynmt.training - Example #2
2025-05-29 19:24:46,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:24:46,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:24:46,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:24:46,283 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:24:46,283 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:24:46,283 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen van onze wereldwijde klimaatsysteem.
2025-05-29 19:24:46,285 - INFO - joeynmt.training - Example #3
2025-05-29 19:24:46,285 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:24:46,285 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:24:46,285 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', '.', '</s>']
2025-05-29 19:24:46,286 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:24:46,286 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:24:46,286 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroep.
2025-05-29 19:24:46,286 - INFO - joeynmt.training - Example #4
2025-05-29 19:24:46,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:24:46,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:24:46,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'je', 't@@', 'on@@', 'en', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:24:46,288 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:24:46,288 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:24:46,288 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen is een tijdje tonen wat er gebeurt in de laatste 25 jaar is gebeurd.
2025-05-29 19:24:55,976 - INFO - joeynmt.training - Epoch   3, Step:    24100, Batch Loss:     1.631427, Batch Acc: 0.499631, Tokens per Sec:     7104, Lr: 0.000300
2025-05-29 19:25:04,841 - INFO - joeynmt.training - Epoch   3, Step:    24200, Batch Loss:     1.765139, Batch Acc: 0.495418, Tokens per Sec:     7831, Lr: 0.000300
2025-05-29 19:25:13,348 - INFO - joeynmt.training - Epoch   3, Step:    24300, Batch Loss:     1.667134, Batch Acc: 0.512136, Tokens per Sec:     7885, Lr: 0.000300
2025-05-29 19:25:21,915 - INFO - joeynmt.training - Epoch   3, Step:    24400, Batch Loss:     1.898790, Batch Acc: 0.498795, Tokens per Sec:     8092, Lr: 0.000300
2025-05-29 19:25:30,503 - INFO - joeynmt.training - Epoch   3, Step:    24500, Batch Loss:     1.632695, Batch Acc: 0.499684, Tokens per Sec:     7926, Lr: 0.000300
2025-05-29 19:25:30,505 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:25:30,505 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:26:12,258 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   5.99, acc:   0.48, generation: 41.7111[sec], evaluation: 0.0000[sec]
2025-05-29 19:26:12,445 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/22000.ckpt
2025-05-29 19:26:12,462 - INFO - joeynmt.training - Example #0
2025-05-29 19:26:12,464 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:26:12,464 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:26:12,464 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'ik', 'deze', 'twee', 'di@@', 'a', 'to@@', 'on@@', 't', 'om', 'te', 'ver@@', 'anderen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en', 'die', 'de', 'gr@@', 'on@@', 'd@@', 'se', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'uur', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'was', 'ge@@', 'dur@@', 'ende', '4@@', '0', 'proc@@', 'ent', 'van', 'de', '1@@', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'maa@@', 'kt.', '</s>']
2025-05-29 19:26:12,465 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:26:12,466 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:26:12,466 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia getoond ik deze twee dia toont om te veranderen dat de artische ijskappen die de grondse grondstoffen van de onderste 48 uur van de onderste 40 procent was gedurende 40 procent van de 140 procent is gemaakt.
2025-05-29 19:26:12,466 - INFO - joeynmt.training - Example #1
2025-05-29 19:26:12,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:26:12,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:26:12,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'is', 'dat', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'es', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 19:26:12,468 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:26:12,468 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:26:12,468 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste eerste is dat speciale problemen van dit speciale probleem omdat het niet de dikke van de ijskes toont.
2025-05-29 19:26:12,468 - INFO - joeynmt.training - Example #2
2025-05-29 19:26:12,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:26:12,469 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:26:12,469 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:26:12,470 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:26:12,470 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:26:12,470 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het slaaglobale klimaatsysteem.
2025-05-29 19:26:12,470 - INFO - joeynmt.training - Example #3
2025-05-29 19:26:12,471 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:26:12,471 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:26:12,471 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'u@@', 'il@@', '.', '</s>']
2025-05-29 19:26:12,472 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:26:12,472 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:26:12,472 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schuil.
2025-05-29 19:26:12,472 - INFO - joeynmt.training - Example #4
2025-05-29 19:26:12,473 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:26:12,473 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:26:12,473 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 're@@', 'c@@', 'te@@', 'ur', 'die', 'ik', 't@@', 'oon', 'l@@', 'aat', 'zien', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:26:12,474 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:26:12,474 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:26:12,474 - INFO - joeynmt.training - 	Hypothesis: De volgende directeur die ik toon laat zien wat er in de laatste 25 jaar gebeurd.
2025-05-29 19:26:22,440 - INFO - joeynmt.training - Epoch   3, Step:    24600, Batch Loss:     1.621918, Batch Acc: 0.499958, Tokens per Sec:     7028, Lr: 0.000300
2025-05-29 19:26:32,157 - INFO - joeynmt.training - Epoch   3, Step:    24700, Batch Loss:     1.745901, Batch Acc: 0.507012, Tokens per Sec:     7193, Lr: 0.000300
2025-05-29 19:26:41,774 - INFO - joeynmt.training - Epoch   3, Step:    24800, Batch Loss:     1.748533, Batch Acc: 0.499865, Tokens per Sec:     7305, Lr: 0.000300
2025-05-29 19:26:51,424 - INFO - joeynmt.training - Epoch   3, Step:    24900, Batch Loss:     1.547711, Batch Acc: 0.503499, Tokens per Sec:     7526, Lr: 0.000300
2025-05-29 19:27:00,980 - INFO - joeynmt.training - Epoch   3, Step:    25000, Batch Loss:     1.794954, Batch Acc: 0.505866, Tokens per Sec:     7441, Lr: 0.000300
2025-05-29 19:27:00,981 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:27:00,981 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:27:35,158 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.96, acc:   0.48, generation: 34.1368[sec], evaluation: 0.0000[sec]
2025-05-29 19:27:35,160 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:27:35,350 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/22500.ckpt
2025-05-29 19:27:35,371 - INFO - joeynmt.training - Example #0
2025-05-29 19:27:35,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:27:35,372 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:27:35,372 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'de', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'voor', 'de', 'gr@@', 'on@@', 'd@@', 'se', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'de', 'onder@@', 'ste', '4@@', '8', 'proc@@', 'ent', 'van', 'de', '1@@', '0@@', '%', 'van', 'de', '1@@', '0@@', '%', 'van', 'de', '1@@', '0@@', '%', 'van', 'de', '1@@', '0@@', '%', 'van', 'de', '1@@', '0@@', '%', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'be@@', 'vol@@', 'k@@', 'ing', 'van', 'de', '1@@', '0@@', '%', 'proc@@', 'ent', 'van', 'de', 'ge@@', 'vol@@', 'gen', 'van', 'de', 'ge@@', 'vol@@', 'gen', 'van', 'de', '1@@', '0@@', '%']
2025-05-29 19:27:35,373 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:27:35,373 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:27:35,373 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoonde dat de artische ijskappe die voor de artische ijskappe die voor de grondse ijskappe die de onderste 48 procent van de 10% van de 10% van de 10% van de 10% van de 10% procent van de reden van de reden van de bevolking van de 10% procent van de gevolgen van de gevolgen van de 10%
2025-05-29 19:27:35,373 - INFO - joeynmt.training - Example #1
2025-05-29 19:27:35,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:27:35,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:27:35,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'men', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 19:27:35,375 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:27:35,375 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:27:35,375 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste is dat het specifieke problemen van dit specifieke problemen omdat het niet de dikke van het ijskaart toont.
2025-05-29 19:27:35,376 - INFO - joeynmt.training - Example #2
2025-05-29 19:27:35,376 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:27:35,376 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:27:35,376 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'p@@', 'la@@', 'st@@', 'i@@', 'c', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:27:35,377 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:27:35,380 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:27:35,380 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het plastic van onze wereldwijde klimaatsysteem.
2025-05-29 19:27:35,381 - INFO - joeynmt.training - Example #3
2025-05-29 19:27:35,381 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:27:35,381 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:27:35,381 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'u@@', 'p@@', '.', '</s>']
2025-05-29 19:27:35,382 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:27:35,382 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:27:35,383 - INFO - joeynmt.training - 	Hypothesis: Ze groeide in het winter en schup.
2025-05-29 19:27:35,383 - INFO - joeynmt.training - Example #4
2025-05-29 19:27:35,383 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:27:35,383 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:27:35,383 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:27:35,384 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:27:35,385 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:27:35,385 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje in de afgelopen 25 jaar gebeurd.
2025-05-29 19:27:44,588 - INFO - joeynmt.training - Epoch   3, Step:    25100, Batch Loss:     1.719414, Batch Acc: 0.501902, Tokens per Sec:     7418, Lr: 0.000300
2025-05-29 19:27:52,973 - INFO - joeynmt.training - Epoch   3, Step:    25200, Batch Loss:     1.649000, Batch Acc: 0.503332, Tokens per Sec:     8305, Lr: 0.000300
2025-05-29 19:28:01,498 - INFO - joeynmt.training - Epoch   3, Step:    25300, Batch Loss:     1.654742, Batch Acc: 0.506369, Tokens per Sec:     8399, Lr: 0.000300
2025-05-29 19:28:09,910 - INFO - joeynmt.training - Epoch   3, Step:    25400, Batch Loss:     1.582711, Batch Acc: 0.497735, Tokens per Sec:     8345, Lr: 0.000300
2025-05-29 19:28:18,840 - INFO - joeynmt.training - Epoch   3, Step:    25500, Batch Loss:     1.610186, Batch Acc: 0.513138, Tokens per Sec:     7598, Lr: 0.000300
2025-05-29 19:28:18,841 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:28:18,842 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:29:00,338 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.93, acc:   0.48, generation: 41.4560[sec], evaluation: 0.0000[sec]
2025-05-29 19:29:00,340 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:29:00,531 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/23000.ckpt
2025-05-29 19:29:00,550 - INFO - joeynmt.training - Example #0
2025-05-29 19:29:00,551 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:29:00,551 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:29:00,551 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'het', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'zien', 'dat', 'de', 'ar@@', 'ct@@', 'ie', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 're@@', 'den', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'lan@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'lan@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 'lan@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'twee', 'di@@', 'enen', 'jaren', 'de', 're@@', 'den', 'van', 'de', 'twee', 'di@@', 'a', 'ge@@', 'vol@@', 'g', 'van']
2025-05-29 19:29:00,552 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:29:00,553 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:29:00,553 - INFO - joeynmt.training - 	Hypothesis: In het jaar heb ik deze twee dia getoond om te verzien dat de arctie te bekijken dat de artische ijskappen, de reden drie miljoen jaar de grondstoffen van 40 procent van de landen van 40 procent van de landen van 40 procent van de reden van de landen van 40 procent van de reden van de reden van de reden van de reden van de twee dienen jaren de reden van de twee dia gevolg van
2025-05-29 19:29:00,553 - INFO - joeynmt.training - Example #1
2025-05-29 19:29:00,553 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:29:00,554 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:29:00,554 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'genoe@@', 'g', 'is', 'dat', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van@@', 'uit', 'het', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'het', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ru@@', 'i@@', 'd', 'van', 'de', 'ij@@', 's', 'van', 'het', 'ij@@', 'z@@', 'en.', '</s>']
2025-05-29 19:29:00,554 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:29:00,554 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:29:00,555 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg is dat het specifieke probleem van dit speciale probleem vanuit het ijs van de ijs van de ijskaart van het ijskaart van het ijskruid van de ijs van het ijzen.
2025-05-29 19:29:00,555 - INFO - joeynmt.training - Example #2
2025-05-29 19:29:00,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:29:00,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:29:00,555 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:29:00,556 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:29:00,557 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:29:00,557 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het slaagde klimaatsysteem van onze wereldwijde klimaatsysteem.
2025-05-29 19:29:00,557 - INFO - joeynmt.training - Example #3
2025-05-29 19:29:00,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:29:00,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:29:00,558 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 's@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:29:00,558 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:29:00,559 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:29:00,559 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en somers.
2025-05-29 19:29:00,559 - INFO - joeynmt.training - Example #4
2025-05-29 19:29:00,559 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:29:00,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:29:00,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'st@@', 'ri@@', 'p@@', ',', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:29:00,561 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:29:00,561 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:29:00,561 - INFO - joeynmt.training - 	Hypothesis: De volgende distrip, is een tijdperk van wat er in de afgelopen 25 jaar gebeurd.
2025-05-29 19:29:10,347 - INFO - joeynmt.training - Epoch   3, Step:    25600, Batch Loss:     1.821273, Batch Acc: 0.504351, Tokens per Sec:     6970, Lr: 0.000300
2025-05-29 19:29:19,918 - INFO - joeynmt.training - Epoch   3, Step:    25700, Batch Loss:     1.695479, Batch Acc: 0.507179, Tokens per Sec:     7672, Lr: 0.000300
2025-05-29 19:29:29,421 - INFO - joeynmt.training - Epoch   3, Step:    25800, Batch Loss:     1.720948, Batch Acc: 0.505157, Tokens per Sec:     7203, Lr: 0.000300
2025-05-29 19:29:39,130 - INFO - joeynmt.training - Epoch   3, Step:    25900, Batch Loss:     1.774572, Batch Acc: 0.497439, Tokens per Sec:     7362, Lr: 0.000300
2025-05-29 19:29:48,658 - INFO - joeynmt.training - Epoch   3, Step:    26000, Batch Loss:     1.600915, Batch Acc: 0.508832, Tokens per Sec:     7280, Lr: 0.000300
2025-05-29 19:29:48,658 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:29:48,658 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:30:37,445 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.91, acc:   0.48, generation: 48.7452[sec], evaluation: 0.0000[sec]
2025-05-29 19:30:37,446 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:30:37,623 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/23500.ckpt
2025-05-29 19:30:37,640 - INFO - joeynmt.training - Example #0
2025-05-29 19:30:37,641 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:30:37,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:30:37,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 't', 'om', 'te', 'ver@@', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'be@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', '4@@', '0@@', '%', 'van', 'de', 're@@', 'den', 'van', '4@@', '0@@', '%', 'van', 'de', 'mensen', 'die', '4@@', '0@@', '%', 'van', 'de', 'mensen', 'die', '4@@', '0@@', '%', 'van', '4@@', '0@@', '%', 'van', 'de', 're@@', 'den', 'van', '4@@', '0@@', '%', 'van', '4@@', '0@@', '%', 'van', 'de', 're@@', 'den', 'van', '4@@', '0@@', '%', 'van', 'de', 'vol@@', 'gende', '4@@', '0@@', '%', 'van', 'de', 'mensen', 'die', 'twee', 'keer', 'dat']
2025-05-29 19:30:37,642 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:30:37,642 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:30:37,642 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee getoont om te verzien dat de artische ijskappen, dat de artische ijskappen, die voor de reden van de reden van de grootte van de beste 48 staten van 40% van de reden van 40% van de mensen die 40% van de mensen die 40% van 40% van de reden van 40% van 40% van de reden van 40% van de volgende 40% van de mensen die twee keer dat
2025-05-29 19:30:37,642 - INFO - joeynmt.training - Example #1
2025-05-29 19:30:37,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:30:37,643 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:30:37,643 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'is', 'dat', 'de', 'eerste', 'st@@', 'ij@@', 'ging', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van@@', 'uit', 'de', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'het', 'ij@@', 's@@', 'je@@', 's.', '</s>']
2025-05-29 19:30:37,644 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:30:37,644 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:30:37,644 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg is dat de eerste stijging van dit speciale probleem vanuit de ijskwestie van het ijsjes.
2025-05-29 19:30:37,644 - INFO - joeynmt.training - Example #2
2025-05-29 19:30:37,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:30:37,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:30:37,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:30:37,646 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:30:37,646 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:30:37,646 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het hart van onze wereldwijde klimaatsysteem.
2025-05-29 19:30:37,646 - INFO - joeynmt.training - Example #3
2025-05-29 19:30:37,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:30:37,647 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:30:37,647 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'k@@', 'ken@@', 'd', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:30:37,648 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:30:37,648 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:30:37,648 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schokkend in de zomers.
2025-05-29 19:30:37,648 - INFO - joeynmt.training - Example #4
2025-05-29 19:30:37,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:30:37,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:30:37,649 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:30:37,650 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:30:37,650 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:30:37,650 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende dia die ik jullie laten zien, is een tijdperk in de laatste 25 jaar is gebeurd.
2025-05-29 19:30:46,190 - INFO - joeynmt.training - Epoch   3, Step:    26100, Batch Loss:     1.600694, Batch Acc: 0.498938, Tokens per Sec:     7918, Lr: 0.000300
2025-05-29 19:30:54,702 - INFO - joeynmt.training - Epoch   3, Step:    26200, Batch Loss:     1.757353, Batch Acc: 0.507853, Tokens per Sec:     8223, Lr: 0.000300
2025-05-29 19:31:03,915 - INFO - joeynmt.training - Epoch   3, Step:    26300, Batch Loss:     1.728561, Batch Acc: 0.507594, Tokens per Sec:     7690, Lr: 0.000300
2025-05-29 19:31:13,437 - INFO - joeynmt.training - Epoch   3, Step:    26400, Batch Loss:     1.727431, Batch Acc: 0.509117, Tokens per Sec:     7517, Lr: 0.000300
2025-05-29 19:31:21,795 - INFO - joeynmt.training - Epoch   3, Step:    26500, Batch Loss:     1.660769, Batch Acc: 0.507275, Tokens per Sec:     8118, Lr: 0.000300
2025-05-29 19:31:21,795 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:31:21,796 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:32:02,329 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.90, acc:   0.48, generation: 40.4924[sec], evaluation: 0.0000[sec]
2025-05-29 19:32:02,330 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:32:02,532 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/24500.ckpt
2025-05-29 19:32:02,549 - INFO - joeynmt.training - Example #0
2025-05-29 19:32:02,550 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:32:02,550 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:32:02,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 't', 'om', 'te', 'ver@@', 'anderen', 'om', 'te', 'ver@@', 'anderen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 're@@', 'eu@@', 'ze', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'ijk@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'was', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-29 19:32:02,551 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:32:02,551 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:32:02,552 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoont om te veranderen om te veranderen dat de artische ijskappen, die voor de reeuze die drie miljoen jaar de grijkste 40 procent was om 40 procent te verzamelen.
2025-05-29 19:32:02,552 - INFO - joeynmt.training - Example #1
2025-05-29 19:32:02,553 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:32:02,553 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:32:02,553 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'dat', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't', 'te', 'zien.', '</s>']
2025-05-29 19:32:02,554 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:32:02,555 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:32:02,555 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste dat specifiek van dit speciale probleem omdat het niet de dikke van het ijs toont te zien.
2025-05-29 19:32:02,555 - INFO - joeynmt.training - Example #2
2025-05-29 19:32:02,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:32:02,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:32:02,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:32:02,557 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:32:02,557 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:32:02,557 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het slaaglobale klimaatsysteem.
2025-05-29 19:32:02,557 - INFO - joeynmt.training - Example #3
2025-05-29 19:32:02,558 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:32:02,558 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:32:02,558 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'u@@', 'il@@', '.', '</s>']
2025-05-29 19:32:02,559 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:32:02,559 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:32:02,559 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en schuil.
2025-05-29 19:32:02,559 - INFO - joeynmt.training - Example #4
2025-05-29 19:32:02,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:32:02,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:32:02,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'een', 'tij@@', 'd@@', 'je', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de.', '</s>']
2025-05-29 19:32:02,561 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:32:02,561 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:32:02,562 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie een tijdje is een tijdje in de laatste 25 jaar gebeurde.
2025-05-29 19:32:12,114 - INFO - joeynmt.training - Epoch   3, Step:    26600, Batch Loss:     1.680919, Batch Acc: 0.504027, Tokens per Sec:     7271, Lr: 0.000300
2025-05-29 19:32:21,933 - INFO - joeynmt.training - Epoch   3, Step:    26700, Batch Loss:     1.766824, Batch Acc: 0.502384, Tokens per Sec:     7327, Lr: 0.000300
2025-05-29 19:32:31,532 - INFO - joeynmt.training - Epoch   3, Step:    26800, Batch Loss:     1.695508, Batch Acc: 0.500579, Tokens per Sec:     7559, Lr: 0.000300
2025-05-29 19:32:40,899 - INFO - joeynmt.training - Epoch   3, Step:    26900, Batch Loss:     1.765640, Batch Acc: 0.508615, Tokens per Sec:     7639, Lr: 0.000300
2025-05-29 19:32:50,426 - INFO - joeynmt.training - Epoch   3, Step:    27000, Batch Loss:     1.793940, Batch Acc: 0.505780, Tokens per Sec:     7420, Lr: 0.000300
2025-05-29 19:32:50,427 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:32:50,427 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:33:27,037 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.86, acc:   0.48, generation: 36.5764[sec], evaluation: 0.0000[sec]
2025-05-29 19:33:27,037 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:33:27,206 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/24000.ckpt
2025-05-29 19:33:27,223 - INFO - joeynmt.training - Example #0
2025-05-29 19:33:27,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:33:27,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:33:27,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'jaar', 'gele@@', 'den', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'kel', 'te', 'kijk@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'kel@@', 'en', 'jaar', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@']
2025-05-29 19:33:27,225 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:33:27,225 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:33:27,226 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar geleden om te zien dat de artikel te kijken, dat de artische ijskappen, die voor de artikelen jaar de grondstoffen van de grondstoffen van de onderste 40 procent van de onderkant van 40 procent van de reden van 40 procent van de reden van 40 procent van de reden van 40 procent van de reden van de reden van de reden van de reden van de reden van de re
2025-05-29 19:33:27,226 - INFO - joeynmt.training - Example #1
2025-05-29 19:33:27,226 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:33:27,226 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:33:27,226 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'ap@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'je', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 19:33:27,227 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:33:27,227 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:33:27,228 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste stap, omdat het niet de dikke probleem omdat het niet de dikke van het ijsje toont.
2025-05-29 19:33:27,228 - INFO - joeynmt.training - Example #2
2025-05-29 19:33:27,228 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:33:27,228 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:33:27,228 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', ',', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'de', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:33:27,229 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:33:27,229 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:33:27,230 - INFO - joeynmt.training - 	Hypothesis: In zekere zin, is de artische ijskappe is het slaagde hart van onze wereldwijde klimaatsysteem.
2025-05-29 19:33:27,230 - INFO - joeynmt.training - Example #3
2025-05-29 19:33:27,230 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:33:27,230 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:33:27,230 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 're@@', 'ef@@', '.', '</s>']
2025-05-29 19:33:27,231 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:33:27,231 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:33:27,231 - INFO - joeynmt.training - 	Hypothesis: Ze groeide in het winter en schreef.
2025-05-29 19:33:27,231 - INFO - joeynmt.training - Example #4
2025-05-29 19:33:27,232 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:33:27,232 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:33:27,232 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'oon', 'een', 'tij@@', 'd@@', 'je', 'van', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:33:27,233 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:33:27,233 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:33:27,233 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik toon een tijdje van de afgelopen 25 jaar gebeurd.
2025-05-29 19:33:35,967 - INFO - joeynmt.training - Epoch   3, Step:    27100, Batch Loss:     1.777910, Batch Acc: 0.511761, Tokens per Sec:     7779, Lr: 0.000300
2025-05-29 19:33:45,355 - INFO - joeynmt.training - Epoch   3, Step:    27200, Batch Loss:     1.898434, Batch Acc: 0.504465, Tokens per Sec:     7434, Lr: 0.000300
2025-05-29 19:33:54,638 - INFO - joeynmt.training - Epoch   3, Step:    27300, Batch Loss:     1.601079, Batch Acc: 0.505108, Tokens per Sec:     7413, Lr: 0.000300
2025-05-29 19:34:04,877 - INFO - joeynmt.training - Epoch   3, Step:    27400, Batch Loss:     1.707625, Batch Acc: 0.504655, Tokens per Sec:     6871, Lr: 0.000300
2025-05-29 19:34:14,227 - INFO - joeynmt.training - Epoch   3, Step:    27500, Batch Loss:     1.624589, Batch Acc: 0.509362, Tokens per Sec:     7604, Lr: 0.000300
2025-05-29 19:34:14,227 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:34:14,227 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:34:59,876 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.86, acc:   0.48, generation: 45.6088[sec], evaluation: 0.0000[sec]
2025-05-29 19:34:59,877 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:35:00,082 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/25000.ckpt
2025-05-29 19:35:00,100 - INFO - joeynmt.training - Example #0
2025-05-29 19:35:00,100 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:35:00,101 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:35:00,101 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'g', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 'gro@@', 'ter@@', 'e', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'maakt', 'van', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 19:35:00,102 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:35:00,102 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:35:00,102 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolg getoond om te verzien dat de artische ijskappen, die de artische ijskappen, de grotere van de onderste 48 staten van de onderste 40 procent is gemaakt van 40 procent is geslaagd is.
2025-05-29 19:35:00,102 - INFO - joeynmt.training - Example #1
2025-05-29 19:35:00,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:35:00,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:35:00,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'eerste', 'is', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's@@', 'z@@', 'er', 'to@@', 'on@@', 't', 'is.', '</s>']
2025-05-29 19:35:00,105 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:35:00,105 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:35:00,105 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste eerste is van dit speciale problemen omdat het niet de dikke van het ijs van de ijs van de ijszer toont is.
2025-05-29 19:35:00,105 - INFO - joeynmt.training - Example #2
2025-05-29 19:35:00,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:35:00,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:35:00,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'c@@', 'ale', 'ij@@', 'f@@', 'ic@@', 'atie', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:35:00,107 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:35:00,107 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:35:00,107 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de articale ijficatie van onze wereldwijd hart van onze wereldwijd klimaatsysteem.
2025-05-29 19:35:00,107 - INFO - joeynmt.training - Example #3
2025-05-29 19:35:00,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:35:00,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:35:00,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 're@@', 'ef@@', '.', '</s>']
2025-05-29 19:35:00,109 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:35:00,109 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:35:00,109 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en schreef.
2025-05-29 19:35:00,110 - INFO - joeynmt.training - Example #4
2025-05-29 19:35:00,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:35:00,110 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:35:00,110 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'ge@@', 'vol@@', 'g', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:35:00,111 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:35:00,111 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:35:00,112 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik jullie laten zien is een tijdschrift van wat er in de laatste 25 jaar gebeurd.
2025-05-29 19:35:09,661 - INFO - joeynmt.training - Epoch   3, Step:    27600, Batch Loss:     1.971777, Batch Acc: 0.505629, Tokens per Sec:     7126, Lr: 0.000300
2025-05-29 19:35:18,852 - INFO - joeynmt.training - Epoch   3: total training loss 15760.94
2025-05-29 19:35:18,852 - INFO - joeynmt.training - EPOCH 4
2025-05-29 19:35:19,472 - INFO - joeynmt.training - Epoch   4, Step:    27700, Batch Loss:     1.596746, Batch Acc: 0.527383, Tokens per Sec:     6381, Lr: 0.000300
2025-05-29 19:35:29,180 - INFO - joeynmt.training - Epoch   4, Step:    27800, Batch Loss:     1.509917, Batch Acc: 0.523980, Tokens per Sec:     7437, Lr: 0.000300
2025-05-29 19:35:38,749 - INFO - joeynmt.training - Epoch   4, Step:    27900, Batch Loss:     1.655565, Batch Acc: 0.523992, Tokens per Sec:     7372, Lr: 0.000300
2025-05-29 19:35:48,019 - INFO - joeynmt.training - Epoch   4, Step:    28000, Batch Loss:     1.787387, Batch Acc: 0.517971, Tokens per Sec:     7328, Lr: 0.000300
2025-05-29 19:35:48,020 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:35:48,020 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:36:29,411 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.85, acc:   0.49, generation: 41.3368[sec], evaluation: 0.0000[sec]
2025-05-29 19:36:29,413 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:36:29,597 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/25500.ckpt
2025-05-29 19:36:29,620 - INFO - joeynmt.training - Example #0
2025-05-29 19:36:29,621 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:36:29,621 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:36:29,621 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'de', 'te', 'laten', 'zi@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 'gr@@', 'oo@@', 'g', 'van', 'de', 'gr@@', 'ij@@', 'ze', 'hebben', '4@@', '8', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 'ar@@', 'ti@@', 'kel', 'en', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 's@@', 'ult@@', 'aten', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'mensen', 'die', 'de', 'gr@@', 'ij@@', 'ze', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@']
2025-05-29 19:36:29,622 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:36:29,622 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:36:29,622 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoonde te laten zien, dat de artische ijskappen, die voor de artische ijskappen, de groog van de grijze hebben 48 procent van de onderste 40 procent van de onderste 40 procent van de reden van 40 procent van de reden van de artikel en 40 procent van de resultaten van 40 procent van de mensen die de grijze 40 procent van de re
2025-05-29 19:36:29,623 - INFO - joeynmt.training - Example #1
2025-05-29 19:36:29,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:36:29,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:36:29,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'art@@', 'te', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'men', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'ber@@', 'oe@@', 'p@@', 's@@', 'be@@', 'kijk@@', 'en.', '</s>']
2025-05-29 19:36:29,624 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:36:29,624 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:36:29,624 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste startte van dit specifieke problemen omdat het niet de dikke van de ijsberoepsbekijken.
2025-05-29 19:36:29,625 - INFO - joeynmt.training - Example #2
2025-05-29 19:36:29,625 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:36:29,625 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:36:29,625 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en', 'het', 'sl@@', 'aa@@', 'g@@', 'de', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:36:29,629 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:36:29,630 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:36:29,630 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het slaagde hart van onze wereldklimaatsysteem.
2025-05-29 19:36:29,630 - INFO - joeynmt.training - Example #3
2025-05-29 19:36:29,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:36:29,631 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:36:29,631 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:36:29,632 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:36:29,632 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:36:29,632 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en schrumpt in de zomers.
2025-05-29 19:36:29,632 - INFO - joeynmt.training - Example #4
2025-05-29 19:36:29,633 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:36:29,633 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:36:29,633 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:36:29,634 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:36:29,634 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:36:29,634 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift van wat er in de laatste 25 jaar gebeurd.
2025-05-29 19:36:39,143 - INFO - joeynmt.training - Epoch   4, Step:    28100, Batch Loss:     1.721690, Batch Acc: 0.516281, Tokens per Sec:     7378, Lr: 0.000300
2025-05-29 19:36:48,483 - INFO - joeynmt.training - Epoch   4, Step:    28200, Batch Loss:     1.576505, Batch Acc: 0.520871, Tokens per Sec:     7472, Lr: 0.000300
2025-05-29 19:36:57,813 - INFO - joeynmt.training - Epoch   4, Step:    28300, Batch Loss:     1.735501, Batch Acc: 0.517018, Tokens per Sec:     7479, Lr: 0.000300
2025-05-29 19:37:07,117 - INFO - joeynmt.training - Epoch   4, Step:    28400, Batch Loss:     1.639904, Batch Acc: 0.520603, Tokens per Sec:     7410, Lr: 0.000300
2025-05-29 19:37:15,718 - INFO - joeynmt.training - Epoch   4, Step:    28500, Batch Loss:     1.568962, Batch Acc: 0.519802, Tokens per Sec:     8339, Lr: 0.000300
2025-05-29 19:37:15,718 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:37:15,719 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:37:59,180 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.85, acc:   0.49, generation: 43.4183[sec], evaluation: 0.0000[sec]
2025-05-29 19:37:59,181 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:37:59,384 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/26000.ckpt
2025-05-29 19:37:59,400 - INFO - joeynmt.training - Example #0
2025-05-29 19:37:59,401 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:37:59,401 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:37:59,401 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'zien', 'die', 'twee', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'de', 'mee@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste']
2025-05-29 19:37:59,402 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:37:59,402 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:37:59,402 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gezien die twee gevolgen om te zien dat de artische ijskappe ijskappe ijskappe die de meeste 48 staten van de onderste 48 staten van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de reden van de reden van de onderste 40 procent van de onderste 40 procent van de reden van de onderste 48 staten van de onderste
2025-05-29 19:37:59,402 - INFO - joeynmt.training - Example #1
2025-05-29 19:37:59,403 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:37:59,403 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:37:59,403 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'men', 'van', 'dit', 'soort', 'd@@', 'k@@', 'ik@@', 'ker@@', '.', '</s>']
2025-05-29 19:37:59,404 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:37:59,404 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:37:59,404 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste staat, want het is niet de dikke problemen van dit soort dkikker.
2025-05-29 19:37:59,404 - INFO - joeynmt.training - Example #2
2025-05-29 19:37:59,404 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:37:59,404 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:37:59,404 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sch@@', 'aa@@', 'k@@', '-@@', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:37:59,405 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:37:59,405 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:37:59,405 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het schaak-hart van onze wereldwijde klimaatsysteem.
2025-05-29 19:37:59,406 - INFO - joeynmt.training - Example #3
2025-05-29 19:37:59,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:37:59,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:37:59,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'en', 'en', 'sch@@', 'u@@', 'il@@', ',', 'en', 'sch@@', 'o@@', 'on@@', '.', '</s>']
2025-05-29 19:37:59,407 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:37:59,407 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:37:59,407 - INFO - joeynmt.training - 	Hypothesis: Ze groeien en en schuil, en schoon.
2025-05-29 19:37:59,407 - INFO - joeynmt.training - Example #4
2025-05-29 19:37:59,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:37:59,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:37:59,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:37:59,408 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:37:59,408 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:37:59,409 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschrift van wat er in de afgelopen 25 jaar is gebeurd.
2025-05-29 19:38:09,082 - INFO - joeynmt.training - Epoch   4, Step:    28600, Batch Loss:     1.628276, Batch Acc: 0.518564, Tokens per Sec:     7336, Lr: 0.000300
2025-05-29 19:38:18,643 - INFO - joeynmt.training - Epoch   4, Step:    28700, Batch Loss:     1.581995, Batch Acc: 0.515204, Tokens per Sec:     7179, Lr: 0.000300
2025-05-29 19:38:28,192 - INFO - joeynmt.training - Epoch   4, Step:    28800, Batch Loss:     1.528004, Batch Acc: 0.512817, Tokens per Sec:     7367, Lr: 0.000300
2025-05-29 19:38:37,976 - INFO - joeynmt.training - Epoch   4, Step:    28900, Batch Loss:     1.604562, Batch Acc: 0.517877, Tokens per Sec:     7137, Lr: 0.000300
2025-05-29 19:38:47,539 - INFO - joeynmt.training - Epoch   4, Step:    29000, Batch Loss:     1.650095, Batch Acc: 0.520933, Tokens per Sec:     7505, Lr: 0.000300
2025-05-29 19:38:47,540 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:38:47,540 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:39:20,106 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.82, acc:   0.49, generation: 32.5266[sec], evaluation: 0.0000[sec]
2025-05-29 19:39:20,107 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:39:20,300 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/26500.ckpt
2025-05-29 19:39:20,317 - INFO - joeynmt.training - Example #0
2025-05-29 19:39:20,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:39:20,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:39:20,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'jaar', 'gele@@', 'den', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'gr@@', 'oo@@', 'g', 'van', 'de', 'gr@@', 'o@@', 'ze', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ter@@', 'e', 'st@@', 'aten', 'van', '4@@', '0', 'proc@@', 'ent', 'was', 'ge@@', 'ï@@', 'n@@', 'ter@@', 'ess@@', 'eerd', 'in', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'at@@', 'is', 'van', 'de', 'mee@@']
2025-05-29 19:39:20,320 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:39:20,320 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:39:20,320 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee getoond jaar geleden heb ik deze twee getoond, om te zien dat de artische ijskappen, die voor de groog van de groze drie miljoen jaar de grotere staten van 40 procent was geïnteresseerd in de onderste 40 procent van de onderste 40 procent van de reden van de onderste 40 procent van de onderste 40 procent van de reden van de reden van de gratis van de mee
2025-05-29 19:39:20,320 - INFO - joeynmt.training - Example #1
2025-05-29 19:39:20,321 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:39:20,321 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:39:20,321 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'n@@', 'u@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'ver@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's@@', 'ver@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's@@', 'ver@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's@@', 'ver@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's@@', 'ver@@', 's', 'van', 'het', 'ij@@', 'st', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'dat', 'is', 'dat', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'niet']
2025-05-29 19:39:20,322 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:39:20,322 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:39:20,322 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste nut van dit specifieke probleem omdat het niet de dikke dikke van het ijsvers van het ijs van het ijsvers van het ijs van het ijs van het ijs van het ijsvers van het ijs van het ijs van het ijs van het ijsvers van het ijs van het ijsvers van het ijst is niet de dikke probleem dat is dat specifieke probleem niet
2025-05-29 19:39:20,323 - INFO - joeynmt.training - Example #2
2025-05-29 19:39:20,323 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:39:20,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:39:20,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'c@@', 'ale', 'ij@@', 'f@@', 's@@', 'el', 'het', 'p@@', 'la@@', 'k@@', 'n@@', 'aa@@', 'st', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:39:20,324 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:39:20,324 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:39:20,325 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de articale ijfsel het plaknaast het hart van onze wereldklimaatsysteem.
2025-05-29 19:39:20,325 - INFO - joeynmt.training - Example #3
2025-05-29 19:39:20,325 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:39:20,325 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:39:20,325 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 't', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'u@@', 'p@@', ',', 'ze', 'gro@@', 'ei@@', 't.', '</s>']
2025-05-29 19:39:20,326 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:39:20,326 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:39:20,327 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schup, ze groeit.
2025-05-29 19:39:20,327 - INFO - joeynmt.training - Example #4
2025-05-29 19:39:20,327 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:39:20,327 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:39:20,328 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'je', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'is', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:39:20,328 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:39:20,329 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:39:20,329 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je tonen is een tijdschrift is in de afgelopen 25 jaar is gebeurd.
2025-05-29 19:39:30,486 - INFO - joeynmt.training - Epoch   4, Step:    29100, Batch Loss:     1.395372, Batch Acc: 0.516548, Tokens per Sec:     6577, Lr: 0.000300
2025-05-29 19:39:39,888 - INFO - joeynmt.training - Epoch   4, Step:    29200, Batch Loss:     1.594352, Batch Acc: 0.520116, Tokens per Sec:     7407, Lr: 0.000300
2025-05-29 19:39:49,184 - INFO - joeynmt.training - Epoch   4, Step:    29300, Batch Loss:     1.743066, Batch Acc: 0.520864, Tokens per Sec:     7615, Lr: 0.000300
2025-05-29 19:39:58,533 - INFO - joeynmt.training - Epoch   4, Step:    29400, Batch Loss:     1.769513, Batch Acc: 0.518768, Tokens per Sec:     7307, Lr: 0.000300
2025-05-29 19:40:07,973 - INFO - joeynmt.training - Epoch   4, Step:    29500, Batch Loss:     1.461732, Batch Acc: 0.514618, Tokens per Sec:     7682, Lr: 0.000300
2025-05-29 19:40:07,973 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:40:07,973 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:40:47,519 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.83, acc:   0.49, generation: 39.4993[sec], evaluation: 0.0000[sec]
2025-05-29 19:40:47,715 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/27000.ckpt
2025-05-29 19:40:47,732 - INFO - joeynmt.training - Example #0
2025-05-29 19:40:47,733 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:40:47,733 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:40:47,733 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'zor@@', 'gen', 'dat', 'de', 'ar@@', 'ti@@', 'kel', 'dat', 'de', 'ar@@', 'ti@@', 'kel', 'die', 'voor', 'de', 'lan@@', 'den', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'die', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'gebeur@@', 't.', '</s>']
2025-05-29 19:40:47,734 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:40:47,735 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:40:47,735 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verzorgen dat de artikel dat de artikel die voor de landen die voor de onderste 48 staten die de onderste 40 procent van de onderste 40 procent gebeurt.
2025-05-29 19:40:47,735 - INFO - joeynmt.training - Example #1
2025-05-29 19:40:47,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:40:47,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:40:47,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'in@@', 't@@', 'ie@@', 'k', 'genoe@@', 'g', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'is', 'dat', 'niet', 'de', 'di@@', 'k@@', 'ke', 'be@@', 'hoe@@', 'f@@', 'te', 'van', 'het', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 19:40:47,737 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:40:47,737 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:40:47,737 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste intiek genoeg van dit specifiek is dat niet de dikke behoefte van het ijsver.
2025-05-29 19:40:47,737 - INFO - joeynmt.training - Example #2
2025-05-29 19:40:47,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:40:47,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:40:47,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'c@@', 'a', 'het', 'p@@', 'ra@@', 'kt@@', 'ijk@@', ',', 'het', 'sl@@', 'im@@', 'me', 'het', 'p@@', 'ub@@', 'lie@@', 'ke', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:40:47,739 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:40:47,739 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:40:47,739 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artica het praktijk, het slimme het publieke klimaatsysteem.
2025-05-29 19:40:47,739 - INFO - joeynmt.training - Example #3
2025-05-29 19:40:47,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:40:47,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:40:47,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 19:40:47,741 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:40:47,741 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:40:47,741 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schrumpt in de zomer.
2025-05-29 19:40:47,741 - INFO - joeynmt.training - Example #4
2025-05-29 19:40:47,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:40:47,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:40:47,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd', 'is.', '</s>']
2025-05-29 19:40:47,743 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:40:47,743 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:40:47,743 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje in de afgelopen 25 jaar gebeurd is.
2025-05-29 19:40:57,223 - INFO - joeynmt.training - Epoch   4, Step:    29600, Batch Loss:     1.728622, Batch Acc: 0.521802, Tokens per Sec:     7018, Lr: 0.000300
2025-05-29 19:41:06,550 - INFO - joeynmt.training - Epoch   4, Step:    29700, Batch Loss:     1.504578, Batch Acc: 0.511993, Tokens per Sec:     7702, Lr: 0.000300
2025-05-29 19:41:16,201 - INFO - joeynmt.training - Epoch   4, Step:    29800, Batch Loss:     1.744989, Batch Acc: 0.520886, Tokens per Sec:     7263, Lr: 0.000300
2025-05-29 19:41:25,899 - INFO - joeynmt.training - Epoch   4, Step:    29900, Batch Loss:     1.494588, Batch Acc: 0.520223, Tokens per Sec:     7246, Lr: 0.000300
2025-05-29 19:41:35,347 - INFO - joeynmt.training - Epoch   4, Step:    30000, Batch Loss:     1.767490, Batch Acc: 0.517875, Tokens per Sec:     7352, Lr: 0.000300
2025-05-29 19:41:35,348 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:41:35,348 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:42:09,730 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.78, acc:   0.49, generation: 34.3376[sec], evaluation: 0.0000[sec]
2025-05-29 19:42:09,731 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:42:09,908 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/27500.ckpt
2025-05-29 19:42:09,926 - INFO - joeynmt.training - Example #0
2025-05-29 19:42:09,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:42:09,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:42:09,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'g', 'ge@@', 'to@@', 'ond', 'om', 'te', 'kijken', 'naar', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en', 'die', 'de', 're@@', 'den', 'voor', 'de', 'A@@', 'zi@@', 'ë@@', ',', 'die', 'voor', 'de', 'lan@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', '4@@', '0', 'proc@@', 'ent', 'was', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd', 'om', '4@@', '0', 'proc@@', 'ent', 'is.', '</s>']
2025-05-29 19:42:09,929 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:42:09,929 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:42:09,929 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolg getoond om te kijken naar de artische ijskappen die de reden voor de Azië, die voor de landen van de onderste 48 staten van 40 procent van de 40 procent was gegooid om 40 procent is.
2025-05-29 19:42:09,929 - INFO - joeynmt.training - Example #1
2025-05-29 19:42:09,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:42:09,930 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:42:09,930 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'omdat', 'het', 'ge@@', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'het', 'ij@@', 's@@', 'ver@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's@@', '-@@', 'pro@@', 'f@@', 'it@@', '.', '</s>']
2025-05-29 19:42:09,932 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:42:09,932 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:42:09,932 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste staat, omdat het gespecifiek van het ijsvers van de ijs van de ijs van de ijs-profit.
2025-05-29 19:42:09,932 - INFO - joeynmt.training - Example #2
2025-05-29 19:42:09,933 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:42:09,933 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:42:09,933 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'p@@', 'la@@', 'st@@', 'i@@', 'ma@@', 'ss@@', 'a@@', 'ir@@', 'e', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:42:09,934 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:42:09,934 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:42:09,934 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het plastimassaire klimaatsysteem.
2025-05-29 19:42:09,934 - INFO - joeynmt.training - Example #3
2025-05-29 19:42:09,935 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:42:09,936 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:42:09,936 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 19:42:09,937 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:42:09,937 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:42:09,937 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schrumpt in de zomer.
2025-05-29 19:42:09,937 - INFO - joeynmt.training - Example #4
2025-05-29 19:42:09,938 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:42:09,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:42:09,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'je', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'die', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:42:09,939 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:42:09,939 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:42:09,939 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laten zien is een tijdje die in de afgelopen 25 jaar gebeurd.
2025-05-29 19:42:19,436 - INFO - joeynmt.training - Epoch   4, Step:    30100, Batch Loss:     1.659781, Batch Acc: 0.516762, Tokens per Sec:     7247, Lr: 0.000300
2025-05-29 19:42:29,259 - INFO - joeynmt.training - Epoch   4, Step:    30200, Batch Loss:     1.581517, Batch Acc: 0.519829, Tokens per Sec:     7204, Lr: 0.000300
2025-05-29 19:42:38,803 - INFO - joeynmt.training - Epoch   4, Step:    30300, Batch Loss:     1.523681, Batch Acc: 0.521070, Tokens per Sec:     7584, Lr: 0.000300
2025-05-29 19:42:48,102 - INFO - joeynmt.training - Epoch   4, Step:    30400, Batch Loss:     1.625709, Batch Acc: 0.515422, Tokens per Sec:     7623, Lr: 0.000300
2025-05-29 19:42:57,541 - INFO - joeynmt.training - Epoch   4, Step:    30500, Batch Loss:     1.546374, Batch Acc: 0.520143, Tokens per Sec:     7389, Lr: 0.000300
2025-05-29 19:42:57,541 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:42:57,542 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:43:41,907 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.79, acc:   0.49, generation: 44.3168[sec], evaluation: 0.0000[sec]
2025-05-29 19:43:42,121 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/28000.ckpt
2025-05-29 19:43:42,139 - INFO - joeynmt.training - Example #0
2025-05-29 19:43:42,141 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:43:42,141 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:43:42,141 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'voor', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'voor', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'voor', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'f@@', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'A@@', 'ar@@', 'de', 'van', 'de', '1@@', '0@@', '%', 'van', 'de', 'A@@', 'ar@@', 'de', 'van', 'de', 'A@@', 'ar@@', 'de', 'voor', 'de', 'l@@', 'oo@@', 'p', 'van', 'de', 'A@@', 'ar@@', 'de', 'van', 'de', 'A@@', 'ar@@', 'de', 'voor', 'de', 'A@@', 'ar@@', 'de', 'voor', 'de', 'l@@', 'ij@@', 'nen', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 'groot@@', 'te']
2025-05-29 19:43:42,142 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:43:42,142 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:43:42,143 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia getoond om te zien dat de artische ijskappen dat de artische ijskapen die voor de grondstoffen voor de grondstoffen voor de grondstof, om 40 procent van de Aarde van de 10% van de Aarde van de Aarde voor de loop van de Aarde van de Aarde voor de Aarde voor de lijnen 40 procent van de reden van de grootte
2025-05-29 19:43:42,143 - INFO - joeynmt.training - Example #1
2025-05-29 19:43:42,143 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:43:42,143 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:43:42,143 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'en@@', 'aar@@', 's', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em@@', ',', 'omdat', 'het', 'to@@', 'on@@', 't', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 19:43:42,144 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:43:42,144 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:43:42,145 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste stenaars van dit specifieke probleem, omdat het toont niet de dikke van de ijsver.
2025-05-29 19:43:42,145 - INFO - joeynmt.training - Example #2
2025-05-29 19:43:42,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:43:42,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:43:42,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'dat', 'sl@@', 'aa@@', 'g@@', 'de', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:43:42,146 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:43:42,147 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:43:42,147 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen dat slaagde hart van onze wereldwijd klimaatsysteem.
2025-05-29 19:43:42,147 - INFO - joeynmt.training - Example #3
2025-05-29 19:43:42,147 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:43:42,147 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:43:42,147 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:43:42,148 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:43:42,148 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:43:42,148 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schromp in de zomers.
2025-05-29 19:43:42,149 - INFO - joeynmt.training - Example #4
2025-05-29 19:43:42,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:43:42,149 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:43:42,149 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'op', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de.', '</s>']
2025-05-29 19:43:42,150 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:43:42,150 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:43:42,150 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje op de laatste 25 jaar gebeurde.
2025-05-29 19:43:51,808 - INFO - joeynmt.training - Epoch   4, Step:    30600, Batch Loss:     1.739173, Batch Acc: 0.517087, Tokens per Sec:     6854, Lr: 0.000300
2025-05-29 19:44:01,488 - INFO - joeynmt.training - Epoch   4, Step:    30700, Batch Loss:     1.634088, Batch Acc: 0.520171, Tokens per Sec:     7400, Lr: 0.000300
2025-05-29 19:44:11,223 - INFO - joeynmt.training - Epoch   4, Step:    30800, Batch Loss:     1.614550, Batch Acc: 0.511597, Tokens per Sec:     7140, Lr: 0.000300
2025-05-29 19:44:20,778 - INFO - joeynmt.training - Epoch   4, Step:    30900, Batch Loss:     1.477442, Batch Acc: 0.518612, Tokens per Sec:     7343, Lr: 0.000300
2025-05-29 19:44:29,947 - INFO - joeynmt.training - Epoch   4, Step:    31000, Batch Loss:     1.656182, Batch Acc: 0.524084, Tokens per Sec:     7729, Lr: 0.000300
2025-05-29 19:44:29,948 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:44:29,948 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:45:02,780 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.77, acc:   0.49, generation: 32.7846[sec], evaluation: 0.0000[sec]
2025-05-29 19:45:02,781 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:45:02,972 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/28500.ckpt
2025-05-29 19:45:02,988 - INFO - joeynmt.training - Example #0
2025-05-29 19:45:02,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:45:02,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:45:02,990 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'der', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'is', 'gesch@@', 'ru@@', 'mp@@', 't.', '</s>']
2025-05-29 19:45:02,991 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:45:02,991 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:45:02,991 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verder te zien dat de artische ijskappen, de reden van de reden van de onderste 48 staten van de onderste 48 staten van de onderste 40 procent is geschrumpt.
2025-05-29 19:45:02,991 - INFO - joeynmt.training - Example #1
2025-05-29 19:45:02,992 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:45:02,992 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:45:02,992 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'e,', 'de', 'eerste', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'men', 'van', 'het', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 19:45:02,993 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:45:02,993 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:45:02,993 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste, de eerste van dit specifieke problemen van het ijsver.
2025-05-29 19:45:02,993 - INFO - joeynmt.training - Example #2
2025-05-29 19:45:02,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:45:02,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:45:02,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'p@@', 'la@@', 'k', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:45:02,995 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:45:02,995 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:45:02,995 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het plak van onze wereldwijde klimaatsysteem.
2025-05-29 19:45:02,995 - INFO - joeynmt.training - Example #3
2025-05-29 19:45:02,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:45:02,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:45:02,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'en', 'en', 'sch@@', 'ru@@', 'mp@@', 't', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:45:02,997 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:45:02,997 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:45:02,997 - INFO - joeynmt.training - 	Hypothesis: Ze groeien en en schrumpt in het zomers.
2025-05-29 19:45:02,997 - INFO - joeynmt.training - Example #4
2025-05-29 19:45:02,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:45:02,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:45:02,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:45:02,998 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:45:02,998 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:45:02,998 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje van de laatste 25 jaar is gebeurd.
2025-05-29 19:45:12,686 - INFO - joeynmt.training - Epoch   4, Step:    31100, Batch Loss:     1.597914, Batch Acc: 0.514392, Tokens per Sec:     7229, Lr: 0.000300
2025-05-29 19:45:22,231 - INFO - joeynmt.training - Epoch   4, Step:    31200, Batch Loss:     1.763509, Batch Acc: 0.512510, Tokens per Sec:     7199, Lr: 0.000300
2025-05-29 19:45:31,681 - INFO - joeynmt.training - Epoch   4, Step:    31300, Batch Loss:     1.644617, Batch Acc: 0.510759, Tokens per Sec:     7255, Lr: 0.000300
2025-05-29 19:45:41,261 - INFO - joeynmt.training - Epoch   4, Step:    31400, Batch Loss:     1.614951, Batch Acc: 0.514771, Tokens per Sec:     7425, Lr: 0.000300
2025-05-29 19:45:50,653 - INFO - joeynmt.training - Epoch   4, Step:    31500, Batch Loss:     1.684934, Batch Acc: 0.518233, Tokens per Sec:     7694, Lr: 0.000300
2025-05-29 19:45:50,654 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:45:50,654 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:46:33,571 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.73, acc:   0.49, generation: 42.8745[sec], evaluation: 0.0000[sec]
2025-05-29 19:46:33,572 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:46:33,760 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/29500.ckpt
2025-05-29 19:46:33,777 - INFO - joeynmt.training - Example #0
2025-05-29 19:46:33,778 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:46:33,778 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:46:33,778 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'de', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'antwoor@@', 'delijk', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', '4@@', '0', 'proc@@', 'ent', 'is.', '</s>']
2025-05-29 19:46:33,780 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:46:33,780 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:46:33,780 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoonde getoond om te verantwoordelijk dat de artische ijskappen die voor de reden van de onderkant van de onderkant van de onderkant van 48 staten van de onderkant van 40 procent is.
2025-05-29 19:46:33,780 - INFO - joeynmt.training - Example #1
2025-05-29 19:46:33,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:46:33,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:46:33,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 19:46:33,782 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:46:33,782 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:46:33,782 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste staat, dat het speciale probleem van dit ijsver.
2025-05-29 19:46:33,783 - INFO - joeynmt.training - Example #2
2025-05-29 19:46:33,783 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:46:33,783 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:46:33,783 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', ',', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:46:33,784 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:46:33,785 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:46:33,785 - INFO - joeynmt.training - 	Hypothesis: In zekere zin, is de artische ijskappe klimaatsysteem.
2025-05-29 19:46:33,785 - INFO - joeynmt.training - Example #3
2025-05-29 19:46:33,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:46:33,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:46:33,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'en', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 19:46:33,786 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:46:33,787 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:46:33,787 - INFO - joeynmt.training - 	Hypothesis: Ze groeien en en zomer.
2025-05-29 19:46:33,787 - INFO - joeynmt.training - Example #4
2025-05-29 19:46:33,787 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:46:33,788 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:46:33,788 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:46:33,789 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:46:33,789 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:46:33,789 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdje in de laatste 25 jaar is gebeurd.
2025-05-29 19:46:43,507 - INFO - joeynmt.training - Epoch   4, Step:    31600, Batch Loss:     1.649711, Batch Acc: 0.515032, Tokens per Sec:     7055, Lr: 0.000300
2025-05-29 19:46:53,066 - INFO - joeynmt.training - Epoch   4, Step:    31700, Batch Loss:     1.551410, Batch Acc: 0.522310, Tokens per Sec:     7489, Lr: 0.000300
2025-05-29 19:47:02,814 - INFO - joeynmt.training - Epoch   4, Step:    31800, Batch Loss:     1.701473, Batch Acc: 0.520045, Tokens per Sec:     7134, Lr: 0.000300
2025-05-29 19:47:12,319 - INFO - joeynmt.training - Epoch   4, Step:    31900, Batch Loss:     1.677230, Batch Acc: 0.512418, Tokens per Sec:     7333, Lr: 0.000300
2025-05-29 19:47:21,532 - INFO - joeynmt.training - Epoch   4, Step:    32000, Batch Loss:     1.533905, Batch Acc: 0.514644, Tokens per Sec:     7672, Lr: 0.000300
2025-05-29 19:47:21,532 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:47:21,532 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:48:00,734 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.71, acc:   0.49, generation: 39.1609[sec], evaluation: 0.0000[sec]
2025-05-29 19:48:00,735 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:48:00,944 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/29000.ckpt
2025-05-29 19:48:00,991 - INFO - joeynmt.training - Example #0
2025-05-29 19:48:00,992 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:48:00,992 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:48:00,992 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 't', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'in', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'w@@', 'ijn@@', 'lijk', 'was', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'tro@@', 'uw@@', 'en.', '</s>']
2025-05-29 19:48:00,993 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:48:00,993 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:48:00,994 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoont om te zien dat de artische ijskappen die voor de artische ijskap, die voor de reden van de grondstoffen in de onderste 40 procent van de grondwijnlijk was gegooid om 40 procent te vertrouwen.
2025-05-29 19:48:00,994 - INFO - joeynmt.training - Example #1
2025-05-29 19:48:00,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:48:00,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:48:00,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'op@@', 'pen', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'uit@@', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'je', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 19:48:00,995 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:48:00,995 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:48:00,996 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste stoppen van dit speciale probleem uit, want het is niet de dikke dikke van het ijsje toont.
2025-05-29 19:48:00,996 - INFO - joeynmt.training - Example #2
2025-05-29 19:48:00,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:48:00,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:48:00,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:48:00,997 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:48:00,997 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:48:00,998 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen van de klimaatsysteem.
2025-05-29 19:48:00,998 - INFO - joeynmt.training - Example #3
2025-05-29 19:48:00,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:48:00,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:48:00,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'mp@@', 'pt', 'in', 'het', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 19:48:01,000 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:48:01,000 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:48:01,000 - INFO - joeynmt.training - 	Hypothesis: Ze groeide in de winter en schrumppt in het zomert.
2025-05-29 19:48:01,000 - INFO - joeynmt.training - Example #4
2025-05-29 19:48:01,001 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:48:01,001 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:48:01,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:48:01,002 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:48:01,002 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:48:01,002 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdperk in de afgelopen 25 jaar gebeurd.
2025-05-29 19:48:11,137 - INFO - joeynmt.training - Epoch   4, Step:    32100, Batch Loss:     1.509939, Batch Acc: 0.520091, Tokens per Sec:     6775, Lr: 0.000300
2025-05-29 19:48:20,712 - INFO - joeynmt.training - Epoch   4, Step:    32200, Batch Loss:     1.355669, Batch Acc: 0.510521, Tokens per Sec:     7281, Lr: 0.000300
2025-05-29 19:48:29,906 - INFO - joeynmt.training - Epoch   4, Step:    32300, Batch Loss:     1.938745, Batch Acc: 0.518264, Tokens per Sec:     7564, Lr: 0.000300
2025-05-29 19:48:39,620 - INFO - joeynmt.training - Epoch   4, Step:    32400, Batch Loss:     1.806302, Batch Acc: 0.517997, Tokens per Sec:     7113, Lr: 0.000300
2025-05-29 19:48:49,403 - INFO - joeynmt.training - Epoch   4, Step:    32500, Batch Loss:     1.666196, Batch Acc: 0.524293, Tokens per Sec:     7231, Lr: 0.000300
2025-05-29 19:48:49,404 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:48:49,404 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:49:27,367 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.70, acc:   0.49, generation: 37.9191[sec], evaluation: 0.0000[sec]
2025-05-29 19:49:27,368 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:49:27,570 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/30500.ckpt
2025-05-29 19:49:27,588 - INFO - joeynmt.training - Example #0
2025-05-29 19:49:27,589 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:49:27,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:49:27,589 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 't', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gr@@', 'ie@@', 'zen', 'van', 'de', 'onder@@', 'ste', '4@@', '0@@', '%', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'dur@@', 'ende', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'dur@@', 'ende', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'A@@', 'c@@', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 'f@@', 'ers', 'van', '4@@', '0@@', '%', 'ge@@', 'vol@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 19:49:27,590 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:49:27,590 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:49:27,590 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoont om te verbeteren dat de arctische ijskappen die voor de artische ijskappen, die de griezen van de onderste 40% van de onderste 40 procent gedurende 40 procent gedurende 40 procent van de Acarctische ijfers van 40% gevolgd is.
2025-05-29 19:49:27,590 - INFO - joeynmt.training - Example #1
2025-05-29 19:49:27,590 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:49:27,590 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:49:27,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'e,', 'de', 'eerste', 'st@@', 'aa@@', 'm@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'uit@@', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'oo@@', 's', 'van', 'de', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'to@@', 'on@@', 't', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ijk', 'niet', 'de', 'di@@', 'k@@', 'ke', 'genoe@@', 'g', 'om', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'men', 'van', 'het', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'genoe@@', 'g', 'genoe@@', 'g', 'voor', 'de', 'eer@@', 'st', 'niet', 'de', 'di@@']
2025-05-29 19:49:27,592 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:49:27,592 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:49:27,592 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste, de eerste staamheid van dit speciale problemen uit, want het is niet de dikke van de ijskoos van de ijskaart toont niet de dikke van de ijskwestie van het ijskijk niet de dikke genoeg om dit speciale problemen van het ijskwestie niet sterk genoeg is dat het niet de dikke genoeg genoeg voor de eerst niet de di
2025-05-29 19:49:27,592 - INFO - joeynmt.training - Example #2
2025-05-29 19:49:27,592 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:49:27,592 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:49:27,592 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'de', 'aar@@', 'de', 'har@@', 't', 'van', 'de', 'aar@@', 'de', 'har@@', 't', 'van', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:49:27,593 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:49:27,593 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:49:27,593 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen van de aarde hart van de aarde hart van de klimaatsysteem.
2025-05-29 19:49:27,593 - INFO - joeynmt.training - Example #3
2025-05-29 19:49:27,593 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:49:27,594 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:49:27,594 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'k@@', 'ken@@', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:49:27,594 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:49:27,594 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:49:27,595 - INFO - joeynmt.training - 	Hypothesis: Ze groeide in de winter en schokkende zomers.
2025-05-29 19:49:27,595 - INFO - joeynmt.training - Example #4
2025-05-29 19:49:27,595 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:49:27,595 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:49:27,596 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:49:27,596 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:49:27,597 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:49:27,597 - INFO - joeynmt.training - 	Hypothesis: De volgende die ik jullie laten zien is een tijdje is een tijdje in de laatste 25 jaar is gebeurd.
2025-05-29 19:49:37,131 - INFO - joeynmt.training - Epoch   4, Step:    32600, Batch Loss:     1.740503, Batch Acc: 0.517888, Tokens per Sec:     7203, Lr: 0.000300
2025-05-29 19:49:46,612 - INFO - joeynmt.training - Epoch   4, Step:    32700, Batch Loss:     1.744048, Batch Acc: 0.511725, Tokens per Sec:     7359, Lr: 0.000300
2025-05-29 19:49:56,251 - INFO - joeynmt.training - Epoch   4, Step:    32800, Batch Loss:     1.461779, Batch Acc: 0.520236, Tokens per Sec:     7179, Lr: 0.000300
2025-05-29 19:50:05,731 - INFO - joeynmt.training - Epoch   4, Step:    32900, Batch Loss:     1.589042, Batch Acc: 0.516492, Tokens per Sec:     7387, Lr: 0.000300
2025-05-29 19:50:15,428 - INFO - joeynmt.training - Epoch   4, Step:    33000, Batch Loss:     1.680915, Batch Acc: 0.521034, Tokens per Sec:     7480, Lr: 0.000300
2025-05-29 19:50:15,428 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:50:15,429 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:50:48,468 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.69, acc:   0.49, generation: 33.0045[sec], evaluation: 0.0000[sec]
2025-05-29 19:50:48,470 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:50:48,649 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/30000.ckpt
2025-05-29 19:50:48,666 - INFO - joeynmt.training - Example #0
2025-05-29 19:50:48,666 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:50:48,667 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:50:48,667 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'de', 'te', 'ver@@', 'tel@@', 't', 'om', 'te', 'ver@@', 'antwoor@@', 'delijk', 'te', 'be@@', 'se@@', 'ffen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '0@@', '%', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 19:50:48,668 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:50:48,668 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:50:48,668 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoonde te vertelt om te verantwoordelijk te beseffen dat de artische ijskappen, die de reden van de onderste 40% van de onderste 40 procent van de onderste 40 procent is geslaagd is.
2025-05-29 19:50:48,668 - INFO - joeynmt.training - Example #1
2025-05-29 19:50:48,669 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:50:48,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:50:48,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'genoe@@', 'g', 'is', 'om', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'te', 'zien', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'je', 'to@@', 'on@@', 't', 'l@@', 'aat', 'zien.', '</s>']
2025-05-29 19:50:48,670 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:50:48,670 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:50:48,670 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg genoeg is om dit speciale probleem te zien dat het niet de dikke van het ijsje toont laat zien.
2025-05-29 19:50:48,670 - INFO - joeynmt.training - Example #2
2025-05-29 19:50:48,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:50:48,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:50:48,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en', 'het', 'sl@@', 'im@@', 'syste@@', 'em', 'van', 'het', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:50:48,672 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:50:48,672 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:50:48,672 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het slimsysteem van het wereldwijde klimaatsysteem.
2025-05-29 19:50:48,672 - INFO - joeynmt.training - Example #3
2025-05-29 19:50:48,673 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:50:48,673 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:50:48,673 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'm@@', 'p', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 19:50:48,674 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:50:48,674 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:50:48,674 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schrump in de zomer.
2025-05-29 19:50:48,674 - INFO - joeynmt.training - Example #4
2025-05-29 19:50:48,675 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:50:48,675 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:50:48,675 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'draa@@', 'i@@', 'de', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:50:48,676 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:50:48,676 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:50:48,676 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijddraaide wat er in de afgelopen 25 jaar gebeurd.
2025-05-29 19:50:58,179 - INFO - joeynmt.training - Epoch   4, Step:    33100, Batch Loss:     1.655546, Batch Acc: 0.518332, Tokens per Sec:     7171, Lr: 0.000300
2025-05-29 19:51:07,914 - INFO - joeynmt.training - Epoch   4, Step:    33200, Batch Loss:     1.625276, Batch Acc: 0.519432, Tokens per Sec:     7198, Lr: 0.000300
2025-05-29 19:51:17,160 - INFO - joeynmt.training - Epoch   4, Step:    33300, Batch Loss:     1.647448, Batch Acc: 0.514457, Tokens per Sec:     7654, Lr: 0.000300
2025-05-29 19:51:26,521 - INFO - joeynmt.training - Epoch   4, Step:    33400, Batch Loss:     1.717151, Batch Acc: 0.517615, Tokens per Sec:     7500, Lr: 0.000300
2025-05-29 19:51:35,953 - INFO - joeynmt.training - Epoch   4, Step:    33500, Batch Loss:     1.747790, Batch Acc: 0.519471, Tokens per Sec:     7455, Lr: 0.000300
2025-05-29 19:51:35,954 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:51:35,955 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:52:20,712 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.70, acc:   0.49, generation: 44.7214[sec], evaluation: 0.0000[sec]
2025-05-29 19:52:20,894 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/31000.ckpt
2025-05-29 19:52:20,915 - INFO - joeynmt.training - Example #0
2025-05-29 19:52:20,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:52:20,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:52:20,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijk@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'in', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'c@@', 'ru@@', 'ci@@', 'ale', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'at@@', 'uur', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'c@@', 'en@@', 'te', 'zijn.', '</s>']
2025-05-29 19:52:20,917 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:52:20,917 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:52:20,917 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, getoond om te verkijken, dat de artische ijskappen, die voor de artische ijskappen, de grondstoffen in de onderste 40 procent gecruciale ijskapparatuur van 40 procent van de recente zijn.
2025-05-29 19:52:20,918 - INFO - joeynmt.training - Example #1
2025-05-29 19:52:20,918 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:52:20,918 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:52:20,918 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'want', 'het', 'is', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'je', 'to@@', 'on@@', 't', 'zien.', '</s>']
2025-05-29 19:52:20,919 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:52:20,919 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:52:20,920 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste staat, want het is het specifieke probleem is dat het niet de dikke ijsje toont zien.
2025-05-29 19:52:20,920 - INFO - joeynmt.training - Example #2
2025-05-29 19:52:20,920 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:52:20,920 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:52:20,920 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'sl@@', 'aa@@', 'g@@', 'de', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:52:20,921 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:52:20,922 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:52:20,922 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het slaagde hart van onze wereldwijde klimaatsysteem.
2025-05-29 19:52:20,922 - INFO - joeynmt.training - Example #3
2025-05-29 19:52:20,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:52:20,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:52:20,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 're@@', 'ef@@', '.', '</s>']
2025-05-29 19:52:20,924 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:52:20,924 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:52:20,924 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schreef.
2025-05-29 19:52:20,924 - INFO - joeynmt.training - Example #4
2025-05-29 19:52:20,924 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:52:20,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:52:20,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 't.', '</s>']
2025-05-29 19:52:20,926 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:52:20,926 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:52:20,926 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje in de afgelopen 25 jaar gebeurt.
2025-05-29 19:52:30,526 - INFO - joeynmt.training - Epoch   4, Step:    33600, Batch Loss:     1.749132, Batch Acc: 0.516571, Tokens per Sec:     6912, Lr: 0.000300
2025-05-29 19:52:40,266 - INFO - joeynmt.training - Epoch   4, Step:    33700, Batch Loss:     1.693247, Batch Acc: 0.525729, Tokens per Sec:     7114, Lr: 0.000300
2025-05-29 19:52:49,878 - INFO - joeynmt.training - Epoch   4, Step:    33800, Batch Loss:     1.581854, Batch Acc: 0.522178, Tokens per Sec:     7548, Lr: 0.000300
2025-05-29 19:52:59,610 - INFO - joeynmt.training - Epoch   4, Step:    33900, Batch Loss:     1.677710, Batch Acc: 0.515755, Tokens per Sec:     7398, Lr: 0.000300
2025-05-29 19:53:08,982 - INFO - joeynmt.training - Epoch   4, Step:    34000, Batch Loss:     1.540066, Batch Acc: 0.518878, Tokens per Sec:     7543, Lr: 0.000300
2025-05-29 19:53:08,983 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:53:08,983 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:53:42,996 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.66, acc:   0.49, generation: 33.9745[sec], evaluation: 0.0000[sec]
2025-05-29 19:53:42,997 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:53:43,180 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/31500.ckpt
2025-05-29 19:53:43,200 - INFO - joeynmt.training - Example #0
2025-05-29 19:53:43,201 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:53:43,201 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:53:43,202 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'kijk@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'dur@@', 'ende', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'A@@', 'ar@@', 'de', 'voor', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'A@@', 'zi@@', 'ë@@', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den']
2025-05-29 19:53:43,203 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:53:43,203 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:53:43,203 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verkijken, dat de artische ijskappen, die voor de artische ijskappen, de reden van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent is gedurende 40 procent van de Aarde voor 40 procent van de Azië, om 40 procent van de reden van de onderste 40 procent van de reden
2025-05-29 19:53:43,203 - INFO - joeynmt.training - Example #1
2025-05-29 19:53:43,203 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:53:43,203 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:53:43,203 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 'f@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 19:53:43,204 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:53:43,206 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:53:43,206 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste staafheid van dit speciale probleem, omdat het niet de dikke van het ijs toont.
2025-05-29 19:53:43,206 - INFO - joeynmt.training - Example #2
2025-05-29 19:53:43,206 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:53:43,206 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:53:43,206 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', 'tu@@', 'igen', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:53:43,206 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:53:43,206 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:53:43,208 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigen is de artische ijskappe het hart van onze wereldwijde klimaatsysteem.
2025-05-29 19:53:43,208 - INFO - joeynmt.training - Example #3
2025-05-29 19:53:43,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:53:43,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:53:43,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 're@@', 'ef@@', '.', '</s>']
2025-05-29 19:53:43,209 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:53:43,209 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:53:43,209 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schreef.
2025-05-29 19:53:43,209 - INFO - joeynmt.training - Example #4
2025-05-29 19:53:43,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:53:43,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:53:43,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'je', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'er@@', 't@@', '-@@', 'op@@', 'nam@@', 'e', 'van', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:53:43,211 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:53:43,211 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:53:43,211 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laten zien is een tijdschrifert-opname van wat er in de afgelopen 25 jaar gebeurd.
2025-05-29 19:53:52,735 - INFO - joeynmt.training - Epoch   4, Step:    34100, Batch Loss:     1.686947, Batch Acc: 0.522727, Tokens per Sec:     7273, Lr: 0.000300
2025-05-29 19:54:02,041 - INFO - joeynmt.training - Epoch   4, Step:    34200, Batch Loss:     1.782674, Batch Acc: 0.513856, Tokens per Sec:     7504, Lr: 0.000300
2025-05-29 19:54:11,483 - INFO - joeynmt.training - Epoch   4, Step:    34300, Batch Loss:     1.723264, Batch Acc: 0.524420, Tokens per Sec:     7568, Lr: 0.000300
2025-05-29 19:54:20,645 - INFO - joeynmt.training - Epoch   4, Step:    34400, Batch Loss:     1.675590, Batch Acc: 0.521970, Tokens per Sec:     7410, Lr: 0.000300
2025-05-29 19:54:30,258 - INFO - joeynmt.training - Epoch   4, Step:    34500, Batch Loss:     1.585908, Batch Acc: 0.517080, Tokens per Sec:     6970, Lr: 0.000300
2025-05-29 19:54:30,259 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:54:30,260 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:55:13,404 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.68, acc:   0.49, generation: 43.1002[sec], evaluation: 0.0000[sec]
2025-05-29 19:55:13,580 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/32000.ckpt
2025-05-29 19:55:13,598 - INFO - joeynmt.training - Example #0
2025-05-29 19:55:13,599 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:55:13,599 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:55:13,600 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'we', 'het', 'jaar', 'twee', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'ver@@', 'zor@@', 'gen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 're@@', 'eu@@', 'w@@', 'en', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'w@@', 'ijn@@', 'lijk', '4@@', '0', 'proc@@', 'ent', 'was', 'ge@@', 'g@@', 'aa@@', 't.', '</s>']
2025-05-29 19:55:13,601 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:55:13,601 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:55:13,601 - INFO - joeynmt.training - 	Hypothesis: Laten we het jaar twee deze twee gevolgen om te verzorgen dat de artische ijskappen, die de artische ijskappen, die de reeuwen van de grondwijnlijk 40 procent was gegaat.
2025-05-29 19:55:13,601 - INFO - joeynmt.training - Example #1
2025-05-29 19:55:13,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:55:13,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:55:13,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'en@@', 'aar@@', 'd@@', 'se', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 19:55:13,602 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:55:13,603 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:55:13,603 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste stenaardse probleem, omdat het niet de dikke van het ijs van het ijs toont.
2025-05-29 19:55:13,603 - INFO - joeynmt.training - Example #2
2025-05-29 19:55:13,603 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:55:13,603 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:55:13,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'ver@@', 'sla@@', 'gen@@', 'e', 'is', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:55:13,604 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:55:13,605 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:55:13,605 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe het verslagene is van onze wereldwijde klimaatsysteem.
2025-05-29 19:55:13,605 - INFO - joeynmt.training - Example #3
2025-05-29 19:55:13,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:55:13,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:55:13,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 19:55:13,606 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:55:13,606 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:55:13,606 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomer.
2025-05-29 19:55:13,606 - INFO - joeynmt.training - Example #4
2025-05-29 19:55:13,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:55:13,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:55:13,606 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'teken@@', 'ing', 'van', 'een', 'teken@@', 'ing', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 19:55:13,607 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:55:13,607 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:55:13,607 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tekening van een tekening van wat er gebeurt in de afgelopen 25 jaar is.
2025-05-29 19:55:23,199 - INFO - joeynmt.training - Epoch   4, Step:    34600, Batch Loss:     1.763852, Batch Acc: 0.519623, Tokens per Sec:     7014, Lr: 0.000300
2025-05-29 19:55:32,895 - INFO - joeynmt.training - Epoch   4, Step:    34700, Batch Loss:     1.776514, Batch Acc: 0.520115, Tokens per Sec:     7096, Lr: 0.000300
2025-05-29 19:55:42,593 - INFO - joeynmt.training - Epoch   4, Step:    34800, Batch Loss:     1.660976, Batch Acc: 0.518352, Tokens per Sec:     7486, Lr: 0.000300
2025-05-29 19:55:52,012 - INFO - joeynmt.training - Epoch   4, Step:    34900, Batch Loss:     1.513035, Batch Acc: 0.520038, Tokens per Sec:     7422, Lr: 0.000300
2025-05-29 19:56:01,194 - INFO - joeynmt.training - Epoch   4, Step:    35000, Batch Loss:     1.391337, Batch Acc: 0.520481, Tokens per Sec:     7550, Lr: 0.000300
2025-05-29 19:56:01,194 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:56:01,195 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:56:33,683 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.65, acc:   0.49, generation: 32.4501[sec], evaluation: 0.0000[sec]
2025-05-29 19:56:33,684 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:56:33,879 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/32500.ckpt
2025-05-29 19:56:33,895 - INFO - joeynmt.training - Example #0
2025-05-29 19:56:33,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:56:33,896 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:56:33,896 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'kijk@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'v@@', 'it@@', 'ei@@', 'ten', 'die', 'de', 'gr@@', 'on@@', 'den', 'van', 'de', 'gr@@', 'on@@', 'd@@', 's,', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'm@@', 'ij@@', 'den', 'met', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'ach@@', 't.', '</s>']
2025-05-29 19:56:33,897 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:56:33,897 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:56:33,897 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond getoond om te verkijken, dat de artische ijskappen, die voor de artiviteiten die de gronden van de gronds, om 40 procent te vermijden met 40 procent geslacht.
2025-05-29 19:56:33,897 - INFO - joeynmt.training - Example #1
2025-05-29 19:56:33,898 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:56:33,898 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:56:33,898 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'e,', 'het', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'om', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'het', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie.', '</s>']
2025-05-29 19:56:33,899 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:56:33,899 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:56:33,899 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste, het is niet sterk genoeg om dit specifiek van het ijskaart niet de dikke van het ijskaart van het ijsje van het ijskwestie.
2025-05-29 19:56:33,899 - INFO - joeynmt.training - Example #2
2025-05-29 19:56:33,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:56:33,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:56:33,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'men.', '</s>']
2025-05-29 19:56:33,901 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:56:33,901 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:56:33,901 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het globale klimaatsysteem van onze wereldwijde klimaatsystemen.
2025-05-29 19:56:33,901 - INFO - joeynmt.training - Example #3
2025-05-29 19:56:33,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:56:33,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:56:33,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'en', 'en', 'sch@@', 'ru@@', 'ik@@', 't', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 're@@', 'ef@@', '.', '</s>']
2025-05-29 19:56:33,903 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:56:33,903 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:56:33,903 - INFO - joeynmt.training - 	Hypothesis: Ze groeien en en schruikt in de winter en schreef.
2025-05-29 19:56:33,903 - INFO - joeynmt.training - Example #4
2025-05-29 19:56:33,904 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:56:33,904 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:56:33,904 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:56:33,905 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:56:33,905 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:56:33,905 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdperk van wat er in de afgelopen 25 jaar gebeurd.
2025-05-29 19:56:43,198 - INFO - joeynmt.training - Epoch   4, Step:    35100, Batch Loss:     1.685847, Batch Acc: 0.522428, Tokens per Sec:     7290, Lr: 0.000300
2025-05-29 19:56:52,572 - INFO - joeynmt.training - Epoch   4, Step:    35200, Batch Loss:     1.619810, Batch Acc: 0.517574, Tokens per Sec:     7448, Lr: 0.000300
2025-05-29 19:57:01,949 - INFO - joeynmt.training - Epoch   4, Step:    35300, Batch Loss:     1.550814, Batch Acc: 0.520307, Tokens per Sec:     7301, Lr: 0.000300
2025-05-29 19:57:11,185 - INFO - joeynmt.training - Epoch   4, Step:    35400, Batch Loss:     1.594431, Batch Acc: 0.525056, Tokens per Sec:     7660, Lr: 0.000300
2025-05-29 19:57:20,954 - INFO - joeynmt.training - Epoch   4, Step:    35500, Batch Loss:     1.531583, Batch Acc: 0.520639, Tokens per Sec:     7205, Lr: 0.000300
2025-05-29 19:57:20,954 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:57:20,955 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:58:02,369 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.63, acc:   0.50, generation: 41.3828[sec], evaluation: 0.0000[sec]
2025-05-29 19:58:02,370 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:58:02,544 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/33500.ckpt
2025-05-29 19:58:02,569 - INFO - joeynmt.training - Example #0
2025-05-29 19:58:02,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:58:02,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:58:02,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'zor@@', 'gen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'f@@', '.', '</s>']
2025-05-29 19:58:02,571 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:58:02,572 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:58:02,572 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verzorgen dat de artische ijskappen, die de artische ijskappen, die drie miljoen jaar de grondstoffen van de grondstof.
2025-05-29 19:58:02,572 - INFO - joeynmt.training - Example #1
2025-05-29 19:58:02,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:58:02,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:58:02,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'de', 'eerste', 'hoe@@', 've@@', 'el@@', 'heid', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'dat', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'to@@', 'on@@', 't', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 19:58:02,574 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:58:02,574 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:58:02,574 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste is dat de eerste hoeveelheid dit speciale probleem dat niet de dikke dikke ijs toont van het ijs toont.
2025-05-29 19:58:02,574 - INFO - joeynmt.training - Example #2
2025-05-29 19:58:02,574 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:58:02,575 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:58:02,575 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:58:02,576 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:58:02,576 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:58:02,576 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het hart van ons wereldwijde klimaatsysteem.
2025-05-29 19:58:02,576 - INFO - joeynmt.training - Example #3
2025-05-29 19:58:02,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:58:02,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:58:02,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'u@@', 'il@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:58:02,577 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:58:02,578 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:58:02,578 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schuilt in de zomers.
2025-05-29 19:58:02,578 - INFO - joeynmt.training - Example #4
2025-05-29 19:58:02,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:58:02,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:58:02,579 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 19:58:02,579 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:58:02,580 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:58:02,580 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje van de laatste 25 jaar.
2025-05-29 19:58:12,078 - INFO - joeynmt.training - Epoch   4, Step:    35600, Batch Loss:     1.408232, Batch Acc: 0.518495, Tokens per Sec:     7009, Lr: 0.000300
2025-05-29 19:58:21,625 - INFO - joeynmt.training - Epoch   4, Step:    35700, Batch Loss:     1.721242, Batch Acc: 0.518826, Tokens per Sec:     7548, Lr: 0.000300
2025-05-29 19:58:31,142 - INFO - joeynmt.training - Epoch   4, Step:    35800, Batch Loss:     1.691782, Batch Acc: 0.518570, Tokens per Sec:     7288, Lr: 0.000300
2025-05-29 19:58:40,653 - INFO - joeynmt.training - Epoch   4, Step:    35900, Batch Loss:     1.645908, Batch Acc: 0.522702, Tokens per Sec:     6995, Lr: 0.000300
2025-05-29 19:58:50,290 - INFO - joeynmt.training - Epoch   4, Step:    36000, Batch Loss:     1.419407, Batch Acc: 0.517111, Tokens per Sec:     7166, Lr: 0.000300
2025-05-29 19:58:50,290 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 19:58:50,291 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:59:22,021 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.61, acc:   0.50, generation: 31.6916[sec], evaluation: 0.0000[sec]
2025-05-29 19:59:22,022 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:59:22,229 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/33000.ckpt
2025-05-29 19:59:22,244 - INFO - joeynmt.training - Example #0
2025-05-29 19:59:22,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 19:59:22,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 19:59:22,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'het', 'jaar', 'gele@@', 'den', 'van', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'den', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'A@@', 'ar@@', 'de', 'voor', 'de', 'be@@', 'vol@@', 'k@@', 'ing', 'van', 'de', 'gr@@', 'on@@', 'den', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'van', '4@@', '0', 'proc@@', 'ent', 'was', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'ar@@', 'ti@@', 'kel', 'is.', '</s>']
2025-05-29 19:59:22,247 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:59:22,247 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 19:59:22,247 - INFO - joeynmt.training - 	Hypothesis: Ik heb het jaar geleden van deze twee getoond om te verzamelden dat de artische ijskappen, die voor de Aarde voor de bevolking van de gronden van de grondstoffen van 40 procent was 40 procent van de reden van 40 procent van de reden van 40 procent van de artikel is.
2025-05-29 19:59:22,247 - INFO - joeynmt.training - Example #1
2025-05-29 19:59:22,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 19:59:22,248 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 19:59:22,248 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'de', 'eerste', 'hoe@@', 've@@', 'el@@', 'heid', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'is', 'dat', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'ap@@', '.', '</s>']
2025-05-29 19:59:22,248 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:59:22,248 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 19:59:22,249 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste is dat de eerste hoeveelheid dit specifiek is dat niet de dikke ijskap.
2025-05-29 19:59:22,249 - INFO - joeynmt.training - Example #2
2025-05-29 19:59:22,249 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 19:59:22,249 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 19:59:22,249 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'de', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 19:59:22,250 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:59:22,251 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 19:59:22,251 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het slaagde hart van onze wereldwijde klimaatsysteem.
2025-05-29 19:59:22,251 - INFO - joeynmt.training - Example #3
2025-05-29 19:59:22,251 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 19:59:22,252 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 19:59:22,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'ijn@@', 'er', 'en', 's@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 19:59:22,253 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:59:22,253 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 19:59:22,253 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de wijner en somers.
2025-05-29 19:59:22,253 - INFO - joeynmt.training - Example #4
2025-05-29 19:59:22,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 19:59:22,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 19:59:22,254 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'ge@@', 'vol@@', 'g', 'die', 'ik', 't@@', 'on@@', 'g', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 19:59:22,254 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:59:22,255 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 19:59:22,255 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik tong is een tijdje in de laatste 25 jaar gebeurd.
2025-05-29 19:59:31,595 - INFO - joeynmt.training - Epoch   4, Step:    36100, Batch Loss:     1.599737, Batch Acc: 0.520390, Tokens per Sec:     7464, Lr: 0.000300
2025-05-29 19:59:41,009 - INFO - joeynmt.training - Epoch   4, Step:    36200, Batch Loss:     1.676450, Batch Acc: 0.520751, Tokens per Sec:     7368, Lr: 0.000300
2025-05-29 19:59:50,393 - INFO - joeynmt.training - Epoch   4, Step:    36300, Batch Loss:     1.721874, Batch Acc: 0.521508, Tokens per Sec:     7460, Lr: 0.000300
2025-05-29 19:59:59,764 - INFO - joeynmt.training - Epoch   4, Step:    36400, Batch Loss:     1.694461, Batch Acc: 0.521092, Tokens per Sec:     7423, Lr: 0.000300
2025-05-29 20:00:09,412 - INFO - joeynmt.training - Epoch   4, Step:    36500, Batch Loss:     1.727534, Batch Acc: 0.520034, Tokens per Sec:     7117, Lr: 0.000300
2025-05-29 20:00:09,413 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:00:09,413 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:00:49,225 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.61, acc:   0.49, generation: 39.7717[sec], evaluation: 0.0000[sec]
2025-05-29 20:00:49,226 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:00:49,426 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/34500.ckpt
2025-05-29 20:00:49,444 - INFO - joeynmt.training - Example #0
2025-05-29 20:00:49,445 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:00:49,445 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:00:49,446 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'de', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'tel@@', 'den', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 'gr@@', 'on@@', 'd@@', 'w@@', 'ijn@@', ',', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'on@@', 'd,', 'om', '4@@', '0@@', '%', 'van', 'de', 'onder@@', 'ste', '4@@', '0@@', '%', 'van', 'de', 'onder@@', 'ste', '4@@', '0@@', '%', 'van', 'de', 'onder@@', 'ste', '4@@', '0@@', '%', 'van', 'de', 'onder@@', 'ste', '4@@', '0@@', '%', 'van', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '0@@', '%', 'van', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '0@@', '%', 'van', 'de', 'onder@@', 'ste', '4@@', '0@@', '%', 'van', 'de', 'onder@@']
2025-05-29 20:00:49,446 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:00:49,447 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:00:49,447 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee getoonde getoond, om te vertelden dat de artische ijskappen, die voor de artische ijskappen, de grondwijn, drie miljoen jaar de grond, om 40% van de onderste 40% van de onderste 40% van de onderste 40% van de onderste 40% van de reden van de onderste 40% van de reden van de onderste 40% van de onderste 40% van de onder
2025-05-29 20:00:49,447 - INFO - joeynmt.training - Example #1
2025-05-29 20:00:49,447 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:00:49,448 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:00:49,448 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'n@@', 'eer@@', 'st@@', 'h@@', 'aa@@', 'm@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'is', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:00:49,449 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:00:49,449 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:00:49,449 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste neersthaamheid van dit speciale probleem, want het is niet de dikke is toont.
2025-05-29 20:00:49,449 - INFO - joeynmt.training - Example #2
2025-05-29 20:00:49,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:00:49,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:00:49,450 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:00:49,450 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:00:49,451 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:00:49,451 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het hart van onze wereldwijde klimaatsysteem.
2025-05-29 20:00:49,451 - INFO - joeynmt.training - Example #3
2025-05-29 20:00:49,451 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:00:49,451 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:00:49,451 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'u@@', 'd@@', 'den', 'en', 'ze', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-29 20:00:49,452 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:00:49,452 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:00:49,452 - INFO - joeynmt.training - 	Hypothesis: Ze groeide in de winter en schudden en ze verzamelen.
2025-05-29 20:00:49,453 - INFO - joeynmt.training - Example #4
2025-05-29 20:00:49,453 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:00:49,453 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:00:49,453 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:00:49,454 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:00:49,454 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:00:49,454 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje van de laatste 25 jaar gebeurd.
2025-05-29 20:00:59,588 - INFO - joeynmt.training - Epoch   4, Step:    36600, Batch Loss:     1.485190, Batch Acc: 0.522443, Tokens per Sec:     6534, Lr: 0.000300
2025-05-29 20:01:09,157 - INFO - joeynmt.training - Epoch   4, Step:    36700, Batch Loss:     1.560268, Batch Acc: 0.518047, Tokens per Sec:     7436, Lr: 0.000300
2025-05-29 20:01:18,596 - INFO - joeynmt.training - Epoch   4, Step:    36800, Batch Loss:     1.595167, Batch Acc: 0.525378, Tokens per Sec:     7237, Lr: 0.000300
2025-05-29 20:01:28,027 - INFO - joeynmt.training - Epoch   4, Step:    36900, Batch Loss:     1.513601, Batch Acc: 0.523460, Tokens per Sec:     7497, Lr: 0.000300
2025-05-29 20:01:30,507 - INFO - joeynmt.training - Epoch   4: total training loss 15114.92
2025-05-29 20:01:30,507 - INFO - joeynmt.training - EPOCH 5
2025-05-29 20:01:37,357 - INFO - joeynmt.training - Epoch   5, Step:    37000, Batch Loss:     1.393505, Batch Acc: 0.534814, Tokens per Sec:     7552, Lr: 0.000300
2025-05-29 20:01:37,357 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:01:37,358 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:02:11,095 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.57, acc:   0.50, generation: 33.6992[sec], evaluation: 0.0000[sec]
2025-05-29 20:02:11,096 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:02:11,273 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/34000.ckpt
2025-05-29 20:02:11,288 - INFO - joeynmt.training - Example #0
2025-05-29 20:02:11,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:02:11,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:02:11,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'om', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'ver@@', 'der', 'te', 'zien', 'dat', 'de', 'ar@@', 'ct@@', 'ische', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 'A@@', 'ar@@', 'de', 'gr@@', 'ond', 'van', 'de', 'gr@@', 'ond', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'van', 'de', 'gr@@', 'ond', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'denen', 'van', 'de', 'A@@', 'ar@@', 'de', 'op@@', 'kom@@', 'st', 'is.', '</s>']
2025-05-29 20:02:11,290 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:02:11,290 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:02:11,291 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee getoond om deze twee gevolgen om te verder te zien dat de arctische ijskappen, de Aarde grond van de grond van de grondstoffen van de grond van 40 procent van de grondstoffen van 40 procent van de redenen van de Aarde opkomst is.
2025-05-29 20:02:11,291 - INFO - joeynmt.training - Example #1
2025-05-29 20:02:11,291 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:02:11,291 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:02:11,291 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'e,', 'die', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'er@@', 'uit', 'uit', 'uit', 'te', 'vo@@', 'eren.', '</s>']
2025-05-29 20:02:11,296 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:02:11,296 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:02:11,296 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste, die specifiek is dat het niet de dikke probleem eruit uit uit te voeren.
2025-05-29 20:02:11,297 - INFO - joeynmt.training - Example #2
2025-05-29 20:02:11,297 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:02:11,297 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:02:11,297 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', ',', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:02:11,298 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:02:11,298 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:02:11,299 - INFO - joeynmt.training - 	Hypothesis: In zekere zin, is de artische ijskappe is het slaaglobale klimaatsysteem.
2025-05-29 20:02:11,299 - INFO - joeynmt.training - Example #3
2025-05-29 20:02:11,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:02:11,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:02:11,300 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 20:02:11,301 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:02:11,301 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:02:11,301 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en zomers.
2025-05-29 20:02:11,302 - INFO - joeynmt.training - Example #4
2025-05-29 20:02:11,302 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:02:11,302 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:02:11,302 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'oon', 'jullie', 'laten', 'zien', 'is', 'een', 'teken@@', 'ing', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:02:11,303 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:02:11,303 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:02:11,304 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik toon jullie laten zien is een tekening van de laatste 25 jaar gebeurd.
2025-05-29 20:02:19,933 - INFO - joeynmt.training - Epoch   5, Step:    37100, Batch Loss:     1.754940, Batch Acc: 0.529938, Tokens per Sec:     8026, Lr: 0.000300
2025-05-29 20:02:29,102 - INFO - joeynmt.training - Epoch   5, Step:    37200, Batch Loss:     1.787012, Batch Acc: 0.532743, Tokens per Sec:     7535, Lr: 0.000300
2025-05-29 20:02:38,381 - INFO - joeynmt.training - Epoch   5, Step:    37300, Batch Loss:     1.585904, Batch Acc: 0.528547, Tokens per Sec:     7580, Lr: 0.000300
2025-05-29 20:02:47,667 - INFO - joeynmt.training - Epoch   5, Step:    37400, Batch Loss:     1.483336, Batch Acc: 0.534780, Tokens per Sec:     7400, Lr: 0.000300
2025-05-29 20:02:57,534 - INFO - joeynmt.training - Epoch   5, Step:    37500, Batch Loss:     1.500911, Batch Acc: 0.531679, Tokens per Sec:     6988, Lr: 0.000300
2025-05-29 20:02:57,535 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:02:57,535 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:03:36,576 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.59, acc:   0.50, generation: 38.9961[sec], evaluation: 0.0000[sec]
2025-05-29 20:03:36,770 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/35000.ckpt
2025-05-29 20:03:36,784 - INFO - joeynmt.training - Example #0
2025-05-29 20:03:36,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:03:36,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:03:36,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'kijken', 'naar', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'de', 'gr@@', 'on@@', 'd@@', 'w@@', 'on@@', 'en', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'is', 'gesch@@', 'ru@@', 'mp@@', 'eld', 'om', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd', 'te', 'zijn.', '</s>']
2025-05-29 20:03:36,787 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:03:36,787 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:03:36,787 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te kijken naar de artische ijskappen dat de artische ijskappen die de grondwonen van de onderste 40 procent is geschrumpeld om 40 procent gegooid te zijn.
2025-05-29 20:03:36,787 - INFO - joeynmt.training - Example #1
2025-05-29 20:03:36,787 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:03:36,788 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:03:36,788 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'er@@', 'uit', 'uit', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'om', 'van', 'de', 'ij@@', 's@@', 'be@@', 'l', 'te', 'laten', 'zien.', '</s>']
2025-05-29 20:03:36,788 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:03:36,789 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:03:36,789 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van dit specifieke probleem van dit specifieke probleem eruit uit omdat het niet de dikom van de ijsbel te laten zien.
2025-05-29 20:03:36,789 - INFO - joeynmt.training - Example #2
2025-05-29 20:03:36,789 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:03:36,789 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:03:36,789 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'on@@', 'be@@', 'ken@@', 'de', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:03:36,790 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:03:36,790 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:03:36,791 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het onbekende hart van ons wereldwijde klimaatsysteem.
2025-05-29 20:03:36,791 - INFO - joeynmt.training - Example #3
2025-05-29 20:03:36,791 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:03:36,791 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:03:36,791 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'in', 'het', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:03:36,792 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:03:36,792 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:03:36,792 - INFO - joeynmt.training - 	Hypothesis: Ze groeide in het winter en zomert.
2025-05-29 20:03:36,793 - INFO - joeynmt.training - Example #4
2025-05-29 20:03:36,793 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:03:36,793 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:03:36,793 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:03:36,794 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:03:36,794 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:03:36,794 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschriften wat er gebeurt in de laatste 25 jaar gebeurd.
2025-05-29 20:03:46,212 - INFO - joeynmt.training - Epoch   5, Step:    37600, Batch Loss:     1.471018, Batch Acc: 0.533633, Tokens per Sec:     7307, Lr: 0.000300
2025-05-29 20:03:56,419 - INFO - joeynmt.training - Epoch   5, Step:    37700, Batch Loss:     1.524737, Batch Acc: 0.529397, Tokens per Sec:     6862, Lr: 0.000300
2025-05-29 20:04:05,896 - INFO - joeynmt.training - Epoch   5, Step:    37800, Batch Loss:     1.755682, Batch Acc: 0.532257, Tokens per Sec:     7395, Lr: 0.000300
2025-05-29 20:04:15,404 - INFO - joeynmt.training - Epoch   5, Step:    37900, Batch Loss:     1.496622, Batch Acc: 0.533366, Tokens per Sec:     7466, Lr: 0.000300
2025-05-29 20:04:24,959 - INFO - joeynmt.training - Epoch   5, Step:    38000, Batch Loss:     1.460636, Batch Acc: 0.532579, Tokens per Sec:     7130, Lr: 0.000300
2025-05-29 20:04:24,960 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:04:24,960 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:05:05,377 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.56, acc:   0.50, generation: 40.3839[sec], evaluation: 0.0000[sec]
2025-05-29 20:05:05,378 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:05:05,546 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/35500.ckpt
2025-05-29 20:05:05,560 - INFO - joeynmt.training - Example #0
2025-05-29 20:05:05,561 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:05:05,561 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:05:05,561 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['U@@', 'it@@', 'ein@@', 'delijk', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'zor@@', 'gen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ter@@', 'e', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'c@@', 'ontro@@', 'le@@', 'erd', 'is.', '</s>']
2025-05-29 20:05:05,562 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:05:05,562 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:05:05,562 - INFO - joeynmt.training - 	Hypothesis: Uiteindelijk heb ik deze twee getoond om te verzorgen dat de artische ijskappels die voor de artische ijskappen, drie miljoen jaar de grotere van de onderste 40 procent gecontroleerd is.
2025-05-29 20:05:05,562 - INFO - joeynmt.training - Example #1
2025-05-29 20:05:05,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:05:05,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:05:05,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'ro@@', 'om@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'van', 'het', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 20:05:05,564 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:05:05,564 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:05:05,564 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste stroom, omdat het niet de dikke probleem van het ijsver.
2025-05-29 20:05:05,564 - INFO - joeynmt.training - Example #2
2025-05-29 20:05:05,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:05:05,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:05:05,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:05:05,566 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:05:05,566 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:05:05,566 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het slaaglobale klimaatsysteem.
2025-05-29 20:05:05,566 - INFO - joeynmt.training - Example #3
2025-05-29 20:05:05,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:05:05,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:05:05,567 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 20:05:05,567 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:05:05,568 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:05:05,568 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en schroept in de zomer.
2025-05-29 20:05:05,568 - INFO - joeynmt.training - Example #4
2025-05-29 20:05:05,568 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:05:05,568 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:05:05,568 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'g', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd', 'is.', '</s>']
2025-05-29 20:05:05,569 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:05:05,569 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:05:05,570 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tong is een tijdje in de laatste 25 jaar gebeurd in de laatste 25 jaar gebeurd is.
2025-05-29 20:05:13,992 - INFO - joeynmt.training - Epoch   5, Step:    38100, Batch Loss:     1.679124, Batch Acc: 0.533188, Tokens per Sec:     8367, Lr: 0.000300
2025-05-29 20:05:22,100 - INFO - joeynmt.training - Epoch   5, Step:    38200, Batch Loss:     1.505239, Batch Acc: 0.527704, Tokens per Sec:     8636, Lr: 0.000300
2025-05-29 20:05:31,217 - INFO - joeynmt.training - Epoch   5, Step:    38300, Batch Loss:     1.581913, Batch Acc: 0.532483, Tokens per Sec:     7608, Lr: 0.000300
2025-05-29 20:05:40,308 - INFO - joeynmt.training - Epoch   5, Step:    38400, Batch Loss:     1.434360, Batch Acc: 0.526433, Tokens per Sec:     7684, Lr: 0.000300
2025-05-29 20:05:49,343 - INFO - joeynmt.training - Epoch   5, Step:    38500, Batch Loss:     1.688698, Batch Acc: 0.531669, Tokens per Sec:     7618, Lr: 0.000300
2025-05-29 20:05:49,343 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:05:49,343 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:06:31,497 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.61, acc:   0.50, generation: 42.1079[sec], evaluation: 0.0000[sec]
2025-05-29 20:06:31,676 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/36000.ckpt
2025-05-29 20:06:31,692 - INFO - joeynmt.training - Example #0
2025-05-29 20:06:31,693 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:06:31,693 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:06:31,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'der', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'app@@', 'e', 'ij@@', 's@@', 'app@@', 'e', 'die', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'maakt', 'voor', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'voor', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'maakt', 'is.', '</s>']
2025-05-29 20:06:31,694 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:06:31,694 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:06:31,695 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verder te zien dat de artische ijsappe ijsappe die de reden van de onderste drie miljoen jaar de grootte van de onderste 40 procent is gemaakt voor 40 procent is geslaagd voor 40 procent is gemaakt is.
2025-05-29 20:06:31,695 - INFO - joeynmt.training - Example #1
2025-05-29 20:06:31,695 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:06:31,695 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:06:31,695 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'art@@', 'te', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 20:06:31,696 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:06:31,696 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:06:31,697 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste startte van dit speciale probleem, omdat het niet de dikke ijsver.
2025-05-29 20:06:31,697 - INFO - joeynmt.training - Example #2
2025-05-29 20:06:31,697 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:06:31,697 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:06:31,697 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:06:31,698 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:06:31,698 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:06:31,699 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe ijskappe klimaatsysteem.
2025-05-29 20:06:31,699 - INFO - joeynmt.training - Example #3
2025-05-29 20:06:31,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:06:31,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:06:31,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 20:06:31,700 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:06:31,700 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:06:31,700 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en sluit in de zomer.
2025-05-29 20:06:31,701 - INFO - joeynmt.training - Example #4
2025-05-29 20:06:31,701 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:06:31,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:06:31,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:06:31,702 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:06:31,702 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:06:31,702 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdschrift in de afgelopen 25 jaar gebeurd.
2025-05-29 20:06:40,974 - INFO - joeynmt.training - Epoch   5, Step:    38600, Batch Loss:     1.727481, Batch Acc: 0.532597, Tokens per Sec:     7374, Lr: 0.000300
2025-05-29 20:06:50,166 - INFO - joeynmt.training - Epoch   5, Step:    38700, Batch Loss:     1.429566, Batch Acc: 0.527373, Tokens per Sec:     7576, Lr: 0.000300
2025-05-29 20:06:59,398 - INFO - joeynmt.training - Epoch   5, Step:    38800, Batch Loss:     1.445778, Batch Acc: 0.532256, Tokens per Sec:     7622, Lr: 0.000300
2025-05-29 20:07:08,772 - INFO - joeynmt.training - Epoch   5, Step:    38900, Batch Loss:     1.624636, Batch Acc: 0.533747, Tokens per Sec:     7626, Lr: 0.000300
2025-05-29 20:07:17,966 - INFO - joeynmt.training - Epoch   5, Step:    39000, Batch Loss:     1.456521, Batch Acc: 0.526411, Tokens per Sec:     7683, Lr: 0.000300
2025-05-29 20:07:17,967 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:07:17,967 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:07:50,140 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.58, acc:   0.50, generation: 32.1393[sec], evaluation: 0.0000[sec]
2025-05-29 20:07:50,313 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/38500.ckpt
2025-05-29 20:07:50,324 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit_bpe/38500.ckpt
2025-05-29 20:07:50,325 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe\38500.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit_bpe\\38500.ckpt')
2025-05-29 20:07:50,330 - INFO - joeynmt.training - Example #0
2025-05-29 20:07:50,331 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:07:50,331 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:07:50,331 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'ik', 'deze', 'twee', 'di@@', 'a', 'om', 'te', 'ver@@', 'zor@@', 'gen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'die', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'f@@', 'el@@', 'ijke', 'was', 'dat', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'c@@', 'en@@', 'te', 'te', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'c@@', 'en@@', 'te', 'te', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'w@@', 'on@@']
2025-05-29 20:07:50,332 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:07:50,332 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:07:50,332 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia getoond ik deze twee dia om te verzorgen dat de arctische ijskappe die de reden van de grondstoffen die de grondstofelijke was dat 40 procent van de reden van 40 procent van de recente te van 40 procent van de recente te van 40 procent van de reden van 40 procent van de reden van de reden van de reden van de grondwon
2025-05-29 20:07:50,332 - INFO - joeynmt.training - Example #1
2025-05-29 20:07:50,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:07:50,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:07:50,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:07:50,334 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:07:50,334 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:07:50,334 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste staat, omdat het niet de dikke probleem van dit specifieke probleem toont.
2025-05-29 20:07:50,334 - INFO - joeynmt.training - Example #2
2025-05-29 20:07:50,335 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:07:50,335 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:07:50,335 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', 'tu@@', 'igen', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'on@@', 's@@', 'har@@', 't', 'van', 'ons', 'mon@@', 'di@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:07:50,336 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:07:50,336 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:07:50,336 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigen is de arctische ijskappe is het onshart van ons mondiale klimaatsysteem.
2025-05-29 20:07:50,336 - INFO - joeynmt.training - Example #3
2025-05-29 20:07:50,337 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:07:50,337 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:07:50,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 20:07:50,337 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:07:50,338 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:07:50,338 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zomers.
2025-05-29 20:07:50,338 - INFO - joeynmt.training - Example #4
2025-05-29 20:07:50,338 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:07:50,338 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:07:50,339 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:07:50,339 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:07:50,340 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:07:50,340 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdje in de laatste 25 jaar gebeurd.
2025-05-29 20:07:59,158 - INFO - joeynmt.training - Epoch   5, Step:    39100, Batch Loss:     1.412800, Batch Acc: 0.536967, Tokens per Sec:     7698, Lr: 0.000300
2025-05-29 20:08:07,530 - INFO - joeynmt.training - Epoch   5, Step:    39200, Batch Loss:     1.667811, Batch Acc: 0.526774, Tokens per Sec:     8484, Lr: 0.000300
2025-05-29 20:08:15,696 - INFO - joeynmt.training - Epoch   5, Step:    39300, Batch Loss:     1.839169, Batch Acc: 0.537593, Tokens per Sec:     8667, Lr: 0.000300
2025-05-29 20:08:24,585 - INFO - joeynmt.training - Epoch   5, Step:    39400, Batch Loss:     1.517354, Batch Acc: 0.533828, Tokens per Sec:     7903, Lr: 0.000300
2025-05-29 20:08:33,554 - INFO - joeynmt.training - Epoch   5, Step:    39500, Batch Loss:     1.386879, Batch Acc: 0.528619, Tokens per Sec:     7784, Lr: 0.000300
2025-05-29 20:08:33,555 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:08:33,555 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:09:08,582 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.57, acc:   0.50, generation: 34.9848[sec], evaluation: 0.0000[sec]
2025-05-29 20:09:08,773 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/36500.ckpt
2025-05-29 20:09:08,791 - INFO - joeynmt.training - Example #0
2025-05-29 20:09:08,792 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:09:08,792 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:09:08,792 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'het', 'laat@@', 'ste', 'twee', 'f@@', 'ol@@', 'en', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'zor@@', 'gen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'ï@@', 'n@@', 'ter@@', 'ess@@', 'eerd', 'is.', '</s>']
2025-05-29 20:09:08,793 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:09:08,793 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:09:08,793 - INFO - joeynmt.training - 	Hypothesis: Ik heb het laatste twee folen getoond om te verzorgen dat de arctische ijskappen, die voor de artische ijskappen, die de reden van 40 procent van de onderste 40 procent geïnteresseerd is.
2025-05-29 20:09:08,794 - INFO - joeynmt.training - Example #1
2025-05-29 20:09:08,794 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:09:08,794 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:09:08,794 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 20:09:08,795 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:09:08,795 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:09:08,795 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste staat, omdat het niet de dikke probleem niet de dikke van het ijsver.
2025-05-29 20:09:08,795 - INFO - joeynmt.training - Example #2
2025-05-29 20:09:08,795 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:09:08,796 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:09:08,796 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'im@@', 'me', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:09:08,796 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:09:08,796 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:09:08,796 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het slimme systeem.
2025-05-29 20:09:08,796 - INFO - joeynmt.training - Example #3
2025-05-29 20:09:08,797 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:09:08,797 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:09:08,797 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:09:08,797 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:09:08,797 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:09:08,797 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en zomert.
2025-05-29 20:09:08,797 - INFO - joeynmt.training - Example #4
2025-05-29 20:09:08,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:09:08,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:09:08,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:09:08,799 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:09:08,799 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:09:08,799 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen wat er gebeurt in de afgelopen 25 jaar is in de laatste 25 jaar is gebeurd.
2025-05-29 20:09:18,273 - INFO - joeynmt.training - Epoch   5, Step:    39600, Batch Loss:     1.513235, Batch Acc: 0.528305, Tokens per Sec:     7418, Lr: 0.000300
2025-05-29 20:09:27,667 - INFO - joeynmt.training - Epoch   5, Step:    39700, Batch Loss:     1.602336, Batch Acc: 0.533466, Tokens per Sec:     7202, Lr: 0.000300
2025-05-29 20:09:37,003 - INFO - joeynmt.training - Epoch   5, Step:    39800, Batch Loss:     1.635932, Batch Acc: 0.532460, Tokens per Sec:     7257, Lr: 0.000300
2025-05-29 20:09:46,254 - INFO - joeynmt.training - Epoch   5, Step:    39900, Batch Loss:     1.480416, Batch Acc: 0.538751, Tokens per Sec:     7635, Lr: 0.000300
2025-05-29 20:09:55,503 - INFO - joeynmt.training - Epoch   5, Step:    40000, Batch Loss:     1.668087, Batch Acc: 0.528984, Tokens per Sec:     7340, Lr: 0.000300
2025-05-29 20:09:55,504 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:09:55,504 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:10:39,191 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.52, acc:   0.50, generation: 43.6415[sec], evaluation: 0.0000[sec]
2025-05-29 20:10:39,192 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:10:39,386 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/37500.ckpt
2025-05-29 20:10:39,403 - INFO - joeynmt.training - Example #0
2025-05-29 20:10:39,403 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:10:39,404 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:10:39,404 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'jaar', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'der', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'A@@', 'ar@@', 'de', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'is', 'gesch@@', 'ru@@', 'ik@@', 't.', '</s>']
2025-05-29 20:10:39,405 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:10:39,405 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:10:39,405 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee getoond jaar getoond, om te verder te zien dat de artische ijskappen, die voor de Aarde voor de onderste 40 procent van de onderste 40 procent van de onderste 40 procent is geschruikt.
2025-05-29 20:10:39,405 - INFO - joeynmt.training - Example #1
2025-05-29 20:10:39,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:10:39,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:10:39,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'uit@@', 'ne@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'men', 'uit@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:10:39,407 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:10:39,407 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:10:39,407 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de uitnemen van dit specifieke problemen uit, omdat het niet de dikke van het ijs toont.
2025-05-29 20:10:39,407 - INFO - joeynmt.training - Example #2
2025-05-29 20:10:39,407 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:10:39,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:10:39,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'p@@', 'la@@', 'st@@', 'ige', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:10:39,409 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:10:39,409 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:10:39,409 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe het plastige hart van onze wereldwijde klimaatsysteem.
2025-05-29 20:10:39,409 - INFO - joeynmt.training - Example #3
2025-05-29 20:10:39,409 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:10:39,409 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:10:39,410 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:10:39,410 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:10:39,411 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:10:39,411 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het zomert.
2025-05-29 20:10:39,411 - INFO - joeynmt.training - Example #4
2025-05-29 20:10:39,411 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:10:39,411 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:10:39,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'er@@', 't,', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 20:10:39,412 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:10:39,413 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:10:39,413 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschrifert, wat er gebeurde in de laatste 25 jaar.
2025-05-29 20:10:48,257 - INFO - joeynmt.training - Epoch   5, Step:    40100, Batch Loss:     1.669932, Batch Acc: 0.526327, Tokens per Sec:     7897, Lr: 0.000300
2025-05-29 20:10:56,512 - INFO - joeynmt.training - Epoch   5, Step:    40200, Batch Loss:     1.635971, Batch Acc: 0.528846, Tokens per Sec:     8686, Lr: 0.000300
2025-05-29 20:11:04,666 - INFO - joeynmt.training - Epoch   5, Step:    40300, Batch Loss:     1.614949, Batch Acc: 0.533821, Tokens per Sec:     8538, Lr: 0.000300
2025-05-29 20:11:12,805 - INFO - joeynmt.training - Epoch   5, Step:    40400, Batch Loss:     1.567153, Batch Acc: 0.534788, Tokens per Sec:     8806, Lr: 0.000300
2025-05-29 20:11:21,622 - INFO - joeynmt.training - Epoch   5, Step:    40500, Batch Loss:     1.582953, Batch Acc: 0.530781, Tokens per Sec:     7699, Lr: 0.000300
2025-05-29 20:11:21,623 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:11:21,623 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:12:03,068 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.53, acc:   0.50, generation: 41.3988[sec], evaluation: 0.0000[sec]
2025-05-29 20:12:03,250 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/39000.ckpt
2025-05-29 20:12:03,267 - INFO - joeynmt.training - Example #0
2025-05-29 20:12:03,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:12:03,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:12:03,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['A@@', 'an', 'de', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'zor@@', 'gen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'maakt', 'om', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'dur@@', 'ende', 'de', 'gr@@', 'ond', 'is', 'dat', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'g@@', 'aan.', '</s>']
2025-05-29 20:12:03,268 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:12:03,269 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:12:03,269 - INFO - joeynmt.training - 	Hypothesis: Aan de twee dia getoond, om te verzorgen dat de arctische ijskappen die voor de arctische ijskappen die de grens van de onderste 40 procent is gemaakt om 40 procent gedurende de grond is dat 40 procent is gegaan.
2025-05-29 20:12:03,269 - INFO - joeynmt.training - Example #1
2025-05-29 20:12:03,269 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:12:03,269 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:12:03,269 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'er@@', 'uit', 'omdat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's@@', 'k@@', 'je', 'l@@', 'aat', 'zien.', '</s>']
2025-05-29 20:12:03,270 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:12:03,270 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:12:03,271 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerst van dit specifieke probleem eruit omdat het niet de dik van het ijskje laat zien.
2025-05-29 20:12:03,271 - INFO - joeynmt.training - Example #2
2025-05-29 20:12:03,271 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:12:03,271 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:12:03,271 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'be@@', 'sl@@', 'oo@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:12:03,272 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:12:03,272 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:12:03,272 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappen het besloot van onze wereldwijde klimaatsysteem.
2025-05-29 20:12:03,273 - INFO - joeynmt.training - Example #3
2025-05-29 20:12:03,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:12:03,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:12:03,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:12:03,274 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:12:03,274 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:12:03,274 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomert.
2025-05-29 20:12:03,274 - INFO - joeynmt.training - Example #4
2025-05-29 20:12:03,275 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:12:03,275 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:12:03,275 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 20:12:03,276 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:12:03,276 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:12:03,276 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje tijdschrift van wat er gebeurt in de afgelopen 25 jaar is.
2025-05-29 20:12:12,660 - INFO - joeynmt.training - Epoch   5, Step:    40600, Batch Loss:     1.599385, Batch Acc: 0.528620, Tokens per Sec:     7383, Lr: 0.000300
2025-05-29 20:12:21,988 - INFO - joeynmt.training - Epoch   5, Step:    40700, Batch Loss:     1.511448, Batch Acc: 0.532014, Tokens per Sec:     7684, Lr: 0.000300
2025-05-29 20:12:31,343 - INFO - joeynmt.training - Epoch   5, Step:    40800, Batch Loss:     1.533574, Batch Acc: 0.533411, Tokens per Sec:     7663, Lr: 0.000300
2025-05-29 20:12:40,654 - INFO - joeynmt.training - Epoch   5, Step:    40900, Batch Loss:     1.654796, Batch Acc: 0.529536, Tokens per Sec:     7404, Lr: 0.000300
2025-05-29 20:12:50,084 - INFO - joeynmt.training - Epoch   5, Step:    41000, Batch Loss:     1.683352, Batch Acc: 0.525170, Tokens per Sec:     7495, Lr: 0.000300
2025-05-29 20:12:50,084 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:12:50,084 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:13:30,670 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.52, acc:   0.50, generation: 40.5474[sec], evaluation: 0.0000[sec]
2025-05-29 20:13:30,672 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:13:30,852 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/37000.ckpt
2025-05-29 20:13:30,867 - INFO - joeynmt.training - Example #0
2025-05-29 20:13:30,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:13:30,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:13:30,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'zor@@', 'gen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'gr@@', 'ond', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'k@@', 'n@@', 'eer@@', 'd,', 'om', '4@@', '0', 'proc@@', 'ent', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'kan@@', 's', 'dat', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste']
2025-05-29 20:13:30,870 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:13:30,871 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:13:30,871 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te verzorgen dat de artische ijskappen, die voor de artische ijskappen, die voor 40 procent van de grond van 40 procent van de onderste 40 procent van 40 procent is gekneerd, om 40 procent van 40 procent van de reden van 40 procent van de reden van 40 procent van de onderkans dat de reden van 40 procent van de onderste
2025-05-29 20:13:30,871 - INFO - joeynmt.training - Example #1
2025-05-29 20:13:30,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:13:30,872 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:13:30,872 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'want', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ap@@', '.', '</s>']
2025-05-29 20:13:30,873 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:13:30,873 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:13:30,873 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste staat, want het is niet de dikke probleem, omdat het niet de dikke van het ijskwestie van de ijskap.
2025-05-29 20:13:30,873 - INFO - joeynmt.training - Example #2
2025-05-29 20:13:30,874 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:13:30,874 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:13:30,874 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'kel', 'het', 'har@@', 't', 'van', 'de', 'ar@@', 'ti@@', 'kel', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:13:30,875 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:13:30,875 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:13:30,875 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artikel het hart van de artikel het hart van onze wereldwijde klimaatsysteem.
2025-05-29 20:13:30,875 - INFO - joeynmt.training - Example #3
2025-05-29 20:13:30,875 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:13:30,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:13:30,876 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 20:13:30,876 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:13:30,877 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:13:30,877 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomer.
2025-05-29 20:13:30,877 - INFO - joeynmt.training - Example #4
2025-05-29 20:13:30,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:13:30,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:13:30,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:13:30,878 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:13:30,878 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:13:30,878 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdje van de laatste 25 jaar is gebeurd.
2025-05-29 20:13:40,370 - INFO - joeynmt.training - Epoch   5, Step:    41100, Batch Loss:     1.637435, Batch Acc: 0.527717, Tokens per Sec:     7231, Lr: 0.000300
2025-05-29 20:13:49,064 - INFO - joeynmt.training - Epoch   5, Step:    41200, Batch Loss:     1.459836, Batch Acc: 0.534071, Tokens per Sec:     7911, Lr: 0.000300
2025-05-29 20:13:57,396 - INFO - joeynmt.training - Epoch   5, Step:    41300, Batch Loss:     1.747594, Batch Acc: 0.529215, Tokens per Sec:     8647, Lr: 0.000300
2025-05-29 20:14:05,692 - INFO - joeynmt.training - Epoch   5, Step:    41400, Batch Loss:     1.755888, Batch Acc: 0.527152, Tokens per Sec:     8639, Lr: 0.000300
2025-05-29 20:14:13,857 - INFO - joeynmt.training - Epoch   5, Step:    41500, Batch Loss:     1.481147, Batch Acc: 0.527365, Tokens per Sec:     8636, Lr: 0.000300
2025-05-29 20:14:13,858 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:14:13,858 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:14:51,623 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.51, acc:   0.50, generation: 37.7260[sec], evaluation: 0.0000[sec]
2025-05-29 20:14:51,624 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:14:51,813 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/39500.ckpt
2025-05-29 20:14:51,831 - INFO - joeynmt.training - Example #0
2025-05-29 20:14:51,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:14:51,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:14:51,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'der', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'app@@', 'en', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'ens', 'die', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '8@@', 'e', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'is.', '</s>']
2025-05-29 20:14:51,833 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:14:51,833 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:14:51,833 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verder te zien dat de arctische ijsappen die drie miljoen jaar de grens die de reden van de onderste 48e staten van de onderste 40 procent van de onderste 40 procent van de reden van 40 procent is.
2025-05-29 20:14:51,834 - INFO - joeynmt.training - Example #1
2025-05-29 20:14:51,834 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:14:51,834 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:14:51,834 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:14:51,835 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:14:51,835 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:14:51,836 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerst van dit speciale probleem van dit speciale probleem omdat het niet de dikke van het ijskwestie toont.
2025-05-29 20:14:51,836 - INFO - joeynmt.training - Example #2
2025-05-29 20:14:51,836 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:14:51,836 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:14:51,836 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'sl@@', 'aa@@', 'g@@', 'de', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:14:51,837 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:14:51,838 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:14:51,838 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe het slaagde hart van ons wereldwijde klimaatsysteem.
2025-05-29 20:14:51,838 - INFO - joeynmt.training - Example #3
2025-05-29 20:14:51,838 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:14:51,838 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:14:51,838 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'i@@', 'ten', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 20:14:51,839 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:14:51,839 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:14:51,840 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en sluiten in de zomers.
2025-05-29 20:14:51,840 - INFO - joeynmt.training - Example #4
2025-05-29 20:14:51,840 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:14:51,840 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:14:51,840 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 20:14:51,841 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:14:51,842 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:14:51,842 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdperk van wat er gebeurt in de laatste 25 jaar is.
2025-05-29 20:15:01,301 - INFO - joeynmt.training - Epoch   5, Step:    41600, Batch Loss:     1.639991, Batch Acc: 0.527986, Tokens per Sec:     7433, Lr: 0.000300
2025-05-29 20:15:10,823 - INFO - joeynmt.training - Epoch   5, Step:    41700, Batch Loss:     1.651274, Batch Acc: 0.530731, Tokens per Sec:     7526, Lr: 0.000300
2025-05-29 20:15:20,102 - INFO - joeynmt.training - Epoch   5, Step:    41800, Batch Loss:     1.654818, Batch Acc: 0.528371, Tokens per Sec:     7359, Lr: 0.000300
2025-05-29 20:15:29,534 - INFO - joeynmt.training - Epoch   5, Step:    41900, Batch Loss:     1.741199, Batch Acc: 0.525866, Tokens per Sec:     7505, Lr: 0.000300
2025-05-29 20:15:38,825 - INFO - joeynmt.training - Epoch   5, Step:    42000, Batch Loss:     1.502545, Batch Acc: 0.530883, Tokens per Sec:     7508, Lr: 0.000300
2025-05-29 20:15:38,826 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:15:38,826 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:16:21,792 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.53, acc:   0.50, generation: 42.9172[sec], evaluation: 0.0000[sec]
2025-05-29 20:16:21,972 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/38000.ckpt
2025-05-29 20:16:21,990 - INFO - joeynmt.training - Example #0
2025-05-29 20:16:21,991 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:16:21,991 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:16:21,991 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'de', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'der', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 're@@', 'den', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'ï@@', 'n@@', 'ter@@', 'ess@@', 'eerd', 'is.', '</s>']
2025-05-29 20:16:21,992 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:16:21,992 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:16:21,992 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoonde getoond om te verder te zien dat de artische ijskappen, die de reden voor de onderste 48 staten van de onderste 48 staten van de onderste 40 procent geïnteresseerd is.
2025-05-29 20:16:21,993 - INFO - joeynmt.training - Example #1
2025-05-29 20:16:21,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:16:21,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:16:21,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'ck@@', 'e', 'van', 'het', 'ij@@', 's@@', 'ver@@', 'mo@@', 'gen', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:16:21,994 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:16:21,994 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:16:21,994 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerst van dit specifiek is dat het niet de dikke dicke van het ijsvermogen toont.
2025-05-29 20:16:21,995 - INFO - joeynmt.training - Example #2
2025-05-29 20:16:21,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:16:21,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:16:21,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'sl@@', 'aa@@', 'g@@', 'd', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:16:21,996 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:16:21,996 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:16:21,996 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het slaagd van onze wereldwijd systeem.
2025-05-29 20:16:21,996 - INFO - joeynmt.training - Example #3
2025-05-29 20:16:21,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:16:21,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:16:21,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 20:16:21,998 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:16:21,998 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:16:21,998 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zomer.
2025-05-29 20:16:21,998 - INFO - joeynmt.training - Example #4
2025-05-29 20:16:21,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:16:21,999 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:16:21,999 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'ti@@', 'ent@@', 'allen', 'jaar', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:16:22,000 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:16:22,000 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:16:22,000 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tientallen jaar opname wat er gebeurde in de laatste 25 jaar is gebeurd.
2025-05-29 20:16:31,436 - INFO - joeynmt.training - Epoch   5, Step:    42100, Batch Loss:     1.814674, Batch Acc: 0.520644, Tokens per Sec:     7228, Lr: 0.000300
2025-05-29 20:16:40,420 - INFO - joeynmt.training - Epoch   5, Step:    42200, Batch Loss:     1.321858, Batch Acc: 0.531349, Tokens per Sec:     7673, Lr: 0.000300
2025-05-29 20:16:49,100 - INFO - joeynmt.training - Epoch   5, Step:    42300, Batch Loss:     1.556438, Batch Acc: 0.533713, Tokens per Sec:     8198, Lr: 0.000300
2025-05-29 20:16:57,381 - INFO - joeynmt.training - Epoch   5, Step:    42400, Batch Loss:     1.399277, Batch Acc: 0.529870, Tokens per Sec:     8615, Lr: 0.000300
2025-05-29 20:17:05,501 - INFO - joeynmt.training - Epoch   5, Step:    42500, Batch Loss:     1.567821, Batch Acc: 0.530414, Tokens per Sec:     8836, Lr: 0.000300
2025-05-29 20:17:05,502 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:17:05,502 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:17:40,967 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.51, acc:   0.50, generation: 35.4248[sec], evaluation: 0.0000[sec]
2025-05-29 20:17:40,968 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:17:41,166 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/40500.ckpt
2025-05-29 20:17:41,187 - INFO - joeynmt.training - Example #0
2025-05-29 20:17:41,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:17:41,188 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:17:41,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'om', 'te', 'ver@@', 'kijken', 'om', 'te', 'ver@@', 'kijken', 'naar', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'voor', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'had', 'ge@@', 'had', 'om', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'te', 'zijn.', '</s>']
2025-05-29 20:17:41,189 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:17:41,189 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:17:41,190 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verkijken om te verkijken om te verkijken naar de artische ijskappen, die voor de grondstoffen voor de grondstoffen had gehad om 40 procent geslaagd te zijn.
2025-05-29 20:17:41,190 - INFO - joeynmt.training - Example #1
2025-05-29 20:17:41,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:17:41,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:17:41,190 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'e,', 'die', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'is', 'dat', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'at@@', 'uur@@', '.', '</s>']
2025-05-29 20:17:41,196 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:17:41,196 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:17:41,196 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de eerste, die specifieke probleem is dat niet de dikke van het ijskapparatuur.
2025-05-29 20:17:41,197 - INFO - joeynmt.training - Example #2
2025-05-29 20:17:41,197 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:17:41,197 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:17:41,197 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'on@@', 'be@@', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:17:41,198 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:17:41,198 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:17:41,198 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het onbehart van onze wereldwijde klimaatsysteem.
2025-05-29 20:17:41,198 - INFO - joeynmt.training - Example #3
2025-05-29 20:17:41,198 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:17:41,198 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:17:41,198 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lo@@', 'ten', 'in', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 20:17:41,198 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:17:41,198 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:17:41,201 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en sloten in de zomer in de zomer en zomer.
2025-05-29 20:17:41,201 - INFO - joeynmt.training - Example #4
2025-05-29 20:17:41,201 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:17:41,201 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:17:41,201 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:17:41,202 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:17:41,203 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:17:41,203 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat is een tijdschrift van wat er in de laatste 25 jaar gebeurd.
2025-05-29 20:17:50,736 - INFO - joeynmt.training - Epoch   5, Step:    42600, Batch Loss:     1.533468, Batch Acc: 0.536032, Tokens per Sec:     6981, Lr: 0.000300
2025-05-29 20:18:00,130 - INFO - joeynmt.training - Epoch   5, Step:    42700, Batch Loss:     1.534950, Batch Acc: 0.530416, Tokens per Sec:     7517, Lr: 0.000300
2025-05-29 20:18:09,440 - INFO - joeynmt.training - Epoch   5, Step:    42800, Batch Loss:     1.774525, Batch Acc: 0.532609, Tokens per Sec:     7656, Lr: 0.000300
2025-05-29 20:18:18,693 - INFO - joeynmt.training - Epoch   5, Step:    42900, Batch Loss:     1.739369, Batch Acc: 0.528654, Tokens per Sec:     7574, Lr: 0.000300
2025-05-29 20:18:28,059 - INFO - joeynmt.training - Epoch   5, Step:    43000, Batch Loss:     1.539917, Batch Acc: 0.534517, Tokens per Sec:     7481, Lr: 0.000300
2025-05-29 20:18:28,060 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:18:28,060 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:19:10,329 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.50, acc:   0.50, generation: 42.2213[sec], evaluation: 0.0000[sec]
2025-05-29 20:19:10,332 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:19:10,532 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/42000.ckpt
2025-05-29 20:19:10,547 - INFO - joeynmt.training - Example #0
2025-05-29 20:19:10,548 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:19:10,548 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:19:10,548 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'ver@@', 'tel@@', 'den', 'om', 'te', 'ver@@', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 't@@', 'op', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'waarom', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'waarom', 'we', 'de', 're@@']
2025-05-29 20:19:10,549 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:19:10,549 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:19:10,549 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen om te vertelden om te verzien dat de arctische ijskappen, die voor de top van de onderste 48 staten van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de reden van 40 procent van de reden van de onderste 40 procent van de reden waarom de reden van 40 procent van de reden waarom we de re
2025-05-29 20:19:10,550 - INFO - joeynmt.training - Example #1
2025-05-29 20:19:10,550 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:19:10,550 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:19:10,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'and@@', 'pun@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 20:19:10,551 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:19:10,551 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:19:10,551 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste standpunt van dit specifiek is dat het niet de dikke van het ijsver.
2025-05-29 20:19:10,552 - INFO - joeynmt.training - Example #2
2025-05-29 20:19:10,552 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:19:10,552 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:19:10,552 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'de', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:19:10,553 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:19:10,553 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:19:10,553 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het slaagde hart van ons wereldwijde klimaatsysteem.
2025-05-29 20:19:10,554 - INFO - joeynmt.training - Example #3
2025-05-29 20:19:10,554 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:19:10,554 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:19:10,554 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:19:10,555 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:19:10,555 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:19:10,555 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomert.
2025-05-29 20:19:10,556 - INFO - joeynmt.training - Example #4
2025-05-29 20:19:10,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:19:10,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:19:10,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'ge@@', 'vol@@', 'g', 'is', 'een', 'tij@@', 'd@@', 'je', 'l@@', 'aat', 'zien', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de.', '</s>']
2025-05-29 20:19:10,557 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:19:10,557 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:19:10,557 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg is een tijdje laat zien wat er in de laatste 25 jaar gebeurde.
2025-05-29 20:19:20,003 - INFO - joeynmt.training - Epoch   5, Step:    43100, Batch Loss:     1.488770, Batch Acc: 0.530402, Tokens per Sec:     7225, Lr: 0.000300
2025-05-29 20:19:28,820 - INFO - joeynmt.training - Epoch   5, Step:    43200, Batch Loss:     1.416334, Batch Acc: 0.539392, Tokens per Sec:     7696, Lr: 0.000300
2025-05-29 20:19:37,716 - INFO - joeynmt.training - Epoch   5, Step:    43300, Batch Loss:     1.550505, Batch Acc: 0.532322, Tokens per Sec:     7660, Lr: 0.000300
2025-05-29 20:19:46,125 - INFO - joeynmt.training - Epoch   5, Step:    43400, Batch Loss:     1.753714, Batch Acc: 0.529126, Tokens per Sec:     8244, Lr: 0.000300
2025-05-29 20:19:54,206 - INFO - joeynmt.training - Epoch   5, Step:    43500, Batch Loss:     1.425122, Batch Acc: 0.530315, Tokens per Sec:     8729, Lr: 0.000300
2025-05-29 20:19:54,206 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:19:54,207 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:20:27,759 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.47, acc:   0.50, generation: 33.5165[sec], evaluation: 0.0000[sec]
2025-05-29 20:20:27,760 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:20:27,943 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/40000.ckpt
2025-05-29 20:20:27,969 - INFO - joeynmt.training - Example #0
2025-05-29 20:20:27,970 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:20:27,970 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:20:27,970 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'der', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gro@@', 'ter@@', 'e', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd', 'is.', '</s>']
2025-05-29 20:20:27,971 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:20:27,971 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:20:27,972 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te verder te zien dat de artische ijskappen, die voor de artische ijskappen, die de grotere van de onderste 40 procent van de onderste 40 procent gegooid is.
2025-05-29 20:20:27,972 - INFO - joeynmt.training - Example #1
2025-05-29 20:20:27,972 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:20:27,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:20:27,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 'm@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'er@@', 'uit', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:20:27,973 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:20:27,974 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:20:27,974 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de eerste staamheid van dit specifieke probleem eruit omdat het niet de dikke van het ijs toont.
2025-05-29 20:20:27,974 - INFO - joeynmt.training - Example #2
2025-05-29 20:20:27,974 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:20:27,974 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:20:27,974 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's', 'het', 'sl@@', 'aa@@', 'g@@', 'de', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:20:27,975 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:20:27,976 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:20:27,976 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijs het slaagde hart van onze wereldwijde klimaatsysteem.
2025-05-29 20:20:27,976 - INFO - joeynmt.training - Example #3
2025-05-29 20:20:27,976 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:20:27,976 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:20:27,977 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:20:27,977 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:20:27,978 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:20:27,978 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomert.
2025-05-29 20:20:27,978 - INFO - joeynmt.training - Example #4
2025-05-29 20:20:27,978 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:20:27,978 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:20:27,978 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:20:27,979 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:20:27,980 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:20:27,980 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje van wat er gebeurt in de laatste 25 jaar gebeurd.
2025-05-29 20:20:37,196 - INFO - joeynmt.training - Epoch   5, Step:    43600, Batch Loss:     1.540735, Batch Acc: 0.530413, Tokens per Sec:     7389, Lr: 0.000300
2025-05-29 20:20:46,629 - INFO - joeynmt.training - Epoch   5, Step:    43700, Batch Loss:     1.494653, Batch Acc: 0.531021, Tokens per Sec:     7268, Lr: 0.000300
2025-05-29 20:20:55,886 - INFO - joeynmt.training - Epoch   5, Step:    43800, Batch Loss:     1.732748, Batch Acc: 0.531370, Tokens per Sec:     7578, Lr: 0.000300
2025-05-29 20:21:05,119 - INFO - joeynmt.training - Epoch   5, Step:    43900, Batch Loss:     1.566576, Batch Acc: 0.533859, Tokens per Sec:     7718, Lr: 0.000300
2025-05-29 20:21:14,457 - INFO - joeynmt.training - Epoch   5, Step:    44000, Batch Loss:     1.648308, Batch Acc: 0.523276, Tokens per Sec:     7482, Lr: 0.000300
2025-05-29 20:21:14,457 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:21:14,458 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:21:54,186 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.47, acc:   0.50, generation: 39.6866[sec], evaluation: 0.0000[sec]
2025-05-29 20:21:54,371 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/41000.ckpt
2025-05-29 20:21:54,389 - INFO - joeynmt.training - Example #0
2025-05-29 20:21:54,390 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:21:54,390 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:21:54,390 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'voor', 'de', 'gr@@', 'ond', 'van', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', '4@@', '0', 'proc@@', 'ent', 'is.', '</s>']
2025-05-29 20:21:54,391 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:21:54,391 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:21:54,392 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond dat de artische ijskappe dat de artische ijskappe die voor de grond van 48 staten van de onderkant van de onderste 40 procent van de onderkant van 40 procent van de onderkant van 40 procent is.
2025-05-29 20:21:54,392 - INFO - joeynmt.training - Example #1
2025-05-29 20:21:54,392 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:21:54,392 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:21:54,392 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'ro@@', 'om', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'uit', 'te', 'hal@@', 'en.', '</s>']
2025-05-29 20:21:54,393 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:21:54,393 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:21:54,393 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste stroom dit speciale probleem van dit speciale probleem uit te halen.
2025-05-29 20:21:54,394 - INFO - joeynmt.training - Example #2
2025-05-29 20:21:54,394 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:21:54,394 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:21:54,394 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'd', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'd', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:21:54,395 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:21:54,395 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:21:54,396 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het slaagd van ons wereldwijd van ons wereldwijd klimaatsysteem.
2025-05-29 20:21:54,396 - INFO - joeynmt.training - Example #3
2025-05-29 20:21:54,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:21:54,396 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:21:54,396 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'z@@', 'am@@', 'el@@', 'ing', 'in', 'de', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:21:54,397 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:21:54,397 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:21:54,398 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en verzameling in de zomert.
2025-05-29 20:21:54,398 - INFO - joeynmt.training - Example #4
2025-05-29 20:21:54,398 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:21:54,398 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:21:54,398 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 20:21:54,399 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:21:54,399 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:21:54,400 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift van wat er gebeurt in de laatste 25 jaar.
2025-05-29 20:22:03,816 - INFO - joeynmt.training - Epoch   5, Step:    44100, Batch Loss:     1.770656, Batch Acc: 0.532186, Tokens per Sec:     7175, Lr: 0.000300
2025-05-29 20:22:12,856 - INFO - joeynmt.training - Epoch   5, Step:    44200, Batch Loss:     1.407754, Batch Acc: 0.529453, Tokens per Sec:     7981, Lr: 0.000300
2025-05-29 20:22:21,864 - INFO - joeynmt.training - Epoch   5, Step:    44300, Batch Loss:     1.526098, Batch Acc: 0.534863, Tokens per Sec:     7645, Lr: 0.000300
2025-05-29 20:22:30,826 - INFO - joeynmt.training - Epoch   5, Step:    44400, Batch Loss:     1.552988, Batch Acc: 0.526908, Tokens per Sec:     7861, Lr: 0.000300
2025-05-29 20:22:40,153 - INFO - joeynmt.training - Epoch   5, Step:    44500, Batch Loss:     1.579833, Batch Acc: 0.537499, Tokens per Sec:     7670, Lr: 0.000300
2025-05-29 20:22:40,153 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:22:40,154 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:23:14,019 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.46, acc:   0.50, generation: 33.8337[sec], evaluation: 0.0000[sec]
2025-05-29 20:23:14,020 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:23:14,196 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/41500.ckpt
2025-05-29 20:23:14,212 - INFO - joeynmt.training - Example #0
2025-05-29 20:23:14,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:23:14,213 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:23:14,213 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'de', 'ge@@', 'vol@@', 'g', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'voor', 'de', 'n@@', 'aam', 'die', 'voor', 'de', 'n@@', 'aa@@', 'st', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'ij@@', 's', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'dur@@', 'ende', 'de', 'V@@', 'S', 'was', 'ge@@', 'dur@@', 'ende', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'is.', '</s>']
2025-05-29 20:23:14,214 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:23:14,214 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:23:14,214 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoonde gevolg om te verkijken dat de arctische ijskappe die voor de naam die voor de naast drie miljoen jaar de grijs van de onderkant van de onderkant van 40 procent gedurende de VS was gedurende de grondstoffen is.
2025-05-29 20:23:14,214 - INFO - joeynmt.training - Example #1
2025-05-29 20:23:14,215 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:23:14,215 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:23:14,215 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'het', 'niet', 'goed', 'genoe@@', 'g', 'is', 'om', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'het', 'ij@@', 's', 'te', 'laten', 'zien.', '</s>']
2025-05-29 20:23:14,216 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:23:14,216 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:23:14,216 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste is dat het niet goed genoeg is om dit speciale probleem van het ijs te laten zien.
2025-05-29 20:23:14,216 - INFO - joeynmt.training - Example #2
2025-05-29 20:23:14,217 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:23:14,217 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:23:14,217 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:23:14,218 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:23:14,218 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:23:14,218 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het slaagsysteem.
2025-05-29 20:23:14,218 - INFO - joeynmt.training - Example #3
2025-05-29 20:23:14,218 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:23:14,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:23:14,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'sch@@', 'ru@@', 'cht', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 20:23:14,220 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:23:14,220 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:23:14,220 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en schrucht in de zomers.
2025-05-29 20:23:14,220 - INFO - joeynmt.training - Example #4
2025-05-29 20:23:14,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:23:14,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:23:14,221 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 20:23:14,221 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:23:14,222 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:23:14,222 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschriften wat er gebeurt in de laatste 25 jaar is.
2025-05-29 20:23:22,953 - INFO - joeynmt.training - Epoch   5, Step:    44600, Batch Loss:     1.536557, Batch Acc: 0.533164, Tokens per Sec:     7994, Lr: 0.000300
2025-05-29 20:23:32,166 - INFO - joeynmt.training - Epoch   5, Step:    44700, Batch Loss:     1.500839, Batch Acc: 0.538517, Tokens per Sec:     7483, Lr: 0.000300
2025-05-29 20:23:41,598 - INFO - joeynmt.training - Epoch   5, Step:    44800, Batch Loss:     1.568599, Batch Acc: 0.526331, Tokens per Sec:     7450, Lr: 0.000300
2025-05-29 20:23:50,919 - INFO - joeynmt.training - Epoch   5, Step:    44900, Batch Loss:     1.468537, Batch Acc: 0.533812, Tokens per Sec:     7689, Lr: 0.000300
2025-05-29 20:24:00,376 - INFO - joeynmt.training - Epoch   5, Step:    45000, Batch Loss:     1.364736, Batch Acc: 0.527864, Tokens per Sec:     7266, Lr: 0.000300
2025-05-29 20:24:00,376 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:24:00,376 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:24:39,593 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.45, acc:   0.50, generation: 39.1687[sec], evaluation: 0.0000[sec]
2025-05-29 20:24:39,594 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:24:39,774 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/42500.ckpt
2025-05-29 20:24:39,792 - INFO - joeynmt.training - Example #0
2025-05-29 20:24:39,793 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:24:39,793 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:24:39,793 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'de', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gr@@', 'ond', 'van', 'de', 'gr@@', 'ond', 'van', 'de', 'gr@@', 'ond', 'van', 'de', 'gr@@', 'ond', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'gr@@', 'ond', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'lan@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'c@@', 'en@@', 'te', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 'twee', 'di@@', 'a', 'van', 'de', 'twee', 'di@@', 'a', 'van', 'de', 'ge@@', 'vol@@', 'gen', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'twee', 'di@@', 'a', 'van', 'de', 'ge@@', 'vol@@', 'gen']
2025-05-29 20:24:39,794 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:24:39,794 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:24:39,794 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoonde dat de artische ijskappen die voor de artische ijskappen, die de grond van de grond van de grond van de grond van 40 procent van de grond van 40 procent van de landen van 40 procent van de recente van 40 procent van de reden van de twee dia van de twee dia van de gevolgen 40 procent van de twee dia van de gevolgen
2025-05-29 20:24:39,794 - INFO - joeynmt.training - Example #1
2025-05-29 20:24:39,795 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:24:39,795 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:24:39,795 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 'm@@', 'heid', 'van', 'dit', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ap@@', 'el@@', 's', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'de', 'ij@@', 's@@', 'de', 'van', 'de', 'ij@@', 's@@', 'de', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ap@@', 'el@@', 't.', '</s>']
2025-05-29 20:24:39,796 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:24:39,796 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:24:39,796 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste staamheid van dit ijskaart van het ijskapels van het ijsje van de ijsde van de ijsde van de ijskapelt.
2025-05-29 20:24:39,797 - INFO - joeynmt.training - Example #2
2025-05-29 20:24:39,797 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:24:39,797 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:24:39,797 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:24:39,798 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:24:39,798 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:24:39,798 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het hart van ons wereldwijde klimaatsysteem.
2025-05-29 20:24:39,798 - INFO - joeynmt.training - Example #3
2025-05-29 20:24:39,799 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:24:39,799 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:24:39,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'on@@', '.', '</s>']
2025-05-29 20:24:39,800 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:24:39,800 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:24:39,800 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schoon.
2025-05-29 20:24:39,800 - INFO - joeynmt.training - Example #4
2025-05-29 20:24:39,801 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:24:39,801 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:24:39,801 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'oon', 'l@@', 'aat', 'zien', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:24:39,802 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:24:39,802 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:24:39,802 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik toon laat zien wat er in de laatste 25 jaar is gebeurd.
2025-05-29 20:24:49,091 - INFO - joeynmt.training - Epoch   5, Step:    45100, Batch Loss:     1.530803, Batch Acc: 0.530653, Tokens per Sec:     7336, Lr: 0.000300
2025-05-29 20:24:58,330 - INFO - joeynmt.training - Epoch   5, Step:    45200, Batch Loss:     1.518014, Batch Acc: 0.524678, Tokens per Sec:     7683, Lr: 0.000300
2025-05-29 20:25:07,413 - INFO - joeynmt.training - Epoch   5, Step:    45300, Batch Loss:     1.672543, Batch Acc: 0.530757, Tokens per Sec:     7915, Lr: 0.000300
2025-05-29 20:25:16,530 - INFO - joeynmt.training - Epoch   5, Step:    45400, Batch Loss:     1.737255, Batch Acc: 0.527421, Tokens per Sec:     7504, Lr: 0.000300
2025-05-29 20:25:26,030 - INFO - joeynmt.training - Epoch   5, Step:    45500, Batch Loss:     1.776051, Batch Acc: 0.531981, Tokens per Sec:     7453, Lr: 0.000300
2025-05-29 20:25:26,031 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:25:26,031 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:26:01,427 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.43, acc:   0.51, generation: 35.3574[sec], evaluation: 0.0000[sec]
2025-05-29 20:26:01,428 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:26:01,596 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/43000.ckpt
2025-05-29 20:26:01,611 - INFO - joeynmt.training - Example #0
2025-05-29 20:26:01,612 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:26:01,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:26:01,612 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'tel@@', 'den', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'at@@', 'uur', 'van', 'de', 'onder@@', 'ste', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'ag@@', 'en.', '</s>']
2025-05-29 20:26:01,613 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:26:01,614 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:26:01,614 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te vertelden dat de artische ijskapparatuur van de onderste drie miljoen jaar de grens van de onderste 48 staten van de onderste 48 staten van de 40 procent geslagen.
2025-05-29 20:26:01,614 - INFO - joeynmt.training - Example #1
2025-05-29 20:26:01,614 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:26:01,614 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:26:01,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'het', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'het', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'het', 'ij@@', 's@@', 'je', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:26:01,615 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:26:01,616 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:26:01,616 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste is dat speciale probleem van dit speciale probleem van het ijskaart van het ijskaart van het ijsje toont.
2025-05-29 20:26:01,616 - INFO - joeynmt.training - Example #2
2025-05-29 20:26:01,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:26:01,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:26:01,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'be@@', 'sl@@', 'ag@@', ',', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:26:01,617 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:26:01,618 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:26:01,618 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het beslag, het hart van ons wereldwijde klimaatsysteem.
2025-05-29 20:26:01,618 - INFO - joeynmt.training - Example #3
2025-05-29 20:26:01,618 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:26:01,618 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:26:01,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:26:01,619 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:26:01,620 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:26:01,620 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en somert.
2025-05-29 20:26:01,620 - INFO - joeynmt.training - Example #4
2025-05-29 20:26:01,620 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:26:01,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:26:01,620 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 20:26:01,621 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:26:01,621 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:26:01,621 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdschrift van wat er gebeurt in de laatste 25 jaar.
2025-05-29 20:26:10,207 - INFO - joeynmt.training - Epoch   5, Step:    45600, Batch Loss:     1.706071, Batch Acc: 0.531442, Tokens per Sec:     7897, Lr: 0.000300
2025-05-29 20:26:19,148 - INFO - joeynmt.training - Epoch   5, Step:    45700, Batch Loss:     1.451360, Batch Acc: 0.530542, Tokens per Sec:     7913, Lr: 0.000300
2025-05-29 20:26:28,158 - INFO - joeynmt.training - Epoch   5, Step:    45800, Batch Loss:     1.487870, Batch Acc: 0.533763, Tokens per Sec:     7790, Lr: 0.000300
2025-05-29 20:26:37,472 - INFO - joeynmt.training - Epoch   5, Step:    45900, Batch Loss:     1.854204, Batch Acc: 0.529448, Tokens per Sec:     7418, Lr: 0.000300
2025-05-29 20:26:46,753 - INFO - joeynmt.training - Epoch   5, Step:    46000, Batch Loss:     1.549698, Batch Acc: 0.528133, Tokens per Sec:     7530, Lr: 0.000300
2025-05-29 20:26:46,754 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:26:46,754 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:27:23,902 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.45, acc:   0.50, generation: 37.1033[sec], evaluation: 0.0000[sec]
2025-05-29 20:27:24,080 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/44000.ckpt
2025-05-29 20:27:24,097 - INFO - joeynmt.training - Example #0
2025-05-29 20:27:24,098 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:27:24,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:27:24,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'de', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'zo@@', 'dat', 'de', '4@@', '8', 'st@@', 'aa@@', 't,', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'g@@', 'aan.', '</s>']
2025-05-29 20:27:24,099 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:27:24,099 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:27:24,099 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoonde getoond, om te verbeteren dat de artische ijskappen, die voor de artische ijskappen, zodat de 48 staat, om 40 procent te gaan.
2025-05-29 20:27:24,100 - INFO - joeynmt.training - Example #1
2025-05-29 20:27:24,100 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:27:24,100 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:27:24,100 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'n@@', 'u@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'is', 'dat', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'ge@@', 'eft', 'van', 'het', 'ij@@', 's@@', 'ge@@', 'k.', '</s>']
2025-05-29 20:27:24,101 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:27:24,101 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:27:24,101 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste nut van dit speciale probleem van dit ijskaart is dat niet de dikke van het ijsgeeft van het ijsgek.
2025-05-29 20:27:24,102 - INFO - joeynmt.training - Example #2
2025-05-29 20:27:24,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:27:24,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:27:24,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:27:24,104 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:27:24,104 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:27:24,104 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe het hart van ons wereldwijde klimaatsysteem.
2025-05-29 20:27:24,104 - INFO - joeynmt.training - Example #3
2025-05-29 20:27:24,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:27:24,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:27:24,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'ne@@', 'em@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 20:27:24,106 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:27:24,106 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:27:24,106 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en sneemt in de zomers.
2025-05-29 20:27:24,106 - INFO - joeynmt.training - Example #4
2025-05-29 20:27:24,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:27:24,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:27:24,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'ti@@', 'c@@', 'ul@@', 'a@@', 'ir@@', 'e', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 20:27:24,108 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:27:24,108 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:27:24,108 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een ticulaire opname wat er gebeurt in de laatste 25 jaar.
2025-05-29 20:27:33,282 - INFO - joeynmt.training - Epoch   5, Step:    46100, Batch Loss:     1.533245, Batch Acc: 0.532152, Tokens per Sec:     7524, Lr: 0.000300
2025-05-29 20:27:37,997 - INFO - joeynmt.training - Epoch   5: total training loss 14664.41
2025-05-29 20:27:37,998 - INFO - joeynmt.training - EPOCH 6
2025-05-29 20:27:42,628 - INFO - joeynmt.training - Epoch   6, Step:    46200, Batch Loss:     1.543628, Batch Acc: 0.541234, Tokens per Sec:     7361, Lr: 0.000300
2025-05-29 20:27:51,636 - INFO - joeynmt.training - Epoch   6, Step:    46300, Batch Loss:     1.480423, Batch Acc: 0.547497, Tokens per Sec:     7932, Lr: 0.000300
2025-05-29 20:28:00,519 - INFO - joeynmt.training - Epoch   6, Step:    46400, Batch Loss:     1.529605, Batch Acc: 0.544304, Tokens per Sec:     7775, Lr: 0.000300
2025-05-29 20:28:09,626 - INFO - joeynmt.training - Epoch   6, Step:    46500, Batch Loss:     1.674039, Batch Acc: 0.541524, Tokens per Sec:     7819, Lr: 0.000300
2025-05-29 20:28:09,627 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:28:09,627 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:28:53,448 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.45, acc:   0.51, generation: 43.7816[sec], evaluation: 0.0000[sec]
2025-05-29 20:28:53,627 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/43500.ckpt
2025-05-29 20:28:53,650 - INFO - joeynmt.training - Example #0
2025-05-29 20:28:53,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:28:53,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:28:53,651 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', '4@@', '8', 'st@@', 'aten', 'in', 'de', 'onder@@', '4@@', '8', 'st@@', 'aa@@', 't,', 'om', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'V@@', 'S', 'en', 'de', 'groot@@', 'te', 'van', 'de', 'A@@', 'f@@', 'g@@', 'de', 'om', 'te', 'ver@@', 'tro@@', 'uw@@', 'en', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'van', 'de', 're@@', 'eu@@', 'w@@', 'en', 'dat', 'de', 'groot@@', 'te', 'van', 'de', 'twee', 'ge@@', 'vol@@', 'gen', 'van', 'de', 're@@', 'den', 'van', 'de', 'groot@@', 'te', 'van']
2025-05-29 20:28:53,652 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:28:53,652 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:28:53,652 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verbeteren dat de arctische ijskappen, die voor de arctische ijskappen, de grootte van de onder48 staten in de onder48 staat, om 40 procent van de grootte van de VS en de grootte van de Afgde om te vertrouwen te verbeteren van de reeuwen dat de grootte van de twee gevolgen van de reden van de grootte van
2025-05-29 20:28:53,652 - INFO - joeynmt.training - Example #1
2025-05-29 20:28:53,652 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:28:53,653 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:28:53,653 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'het', 'er@@', 'over', 'het', 'be@@', 'stu@@', 'ur@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', '.', '</s>']
2025-05-29 20:28:53,654 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:28:53,654 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:28:53,654 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste is dat het erover het bestuurt van dit speciale probleem.
2025-05-29 20:28:53,654 - INFO - joeynmt.training - Example #2
2025-05-29 20:28:53,655 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:28:53,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:28:53,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:28:53,657 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:28:53,657 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:28:53,657 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe het hart van onze wereldwijde klimaatsysteem.
2025-05-29 20:28:53,657 - INFO - joeynmt.training - Example #3
2025-05-29 20:28:53,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:28:53,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:28:53,658 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'on@@', 'gen', 'en', 's@@', 'om@@', 'er@@', 'l@@', 'ingen', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 20:28:53,658 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:28:53,658 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:28:53,658 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de wongen en somerlingen in de zomer.
2025-05-29 20:28:53,658 - INFO - joeynmt.training - Example #4
2025-05-29 20:28:53,659 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:28:53,659 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:28:53,659 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'de.', '</s>']
2025-05-29 20:28:53,660 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:28:53,660 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:28:53,661 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje opname wat er gebeurt in de laatste 25 jaar gebeurde.
2025-05-29 20:29:02,704 - INFO - joeynmt.training - Epoch   6, Step:    46600, Batch Loss:     1.742152, Batch Acc: 0.543879, Tokens per Sec:     7369, Lr: 0.000300
2025-05-29 20:29:11,327 - INFO - joeynmt.training - Epoch   6, Step:    46700, Batch Loss:     1.524178, Batch Acc: 0.541454, Tokens per Sec:     8177, Lr: 0.000300
2025-05-29 20:29:19,894 - INFO - joeynmt.training - Epoch   6, Step:    46800, Batch Loss:     1.394799, Batch Acc: 0.538764, Tokens per Sec:     8178, Lr: 0.000300
2025-05-29 20:29:29,067 - INFO - joeynmt.training - Epoch   6, Step:    46900, Batch Loss:     1.344365, Batch Acc: 0.539270, Tokens per Sec:     7446, Lr: 0.000300
2025-05-29 20:29:38,519 - INFO - joeynmt.training - Epoch   6, Step:    47000, Batch Loss:     1.691679, Batch Acc: 0.547124, Tokens per Sec:     7346, Lr: 0.000300
2025-05-29 20:29:38,521 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:29:38,521 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:30:23,692 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.46, acc:   0.50, generation: 45.1294[sec], evaluation: 0.0000[sec]
2025-05-29 20:30:23,706 - INFO - joeynmt.training - Example #0
2025-05-29 20:30:23,707 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:30:23,707 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:30:23,707 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijk@@', 'en,', 'om', 'te', 'ver@@', 'be@@', 'kijk@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'ste', '4@@', '0@@', '%', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'ste', '4@@', '0@@', '%', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 're@@', 'den', 'van', 'de', 'mee@@', 'st', 'com@@', 'p@@', 'et@@', 'it@@', 'ie', 'van', 'de', 'onder@@', 'kan@@', 's', 'dat', 'de', 're@@', 'den', 'van', 'de', 'onder@@', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'lan@@', 'den', 'van', 'de']
2025-05-29 20:30:23,708 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:30:23,708 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:30:23,708 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkijken, om te verbekijken, dat de arctische ijskappen die voor de onderste 48 staten van de onderkant van de onderste 40% van de onderkant van de onderste 40% van de onderkant van de onderkant van de onderkant van de reden van de meest competitie van de onderkans dat de reden van de onder48 staten van de landen van de
2025-05-29 20:30:23,708 - INFO - joeynmt.training - Example #1
2025-05-29 20:30:23,709 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:30:23,709 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:30:23,709 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'is', 'dat', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'van', 'het', 'ij@@', 's@@', 'k@@', 'aar@@', 'heid', 'van', 'het', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:30:23,710 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:30:23,710 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:30:23,710 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste is dat speciale probleem is dat de dikke probleem van het ijskaarheid van het ijskaart toont.
2025-05-29 20:30:23,710 - INFO - joeynmt.training - Example #2
2025-05-29 20:30:23,711 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:30:23,711 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:30:23,711 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', ',', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', 'van', 'de', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:30:23,712 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:30:23,712 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:30:23,713 - INFO - joeynmt.training - 	Hypothesis: In zekere zin, is de artische ijskapen het klimaatsysteem van de wereldwijde klimaatsysteem.
2025-05-29 20:30:23,713 - INFO - joeynmt.training - Example #3
2025-05-29 20:30:23,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:30:23,713 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:30:23,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 20:30:23,714 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:30:23,714 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:30:23,715 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en somer.
2025-05-29 20:30:23,715 - INFO - joeynmt.training - Example #4
2025-05-29 20:30:23,715 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:30:23,715 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:30:23,715 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 20:30:23,716 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:30:23,717 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:30:23,718 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje in de laatste 25 jaar.
2025-05-29 20:30:33,304 - INFO - joeynmt.training - Epoch   6, Step:    47100, Batch Loss:     1.615787, Batch Acc: 0.539677, Tokens per Sec:     7284, Lr: 0.000300
2025-05-29 20:30:42,441 - INFO - joeynmt.training - Epoch   6, Step:    47200, Batch Loss:     1.408626, Batch Acc: 0.547686, Tokens per Sec:     7707, Lr: 0.000300
2025-05-29 20:30:51,485 - INFO - joeynmt.training - Epoch   6, Step:    47300, Batch Loss:     1.576519, Batch Acc: 0.545042, Tokens per Sec:     7826, Lr: 0.000300
2025-05-29 20:31:00,572 - INFO - joeynmt.training - Epoch   6, Step:    47400, Batch Loss:     1.476896, Batch Acc: 0.547802, Tokens per Sec:     7825, Lr: 0.000300
2025-05-29 20:31:09,605 - INFO - joeynmt.training - Epoch   6, Step:    47500, Batch Loss:     1.579507, Batch Acc: 0.537954, Tokens per Sec:     7596, Lr: 0.000300
2025-05-29 20:31:09,605 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:31:09,606 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:31:48,748 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.45, acc:   0.50, generation: 39.1057[sec], evaluation: 0.0000[sec]
2025-05-29 20:31:48,935 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/44500.ckpt
2025-05-29 20:31:48,958 - INFO - joeynmt.training - Example #0
2025-05-29 20:31:48,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:31:48,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:31:48,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'de', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ge@@', 'g@@', 'aan.', '</s>']
2025-05-29 20:31:48,960 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:31:48,960 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:31:48,960 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoonde getoond om te verbeteren dat de artische ijskappen, die voor de reden van de grens van de onderste 48 staten van de onderste 48 staten van de onderste 48 staten gegaan.
2025-05-29 20:31:48,960 - INFO - joeynmt.training - Example #1
2025-05-29 20:31:48,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:31:48,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:31:48,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's@@', 'k@@', 'aar@@', 'heid', 'van', 'het', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 20:31:48,962 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:31:48,962 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:31:48,962 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de eerste is dat speciale probleem van dit ijskaarheid van het ijsver.
2025-05-29 20:31:48,962 - INFO - joeynmt.training - Example #2
2025-05-29 20:31:48,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:31:48,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:31:48,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:31:48,964 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:31:48,964 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:31:48,964 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe het hart van ons wereldwijde klimaatsysteem.
2025-05-29 20:31:48,964 - INFO - joeynmt.training - Example #3
2025-05-29 20:31:48,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:31:48,965 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:31:48,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'st@@', 'op@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 20:31:48,966 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:31:48,966 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:31:48,966 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en stopt in de zomer.
2025-05-29 20:31:48,966 - INFO - joeynmt.training - Example #4
2025-05-29 20:31:48,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:31:48,967 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:31:48,967 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'ti@@', 'en@@', 'er@@', 'f@@', 'el', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 20:31:48,967 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:31:48,968 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:31:48,968 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tienerfel van wat er gebeurt in de laatste 25 jaar is.
2025-05-29 20:31:58,064 - INFO - joeynmt.training - Epoch   6, Step:    47600, Batch Loss:     1.497217, Batch Acc: 0.540957, Tokens per Sec:     7445, Lr: 0.000300
2025-05-29 20:32:06,553 - INFO - joeynmt.training - Epoch   6, Step:    47700, Batch Loss:     1.533177, Batch Acc: 0.537728, Tokens per Sec:     8148, Lr: 0.000300
2025-05-29 20:32:15,013 - INFO - joeynmt.training - Epoch   6, Step:    47800, Batch Loss:     1.601103, Batch Acc: 0.537026, Tokens per Sec:     8357, Lr: 0.000300
2025-05-29 20:32:23,232 - INFO - joeynmt.training - Epoch   6, Step:    47900, Batch Loss:     1.568722, Batch Acc: 0.537994, Tokens per Sec:     8812, Lr: 0.000300
2025-05-29 20:32:32,195 - INFO - joeynmt.training - Epoch   6, Step:    48000, Batch Loss:     1.675772, Batch Acc: 0.539087, Tokens per Sec:     7747, Lr: 0.000300
2025-05-29 20:32:32,196 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:32:32,196 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:33:06,854 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.44, acc:   0.50, generation: 34.6092[sec], evaluation: 0.0000[sec]
2025-05-29 20:33:07,038 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/45000.ckpt
2025-05-29 20:33:07,061 - INFO - joeynmt.training - Example #0
2025-05-29 20:33:07,062 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:33:07,062 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:33:07,062 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'tel@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'ens', 'van', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'st@@', 'aten', 'over', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'aa@@', 't.', '</s>']
2025-05-29 20:33:07,063 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:33:07,064 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:33:07,064 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond, om te vertelden dat de arctische ijskappen die drie miljoen jaar de grens van de grens van de onderste 48 staten staten over 40 procent gegaat.
2025-05-29 20:33:07,064 - INFO - joeynmt.training - Example #1
2025-05-29 20:33:07,065 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:33:07,065 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:33:07,065 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'kan@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't', 'te', 'laten', 'zien.', '</s>']
2025-05-29 20:33:07,066 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:33:07,066 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:33:07,066 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste kant van dit speciale probleem van dit speciale probleem van het ijs toont te laten zien.
2025-05-29 20:33:07,066 - INFO - joeynmt.training - Example #2
2025-05-29 20:33:07,066 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:33:07,067 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:33:07,067 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', 'tu@@', 'ig@@', 'en,', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:33:07,068 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:33:07,068 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:33:07,068 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigen, is de arctische ijskappe is het hart van onze wereldwijde klimaatsysteem.
2025-05-29 20:33:07,068 - INFO - joeynmt.training - Example #3
2025-05-29 20:33:07,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:33:07,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:33:07,068 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'k@@', 'ken@@', 'de', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:33:07,069 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:33:07,069 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:33:07,069 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schokkende zomert.
2025-05-29 20:33:07,070 - INFO - joeynmt.training - Example #4
2025-05-29 20:33:07,070 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:33:07,070 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:33:07,070 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'oon', 'jullie', 'laten', 'zien', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 20:33:07,071 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:33:07,071 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:33:07,071 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik toon jullie laten zien wat er in de laatste 25 jaar.
2025-05-29 20:33:16,213 - INFO - joeynmt.training - Epoch   6, Step:    48100, Batch Loss:     1.332770, Batch Acc: 0.537586, Tokens per Sec:     7295, Lr: 0.000300
2025-05-29 20:33:25,222 - INFO - joeynmt.training - Epoch   6, Step:    48200, Batch Loss:     1.583849, Batch Acc: 0.538489, Tokens per Sec:     7773, Lr: 0.000300
2025-05-29 20:33:34,505 - INFO - joeynmt.training - Epoch   6, Step:    48300, Batch Loss:     1.583482, Batch Acc: 0.538494, Tokens per Sec:     7747, Lr: 0.000300
2025-05-29 20:33:43,745 - INFO - joeynmt.training - Epoch   6, Step:    48400, Batch Loss:     1.399055, Batch Acc: 0.543722, Tokens per Sec:     7638, Lr: 0.000300
2025-05-29 20:33:53,007 - INFO - joeynmt.training - Epoch   6, Step:    48500, Batch Loss:     1.689898, Batch Acc: 0.534246, Tokens per Sec:     7428, Lr: 0.000300
2025-05-29 20:33:53,007 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:33:53,007 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:34:30,579 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.45, acc:   0.51, generation: 37.5313[sec], evaluation: 0.0000[sec]
2025-05-29 20:34:30,748 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/46000.ckpt
2025-05-29 20:34:30,765 - INFO - joeynmt.training - Example #0
2025-05-29 20:34:30,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:34:30,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:34:30,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'zor@@', 'gen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'kel', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'g@@', 'aan.', '</s>']
2025-05-29 20:34:30,767 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:34:30,768 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:34:30,768 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond, om te verzorgen dat de artische ijskappen, die voor de artikel die drie miljoen jaar de grens van de onderste 48 staten van de onderste 40 procent is gegaan.
2025-05-29 20:34:30,768 - INFO - joeynmt.training - Example #1
2025-05-29 20:34:30,768 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:34:30,768 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:34:30,768 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'kan@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'want', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.', '</s>']
2025-05-29 20:34:30,769 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:34:30,769 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:34:30,769 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste kant van dit speciale probleem, want het is het niet de dikke van het ijs van het ijs laat zien.
2025-05-29 20:34:30,770 - INFO - joeynmt.training - Example #2
2025-05-29 20:34:30,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:34:30,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:34:30,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:34:30,771 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:34:30,771 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:34:30,771 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe het klimaatsysteem.
2025-05-29 20:34:30,771 - INFO - joeynmt.training - Example #3
2025-05-29 20:34:30,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:34:30,772 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:34:30,772 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:34:30,772 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:34:30,772 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:34:30,773 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en somert.
2025-05-29 20:34:30,773 - INFO - joeynmt.training - Example #4
2025-05-29 20:34:30,773 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:34:30,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:34:30,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'gebeur@@', 'd', 'is.', '</s>']
2025-05-29 20:34:30,773 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:34:30,773 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:34:30,773 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdperk van wat er gebeurd is.
2025-05-29 20:34:40,190 - INFO - joeynmt.training - Epoch   6, Step:    48600, Batch Loss:     1.442231, Batch Acc: 0.535544, Tokens per Sec:     7283, Lr: 0.000300
2025-05-29 20:34:49,622 - INFO - joeynmt.training - Epoch   6, Step:    48700, Batch Loss:     1.548572, Batch Acc: 0.545236, Tokens per Sec:     7184, Lr: 0.000300
2025-05-29 20:34:58,980 - INFO - joeynmt.training - Epoch   6, Step:    48800, Batch Loss:     1.613778, Batch Acc: 0.537148, Tokens per Sec:     7266, Lr: 0.000300
2025-05-29 20:35:07,741 - INFO - joeynmt.training - Epoch   6, Step:    48900, Batch Loss:     1.416149, Batch Acc: 0.542756, Tokens per Sec:     8078, Lr: 0.000300
2025-05-29 20:35:16,065 - INFO - joeynmt.training - Epoch   6, Step:    49000, Batch Loss:     1.321020, Batch Acc: 0.544748, Tokens per Sec:     8568, Lr: 0.000300
2025-05-29 20:35:16,065 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:35:16,065 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:35:47,439 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.43, acc:   0.50, generation: 31.3380[sec], evaluation: 0.0000[sec]
2025-05-29 20:35:47,441 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:35:47,620 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/46500.ckpt
2025-05-29 20:35:47,636 - INFO - joeynmt.training - Example #0
2025-05-29 20:35:47,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:35:47,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:35:47,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'de', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', '4@@', '8', 'st@@', 'aten', 'voor', 'de', 'onder@@', 'kan@@', 's', 'voor', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'aan.', '</s>']
2025-05-29 20:35:47,638 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:35:47,639 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:35:47,639 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoonde dat de artische ijs die de artische ijskappen, die voor de reden van de grens van de onder48 staten van de onder48 staten voor de onderkans voor 40 procent gegaan.
2025-05-29 20:35:47,639 - INFO - joeynmt.training - Example #1
2025-05-29 20:35:47,639 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:35:47,639 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:35:47,640 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 20:35:47,640 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:35:47,641 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:35:47,641 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste staat, omdat het niet de dikke probleem van dit ijsver.
2025-05-29 20:35:47,641 - INFO - joeynmt.training - Example #2
2025-05-29 20:35:47,641 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:35:47,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:35:47,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'har@@', 't', 'van', 'ons', 'mon@@', 'di@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:35:47,642 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:35:47,643 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:35:47,643 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe het hart van ons mondiale klimaatsysteem.
2025-05-29 20:35:47,643 - INFO - joeynmt.training - Example #3
2025-05-29 20:35:47,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:35:47,643 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:35:47,643 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 20:35:47,643 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:35:47,644 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:35:47,644 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en sluit in de zomer.
2025-05-29 20:35:47,644 - INFO - joeynmt.training - Example #4
2025-05-29 20:35:47,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:35:47,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:35:47,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en', 'is', 'een', 'teken@@', 'ing', 'van', 'de', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'gebeur@@', 'd', 'is.', '</s>']
2025-05-29 20:35:47,645 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:35:47,645 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:35:47,645 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen is een tekening van de tijdperk van wat er gebeurd is.
2025-05-29 20:35:57,040 - INFO - joeynmt.training - Epoch   6, Step:    49100, Batch Loss:     1.535196, Batch Acc: 0.531679, Tokens per Sec:     7093, Lr: 0.000300
2025-05-29 20:36:06,023 - INFO - joeynmt.training - Epoch   6, Step:    49200, Batch Loss:     1.460109, Batch Acc: 0.547623, Tokens per Sec:     7990, Lr: 0.000300
2025-05-29 20:36:15,526 - INFO - joeynmt.training - Epoch   6, Step:    49300, Batch Loss:     1.589159, Batch Acc: 0.538213, Tokens per Sec:     7613, Lr: 0.000300
2025-05-29 20:36:24,819 - INFO - joeynmt.training - Epoch   6, Step:    49400, Batch Loss:     1.383130, Batch Acc: 0.537378, Tokens per Sec:     7537, Lr: 0.000300
2025-05-29 20:36:33,669 - INFO - joeynmt.training - Epoch   6, Step:    49500, Batch Loss:     1.571627, Batch Acc: 0.539284, Tokens per Sec:     7994, Lr: 0.000300
2025-05-29 20:36:33,670 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:36:33,670 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:37:11,976 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.42, acc:   0.50, generation: 38.2667[sec], evaluation: 0.0000[sec]
2025-05-29 20:37:11,976 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:37:12,174 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/48500.ckpt
2025-05-29 20:37:12,190 - INFO - joeynmt.training - Example #0
2025-05-29 20:37:12,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:37:12,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:37:12,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'de', 'aan', 'om', 'te', 'ver@@', 'zor@@', 'gen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'kan@@', 's', 'hadden', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'van', 'de', 'onder@@', 'kan@@', 's', 'was', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'maakt', 'is.', '</s>']
2025-05-29 20:37:12,192 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:37:12,193 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:37:12,193 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoonde aan om te verzorgen dat de artische ijskappen, de artische ijskappen, de grootte van de onderkans hadden om 48 staten te van de onderkans was 40 procent gemaakt is.
2025-05-29 20:37:12,193 - INFO - joeynmt.training - Example #1
2025-05-29 20:37:12,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:37:12,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:37:12,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'kan@@', 's', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'dat', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'et@@', 'it@@', 'e@@', 's.', '</s>']
2025-05-29 20:37:12,195 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:37:12,196 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:37:12,196 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste kans van dit speciale probleem van dit speciale probleem dat niet de dikke ijsetites.
2025-05-29 20:37:12,196 - INFO - joeynmt.training - Example #2
2025-05-29 20:37:12,196 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:37:12,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:37:12,197 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'c@@', 'a', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:37:12,197 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:37:12,198 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:37:12,198 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artica het hart van onze wereldwijde klimaatsysteem.
2025-05-29 20:37:12,198 - INFO - joeynmt.training - Example #3
2025-05-29 20:37:12,198 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:37:12,198 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:37:12,199 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:37:12,199 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:37:12,200 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:37:12,200 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en somert.
2025-05-29 20:37:12,200 - INFO - joeynmt.training - Example #4
2025-05-29 20:37:12,200 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:37:12,201 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:37:12,201 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 20:37:12,202 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:37:12,202 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:37:12,202 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat is een tijdschriften wat er gebeurt in de afgelopen 25 jaar.
2025-05-29 20:37:21,641 - INFO - joeynmt.training - Epoch   6, Step:    49600, Batch Loss:     1.521323, Batch Acc: 0.534853, Tokens per Sec:     6964, Lr: 0.000300
2025-05-29 20:37:30,986 - INFO - joeynmt.training - Epoch   6, Step:    49700, Batch Loss:     1.639318, Batch Acc: 0.542867, Tokens per Sec:     7481, Lr: 0.000300
2025-05-29 20:37:40,866 - INFO - joeynmt.training - Epoch   6, Step:    49800, Batch Loss:     1.631425, Batch Acc: 0.535633, Tokens per Sec:     7119, Lr: 0.000300
2025-05-29 20:37:50,290 - INFO - joeynmt.training - Epoch   6, Step:    49900, Batch Loss:     1.543809, Batch Acc: 0.541311, Tokens per Sec:     7409, Lr: 0.000300
2025-05-29 20:37:59,712 - INFO - joeynmt.training - Epoch   6, Step:    50000, Batch Loss:     1.508208, Batch Acc: 0.537520, Tokens per Sec:     7528, Lr: 0.000300
2025-05-29 20:37:59,715 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:37:59,715 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:38:29,865 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.42, acc:   0.50, generation: 30.1219[sec], evaluation: 0.0000[sec]
2025-05-29 20:38:29,866 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:38:30,035 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/47500.ckpt
2025-05-29 20:38:30,054 - INFO - joeynmt.training - Example #0
2025-05-29 20:38:30,055 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:38:30,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:38:30,055 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'zor@@', 'gen', 'dat', 'de', 'ar@@', 'ti@@', 'kel', 'dat', 'de', 'ar@@', 'ti@@', 'kel', 'voor', 'de', 'ar@@', 'ti@@', 'kel', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'ond', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'hadden', 'om', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd.', '</s>']
2025-05-29 20:38:30,056 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:38:30,056 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:38:30,056 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te verzorgen dat de artikel dat de artikel voor de artikel die drie miljoen jaar de grootte van de grond van de grondstoffen hadden om 40 procent gegooid.
2025-05-29 20:38:30,056 - INFO - joeynmt.training - Example #1
2025-05-29 20:38:30,056 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:38:30,056 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:38:30,056 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'het', 'eer@@', 'st', 'het', 'uit@@', 'z@@', 'onder@@', 'lijk', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'het', 'ij@@', 'st', 'is.', '</s>']
2025-05-29 20:38:30,057 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:38:30,057 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:38:30,057 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste is dat het eerst het uitzonderlijk niet de dikke ijskwestie van het ijst is.
2025-05-29 20:38:30,057 - INFO - joeynmt.training - Example #2
2025-05-29 20:38:30,057 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:38:30,057 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:38:30,058 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'kel', 'het', 'sl@@', 'aa@@', 'g@@', 'ste', 'deel', 'van', 'het', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:38:30,058 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:38:30,058 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:38:30,058 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artikel het slaagste deel van het wereldwijde klimaatsysteem.
2025-05-29 20:38:30,058 - INFO - joeynmt.training - Example #3
2025-05-29 20:38:30,058 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:38:30,059 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:38:30,059 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'z@@', 'om@@', 'er@@', 't,', 'en', 'je', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 20:38:30,059 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:38:30,059 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:38:30,059 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het zomert, en je zomer.
2025-05-29 20:38:30,059 - INFO - joeynmt.training - Example #4
2025-05-29 20:38:30,059 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:38:30,060 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:38:30,060 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'is', 'een', 'teken@@', 'je', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:38:30,061 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:38:30,061 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:38:30,061 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat is een tekenje van wat er gebeurt in de laatste 25 jaar is gebeurd.
2025-05-29 20:38:38,680 - INFO - joeynmt.training - Epoch   6, Step:    50100, Batch Loss:     1.663162, Batch Acc: 0.541329, Tokens per Sec:     8075, Lr: 0.000300
2025-05-29 20:38:48,354 - INFO - joeynmt.training - Epoch   6, Step:    50200, Batch Loss:     1.472187, Batch Acc: 0.543671, Tokens per Sec:     7302, Lr: 0.000300
2025-05-29 20:38:57,402 - INFO - joeynmt.training - Epoch   6, Step:    50300, Batch Loss:     1.343804, Batch Acc: 0.549199, Tokens per Sec:     7724, Lr: 0.000300
2025-05-29 20:39:06,336 - INFO - joeynmt.training - Epoch   6, Step:    50400, Batch Loss:     1.441776, Batch Acc: 0.541497, Tokens per Sec:     7773, Lr: 0.000300
2025-05-29 20:39:15,095 - INFO - joeynmt.training - Epoch   6, Step:    50500, Batch Loss:     1.598102, Batch Acc: 0.538420, Tokens per Sec:     7960, Lr: 0.000300
2025-05-29 20:39:15,095 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:39:15,096 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:39:53,470 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.39, acc:   0.51, generation: 38.3353[sec], evaluation: 0.0000[sec]
2025-05-29 20:39:53,471 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:39:53,654 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/48000.ckpt
2025-05-29 20:39:53,671 - INFO - joeynmt.training - Example #0
2025-05-29 20:39:53,672 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:39:53,673 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:39:53,673 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'antwoor@@', 'del@@', 'ijke', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ten', 'van', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd', 'is.', '</s>']
2025-05-29 20:39:53,674 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:39:53,674 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:39:53,674 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verantwoordelijke te verzamelen, dat de artische ijskappen die voor de onderste drie miljoen jaar de groten van de grens van de onderste 40 procent is gegooid is.
2025-05-29 20:39:53,674 - INFO - joeynmt.training - Example #1
2025-05-29 20:39:53,675 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:39:53,675 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:39:53,675 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:39:53,676 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:39:53,676 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:39:53,676 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste staat, omdat het niet de dikke probleem van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs toont.
2025-05-29 20:39:53,676 - INFO - joeynmt.training - Example #2
2025-05-29 20:39:53,677 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:39:53,677 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:39:53,677 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's', 'het', 'sl@@', 'aa@@', 'g@@', 'ste', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:39:53,678 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:39:53,678 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:39:53,678 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijs het slaagste hart van ons wereldwijde klimaatsysteem.
2025-05-29 20:39:53,678 - INFO - joeynmt.training - Example #3
2025-05-29 20:39:53,678 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:39:53,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:39:53,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'en', 'en', 'ver@@', 'st@@', 'op@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 20:39:53,680 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:39:53,680 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:39:53,680 - INFO - joeynmt.training - 	Hypothesis: Ze groeien en en verstopt in de zomers.
2025-05-29 20:39:53,681 - INFO - joeynmt.training - Example #4
2025-05-29 20:39:53,681 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:39:53,681 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:39:53,681 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'er@@', 'en,', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:39:53,682 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:39:53,682 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:39:53,682 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschriferen, wat er gebeurde in de laatste 25 jaar is gebeurd.
2025-05-29 20:40:03,043 - INFO - joeynmt.training - Epoch   6, Step:    50600, Batch Loss:     1.491221, Batch Acc: 0.542309, Tokens per Sec:     7170, Lr: 0.000300
2025-05-29 20:40:12,571 - INFO - joeynmt.training - Epoch   6, Step:    50700, Batch Loss:     1.440001, Batch Acc: 0.534491, Tokens per Sec:     7185, Lr: 0.000300
2025-05-29 20:40:21,942 - INFO - joeynmt.training - Epoch   6, Step:    50800, Batch Loss:     1.386056, Batch Acc: 0.541934, Tokens per Sec:     7292, Lr: 0.000300
2025-05-29 20:40:31,261 - INFO - joeynmt.training - Epoch   6, Step:    50900, Batch Loss:     1.549272, Batch Acc: 0.539527, Tokens per Sec:     7453, Lr: 0.000300
2025-05-29 20:40:40,857 - INFO - joeynmt.training - Epoch   6, Step:    51000, Batch Loss:     1.585162, Batch Acc: 0.538175, Tokens per Sec:     7362, Lr: 0.000300
2025-05-29 20:40:40,857 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:40:40,858 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:41:19,592 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.40, acc:   0.51, generation: 38.6986[sec], evaluation: 0.0000[sec]
2025-05-29 20:41:19,763 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/45500.ckpt
2025-05-29 20:41:19,780 - INFO - joeynmt.training - Example #0
2025-05-29 20:41:19,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:41:19,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:41:19,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'f@@', 'ol@@', 'en', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's', 'van', 'de', 'onder@@', 'ste', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'ste', 'ge@@', 'vol@@', 'g', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent']
2025-05-29 20:41:19,782 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:41:19,782 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:41:19,782 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folen getoond om te verkijken dat de artische ijs die de artische ijs die voor de artische ijs van de onderste drie miljoen jaar de grootste gevolg van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent
2025-05-29 20:41:19,783 - INFO - joeynmt.training - Example #1
2025-05-29 20:41:19,783 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:41:19,783 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:41:19,783 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'e,', 'het', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't', 'te', 'zien.', '</s>']
2025-05-29 20:41:19,783 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:41:19,784 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:41:19,784 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste, het is dat het niet de dikke probleem van het ijs van het ijs toont van het ijs toont te zien.
2025-05-29 20:41:19,784 - INFO - joeynmt.training - Example #2
2025-05-29 20:41:19,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:41:19,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:41:19,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's', 'het', 'sl@@', 'aa@@', 'g@@', 'ste', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:41:19,785 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:41:19,785 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:41:19,785 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijs het slaagste van onze wereldwijde klimaatsysteem.
2025-05-29 20:41:19,785 - INFO - joeynmt.training - Example #3
2025-05-29 20:41:19,786 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:41:19,786 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:41:19,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'ru@@', 'mp@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 20:41:19,786 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:41:19,786 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:41:19,786 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en verrumpt in de zomer.
2025-05-29 20:41:19,787 - INFO - joeynmt.training - Example #4
2025-05-29 20:41:19,787 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:41:19,787 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:41:19,787 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:41:19,788 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:41:19,788 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:41:19,788 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdschrift van wat er gebeurde in de afgelopen 25 jaar is gebeurd.
2025-05-29 20:41:28,308 - INFO - joeynmt.training - Epoch   6, Step:    51100, Batch Loss:     1.493813, Batch Acc: 0.541082, Tokens per Sec:     7956, Lr: 0.000300
2025-05-29 20:41:36,634 - INFO - joeynmt.training - Epoch   6, Step:    51200, Batch Loss:     1.533282, Batch Acc: 0.541062, Tokens per Sec:     8489, Lr: 0.000300
2025-05-29 20:41:44,777 - INFO - joeynmt.training - Epoch   6, Step:    51300, Batch Loss:     1.652225, Batch Acc: 0.540911, Tokens per Sec:     8643, Lr: 0.000300
2025-05-29 20:41:53,780 - INFO - joeynmt.training - Epoch   6, Step:    51400, Batch Loss:     1.514063, Batch Acc: 0.541756, Tokens per Sec:     7943, Lr: 0.000300
2025-05-29 20:42:02,850 - INFO - joeynmt.training - Epoch   6, Step:    51500, Batch Loss:     1.454396, Batch Acc: 0.540676, Tokens per Sec:     7737, Lr: 0.000300
2025-05-29 20:42:02,850 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:42:02,851 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:42:44,007 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.37, acc:   0.51, generation: 41.1183[sec], evaluation: 0.0000[sec]
2025-05-29 20:42:44,008 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:42:44,196 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/49000.ckpt
2025-05-29 20:42:44,237 - INFO - joeynmt.training - Example #0
2025-05-29 20:42:44,237 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:42:44,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:42:44,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'maakt', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'gesch@@', 're@@', 'ven', 'in', 'de', 'wereld', 'om', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'maakt', 'is.', '</s>']
2025-05-29 20:42:44,239 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:42:44,239 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:42:44,239 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verbeteren dat de artische ijskappen, dat de artische ijskappen, de grootte van de onderste 48 staten had gemaakt voor de onderste 40 procent geschreven in de wereld om 40 procent gemaakt is.
2025-05-29 20:42:44,239 - INFO - joeynmt.training - Example #1
2025-05-29 20:42:44,240 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:42:44,240 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:42:44,240 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'de@@', 'elt', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'er@@', 'var@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'uit@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'es', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:42:44,241 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:42:44,241 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:42:44,241 - INFO - joeynmt.training - 	Hypothesis: Maar dat deelt niet sterk genoeg de ervaring van dit speciale probleem uit, omdat het niet de dikke ijses toont.
2025-05-29 20:42:44,241 - INFO - joeynmt.training - Example #2
2025-05-29 20:42:44,242 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:42:44,242 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:42:44,242 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'sl@@', 'aa@@', 'g@@', 'de', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:42:44,243 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:42:44,243 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:42:44,243 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe het slaagde hart van ons wereldwijde klimaatsysteem.
2025-05-29 20:42:44,243 - INFO - joeynmt.training - Example #3
2025-05-29 20:42:44,243 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:42:44,243 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:42:44,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'st@@', 'op@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 20:42:44,244 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:42:44,245 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:42:44,245 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en verstopt in de zomer.
2025-05-29 20:42:44,245 - INFO - joeynmt.training - Example #4
2025-05-29 20:42:44,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:42:44,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:42:44,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'is', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:42:44,246 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:42:44,246 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:42:44,247 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een tijdschrift is in de afgelopen 25 jaar is gebeurd.
2025-05-29 20:42:53,633 - INFO - joeynmt.training - Epoch   6, Step:    51600, Batch Loss:     1.537029, Batch Acc: 0.537790, Tokens per Sec:     7246, Lr: 0.000300
2025-05-29 20:43:03,302 - INFO - joeynmt.training - Epoch   6, Step:    51700, Batch Loss:     1.561033, Batch Acc: 0.539842, Tokens per Sec:     7287, Lr: 0.000300
2025-05-29 20:43:12,619 - INFO - joeynmt.training - Epoch   6, Step:    51800, Batch Loss:     1.483059, Batch Acc: 0.543043, Tokens per Sec:     7613, Lr: 0.000300
2025-05-29 20:43:21,914 - INFO - joeynmt.training - Epoch   6, Step:    51900, Batch Loss:     1.411299, Batch Acc: 0.531589, Tokens per Sec:     7276, Lr: 0.000300
2025-05-29 20:43:31,249 - INFO - joeynmt.training - Epoch   6, Step:    52000, Batch Loss:     1.494869, Batch Acc: 0.531286, Tokens per Sec:     7602, Lr: 0.000300
2025-05-29 20:43:31,250 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:43:31,250 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:44:14,313 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.39, acc:   0.51, generation: 43.0248[sec], evaluation: 0.0000[sec]
2025-05-29 20:44:14,496 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/49500.ckpt
2025-05-29 20:44:14,512 - INFO - joeynmt.training - Example #0
2025-05-29 20:44:14,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:44:14,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:44:14,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'der', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'voor', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'was', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'dur@@', 'ende', 'drie', 'proc@@', 'ent', 'ge@@', 'ï@@', 'n@@', 'te@@', 'erde', 'st@@', 'aten', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'oor@@', 'z@@', 'aa@@', 'kt', 'is.', '</s>']
2025-05-29 20:44:14,515 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:44:14,515 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:44:14,515 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond, om te verder te zien dat de arctische ijskap, die voor de grens van de onderste 48 staten was voor de onderste 40 procent gedurende drie procent geïnteerde staten om 40 procent te veroorzaakt is.
2025-05-29 20:44:14,515 - INFO - joeynmt.training - Example #1
2025-05-29 20:44:14,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:44:14,516 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:44:14,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'de@@', 'ed', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'en@@', 'dig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's@@', 'k@@', 'je', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ap@@', '.', '</s>']
2025-05-29 20:44:14,517 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:44:14,517 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:44:14,517 - INFO - joeynmt.training - 	Hypothesis: Maar dat deed niet sterk genoeg de eerste stendigheid van dit speciale probleem, omdat het niet de dik van het ijskje van het ijskap.
2025-05-29 20:44:14,517 - INFO - joeynmt.training - Example #2
2025-05-29 20:44:14,517 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:44:14,517 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:44:14,518 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', 'tu@@', 'igen', 'is', 'de', 'ar@@', 'ct@@', 'ie@@', 'ke', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:44:14,518 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:44:14,525 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:44:14,525 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigen is de arctieke ijskappen het hart van onze wereldwijde klimaatsysteem.
2025-05-29 20:44:14,526 - INFO - joeynmt.training - Example #3
2025-05-29 20:44:14,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:44:14,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:44:14,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 20:44:14,527 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:44:14,527 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:44:14,527 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zomer.
2025-05-29 20:44:14,528 - INFO - joeynmt.training - Example #4
2025-05-29 20:44:14,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:44:14,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:44:14,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:44:14,530 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:44:14,530 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:44:14,530 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift van de afgelopen 25 jaar is gebeurd.
2025-05-29 20:44:23,922 - INFO - joeynmt.training - Epoch   6, Step:    52100, Batch Loss:     1.534437, Batch Acc: 0.536016, Tokens per Sec:     7062, Lr: 0.000300
2025-05-29 20:44:32,289 - INFO - joeynmt.training - Epoch   6, Step:    52200, Batch Loss:     1.488350, Batch Acc: 0.538364, Tokens per Sec:     8407, Lr: 0.000300
2025-05-29 20:44:40,627 - INFO - joeynmt.training - Epoch   6, Step:    52300, Batch Loss:     1.633295, Batch Acc: 0.543103, Tokens per Sec:     8627, Lr: 0.000300
2025-05-29 20:44:49,014 - INFO - joeynmt.training - Epoch   6, Step:    52400, Batch Loss:     1.719447, Batch Acc: 0.539702, Tokens per Sec:     8105, Lr: 0.000300
2025-05-29 20:44:57,437 - INFO - joeynmt.training - Epoch   6, Step:    52500, Batch Loss:     1.474274, Batch Acc: 0.538548, Tokens per Sec:     8590, Lr: 0.000300
2025-05-29 20:44:57,437 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:44:57,438 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:45:40,352 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.35, acc:   0.51, generation: 42.8771[sec], evaluation: 0.0000[sec]
2025-05-29 20:45:40,353 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:45:40,543 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/50000.ckpt
2025-05-29 20:45:40,569 - INFO - joeynmt.training - Example #0
2025-05-29 20:45:40,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:45:40,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:45:40,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'dur@@', 'ende', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'dur@@', 'ende', 'drie', 'proc@@', 'ent', 'ge@@', 'dur@@', 'ende', 'drie', 'miljo@@', 'en', 'jaar', 'lang', 'heb', 'ik', 'ge@@', 'to@@', 'ond', 'dat', 'de', 'ar@@', 'ti@@', 'kel', 'was', 'ge@@', 'to@@', 'e', 'van', 'de', 'ar@@', 'ti@@', 'kel@@', 'en', 'dat', 'de', 'gro@@', 'ter@@', 'e', 'jaar', 'de', 'gro@@', 'ter@@', 'e', 'c@@', 'or@@', 'rel@@']
2025-05-29 20:45:40,571 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:45:40,572 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:45:40,572 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te bekijken dat de artische ijskappen, die de arctische ijskappen, die de grens van de onderste 48 staten van de onderste 40 procent gedurende de grens van de onderste 40 procent gedurende drie procent gedurende drie miljoen jaar lang heb ik getoond dat de artikel was getoe van de artikelen dat de grotere jaar de grotere correl
2025-05-29 20:45:40,572 - INFO - joeynmt.training - Example #1
2025-05-29 20:45:40,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:45:40,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:45:40,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'want', 'het', 'is', 'een', 'bep@@', 'aal@@', 'd', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:45:40,574 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:45:40,574 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:45:40,574 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste staat, want het is een bepaald probleem omdat het niet de dikke dikke van het ijskaart toont.
2025-05-29 20:45:40,574 - INFO - joeynmt.training - Example #2
2025-05-29 20:45:40,575 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:45:40,575 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:45:40,575 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:45:40,576 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:45:40,576 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:45:40,576 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe hart van ons wereldklimaatsysteem.
2025-05-29 20:45:40,576 - INFO - joeynmt.training - Example #3
2025-05-29 20:45:40,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:45:40,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:45:40,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'on@@', '.', '</s>']
2025-05-29 20:45:40,577 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:45:40,578 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:45:40,578 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schoon.
2025-05-29 20:45:40,578 - INFO - joeynmt.training - Example #4
2025-05-29 20:45:40,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:45:40,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:45:40,579 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en', 'is', 'een', 'p@@', 'ra@@', 'cht@@', 'ige', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:45:40,579 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:45:40,579 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:45:40,579 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen is een prachtige tijdperk van wat er gebeurt in de laatste 25 jaar is gebeurd.
2025-05-29 20:45:49,927 - INFO - joeynmt.training - Epoch   6, Step:    52600, Batch Loss:     1.470508, Batch Acc: 0.536619, Tokens per Sec:     7350, Lr: 0.000300
2025-05-29 20:45:59,343 - INFO - joeynmt.training - Epoch   6, Step:    52700, Batch Loss:     1.830692, Batch Acc: 0.532659, Tokens per Sec:     7646, Lr: 0.000300
2025-05-29 20:46:08,671 - INFO - joeynmt.training - Epoch   6, Step:    52800, Batch Loss:     1.707084, Batch Acc: 0.529760, Tokens per Sec:     7433, Lr: 0.000300
2025-05-29 20:46:18,315 - INFO - joeynmt.training - Epoch   6, Step:    52900, Batch Loss:     1.466695, Batch Acc: 0.543147, Tokens per Sec:     7226, Lr: 0.000300
2025-05-29 20:46:28,080 - INFO - joeynmt.training - Epoch   6, Step:    53000, Batch Loss:     1.621026, Batch Acc: 0.540247, Tokens per Sec:     7299, Lr: 0.000300
2025-05-29 20:46:28,080 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:46:28,081 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:47:03,698 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.37, acc:   0.51, generation: 35.5812[sec], evaluation: 0.0000[sec]
2025-05-29 20:47:03,875 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/51000.ckpt
2025-05-29 20:47:03,898 - INFO - joeynmt.training - Example #0
2025-05-29 20:47:03,898 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:47:03,899 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:47:03,899 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'tro@@', 'uw@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'dur@@', 'ende', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'is', 'ge@@', 'dur@@', 'ende', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'aa@@', 't.', '</s>']
2025-05-29 20:47:03,900 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:47:03,900 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:47:03,900 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te vertrouwen dat de arctische ijskappen, die de arctische ijskappen, die de grondstoffen voor de onderste 40 procent gedurende de grondstoffen is gedurende 40 procent gegaat.
2025-05-29 20:47:03,900 - INFO - joeynmt.training - Example #1
2025-05-29 20:47:03,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:47:03,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:47:03,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'dru@@', 'kt', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:47:03,901 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:47:03,901 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:47:03,901 - INFO - joeynmt.training - 	Hypothesis: Maar dat drukt niet sterk genoeg de eerst van dit specifieke problemen van dit speciale probleem toont.
2025-05-29 20:47:03,901 - INFO - joeynmt.training - Example #2
2025-05-29 20:47:03,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:47:03,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:47:03,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:47:03,902 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:47:03,902 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:47:03,902 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe hart van ons wereldwijd klimaatsysteem.
2025-05-29 20:47:03,902 - INFO - joeynmt.training - Example #3
2025-05-29 20:47:03,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:47:03,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:47:03,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 20:47:03,903 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:47:03,903 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:47:03,904 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluit in de winter en zomer.
2025-05-29 20:47:03,904 - INFO - joeynmt.training - Example #4
2025-05-29 20:47:03,904 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:47:03,904 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:47:03,904 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:47:03,905 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:47:03,906 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:47:03,906 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen, is een tijdschriften wat er in de laatste 25 jaar gebeurd.
2025-05-29 20:47:13,236 - INFO - joeynmt.training - Epoch   6, Step:    53100, Batch Loss:     1.522699, Batch Acc: 0.538556, Tokens per Sec:     7416, Lr: 0.000300
2025-05-29 20:47:22,389 - INFO - joeynmt.training - Epoch   6, Step:    53200, Batch Loss:     1.387517, Batch Acc: 0.545917, Tokens per Sec:     7876, Lr: 0.000300
2025-05-29 20:47:31,507 - INFO - joeynmt.training - Epoch   6, Step:    53300, Batch Loss:     1.673324, Batch Acc: 0.536247, Tokens per Sec:     7295, Lr: 0.000300
2025-05-29 20:47:40,545 - INFO - joeynmt.training - Epoch   6, Step:    53400, Batch Loss:     1.336099, Batch Acc: 0.539350, Tokens per Sec:     7936, Lr: 0.000300
2025-05-29 20:47:48,873 - INFO - joeynmt.training - Epoch   6, Step:    53500, Batch Loss:     1.576140, Batch Acc: 0.537376, Tokens per Sec:     8648, Lr: 0.000300
2025-05-29 20:47:48,873 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:47:48,873 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:48:25,039 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.33, acc:   0.51, generation: 36.1267[sec], evaluation: 0.0000[sec]
2025-05-29 20:48:25,040 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:48:25,233 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/52000.ckpt
2025-05-29 20:48:25,250 - INFO - joeynmt.training - Example #0
2025-05-29 20:48:25,251 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:48:25,251 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:48:25,251 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'im@@', 'mer@@', ',', 'om', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'aan.', '</s>']
2025-05-29 20:48:25,252 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:48:25,252 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:48:25,252 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verbeteren dat de arctische ijskappen die voor de onderste 48 staten van de onderste 48 staten van de onderste 40 procent van de onderste 40 procent geslimmer, om 40 procent gegaan.
2025-05-29 20:48:25,253 - INFO - joeynmt.training - Example #1
2025-05-29 20:48:25,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:48:25,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:48:25,253 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'e,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'to@@', 'on@@', 't', 'uit', 'het', 'ij@@', 's@@', 'es', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:48:25,254 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:48:25,254 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:48:25,254 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste, omdat het niet de dik van dit speciale probleem toont uit het ijses toont.
2025-05-29 20:48:25,255 - INFO - joeynmt.training - Example #2
2025-05-29 20:48:25,255 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:48:25,255 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:48:25,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'on@@', 'be@@', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:48:25,256 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:48:25,256 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:48:25,256 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het onbehart van onze wereldwijd systeem.
2025-05-29 20:48:25,256 - INFO - joeynmt.training - Example #3
2025-05-29 20:48:25,257 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:48:25,257 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:48:25,257 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lo@@', 't@@', 'te', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 20:48:25,258 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:48:25,258 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:48:25,258 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en slotte in de zomer.
2025-05-29 20:48:25,258 - INFO - joeynmt.training - Example #4
2025-05-29 20:48:25,258 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:48:25,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:48:25,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'er@@', 't@@', 'je', 'dat', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:48:25,260 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:48:25,260 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:48:25,260 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen, is een tijdschrifertje dat is gebeurd.
2025-05-29 20:48:34,491 - INFO - joeynmt.training - Epoch   6, Step:    53600, Batch Loss:     1.473225, Batch Acc: 0.539741, Tokens per Sec:     7509, Lr: 0.000300
2025-05-29 20:48:44,174 - INFO - joeynmt.training - Epoch   6, Step:    53700, Batch Loss:     1.393605, Batch Acc: 0.537689, Tokens per Sec:     7279, Lr: 0.000300
2025-05-29 20:48:53,570 - INFO - joeynmt.training - Epoch   6, Step:    53800, Batch Loss:     1.619138, Batch Acc: 0.538303, Tokens per Sec:     7433, Lr: 0.000300
2025-05-29 20:49:03,011 - INFO - joeynmt.training - Epoch   6, Step:    53900, Batch Loss:     1.579329, Batch Acc: 0.536598, Tokens per Sec:     7287, Lr: 0.000300
2025-05-29 20:49:12,443 - INFO - joeynmt.training - Epoch   6, Step:    54000, Batch Loss:     1.600819, Batch Acc: 0.537819, Tokens per Sec:     7512, Lr: 0.000300
2025-05-29 20:49:12,444 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:49:12,444 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:49:50,481 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.34, acc:   0.51, generation: 38.0008[sec], evaluation: 0.0000[sec]
2025-05-29 20:49:50,665 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/50500.ckpt
2025-05-29 20:49:50,681 - INFO - joeynmt.training - Example #0
2025-05-29 20:49:50,682 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:49:50,682 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:49:50,682 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'kijken', 'naar', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gr@@', 'ond', 'van', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'maakt', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd', 'is.', '</s>']
2025-05-29 20:49:50,683 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:49:50,683 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:49:50,683 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te verkijken naar de arctische ijskappen, die de arctische ijskappen, die de grond van 48 staten had gemaakt voor de onderste 40 procent van de onderste 40 procent gegooid is.
2025-05-29 20:49:50,683 - INFO - joeynmt.training - Example #1
2025-05-29 20:49:50,684 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:49:50,684 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:49:50,684 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'kken', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ik@@', 'ker@@', 's', 'van', 'het', 'ij@@', 's@@', 'je', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:49:50,685 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:49:50,685 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:49:50,686 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerst van dit speciale probleem, omdat het niet de dikken van het ijskikkers van het ijsje toont.
2025-05-29 20:49:50,686 - INFO - joeynmt.training - Example #2
2025-05-29 20:49:50,686 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:49:50,686 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:49:50,686 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:49:50,687 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:49:50,687 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:49:50,688 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapen het slaagsysteem.
2025-05-29 20:49:50,688 - INFO - joeynmt.training - Example #3
2025-05-29 20:49:50,688 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:49:50,688 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:49:50,688 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'cht', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:49:50,689 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:49:50,689 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:49:50,689 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slucht in de winter en somert.
2025-05-29 20:49:50,690 - INFO - joeynmt.training - Example #4
2025-05-29 20:49:50,690 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:49:50,690 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:49:50,690 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:49:50,692 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:49:50,692 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:49:50,692 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen is een tijdschrift van wat er gebeurt in de laatste 25 jaar gebeurd.
2025-05-29 20:49:59,974 - INFO - joeynmt.training - Epoch   6, Step:    54100, Batch Loss:     1.647771, Batch Acc: 0.536481, Tokens per Sec:     7489, Lr: 0.000300
2025-05-29 20:50:09,310 - INFO - joeynmt.training - Epoch   6, Step:    54200, Batch Loss:     1.432455, Batch Acc: 0.544768, Tokens per Sec:     7557, Lr: 0.000300
2025-05-29 20:50:18,476 - INFO - joeynmt.training - Epoch   6, Step:    54300, Batch Loss:     1.511520, Batch Acc: 0.540031, Tokens per Sec:     7582, Lr: 0.000300
2025-05-29 20:50:27,637 - INFO - joeynmt.training - Epoch   6, Step:    54400, Batch Loss:     1.628854, Batch Acc: 0.539850, Tokens per Sec:     7640, Lr: 0.000300
2025-05-29 20:50:36,982 - INFO - joeynmt.training - Epoch   6, Step:    54500, Batch Loss:     1.479152, Batch Acc: 0.543739, Tokens per Sec:     7640, Lr: 0.000300
2025-05-29 20:50:36,984 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:50:36,984 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:51:11,694 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.35, acc:   0.51, generation: 34.6720[sec], evaluation: 0.0000[sec]
2025-05-29 20:51:11,861 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/53000.ckpt
2025-05-29 20:51:11,877 - INFO - joeynmt.training - Example #0
2025-05-29 20:51:11,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:51:11,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:51:11,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'de', 'gr@@', 'ond', 'van', 'de', 'lan@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'lan@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'ar@@', 'ti@@', 'kel', 'was', 'ge@@', 'maa@@', 'kt.', '</s>']
2025-05-29 20:51:11,879 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:51:11,879 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:51:11,879 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te bekijken dat de artische ijskappen die voor de artische ijskappen die de grond van de landen van de onderste 40 procent van de onderste 40 procent van de landen van 40 procent van de grootte van de artikel was gemaakt.
2025-05-29 20:51:11,879 - INFO - joeynmt.training - Example #1
2025-05-29 20:51:11,879 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:51:11,879 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:51:11,880 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'dr@@', 'oo@@', 't', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'ap@@', 't', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ap@@', '.', '</s>']
2025-05-29 20:51:11,880 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:51:11,881 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:51:11,881 - INFO - joeynmt.training - 	Hypothesis: Maar dat droot niet sterk genoeg de eerste staat, omdat het niet de dikke ijskapt van het ijskap.
2025-05-29 20:51:11,881 - INFO - joeynmt.training - Example #2
2025-05-29 20:51:11,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:51:11,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:51:11,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:51:11,883 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:51:11,883 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:51:11,883 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het hart van onze wereldwijde klimaatsysteem.
2025-05-29 20:51:11,883 - INFO - joeynmt.training - Example #3
2025-05-29 20:51:11,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:51:11,884 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:51:11,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 'ing.', '</s>']
2025-05-29 20:51:11,885 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:51:11,885 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:51:11,885 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zomering.
2025-05-29 20:51:11,885 - INFO - joeynmt.training - Example #4
2025-05-29 20:51:11,885 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:51:11,885 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:51:11,886 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'oon', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:51:11,886 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:51:11,887 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:51:11,887 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik toon is een tijdschriften wat er in de laatste 25 jaar gebeurd.
2025-05-29 20:51:20,365 - INFO - joeynmt.training - Epoch   6, Step:    54600, Batch Loss:     1.603221, Batch Acc: 0.541614, Tokens per Sec:     8057, Lr: 0.000300
2025-05-29 20:51:29,722 - INFO - joeynmt.training - Epoch   6, Step:    54700, Batch Loss:     1.416861, Batch Acc: 0.543024, Tokens per Sec:     7758, Lr: 0.000300
2025-05-29 20:51:39,089 - INFO - joeynmt.training - Epoch   6, Step:    54800, Batch Loss:     1.527932, Batch Acc: 0.539648, Tokens per Sec:     7497, Lr: 0.000300
2025-05-29 20:51:48,451 - INFO - joeynmt.training - Epoch   6, Step:    54900, Batch Loss:     1.557545, Batch Acc: 0.539101, Tokens per Sec:     7383, Lr: 0.000300
2025-05-29 20:51:57,732 - INFO - joeynmt.training - Epoch   6, Step:    55000, Batch Loss:     1.547638, Batch Acc: 0.540917, Tokens per Sec:     7639, Lr: 0.000300
2025-05-29 20:51:57,733 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:51:57,733 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:52:33,675 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.31, acc:   0.51, generation: 35.8975[sec], evaluation: 0.0000[sec]
2025-05-29 20:52:33,676 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:52:33,862 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/51500.ckpt
2025-05-29 20:52:33,879 - INFO - joeynmt.training - Example #0
2025-05-29 20:52:33,879 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:52:33,880 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:52:33,880 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'der', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'n@@', 'aam', 'van', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'sch@@', 'e@@', 'p@@', 'sel@@', '.', '</s>']
2025-05-29 20:52:33,881 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:52:33,881 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:52:33,881 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verder te zien dat de artische ijskappen die voor de naam van drie miljoen jaar de grootte van de onderste 48 staten van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de schepsel.
2025-05-29 20:52:33,881 - INFO - joeynmt.training - Example #1
2025-05-29 20:52:33,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:52:33,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:52:33,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'ver@@', 'n@@', 'u@@', 't', 'van', 'dit', 'ij@@', 's@@', 'k@@', 'aar@@', 'heid', 'van', 'dit', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'is', 'niet', 'de', 'di@@', 'k', 'van', 'de', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'ij@@', 's@@', 'k@@', 'ap@@', 't.', '</s>']
2025-05-29 20:52:33,884 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:52:33,884 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:52:33,884 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de vernut van dit ijskaarheid van dit ijskaart is niet de dik van de ijskwestie van ijskapt.
2025-05-29 20:52:33,884 - INFO - joeynmt.training - Example #2
2025-05-29 20:52:33,885 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:52:33,885 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:52:33,885 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:52:33,886 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:52:33,886 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:52:33,886 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe ijskappe klimaatsysteem.
2025-05-29 20:52:33,886 - INFO - joeynmt.training - Example #3
2025-05-29 20:52:33,887 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:52:33,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:52:33,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'i@@', 'ten', 'in', 'de', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:52:33,888 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:52:33,888 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:52:33,888 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en sluiten in de zomert.
2025-05-29 20:52:33,888 - INFO - joeynmt.training - Example #4
2025-05-29 20:52:33,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:52:33,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:52:33,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:52:33,891 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:52:33,891 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:52:33,892 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdje van wat er in de afgelopen 25 jaar gebeurd.
2025-05-29 20:52:42,806 - INFO - joeynmt.training - Epoch   6, Step:    55100, Batch Loss:     1.557473, Batch Acc: 0.538740, Tokens per Sec:     7472, Lr: 0.000300
2025-05-29 20:52:52,278 - INFO - joeynmt.training - Epoch   6, Step:    55200, Batch Loss:     1.578119, Batch Acc: 0.541379, Tokens per Sec:     7329, Lr: 0.000300
2025-05-29 20:53:01,700 - INFO - joeynmt.training - Epoch   6, Step:    55300, Batch Loss:     1.445089, Batch Acc: 0.535909, Tokens per Sec:     7580, Lr: 0.000300
2025-05-29 20:53:08,627 - INFO - joeynmt.training - Epoch   6: total training loss 14343.19
2025-05-29 20:53:08,627 - INFO - joeynmt.training - EPOCH 7
2025-05-29 20:53:10,758 - INFO - joeynmt.training - Epoch   7, Step:    55400, Batch Loss:     1.458623, Batch Acc: 0.568857, Tokens per Sec:     7434, Lr: 0.000300
2025-05-29 20:53:20,013 - INFO - joeynmt.training - Epoch   7, Step:    55500, Batch Loss:     1.621220, Batch Acc: 0.551435, Tokens per Sec:     7465, Lr: 0.000300
2025-05-29 20:53:20,014 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:53:20,014 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:54:01,599 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.34, acc:   0.51, generation: 41.5355[sec], evaluation: 0.0000[sec]
2025-05-29 20:54:01,794 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/54500.ckpt
2025-05-29 20:54:01,812 - INFO - joeynmt.training - Example #0
2025-05-29 20:54:01,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:54:01,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:54:01,814 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ct@@', 'ie', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ct@@', 'ie', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'en@@', 'zen', 'van', 'de', 'gr@@', 'en@@', 'zen', 'van', 'de', 'gr@@', 'en@@', 'zen', 'van', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'had', 'om', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'was', 'ge@@', 'dur@@', 'ende', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'en@@', 'zen', 'om', 'te', 'be@@', 'kijken', 'naar', 'de', 'gr@@']
2025-05-29 20:54:01,815 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:54:01,815 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:54:01,815 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te bekijken dat de arctie te bekijken dat de arctie drie miljoen jaar de grenzen van de grenzen van de grenzen van 48 staten had gehad om 40 procent van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent van de onderste 48 staten was gedurende drie miljoen jaar de grenzen om te bekijken naar de gr
2025-05-29 20:54:01,815 - INFO - joeynmt.training - Example #1
2025-05-29 20:54:01,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:54:01,816 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:54:01,816 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'ver@@', 'n@@', 'u@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'is', 'niet', 'de', 'di@@', 'k', 'van', 'ij@@', 's@@', 'k@@', 'om', 'van', 'ij@@', 's@@', 's.', '</s>']
2025-05-29 20:54:01,816 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:54:01,816 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:54:01,816 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de vernut van dit speciale probleem van dit ijskwestie is niet de dik van ijskom van ijss.
2025-05-29 20:54:01,816 - INFO - joeynmt.training - Example #2
2025-05-29 20:54:01,817 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:54:01,817 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:54:01,817 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ct@@', 'ie', 'van', 'de', 'ar@@', 'ct@@', 'ie', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:54:01,817 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:54:01,817 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:54:01,817 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctie van de arctie van ons wereldwijd klimaatsysteem.
2025-05-29 20:54:01,817 - INFO - joeynmt.training - Example #3
2025-05-29 20:54:01,818 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:54:01,818 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:54:01,818 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'z@@', 'am@@', 'el@@', 'ing', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 20:54:01,818 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:54:01,818 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:54:01,818 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en verzameling in de zomers.
2025-05-29 20:54:01,818 - INFO - joeynmt.training - Example #4
2025-05-29 20:54:01,819 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:54:01,819 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:54:01,819 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'oon', 'zal', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'je', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 20:54:01,819 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:54:01,819 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:54:01,820 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik toon zal laten zien, is een tijdje opname wat er gebeurt in de afgelopen 25 jaar.
2025-05-29 20:54:10,277 - INFO - joeynmt.training - Epoch   7, Step:    55600, Batch Loss:     1.448331, Batch Acc: 0.550564, Tokens per Sec:     8089, Lr: 0.000300
2025-05-29 20:54:18,691 - INFO - joeynmt.training - Epoch   7, Step:    55700, Batch Loss:     1.593366, Batch Acc: 0.556567, Tokens per Sec:     8591, Lr: 0.000300
2025-05-29 20:54:27,009 - INFO - joeynmt.training - Epoch   7, Step:    55800, Batch Loss:     1.385770, Batch Acc: 0.548537, Tokens per Sec:     8389, Lr: 0.000300
2025-05-29 20:54:35,799 - INFO - joeynmt.training - Epoch   7, Step:    55900, Batch Loss:     1.340754, Batch Acc: 0.550092, Tokens per Sec:     7943, Lr: 0.000300
2025-05-29 20:54:45,235 - INFO - joeynmt.training - Epoch   7, Step:    56000, Batch Loss:     1.357988, Batch Acc: 0.548507, Tokens per Sec:     7449, Lr: 0.000300
2025-05-29 20:54:45,236 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:54:45,236 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:55:21,885 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.34, acc:   0.51, generation: 36.6202[sec], evaluation: 0.0000[sec]
2025-05-29 20:55:22,076 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/52500.ckpt
2025-05-29 20:55:22,094 - INFO - joeynmt.training - Example #0
2025-05-29 20:55:22,095 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:55:22,095 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:55:22,095 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'de', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gro@@', 'ter@@', 'e', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'is.', '</s>']
2025-05-29 20:55:22,100 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:55:22,100 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:55:22,101 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoonde getoond om te bekijken dat de artische ijskappen, die voor de arctische ijskappen, die de grotere van de onderste 40 procent van de onderste 40 procent van de onderste 40 procent is.
2025-05-29 20:55:22,101 - INFO - joeynmt.training - Example #1
2025-05-29 20:55:22,101 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:55:22,101 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:55:22,101 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's.', '</s>']
2025-05-29 20:55:22,102 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:55:22,102 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:55:22,103 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste staat, omdat het niet de dikke probleem is dat het niet de dikke ijs.
2025-05-29 20:55:22,103 - INFO - joeynmt.training - Example #2
2025-05-29 20:55:22,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:55:22,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:55:22,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'im@@', 'syste@@', 'em', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:55:22,104 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:55:22,104 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:55:22,105 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het slimsysteem van ons wereldwijd klimaatsysteem.
2025-05-29 20:55:22,105 - INFO - joeynmt.training - Example #3
2025-05-29 20:55:22,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:55:22,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:55:22,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 'en', 'z@@', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:55:22,106 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:55:22,106 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:55:22,107 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en en zzomert.
2025-05-29 20:55:22,107 - INFO - joeynmt.training - Example #4
2025-05-29 20:55:22,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:55:22,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:55:22,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:55:22,108 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:55:22,110 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:55:22,110 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschriften wat er in de laatste 25 jaar is gebeurd.
2025-05-29 20:55:31,404 - INFO - joeynmt.training - Epoch   7, Step:    56100, Batch Loss:     1.273229, Batch Acc: 0.552969, Tokens per Sec:     7244, Lr: 0.000300
2025-05-29 20:55:40,427 - INFO - joeynmt.training - Epoch   7, Step:    56200, Batch Loss:     1.481474, Batch Acc: 0.550129, Tokens per Sec:     7543, Lr: 0.000300
2025-05-29 20:55:49,427 - INFO - joeynmt.training - Epoch   7, Step:    56300, Batch Loss:     1.494309, Batch Acc: 0.553457, Tokens per Sec:     7653, Lr: 0.000300
2025-05-29 20:55:59,091 - INFO - joeynmt.training - Epoch   7, Step:    56400, Batch Loss:     1.507990, Batch Acc: 0.554917, Tokens per Sec:     7117, Lr: 0.000300
2025-05-29 20:56:08,389 - INFO - joeynmt.training - Epoch   7, Step:    56500, Batch Loss:     1.602549, Batch Acc: 0.552644, Tokens per Sec:     7434, Lr: 0.000300
2025-05-29 20:56:08,390 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:56:08,390 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:56:46,797 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.31, acc:   0.51, generation: 38.3691[sec], evaluation: 0.0000[sec]
2025-05-29 20:56:46,799 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:56:46,981 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/56000.ckpt
2025-05-29 20:56:46,998 - INFO - joeynmt.training - Example #0
2025-05-29 20:56:46,999 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:56:46,999 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:56:47,000 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'ach@@', 't.', '</s>']
2025-05-29 20:56:47,000 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:56:47,000 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:56:47,001 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verkijken dat de artische ijskappen, die de artische ijskappen, die de grootte van de onderste 48 staten van de onderste 48 staten van de onderste 40 procent geslacht.
2025-05-29 20:56:47,001 - INFO - joeynmt.training - Example #1
2025-05-29 20:56:47,001 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:56:47,001 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:56:47,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'ver@@', 'n@@', 'aar@@', 'aar@@', 'dig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'uit@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 'z@@', 'er@@', 'ing', 'van', 'de', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'to@@', 'on@@', 't', 'van', 'het', 'ij@@', 'z@@', 'er', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'is', 'dat', 'het', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'van', 'de', 'ij@@', 'z@@', 'er@@', 'van', 'dat', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'is', 'dat', 'het', 'ge@@', 'dra@@', 'g', 'van', 'het', 'ij@@', 'z@@', 'er@@', 'd.', '</s>']
2025-05-29 20:56:47,002 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:56:47,002 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:56:47,002 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste vernaaraardigheid van dit speciale probleem uit, omdat het niet de dik van het ijzer van de ijzer van de ijzer van de ijzer van de ijzering van de ijskaart toont van het ijzer niet sterk genoeg is dat het niet sterk genoeg van de ijzervan dat ijskaart niet sterk genoeg is dat het gedrag van het ijzerd.
2025-05-29 20:56:47,002 - INFO - joeynmt.training - Example #2
2025-05-29 20:56:47,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:56:47,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:56:47,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:56:47,003 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:56:47,003 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:56:47,003 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe het slaagsysteem van ons wereldwijde klimaatsysteem.
2025-05-29 20:56:47,003 - INFO - joeynmt.training - Example #3
2025-05-29 20:56:47,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:56:47,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:56:47,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'sen', 'in', 'het', 'win@@', 'ter', 'en', 'ver@@', 'st@@', 'op@@', 't', 'in', 'de', 'w@@', 'inter@@', '.', '</s>']
2025-05-29 20:56:47,004 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:56:47,004 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:56:47,004 - INFO - joeynmt.training - 	Hypothesis: Ze groeisen in het winter en verstopt in de winter.
2025-05-29 20:56:47,004 - INFO - joeynmt.training - Example #4
2025-05-29 20:56:47,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:56:47,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:56:47,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 20:56:47,005 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:56:47,005 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:56:47,005 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen is een tijdje van wat er gebeurde in de afgelopen 25 jaar.
2025-05-29 20:56:56,261 - INFO - joeynmt.training - Epoch   7, Step:    56600, Batch Loss:     1.501709, Batch Acc: 0.549560, Tokens per Sec:     7595, Lr: 0.000300
2025-05-29 20:57:05,739 - INFO - joeynmt.training - Epoch   7, Step:    56700, Batch Loss:     1.562563, Batch Acc: 0.553527, Tokens per Sec:     7403, Lr: 0.000300
2025-05-29 20:57:14,554 - INFO - joeynmt.training - Epoch   7, Step:    56800, Batch Loss:     1.591088, Batch Acc: 0.550951, Tokens per Sec:     7445, Lr: 0.000300
2025-05-29 20:57:22,717 - INFO - joeynmt.training - Epoch   7, Step:    56900, Batch Loss:     1.505504, Batch Acc: 0.548210, Tokens per Sec:     8787, Lr: 0.000300
2025-05-29 20:57:30,989 - INFO - joeynmt.training - Epoch   7, Step:    57000, Batch Loss:     1.564050, Batch Acc: 0.546709, Tokens per Sec:     8275, Lr: 0.000300
2025-05-29 20:57:30,990 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:57:30,990 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:58:02,678 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.33, acc:   0.51, generation: 31.6503[sec], evaluation: 0.0000[sec]
2025-05-29 20:58:02,853 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/54000.ckpt
2025-05-29 20:58:02,870 - INFO - joeynmt.training - Example #0
2025-05-29 20:58:02,870 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:58:02,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:58:02,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'naar', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 'z@@', 'er@@', 'van', 'ge@@', 'vol@@', 'g', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'aa@@', 'g', 'van', 'de', 'gr@@', 'aa@@', 'g', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd', 'is.', '</s>']
2025-05-29 20:58:02,872 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:58:02,872 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:58:02,872 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkijken naar de artische ijzervan gevolg drie miljoen jaar de grootte van de graag van de graag van de onderste 48 staten van de 40 procent gegooid is.
2025-05-29 20:58:02,872 - INFO - joeynmt.training - Example #1
2025-05-29 20:58:02,873 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:58:02,873 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:58:02,873 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 'z@@', 'er', 'niet', 'de', 'di@@', 'k', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 'z@@', 'er.', '</s>']
2025-05-29 20:58:02,874 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:58:02,874 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:58:02,874 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste staat, omdat het niet de dik van het ijzer niet de dik van de ijzer van de ijzer.
2025-05-29 20:58:02,874 - INFO - joeynmt.training - Example #2
2025-05-29 20:58:02,875 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:58:02,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:58:02,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:58:02,877 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:58:02,877 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:58:02,877 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskap, het hart van ons wereldwijde klimaatsysteem.
2025-05-29 20:58:02,877 - INFO - joeynmt.training - Example #3
2025-05-29 20:58:02,878 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:58:02,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:58:02,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 20:58:02,879 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:58:02,879 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:58:02,879 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zomert.
2025-05-29 20:58:02,879 - INFO - joeynmt.training - Example #4
2025-05-29 20:58:02,880 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:58:02,880 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:58:02,880 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'je', 'op@@', 'nam@@', 'en', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd', 'is.', '</s>']
2025-05-29 20:58:02,881 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:58:02,881 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:58:02,881 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdje opnamen wat er gebeurt in de afgelopen 25 jaar gebeurd is.
2025-05-29 20:58:12,186 - INFO - joeynmt.training - Epoch   7, Step:    57100, Batch Loss:     1.443199, Batch Acc: 0.537683, Tokens per Sec:     7319, Lr: 0.000300
2025-05-29 20:58:21,089 - INFO - joeynmt.training - Epoch   7, Step:    57200, Batch Loss:     1.679828, Batch Acc: 0.548346, Tokens per Sec:     7812, Lr: 0.000300
2025-05-29 20:58:30,052 - INFO - joeynmt.training - Epoch   7, Step:    57300, Batch Loss:     1.530210, Batch Acc: 0.552004, Tokens per Sec:     7956, Lr: 0.000300
2025-05-29 20:58:39,197 - INFO - joeynmt.training - Epoch   7, Step:    57400, Batch Loss:     1.582090, Batch Acc: 0.548243, Tokens per Sec:     7535, Lr: 0.000300
2025-05-29 20:58:48,470 - INFO - joeynmt.training - Epoch   7, Step:    57500, Batch Loss:     1.592170, Batch Acc: 0.549034, Tokens per Sec:     7654, Lr: 0.000300
2025-05-29 20:58:48,472 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 20:58:48,472 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:59:21,899 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.33, acc:   0.51, generation: 33.3879[sec], evaluation: 0.0000[sec]
2025-05-29 20:59:22,085 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/55500.ckpt
2025-05-29 20:59:22,103 - INFO - joeynmt.training - Example #0
2025-05-29 20:59:22,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 20:59:22,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 20:59:22,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'l@@', 'oo@@', 's', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'in', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'or@@', 'd', 'is.', '</s>']
2025-05-29 20:59:22,106 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:59:22,106 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 20:59:22,106 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verkijken dat de artische ijskappen die voor de artische ijskappen die voor de loos van de onderste 48 staten in de onderste 48 staten van 40 procent geslord is.
2025-05-29 20:59:22,106 - INFO - joeynmt.training - Example #1
2025-05-29 20:59:22,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 20:59:22,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 20:59:22,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'de', 'eerste', 'keer', 'dat', 'het', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'de', 'ij@@', 's@@', 'es', 'to@@', 'on@@', 't', 'van', 'de', 'ij@@', 's@@', 'es', 'to@@', 'on@@', 't', 'van', 'de', 'ij@@', 's@@', 'es', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 20:59:22,108 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:59:22,108 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 20:59:22,108 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerst van de eerste keer dat het is dat het niet de dik van de ijses toont van de ijses toont van de ijses toont.
2025-05-29 20:59:22,108 - INFO - joeynmt.training - Example #2
2025-05-29 20:59:22,109 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 20:59:22,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 20:59:22,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 20:59:22,110 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:59:22,110 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 20:59:22,110 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het hart van ons wereldwijde klimaatsysteem.
2025-05-29 20:59:22,110 - INFO - joeynmt.training - Example #3
2025-05-29 20:59:22,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 20:59:22,110 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 20:59:22,110 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'i@@', 'ten', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'i@@', 'ten', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 20:59:22,111 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:59:22,111 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 20:59:22,111 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluiten in de winter en sluiten in de winter en zomer.
2025-05-29 20:59:22,111 - INFO - joeynmt.training - Example #4
2025-05-29 20:59:22,111 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 20:59:22,111 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 20:59:22,113 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'je', 'is', 'een', 'tij@@', 'd@@', 'je', 'is', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 20:59:22,113 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:59:22,113 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 20:59:22,113 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen is een tijdje is een tijdje is in de afgelopen 25 jaar is gebeurd.
2025-05-29 20:59:31,620 - INFO - joeynmt.training - Epoch   7, Step:    57600, Batch Loss:     1.534969, Batch Acc: 0.543694, Tokens per Sec:     7436, Lr: 0.000300
2025-05-29 20:59:40,851 - INFO - joeynmt.training - Epoch   7, Step:    57700, Batch Loss:     1.590022, Batch Acc: 0.540210, Tokens per Sec:     7599, Lr: 0.000300
2025-05-29 20:59:50,036 - INFO - joeynmt.training - Epoch   7, Step:    57800, Batch Loss:     1.498480, Batch Acc: 0.547389, Tokens per Sec:     7717, Lr: 0.000300
2025-05-29 20:59:59,316 - INFO - joeynmt.training - Epoch   7, Step:    57900, Batch Loss:     1.571128, Batch Acc: 0.548068, Tokens per Sec:     7404, Lr: 0.000300
2025-05-29 21:00:08,709 - INFO - joeynmt.training - Epoch   7, Step:    58000, Batch Loss:     1.590414, Batch Acc: 0.544893, Tokens per Sec:     7302, Lr: 0.000300
2025-05-29 21:00:08,710 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:00:08,710 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:00:41,902 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.34, acc:   0.51, generation: 33.1489[sec], evaluation: 0.0000[sec]
2025-05-29 21:00:41,914 - INFO - joeynmt.training - Example #0
2025-05-29 21:00:41,915 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:00:41,915 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:00:41,915 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'ct@@', 'se', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'in', 'de', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'aa@@', 't.', '</s>']
2025-05-29 21:00:41,916 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:00:41,917 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:00:41,917 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkijken dat de arctse ijskappen, die de artische ijskappen, die de grootte van de onderste 48 staten in de 40 procent gegaat.
2025-05-29 21:00:41,917 - INFO - joeynmt.training - Example #1
2025-05-29 21:00:41,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:00:41,917 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:00:41,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'het', 'ij@@', 's@@', 'k@@', 'oo@@', 's', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's@@', 'je', 'l@@', 'aat', 'zien.', '</s>']
2025-05-29 21:00:41,918 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:00:41,919 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:00:41,919 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerst van het ijskoos probleem omdat het niet de dik van het ijsje laat zien.
2025-05-29 21:00:41,919 - INFO - joeynmt.training - Example #2
2025-05-29 21:00:41,919 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:00:41,919 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:00:41,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ct@@', 'ie@@', 'ke', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'men.', '</s>']
2025-05-29 21:00:41,920 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:00:41,920 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:00:41,920 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctieke ijskappe hart van onze wereldwijd klimaatsystemen.
2025-05-29 21:00:41,921 - INFO - joeynmt.training - Example #3
2025-05-29 21:00:41,921 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:00:41,921 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:00:41,921 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'l@@', 'oo@@', 'pt', 'in', 'de', 'win@@', 'ter', 'en', 'l@@', 'oo@@', 'p@@', 't.', '</s>']
2025-05-29 21:00:41,922 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:00:41,923 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:00:41,923 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en loopt in de winter en loopt.
2025-05-29 21:00:41,923 - INFO - joeynmt.training - Example #4
2025-05-29 21:00:41,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:00:41,924 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:00:41,924 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'oon', 'l@@', 'aat', 'is', 'een', 'teken@@', 'ing', 'van', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd', 'is.', '</s>']
2025-05-29 21:00:41,925 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:00:41,925 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:00:41,925 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik toon laat is een tekening van wat er in de laatste 25 jaar gebeurd is.
2025-05-29 21:00:50,283 - INFO - joeynmt.training - Epoch   7, Step:    58100, Batch Loss:     1.658238, Batch Acc: 0.542860, Tokens per Sec:     8317, Lr: 0.000300
2025-05-29 21:00:58,528 - INFO - joeynmt.training - Epoch   7, Step:    58200, Batch Loss:     1.520160, Batch Acc: 0.545251, Tokens per Sec:     8383, Lr: 0.000300
2025-05-29 21:01:07,539 - INFO - joeynmt.training - Epoch   7, Step:    58300, Batch Loss:     1.297966, Batch Acc: 0.545380, Tokens per Sec:     7672, Lr: 0.000300
2025-05-29 21:01:16,373 - INFO - joeynmt.training - Epoch   7, Step:    58400, Batch Loss:     1.476772, Batch Acc: 0.544589, Tokens per Sec:     7909, Lr: 0.000300
2025-05-29 21:01:24,456 - INFO - joeynmt.training - Epoch   7, Step:    58500, Batch Loss:     1.421279, Batch Acc: 0.544703, Tokens per Sec:     8841, Lr: 0.000300
2025-05-29 21:01:24,457 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:01:24,457 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:02:02,286 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.33, acc:   0.51, generation: 37.7938[sec], evaluation: 0.0000[sec]
2025-05-29 21:02:02,485 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/57500.ckpt
2025-05-29 21:02:02,498 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit_bpe/57500.ckpt
2025-05-29 21:02:02,498 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe\57500.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit_bpe\\57500.ckpt')
2025-05-29 21:02:02,505 - INFO - joeynmt.training - Example #0
2025-05-29 21:02:02,506 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:02:02,506 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:02:02,506 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'uur@@', ',', 'die', 'de', 'gr@@', 'ond', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd.', '</s>']
2025-05-29 21:02:02,507 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:02:02,507 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:02:02,507 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te verkijken dat de artische ijskapparatatatatatuur, die de grond drie miljoen jaar de grootte van de onderste 48 staten van de onderste 40 procent geslaagd.
2025-05-29 21:02:02,507 - INFO - joeynmt.training - Example #1
2025-05-29 21:02:02,508 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:02:02,508 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:02:02,508 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'waar@@', 'de', 'van', 'deze', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'kken', 'van', 'de', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't', 'van', 'de', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'die', 'ge@@', 'eft', 'aan', 'de', 'l@@', 'ijn@@', '.', '</s>']
2025-05-29 21:02:02,508 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:02:02,508 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:02:02,509 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste waarde van deze specifiek probleem, omdat het niet de dikken van de ijs van het ijs toont van de ijskwestie van de ijs van de ijs die geeft aan de lijn.
2025-05-29 21:02:02,509 - INFO - joeynmt.training - Example #2
2025-05-29 21:02:02,509 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:02:02,509 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:02:02,509 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'aat', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:02:02,509 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:02:02,510 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:02:02,510 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe ijskapparaat van onze wereldwijde klimaatsysteem.
2025-05-29 21:02:02,510 - INFO - joeynmt.training - Example #3
2025-05-29 21:02:02,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:02:02,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:02:02,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'm@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 21:02:02,510 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:02:02,510 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:02:02,510 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en smpt in de zomer.
2025-05-29 21:02:02,511 - INFO - joeynmt.training - Example #4
2025-05-29 21:02:02,511 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:02:02,511 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:02:02,511 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd', 'is', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:02:02,512 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:02:02,513 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:02:02,513 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen, is een tijdje in de afgelopen 25 jaar gebeurd is in de afgelopen 25 jaar is gebeurd.
2025-05-29 21:02:11,876 - INFO - joeynmt.training - Epoch   7, Step:    58600, Batch Loss:     1.605339, Batch Acc: 0.544185, Tokens per Sec:     7149, Lr: 0.000300
2025-05-29 21:02:21,001 - INFO - joeynmt.training - Epoch   7, Step:    58700, Batch Loss:     1.529411, Batch Acc: 0.542207, Tokens per Sec:     7523, Lr: 0.000300
2025-05-29 21:02:30,217 - INFO - joeynmt.training - Epoch   7, Step:    58800, Batch Loss:     1.640771, Batch Acc: 0.548115, Tokens per Sec:     7902, Lr: 0.000300
2025-05-29 21:02:39,334 - INFO - joeynmt.training - Epoch   7, Step:    58900, Batch Loss:     1.688876, Batch Acc: 0.550326, Tokens per Sec:     7548, Lr: 0.000300
2025-05-29 21:02:48,462 - INFO - joeynmt.training - Epoch   7, Step:    59000, Batch Loss:     1.464349, Batch Acc: 0.539415, Tokens per Sec:     7608, Lr: 0.000300
2025-05-29 21:02:48,464 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:02:48,464 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:03:31,899 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.33, acc:   0.51, generation: 43.3935[sec], evaluation: 0.0000[sec]
2025-05-29 21:03:31,912 - INFO - joeynmt.training - Example #0
2025-05-29 21:03:31,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:03:31,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:03:31,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's', 'die', 'voor', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'st@@', 'aten', 'van', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'st@@', 'aten', 'van', '4@@', '0@@', '%', 'ge@@', 'sl@@', 'ach@@', 'to@@', 'ff@@', 'er@@', 'd.', '</s>']
2025-05-29 21:03:31,914 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:03:31,915 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:03:31,915 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te verkijken dat de arctische ijskappen, de arctische ijs die voor de reden van de onderste 48 staten van de staten van 48 staten om 40 procent van de staten van 40% geslachtofferd.
2025-05-29 21:03:31,915 - INFO - joeynmt.training - Example #1
2025-05-29 21:03:31,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:03:31,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:03:31,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'n@@', 'u@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kken', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'die', 'het', 'l@@', 'icht', 'niet', 'op', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'oe@@', 'l', 'op', 'de', 'di@@', 'kken', 'van', 'de', 'ij@@', 's', 'van', 'de', 'eerste', 're@@', 'st', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'eerste', 're@@', 'st', 'van', 'de', 'eerste', 'is', 'dat', 'het', 'niet', 'zo', 'veel', 'als', 'het', 'is', 'om', 'de']
2025-05-29 21:03:31,917 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:03:31,917 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:03:31,917 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste nut van dit specifiek probleem omdat het niet de dikken van de ijs van de ijs van de ijs van de ijs van de ijs van de ijs van de ijs van de ijs van de ijs die het licht niet op de dikke doel op de dikken van de ijs van de eerste rest van de ijs van de ijs van de eerste rest van de eerste is dat het niet zo veel als het is om de
2025-05-29 21:03:31,917 - INFO - joeynmt.training - Example #2
2025-05-29 21:03:31,918 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:03:31,918 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:03:31,918 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's', 'het', 'sl@@', 'aa@@', 'g@@', 'ste', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:03:31,919 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:03:31,919 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:03:31,919 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijs het slaagste hart van onze wereldwijd klimaatsysteem.
2025-05-29 21:03:31,920 - INFO - joeynmt.training - Example #3
2025-05-29 21:03:31,920 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:03:31,920 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:03:31,920 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'cht', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 21:03:31,921 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:03:31,921 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:03:31,921 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slucht in de zomer.
2025-05-29 21:03:31,921 - INFO - joeynmt.training - Example #4
2025-05-29 21:03:31,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:03:31,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:03:31,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 21:03:31,923 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:03:31,923 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:03:31,923 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat is een tijdschriften wat er gebeurde in de laatste 25 jaar.
2025-05-29 21:03:41,134 - INFO - joeynmt.training - Epoch   7, Step:    59100, Batch Loss:     1.535942, Batch Acc: 0.548487, Tokens per Sec:     7554, Lr: 0.000300
2025-05-29 21:03:49,522 - INFO - joeynmt.training - Epoch   7, Step:    59200, Batch Loss:     1.183823, Batch Acc: 0.550095, Tokens per Sec:     8316, Lr: 0.000300
2025-05-29 21:03:57,622 - INFO - joeynmt.training - Epoch   7, Step:    59300, Batch Loss:     1.581910, Batch Acc: 0.546285, Tokens per Sec:     8719, Lr: 0.000300
2025-05-29 21:04:05,679 - INFO - joeynmt.training - Epoch   7, Step:    59400, Batch Loss:     1.531313, Batch Acc: 0.552091, Tokens per Sec:     8634, Lr: 0.000300
2025-05-29 21:04:13,649 - INFO - joeynmt.training - Epoch   7, Step:    59500, Batch Loss:     1.379323, Batch Acc: 0.540922, Tokens per Sec:     8812, Lr: 0.000300
2025-05-29 21:04:13,650 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:04:13,650 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:04:55,686 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.32, acc:   0.51, generation: 41.9957[sec], evaluation: 0.0000[sec]
2025-05-29 21:04:55,880 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/57000.ckpt
2025-05-29 21:04:55,897 - INFO - joeynmt.training - Example #0
2025-05-29 21:04:55,898 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:04:55,898 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:04:55,898 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'ver@@', 'kijken', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'had', 'om', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'groot@@', 'te', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'groot@@', 'te', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 'groot@@', 'te', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'waarom', 'de', 'groot@@', 'te', 'van', 'de', 'ge@@', 'vol@@', 'gen', 'voor', 'de', 're@@', 'cht', 'van', 'de', 're@@', 'd@@', 'd@@']
2025-05-29 21:04:55,899 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:04:55,899 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:04:55,899 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen om te verkijken om te verkijken dat de artische ijskappen, die voor de artische ijskappen, die voor de onderste 48 staten had gehad om 40 procent van de grootte van 40 procent van de reden van 40 procent van de grootte van 40 procent van de reden van de grootte van de reden van de reden waarom de grootte van de gevolgen voor de recht van de redd
2025-05-29 21:04:55,900 - INFO - joeynmt.training - Example #1
2025-05-29 21:04:55,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:04:55,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:04:55,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'be@@', 'vol@@', 'k@@', 'ing', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'be@@', 'vol@@', 'k@@', 'ing', 'van', 'de', 'ij@@', 's.', '</s>']
2025-05-29 21:04:55,901 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:04:55,901 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:04:55,901 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerst van dit speciale probleem omdat het niet de dikke bevolking van de ijs van de ijs van de ijs van de ijs van de ijs van de ijs van de ijs van de ijs van de ijs van de bevolking van de ijs.
2025-05-29 21:04:55,902 - INFO - joeynmt.training - Example #2
2025-05-29 21:04:55,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:04:55,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:04:55,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:04:55,903 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:04:55,903 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:04:55,903 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-29 21:04:55,903 - INFO - joeynmt.training - Example #3
2025-05-29 21:04:55,904 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:04:55,904 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:04:55,904 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 'ing.', '</s>']
2025-05-29 21:04:55,905 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:04:55,905 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:04:55,906 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomering.
2025-05-29 21:04:55,906 - INFO - joeynmt.training - Example #4
2025-05-29 21:04:55,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:04:55,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:04:55,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:04:55,907 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:04:55,907 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:04:55,908 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen, is een tijdje van de afgelopen 25 jaar gebeurd.
2025-05-29 21:05:05,806 - INFO - joeynmt.training - Epoch   7, Step:    59600, Batch Loss:     1.517787, Batch Acc: 0.545073, Tokens per Sec:     6973, Lr: 0.000300
2025-05-29 21:05:15,202 - INFO - joeynmt.training - Epoch   7, Step:    59700, Batch Loss:     1.270602, Batch Acc: 0.549782, Tokens per Sec:     7604, Lr: 0.000300
2025-05-29 21:05:24,356 - INFO - joeynmt.training - Epoch   7, Step:    59800, Batch Loss:     1.488412, Batch Acc: 0.550505, Tokens per Sec:     7517, Lr: 0.000300
2025-05-29 21:05:33,639 - INFO - joeynmt.training - Epoch   7, Step:    59900, Batch Loss:     1.531143, Batch Acc: 0.545893, Tokens per Sec:     7505, Lr: 0.000300
2025-05-29 21:05:42,954 - INFO - joeynmt.training - Epoch   7, Step:    60000, Batch Loss:     1.552822, Batch Acc: 0.544942, Tokens per Sec:     7603, Lr: 0.000300
2025-05-29 21:05:42,955 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:05:42,955 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:06:21,978 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.32, acc:   0.51, generation: 38.9889[sec], evaluation: 0.0000[sec]
2025-05-29 21:06:22,163 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/53500.ckpt
2025-05-29 21:06:22,180 - INFO - joeynmt.training - Example #0
2025-05-29 21:06:22,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:06:22,181 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:06:22,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'ond', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'groot@@', 'te', 'van', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'oo@@', 't', 'is.', '</s>']
2025-05-29 21:06:22,182 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:06:22,182 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:06:22,182 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verzien dat de arctische ijskappen, die de arctische ijskappen, die de grootte van de grond van 40 procent van de grootte van 40 procent gesloot is.
2025-05-29 21:06:22,182 - INFO - joeynmt.training - Example #1
2025-05-29 21:06:22,182 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:06:22,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:06:22,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'ver@@', 'n@@', 'ij@@', 'nen', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 21:06:22,185 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:06:22,185 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:06:22,185 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de vernijnen van dit speciale probleem omdat het niet de dikke van het ijs toont.
2025-05-29 21:06:22,185 - INFO - joeynmt.training - Example #2
2025-05-29 21:06:22,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:06:22,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:06:22,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'men.', '</s>']
2025-05-29 21:06:22,187 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:06:22,187 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:06:22,187 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe hart van onze wereldwijde klimaatsystemen.
2025-05-29 21:06:22,187 - INFO - joeynmt.training - Example #3
2025-05-29 21:06:22,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:06:22,188 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:06:22,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lo@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:06:22,189 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:06:22,189 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:06:22,189 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slot in de zomers.
2025-05-29 21:06:22,189 - INFO - joeynmt.training - Example #4
2025-05-29 21:06:22,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:06:22,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:06:22,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'ti@@', '-@@', 'tra@@', 'ff@@', 'er@@', 'ing', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd', 'is.', '</s>']
2025-05-29 21:06:22,190 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:06:22,190 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:06:22,190 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een ti-traffering in de laatste 25 jaar gebeurd is.
2025-05-29 21:06:31,292 - INFO - joeynmt.training - Epoch   7, Step:    60100, Batch Loss:     1.550638, Batch Acc: 0.548568, Tokens per Sec:     7525, Lr: 0.000300
2025-05-29 21:06:40,279 - INFO - joeynmt.training - Epoch   7, Step:    60200, Batch Loss:     1.658031, Batch Acc: 0.544946, Tokens per Sec:     7974, Lr: 0.000300
2025-05-29 21:06:49,276 - INFO - joeynmt.training - Epoch   7, Step:    60300, Batch Loss:     1.612158, Batch Acc: 0.547674, Tokens per Sec:     7379, Lr: 0.000300
2025-05-29 21:06:58,191 - INFO - joeynmt.training - Epoch   7, Step:    60400, Batch Loss:     1.350379, Batch Acc: 0.545543, Tokens per Sec:     7992, Lr: 0.000300
2025-05-29 21:07:06,229 - INFO - joeynmt.training - Epoch   7, Step:    60500, Batch Loss:     1.526443, Batch Acc: 0.542957, Tokens per Sec:     8888, Lr: 0.000300
2025-05-29 21:07:06,229 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:07:06,230 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:07:35,155 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.29, acc:   0.51, generation: 28.8926[sec], evaluation: 0.0000[sec]
2025-05-29 21:07:35,156 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:07:35,346 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/58500.ckpt
2025-05-29 21:07:35,362 - INFO - joeynmt.training - Example #0
2025-05-29 21:07:35,363 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:07:35,363 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:07:35,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'kijken', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'on@@', 'd@@', 'sto@@', 'ffen', 'van', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd.', '</s>']
2025-05-29 21:07:35,364 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:07:35,364 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:07:35,364 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te verkijken om te verkijken dat de artische ijskappe ijskappen, die drie miljoen jaar de grootte van de grondstoffen van 40 procent gegooid.
2025-05-29 21:07:35,364 - INFO - joeynmt.training - Example #1
2025-05-29 21:07:35,365 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:07:35,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:07:35,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'aar@@', 'de', 'is', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'to@@', 'on@@', 't', 'uit', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'oe@@', 'k@@', 'je', 'van', 'de', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'het', 'ij@@', 's', 'is', 'ge@@', 'zien.', '</s>']
2025-05-29 21:07:35,366 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:07:35,366 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:07:35,366 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de aarde is van dit speciale probleem van dit speciale probleem toont uit de dikke ijskoekje van de ijskaart van het ijs is gezien.
2025-05-29 21:07:35,366 - INFO - joeynmt.training - Example #2
2025-05-29 21:07:35,367 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:07:35,367 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:07:35,367 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:07:35,368 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:07:35,368 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:07:35,368 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-29 21:07:35,368 - INFO - joeynmt.training - Example #3
2025-05-29 21:07:35,368 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:07:35,369 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:07:35,369 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'en', 's@@', 'om@@', 'er@@', 'aar@@', 's', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 21:07:35,369 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:07:35,370 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:07:35,370 - INFO - joeynmt.training - 	Hypothesis: Ze groeide en someraars en sluit in de zomer.
2025-05-29 21:07:35,370 - INFO - joeynmt.training - Example #4
2025-05-29 21:07:35,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:07:35,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:07:35,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:07:35,371 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:07:35,371 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:07:35,372 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschrift van wat er in de laatste 25 jaar gebeurd.
2025-05-29 21:07:44,663 - INFO - joeynmt.training - Epoch   7, Step:    60600, Batch Loss:     1.554020, Batch Acc: 0.545299, Tokens per Sec:     7276, Lr: 0.000300
2025-05-29 21:07:53,931 - INFO - joeynmt.training - Epoch   7, Step:    60700, Batch Loss:     1.456872, Batch Acc: 0.550619, Tokens per Sec:     7631, Lr: 0.000300
2025-05-29 21:08:03,526 - INFO - joeynmt.training - Epoch   7, Step:    60800, Batch Loss:     1.487772, Batch Acc: 0.546055, Tokens per Sec:     7470, Lr: 0.000300
2025-05-29 21:08:13,428 - INFO - joeynmt.training - Epoch   7, Step:    60900, Batch Loss:     1.503908, Batch Acc: 0.545830, Tokens per Sec:     7047, Lr: 0.000300
2025-05-29 21:08:22,566 - INFO - joeynmt.training - Epoch   7, Step:    61000, Batch Loss:     1.463728, Batch Acc: 0.549505, Tokens per Sec:     7578, Lr: 0.000300
2025-05-29 21:08:22,566 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:08:22,567 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:09:00,576 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.30, acc:   0.51, generation: 37.9733[sec], evaluation: 0.0000[sec]
2025-05-29 21:09:00,756 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/60000.ckpt
2025-05-29 21:09:00,770 - INFO - joeynmt.training - Example #0
2025-05-29 21:09:00,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:09:00,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:09:00,772 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'om', 'te', 'kijken', 'naar', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 'z@@', 'er', 'te', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 'z@@', 'er', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'ï@@', 'n@@', 'ter@@', 'ess@@', 'eerd', 'is.', '</s>']
2025-05-29 21:09:00,772 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:09:00,772 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:09:00,774 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te kijken naar de artische ijzer te kijken dat de artische ijzer drie miljoen jaar de grootte van de grens van de onderste 40 procent van de onderste 40 procent geïnteresseerd is.
2025-05-29 21:09:00,774 - INFO - joeynmt.training - Example #1
2025-05-29 21:09:00,774 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:09:00,774 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:09:00,774 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'ver@@', 'sla@@', 'v@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 'z@@', 'er', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.', '</s>']
2025-05-29 21:09:00,775 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:09:00,775 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:09:00,775 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste verslaving van dit speciale probleem, omdat het niet de dikke ijzer van het ijs laat zien.
2025-05-29 21:09:00,776 - INFO - joeynmt.training - Example #2
2025-05-29 21:09:00,776 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:09:00,776 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:09:00,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 'z@@', 'er', 'het', 'har@@', 't', 'van', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:09:00,777 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:09:00,777 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:09:00,777 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijzer het hart van de klimaatsysteem.
2025-05-29 21:09:00,778 - INFO - joeynmt.training - Example #3
2025-05-29 21:09:00,778 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:09:00,778 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:09:00,778 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'l@@', 'ig@@', 't', 'in', 'de', 'win@@', 'ter', 'en', 'l@@', 'ig@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:09:00,779 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:09:00,779 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:09:00,779 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en ligt in de winter en ligt in de zomers.
2025-05-29 21:09:00,779 - INFO - joeynmt.training - Example #4
2025-05-29 21:09:00,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:09:00,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:09:00,780 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'ti@@', 'me@@', '-@@', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:09:00,781 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:09:00,781 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:09:00,781 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een time-opname wat er gebeurt in de laatste 25 jaar is gebeurd.
2025-05-29 21:09:10,156 - INFO - joeynmt.training - Epoch   7, Step:    61100, Batch Loss:     1.588284, Batch Acc: 0.548212, Tokens per Sec:     7115, Lr: 0.000300
2025-05-29 21:09:19,343 - INFO - joeynmt.training - Epoch   7, Step:    61200, Batch Loss:     1.546535, Batch Acc: 0.545898, Tokens per Sec:     7568, Lr: 0.000300
2025-05-29 21:09:28,317 - INFO - joeynmt.training - Epoch   7, Step:    61300, Batch Loss:     1.692336, Batch Acc: 0.541787, Tokens per Sec:     7692, Lr: 0.000300
2025-05-29 21:09:37,345 - INFO - joeynmt.training - Epoch   7, Step:    61400, Batch Loss:     1.551671, Batch Acc: 0.548641, Tokens per Sec:     7747, Lr: 0.000300
2025-05-29 21:09:46,296 - INFO - joeynmt.training - Epoch   7, Step:    61500, Batch Loss:     1.444327, Batch Acc: 0.547899, Tokens per Sec:     7844, Lr: 0.000300
2025-05-29 21:09:46,296 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:09:46,297 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:10:25,426 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.29, acc:   0.51, generation: 39.0973[sec], evaluation: 0.0000[sec]
2025-05-29 21:10:25,427 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:10:25,600 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/59500.ckpt
2025-05-29 21:10:25,615 - INFO - joeynmt.training - Example #0
2025-05-29 21:10:25,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:10:25,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:10:25,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'kijken', 'naar', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'ens', 'van', 'de', 'gr@@', 'ens', 'van', 'de', '4@@', '8', 'st@@', 'aten', 'van', 'de', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 21:10:25,617 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:10:25,617 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:10:25,618 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verkijken naar de arctische ijskaart die drie miljoen jaar de grootte van de grens van de grens van de 48 staten van de 40 procent geslaagd is.
2025-05-29 21:10:25,618 - INFO - joeynmt.training - Example #1
2025-05-29 21:10:25,618 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:10:25,618 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:10:25,618 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'is', 'dat', 'de', 'eerste', 'ge@@', 'spe@@', 'ci@@', 'alis@@', 'eerd', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'ap@@', '.', '</s>']
2025-05-29 21:10:25,619 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:10:25,619 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:10:25,620 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste is dat de eerste gespecialiseerd is dat het niet de dikke ijskap.
2025-05-29 21:10:25,620 - INFO - joeynmt.training - Example #2
2025-05-29 21:10:25,620 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:10:25,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:10:25,620 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', ',', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'on@@', 's@@', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:10:25,621 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:10:25,622 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:10:25,622 - INFO - joeynmt.training - 	Hypothesis: In zekere zin, is de artische ijskappe is het onshart van onze wereldklimaatsysteem.
2025-05-29 21:10:25,622 - INFO - joeynmt.training - Example #3
2025-05-29 21:10:25,622 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:10:25,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:10:25,622 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'tro@@', 'uw@@', 'en', 'en', 'ze', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-29 21:10:25,623 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:10:25,623 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:10:25,624 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en vertrouwen en ze verzamelen.
2025-05-29 21:10:25,624 - INFO - joeynmt.training - Example #4
2025-05-29 21:10:25,624 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:10:25,624 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:10:25,624 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en,', 'is', 'een', 'ti@@', 'me@@', '-@@', 'tra@@', 'ff@@', 'er@@', 'ing', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:10:25,626 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:10:25,626 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:10:25,626 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen, is een time-traffering van wat er gebeurt in de laatste 25 jaar is gebeurd.
2025-05-29 21:10:34,274 - INFO - joeynmt.training - Epoch   7, Step:    61600, Batch Loss:     1.470068, Batch Acc: 0.545404, Tokens per Sec:     7974, Lr: 0.000300
2025-05-29 21:10:42,539 - INFO - joeynmt.training - Epoch   7, Step:    61700, Batch Loss:     1.496117, Batch Acc: 0.547313, Tokens per Sec:     8836, Lr: 0.000300
2025-05-29 21:10:50,893 - INFO - joeynmt.training - Epoch   7, Step:    61800, Batch Loss:     1.579333, Batch Acc: 0.544638, Tokens per Sec:     8462, Lr: 0.000300
2025-05-29 21:11:00,151 - INFO - joeynmt.training - Epoch   7, Step:    61900, Batch Loss:     1.265225, Batch Acc: 0.544522, Tokens per Sec:     7445, Lr: 0.000300
2025-05-29 21:11:09,876 - INFO - joeynmt.training - Epoch   7, Step:    62000, Batch Loss:     1.609700, Batch Acc: 0.542693, Tokens per Sec:     7253, Lr: 0.000300
2025-05-29 21:11:09,876 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:11:09,877 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:11:54,133 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.27, acc:   0.51, generation: 44.2172[sec], evaluation: 0.0000[sec]
2025-05-29 21:11:54,135 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:11:54,320 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/55000.ckpt
2025-05-29 21:11:54,336 - INFO - joeynmt.training - Example #0
2025-05-29 21:11:54,336 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:11:54,336 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:11:54,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'laten', 'zien', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'die', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', '4@@', '8', 'st@@', 'aten', 'van', 'de', '4@@', '0', 'proc@@', 'ent', 'ver@@', 'ge@@', 'k@@', 'n@@', 'op@@', 'en.', '</s>']
2025-05-29 21:11:54,338 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:11:54,338 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:11:54,338 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's laten zien om te verkijken dat de artische ijskaart die de artische ijskaart die de onderste 48 staten van de 48 staten van de 40 procent vergeknopen.
2025-05-29 21:11:54,338 - INFO - joeynmt.training - Example #1
2025-05-29 21:11:54,339 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:11:54,339 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:11:54,339 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'dru@@', 'kt', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'ap@@', 'el@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'het', 'ij@@', 's', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ies', 'van', 'het', 'ij@@', 's', 'te', 'zien.', '</s>']
2025-05-29 21:11:54,340 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:11:54,340 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:11:54,340 - INFO - joeynmt.training - 	Hypothesis: Maar dat drukt niet sterk genoeg de eerste stapelheid van dit speciale probleem van het ijs is niet de dikke ijskwesties van het ijs te zien.
2025-05-29 21:11:54,340 - INFO - joeynmt.training - Example #2
2025-05-29 21:11:54,340 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:11:54,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:11:54,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'im@@', 'me', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:11:54,342 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:11:54,342 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:11:54,342 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het slimme hart van ons wereldwijde klimaatsysteem.
2025-05-29 21:11:54,342 - INFO - joeynmt.training - Example #3
2025-05-29 21:11:54,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:11:54,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:11:54,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'on@@', '.', '</s>']
2025-05-29 21:11:54,344 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:11:54,344 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:11:54,344 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schoon.
2025-05-29 21:11:54,344 - INFO - joeynmt.training - Example #4
2025-05-29 21:11:54,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:11:54,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:11:54,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 21:11:54,346 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:11:54,346 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:11:54,346 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift van de afgelopen 25 jaar is gebeurd in de afgelopen 25 jaar is.
2025-05-29 21:12:03,909 - INFO - joeynmt.training - Epoch   7, Step:    62100, Batch Loss:     1.385845, Batch Acc: 0.542938, Tokens per Sec:     7020, Lr: 0.000300
2025-05-29 21:12:13,139 - INFO - joeynmt.training - Epoch   7, Step:    62200, Batch Loss:     1.526269, Batch Acc: 0.544889, Tokens per Sec:     7663, Lr: 0.000300
2025-05-29 21:12:22,114 - INFO - joeynmt.training - Epoch   7, Step:    62300, Batch Loss:     1.522860, Batch Acc: 0.542420, Tokens per Sec:     7879, Lr: 0.000300
2025-05-29 21:12:31,114 - INFO - joeynmt.training - Epoch   7, Step:    62400, Batch Loss:     1.322309, Batch Acc: 0.547152, Tokens per Sec:     7818, Lr: 0.000300
2025-05-29 21:12:40,454 - INFO - joeynmt.training - Epoch   7, Step:    62500, Batch Loss:     1.465865, Batch Acc: 0.547451, Tokens per Sec:     7593, Lr: 0.000300
2025-05-29 21:12:40,454 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:12:40,455 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:13:15,036 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.26, acc:   0.51, generation: 34.5441[sec], evaluation: 0.0000[sec]
2025-05-29 21:13:15,037 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:13:15,237 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/56500.ckpt
2025-05-29 21:13:15,253 - INFO - joeynmt.training - Example #0
2025-05-29 21:13:15,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:13:15,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:13:15,254 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'ag@@', 'en.', '</s>']
2025-05-29 21:13:15,255 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:13:15,255 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:13:15,255 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkijken om te verkijken dat de arctische ijskappen, die voor de artische ijskappen, die de 48 staten had geslagen.
2025-05-29 21:13:15,255 - INFO - joeynmt.training - Example #1
2025-05-29 21:13:15,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:13:15,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:13:15,256 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'ver@@', 'gelijk@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'ik@@', 'ker@@', 's', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ap@@', '.', '</s>']
2025-05-29 21:13:15,257 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:13:15,258 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:13:15,258 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste vergelijking van dit speciale probleem van dit ijskaart omdat het niet de dikke ijskikkers van het ijskap.
2025-05-29 21:13:15,258 - INFO - joeynmt.training - Example #2
2025-05-29 21:13:15,258 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:13:15,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:13:15,258 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:13:15,259 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:13:15,259 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:13:15,259 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe hart van ons wereldklimaatsysteem.
2025-05-29 21:13:15,260 - INFO - joeynmt.training - Example #3
2025-05-29 21:13:15,260 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:13:15,260 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:13:15,260 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:13:15,261 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:13:15,261 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:13:15,261 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en sluit in de zomers.
2025-05-29 21:13:15,261 - INFO - joeynmt.training - Example #4
2025-05-29 21:13:15,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:13:15,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:13:15,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:13:15,263 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:13:15,263 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:13:15,263 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschrift van wat er gebeurt in de laatste 25 jaar gebeurd.
2025-05-29 21:13:24,817 - INFO - joeynmt.training - Epoch   7, Step:    62600, Batch Loss:     1.585692, Batch Acc: 0.550004, Tokens per Sec:     7017, Lr: 0.000300
2025-05-29 21:13:34,112 - INFO - joeynmt.training - Epoch   7, Step:    62700, Batch Loss:     1.402605, Batch Acc: 0.544733, Tokens per Sec:     7500, Lr: 0.000300
2025-05-29 21:13:43,606 - INFO - joeynmt.training - Epoch   7, Step:    62800, Batch Loss:     1.502052, Batch Acc: 0.545843, Tokens per Sec:     7313, Lr: 0.000300
2025-05-29 21:13:51,928 - INFO - joeynmt.training - Epoch   7, Step:    62900, Batch Loss:     1.480606, Batch Acc: 0.545985, Tokens per Sec:     8568, Lr: 0.000300
2025-05-29 21:14:00,409 - INFO - joeynmt.training - Epoch   7, Step:    63000, Batch Loss:     1.448825, Batch Acc: 0.545109, Tokens per Sec:     8478, Lr: 0.000300
2025-05-29 21:14:00,410 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:14:00,411 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:14:33,961 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.51, generation: 33.5133[sec], evaluation: 0.0000[sec]
2025-05-29 21:14:33,962 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:14:34,159 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/61000.ckpt
2025-05-29 21:14:34,175 - INFO - joeynmt.training - Example #0
2025-05-29 21:14:34,176 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:14:34,177 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:14:34,177 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'de', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'A@@', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'had', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd', 'om', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'aa@@', 'g@@', 'd', 'te', 'zijn.', '</s>']
2025-05-29 21:14:34,177 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:14:34,178 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:14:34,178 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoonde om te bekijken dat de artische ijskappen, die de grootte van de Aarctische ijskappels had gegooid om 40 procent gegaagd te zijn.
2025-05-29 21:14:34,178 - INFO - joeynmt.training - Example #1
2025-05-29 21:14:34,178 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:14:34,178 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:14:34,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'du@@', 'i@@', 'delijk', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'ap@@', 'el@@', 'heid', 'van', 'dit', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'be@@', 'e@@', 'st@@', 'en.', '</s>']
2025-05-29 21:14:34,179 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:14:34,180 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:14:34,180 - INFO - joeynmt.training - 	Hypothesis: Maar dit duidelijk niet sterk genoeg de eerste stapelheid van dit ijskaart omdat het niet de dikke beesten.
2025-05-29 21:14:34,180 - INFO - joeynmt.training - Example #2
2025-05-29 21:14:34,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:14:34,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:14:34,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'at@@', 'uur', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:14:34,181 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:14:34,182 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:14:34,182 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapparatuur van ons wereldwijde klimaatsysteem.
2025-05-29 21:14:34,182 - INFO - joeynmt.training - Example #3
2025-05-29 21:14:34,182 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:14:34,182 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:14:34,182 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'rij@@', 'v@@', 'en.', '</s>']
2025-05-29 21:14:34,183 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:14:34,183 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:14:34,184 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schrijven.
2025-05-29 21:14:34,184 - INFO - joeynmt.training - Example #4
2025-05-29 21:14:34,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:14:34,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:14:34,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'is', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:14:34,185 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:14:34,185 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:14:34,185 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschrift is in de laatste 25 jaar is gebeurd.
2025-05-29 21:14:43,394 - INFO - joeynmt.training - Epoch   7, Step:    63100, Batch Loss:     1.596281, Batch Acc: 0.541880, Tokens per Sec:     7446, Lr: 0.000300
2025-05-29 21:14:52,732 - INFO - joeynmt.training - Epoch   7, Step:    63200, Batch Loss:     1.457978, Batch Acc: 0.539777, Tokens per Sec:     7553, Lr: 0.000300
2025-05-29 21:15:01,560 - INFO - joeynmt.training - Epoch   7, Step:    63300, Batch Loss:     1.600977, Batch Acc: 0.546145, Tokens per Sec:     7894, Lr: 0.000300
2025-05-29 21:15:10,650 - INFO - joeynmt.training - Epoch   7, Step:    63400, Batch Loss:     1.492393, Batch Acc: 0.544720, Tokens per Sec:     7723, Lr: 0.000300
2025-05-29 21:15:19,615 - INFO - joeynmt.training - Epoch   7, Step:    63500, Batch Loss:     1.427395, Batch Acc: 0.546524, Tokens per Sec:     8067, Lr: 0.000300
2025-05-29 21:15:19,615 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:15:19,615 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:15:55,841 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.24, acc:   0.52, generation: 36.1857[sec], evaluation: 0.0000[sec]
2025-05-29 21:15:55,842 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:15:56,036 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/60500.ckpt
2025-05-29 21:15:56,054 - INFO - joeynmt.training - Example #0
2025-05-29 21:15:56,055 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:15:56,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:15:56,055 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'naar', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'ond', 'de', 'gr@@', 'ond', 'van', 'de', '4@@', '0', 'proc@@', 'ent', 'gesch@@', 're@@', 'v@@', 'en.', '</s>']
2025-05-29 21:15:56,056 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:15:56,057 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:15:56,057 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verkijken naar de artische ijskappen, dat de artische ijskappen, die de grootte van de grond de grond van de 40 procent geschreven.
2025-05-29 21:15:56,057 - INFO - joeynmt.training - Example #1
2025-05-29 21:15:56,057 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:15:56,057 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:15:56,057 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'du@@', 'w@@', 't', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 'z@@', 'er', 'is', 'uit@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 'z@@', 'er', 'niet', 'uit@@', '.', '</s>']
2025-05-29 21:15:56,058 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:15:56,058 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:15:56,058 - INFO - joeynmt.training - 	Hypothesis: Maar dat duwt niet sterk genoeg de eerste staat, omdat het niet de dikke ijzer is uit, omdat het niet de dikke ijzer van de ijzer van de ijzer van de ijzer niet uit.
2025-05-29 21:15:56,058 - INFO - joeynmt.training - Example #2
2025-05-29 21:15:56,058 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:15:56,058 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:15:56,058 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:15:56,059 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:15:56,059 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:15:56,059 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het slaagsysteem van ons wereldwijde klimaatsysteem.
2025-05-29 21:15:56,059 - INFO - joeynmt.training - Example #3
2025-05-29 21:15:56,059 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:15:56,059 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:15:56,059 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'rij@@', 'ver@@', 's', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:15:56,060 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:15:56,060 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:15:56,060 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schrijvers in de zomers.
2025-05-29 21:15:56,060 - INFO - joeynmt.training - Example #4
2025-05-29 21:15:56,061 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:15:56,061 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:15:56,061 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'is', 'een', 'tij@@', 'd@@', 'je', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'is', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:15:56,062 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:15:56,063 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:15:56,063 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat is een tijdje is een tijdschrift is in de laatste 25 jaar gebeurd.
2025-05-29 21:16:05,677 - INFO - joeynmt.training - Epoch   7, Step:    63600, Batch Loss:     1.642109, Batch Acc: 0.543003, Tokens per Sec:     7155, Lr: 0.000300
2025-05-29 21:16:15,032 - INFO - joeynmt.training - Epoch   7, Step:    63700, Batch Loss:     1.625549, Batch Acc: 0.546397, Tokens per Sec:     7578, Lr: 0.000300
2025-05-29 21:16:24,503 - INFO - joeynmt.training - Epoch   7, Step:    63800, Batch Loss:     1.455920, Batch Acc: 0.544118, Tokens per Sec:     7444, Lr: 0.000300
2025-05-29 21:16:33,809 - INFO - joeynmt.training - Epoch   7, Step:    63900, Batch Loss:     1.577720, Batch Acc: 0.540884, Tokens per Sec:     7320, Lr: 0.000300
2025-05-29 21:16:43,426 - INFO - joeynmt.training - Epoch   7, Step:    64000, Batch Loss:     1.930085, Batch Acc: 0.540966, Tokens per Sec:     7193, Lr: 0.000300
2025-05-29 21:16:43,427 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:16:43,428 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:17:19,039 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.52, generation: 35.5734[sec], evaluation: 0.0000[sec]
2025-05-29 21:17:19,214 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/61500.ckpt
2025-05-29 21:17:19,228 - INFO - joeynmt.training - Example #0
2025-05-29 21:17:19,229 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:17:19,230 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:17:19,230 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'g', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ct@@', 'a@@', 're@@', 's', 'die', 'de', 'ar@@', 'ct@@', 'a@@', 're@@', 's', 'die', 'de', 'groot@@', 'te', 'van', 'de', '4@@', '8', 'st@@', 'aten', 'van', 'de', '4@@', '8', 'st@@', 'aten', 'van', 'de', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'gr@@', 'en@@', 'zen', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'gr@@', 'en@@', 'zen', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'kan@@', 's', 'om', 'te', 're@@', 'ken@@', 'en', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-29 21:17:19,231 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:17:19,231 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:17:19,231 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolg getoond om te verbeteren dat de arctares die de arctares die de grootte van de 48 staten van de 48 staten van de 40 procent van de onderste 40 procent van de grenzen 40 procent van de grenzen 40 procent van de onderkans om te rekenen te verzamelen.
2025-05-29 21:17:19,232 - INFO - joeynmt.training - Example #1
2025-05-29 21:17:19,232 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:17:19,232 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:17:19,232 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 's.', '</s>']
2025-05-29 21:17:19,233 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:17:19,233 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:17:19,234 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste staat, omdat het niet de dikke van het ijs van de ijzer van de ijs van de ijzer van de ijs van de ijzer van de ijs van de ijzer van de ijs.
2025-05-29 21:17:19,234 - INFO - joeynmt.training - Example #2
2025-05-29 21:17:19,234 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:17:19,234 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:17:19,234 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ct@@', 'a@@', 're@@', 's', 'het', 'sl@@', 'aa@@', 'g@@', 'd', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:17:19,235 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:17:19,236 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:17:19,236 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctares het slaagd van onze wereldwijde klimaatsysteem.
2025-05-29 21:17:19,236 - INFO - joeynmt.training - Example #3
2025-05-29 21:17:19,236 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:17:19,236 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:17:19,236 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'rij@@', 'v@@', 'en.', '</s>']
2025-05-29 21:17:19,237 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:17:19,237 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:17:19,237 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schrijven.
2025-05-29 21:17:19,237 - INFO - joeynmt.training - Example #4
2025-05-29 21:17:19,237 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:17:19,237 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:17:19,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'gebeur@@', 'd', 'is', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:17:19,238 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:17:19,238 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:17:19,238 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschriften wat er gebeurd is in de laatste 25 jaar gebeurd.
2025-05-29 21:17:27,620 - INFO - joeynmt.training - Epoch   7, Step:    64100, Batch Loss:     1.439296, Batch Acc: 0.548324, Tokens per Sec:     8246, Lr: 0.000300
2025-05-29 21:17:36,168 - INFO - joeynmt.training - Epoch   7, Step:    64200, Batch Loss:     1.960587, Batch Acc: 0.545179, Tokens per Sec:     8329, Lr: 0.000300
2025-05-29 21:17:45,151 - INFO - joeynmt.training - Epoch   7, Step:    64300, Batch Loss:     1.595086, Batch Acc: 0.542862, Tokens per Sec:     7787, Lr: 0.000300
2025-05-29 21:17:54,021 - INFO - joeynmt.training - Epoch   7, Step:    64400, Batch Loss:     1.400239, Batch Acc: 0.550067, Tokens per Sec:     7846, Lr: 0.000300
2025-05-29 21:18:02,980 - INFO - joeynmt.training - Epoch   7, Step:    64500, Batch Loss:     1.403145, Batch Acc: 0.545236, Tokens per Sec:     7726, Lr: 0.000300
2025-05-29 21:18:02,980 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:18:02,980 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:18:39,436 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.27, acc:   0.52, generation: 36.4153[sec], evaluation: 0.0000[sec]
2025-05-29 21:18:39,612 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/62000.ckpt
2025-05-29 21:18:39,627 - INFO - joeynmt.training - Example #0
2025-05-29 21:18:39,627 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:18:39,628 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:18:39,628 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'g', 'ge@@', 'vol@@', 'g', 'om', 'te', 're@@', 'alis@@', 'eren', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'was', 'voor', 'de', 'onder@@', 'ste', '4@@', '8@@', ',', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 21:18:39,629 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:18:39,629 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:18:39,629 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolg gevolg om te realiseren dat de artische ijskaart die drie miljoen jaar de grootte van de onderste 48 staten was voor de onderste 48, 40 procent geslaagd is.
2025-05-29 21:18:39,629 - INFO - joeynmt.training - Example #1
2025-05-29 21:18:39,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:18:39,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:18:39,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'ij@@', 's@@', 'k@@', 'aar@@', 'heid', 'van', 'dit', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'ap@@', '.', '</s>']
2025-05-29 21:18:39,631 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:18:39,632 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:18:39,632 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerst van dit ijskaarheid van dit ijskaart omdat het niet de dikke ijskap.
2025-05-29 21:18:39,632 - INFO - joeynmt.training - Example #2
2025-05-29 21:18:39,632 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:18:39,632 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:18:39,632 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'onze', 'mon@@', 'di@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:18:39,633 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:18:39,633 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:18:39,633 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart van onze mondiale klimaatsysteem.
2025-05-29 21:18:39,633 - INFO - joeynmt.training - Example #3
2025-05-29 21:18:39,633 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:18:39,633 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:18:39,633 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'z@@', 'am@@', 'el@@', 'ing', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:18:39,634 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:18:39,634 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:18:39,634 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en verzameling in de zomers.
2025-05-29 21:18:39,635 - INFO - joeynmt.training - Example #4
2025-05-29 21:18:39,635 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:18:39,635 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:18:39,635 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'ge@@', 'vol@@', 'g', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'de.', '</s>']
2025-05-29 21:18:39,635 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:18:39,635 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:18:39,635 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik jullie laten zien, is een tijdschriften wat er gebeurt in de afgelopen 25 jaar gebeurde.
2025-05-29 21:18:49,005 - INFO - joeynmt.training - Epoch   7, Step:    64600, Batch Loss:     1.647012, Batch Acc: 0.542360, Tokens per Sec:     7414, Lr: 0.000300
2025-05-29 21:18:50,500 - INFO - joeynmt.training - Epoch   7: total training loss 14108.35
2025-05-29 21:18:50,500 - INFO - joeynmt.training - EPOCH 8
2025-05-29 21:18:58,321 - INFO - joeynmt.training - Epoch   8, Step:    64700, Batch Loss:     1.594991, Batch Acc: 0.560896, Tokens per Sec:     7684, Lr: 0.000300
2025-05-29 21:19:07,685 - INFO - joeynmt.training - Epoch   8, Step:    64800, Batch Loss:     1.479015, Batch Acc: 0.554184, Tokens per Sec:     7517, Lr: 0.000300
2025-05-29 21:19:17,735 - INFO - joeynmt.training - Epoch   8, Step:    64900, Batch Loss:     1.567794, Batch Acc: 0.559899, Tokens per Sec:     7071, Lr: 0.000300
2025-05-29 21:19:27,189 - INFO - joeynmt.training - Epoch   8, Step:    65000, Batch Loss:     1.462071, Batch Acc: 0.556599, Tokens per Sec:     7368, Lr: 0.000300
2025-05-29 21:19:27,189 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:19:27,196 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:20:15,794 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.28, acc:   0.51, generation: 48.5458[sec], evaluation: 0.0000[sec]
2025-05-29 21:20:15,802 - INFO - joeynmt.training - Example #0
2025-05-29 21:20:15,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:20:15,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:20:15,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'kijken', 'naar', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'om', 'te', 'ver@@', 'v@@', 'el@@', 'en.', '</s>']
2025-05-29 21:20:15,805 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:20:15,805 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:20:15,805 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee dia getoond om te verkijken naar de artische ijskappen, dat de artische ijskappen, die de grootte van de onderste 48 staten had om te vervelen.
2025-05-29 21:20:15,805 - INFO - joeynmt.training - Example #1
2025-05-29 21:20:15,805 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:20:15,806 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:20:15,806 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'ver@@', 'n@@', 'u@@', 'g', 'de', 'ver@@', 'n@@', 'u@@', 'ch@@', 'ter@@', 's', 'van', 'dit', 'ij@@', 's@@', 'k@@', 'ap', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ap@@', 'o@@', 't.', '</s>']
2025-05-29 21:20:15,807 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:20:15,807 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:20:15,807 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de vernug de vernuchters van dit ijskap is niet de dikke ijs van de ijskappen van de ijskapot.
2025-05-29 21:20:15,807 - INFO - joeynmt.training - Example #2
2025-05-29 21:20:15,807 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:20:15,808 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:20:15,808 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', ',', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'ste', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:20:15,810 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:20:15,810 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:20:15,810 - INFO - joeynmt.training - 	Hypothesis: In zekere zin, is de artische ijskappe is het slaagste klimaatsysteem.
2025-05-29 21:20:15,810 - INFO - joeynmt.training - Example #3
2025-05-29 21:20:15,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:20:15,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:20:15,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'er@@', 'p@@', 'e', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 21:20:15,812 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:20:15,812 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:20:15,812 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scherpe zomer.
2025-05-29 21:20:15,812 - INFO - joeynmt.training - Example #4
2025-05-29 21:20:15,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:20:15,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:20:15,813 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 21:20:15,814 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:20:15,814 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:20:15,814 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen, is een tijdschriften opname wat er gebeurde in de laatste 25 jaar.
2025-05-29 21:20:25,228 - INFO - joeynmt.training - Epoch   8, Step:    65100, Batch Loss:     1.625344, Batch Acc: 0.556844, Tokens per Sec:     7221, Lr: 0.000300
2025-05-29 21:20:34,288 - INFO - joeynmt.training - Epoch   8, Step:    65200, Batch Loss:     1.592011, Batch Acc: 0.558073, Tokens per Sec:     7464, Lr: 0.000300
2025-05-29 21:20:42,681 - INFO - joeynmt.training - Epoch   8, Step:    65300, Batch Loss:     1.472797, Batch Acc: 0.560505, Tokens per Sec:     8377, Lr: 0.000300
2025-05-29 21:20:51,639 - INFO - joeynmt.training - Epoch   8, Step:    65400, Batch Loss:     1.384982, Batch Acc: 0.555994, Tokens per Sec:     7777, Lr: 0.000300
2025-05-29 21:21:01,409 - INFO - joeynmt.training - Epoch   8, Step:    65500, Batch Loss:     1.604781, Batch Acc: 0.558313, Tokens per Sec:     7155, Lr: 0.000300
2025-05-29 21:21:01,412 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:21:01,412 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:21:53,108 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.28, acc:   0.52, generation: 51.6468[sec], evaluation: 0.0000[sec]
2025-05-29 21:21:53,116 - INFO - joeynmt.training - Example #0
2025-05-29 21:21:53,117 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:21:53,117 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:21:53,118 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'naar', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'hebben', 'ge@@', 'sl@@', 'ach@@', 't.', '</s>']
2025-05-29 21:21:53,118 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:21:53,119 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:21:53,119 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkijken naar de artische ijskappen die de artische ijskappen, die de grens van de onderste 48 staten van de onderste 48 staten om 40 procent te hebben geslacht.
2025-05-29 21:21:53,119 - INFO - joeynmt.training - Example #1
2025-05-29 21:21:53,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:21:53,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:21:53,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'icht@@', 'heid', 'van', 'dit', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ker@@', 'n', 'van', 'het', 'ij@@', 's@@', 'je@@', '.', '</s>']
2025-05-29 21:21:53,120 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:21:53,121 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:21:53,121 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste stichtheid van dit ijskaart omdat het niet de dikkern van het ijsje.
2025-05-29 21:21:53,121 - INFO - joeynmt.training - Example #2
2025-05-29 21:21:53,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:21:53,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:21:53,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'sl@@', 'ag@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:21:53,122 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:21:53,122 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:21:53,123 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het slagsysteem.
2025-05-29 21:21:53,123 - INFO - joeynmt.training - Example #3
2025-05-29 21:21:53,123 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:21:53,123 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:21:53,123 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'ver@@', 'v@@', 'u@@', 'il@@', 'd', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 21:21:53,124 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:21:53,124 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:21:53,124 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en svervuild in de zomer.
2025-05-29 21:21:53,125 - INFO - joeynmt.training - Example #4
2025-05-29 21:21:53,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:21:53,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:21:53,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 21:21:53,126 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:21:53,126 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:21:53,126 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen, is een tijdschriften wat er gebeurt in de afgelopen 25 jaar.
2025-05-29 21:22:03,178 - INFO - joeynmt.training - Epoch   8, Step:    65600, Batch Loss:     1.422372, Batch Acc: 0.557692, Tokens per Sec:     6812, Lr: 0.000300
2025-05-29 21:22:12,632 - INFO - joeynmt.training - Epoch   8, Step:    65700, Batch Loss:     1.433720, Batch Acc: 0.554003, Tokens per Sec:     7222, Lr: 0.000300
2025-05-29 21:22:22,236 - INFO - joeynmt.training - Epoch   8, Step:    65800, Batch Loss:     1.097693, Batch Acc: 0.556847, Tokens per Sec:     7240, Lr: 0.000300
2025-05-29 21:22:31,879 - INFO - joeynmt.training - Epoch   8, Step:    65900, Batch Loss:     1.427105, Batch Acc: 0.558012, Tokens per Sec:     7121, Lr: 0.000300
2025-05-29 21:22:41,099 - INFO - joeynmt.training - Epoch   8, Step:    66000, Batch Loss:     1.470520, Batch Acc: 0.555543, Tokens per Sec:     7522, Lr: 0.000300
2025-05-29 21:22:41,100 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:22:41,100 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:23:20,386 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.28, acc:   0.51, generation: 39.2463[sec], evaluation: 0.0000[sec]
2025-05-29 21:23:20,397 - INFO - joeynmt.training - Example #0
2025-05-29 21:23:20,398 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:23:20,398 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:23:20,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 're@@', 'alis@@', 'eren', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'l@@', 'ag@@', 'ere', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aa@@', 't,', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'kl@@', 'ar@@', 'ing', 'te', 'ver@@', 'tel@@', 'en.', '</s>']
2025-05-29 21:23:20,400 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:23:20,400 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:23:20,400 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te realiseren dat de artische ijskaart die drie miljoen jaar de grootte van de lagere drie miljoen jaar de grootte van de onderste 48 staat, om 40 procent te verklaring te vertelen.
2025-05-29 21:23:20,400 - INFO - joeynmt.training - Example #1
2025-05-29 21:23:20,401 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:23:20,401 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:23:20,401 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'gaat', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'eil@@', 'e', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'is', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 21:23:20,402 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:23:20,402 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:23:20,402 - INFO - joeynmt.training - 	Hypothesis: Maar dit gaat niet sterk genoeg de eerste steile van dit speciale probleem is omdat het niet de dikke van het ijskaart toont.
2025-05-29 21:23:20,402 - INFO - joeynmt.training - Example #2
2025-05-29 21:23:20,403 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:23:20,403 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:23:20,403 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'men.', '</s>']
2025-05-29 21:23:20,403 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:23:20,403 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:23:20,405 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape ijskape ijskaart van onze wereldwijde klimaatsystemen.
2025-05-29 21:23:20,405 - INFO - joeynmt.training - Example #3
2025-05-29 21:23:20,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:23:20,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:23:20,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'k@@', 'ken@@', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 21:23:20,407 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:23:20,407 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:23:20,407 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schokkende zomer.
2025-05-29 21:23:20,407 - INFO - joeynmt.training - Example #4
2025-05-29 21:23:20,408 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:23:20,408 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:23:20,408 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'ge@@', 'vol@@', 'g@@', 'd', 'ge@@', 'eft', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 21:23:20,409 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:23:20,409 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:23:20,409 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolgd geeft een tijdschriften van wat er gebeurt in de laatste 25 jaar is.
2025-05-29 21:23:29,834 - INFO - joeynmt.training - Epoch   8, Step:    66100, Batch Loss:     1.595239, Batch Acc: 0.552536, Tokens per Sec:     7546, Lr: 0.000300
2025-05-29 21:23:38,528 - INFO - joeynmt.training - Epoch   8, Step:    66200, Batch Loss:     1.528494, Batch Acc: 0.554936, Tokens per Sec:     8065, Lr: 0.000300
2025-05-29 21:23:47,350 - INFO - joeynmt.training - Epoch   8, Step:    66300, Batch Loss:     1.597588, Batch Acc: 0.551461, Tokens per Sec:     8133, Lr: 0.000300
2025-05-29 21:23:55,821 - INFO - joeynmt.training - Epoch   8, Step:    66400, Batch Loss:     1.155179, Batch Acc: 0.557220, Tokens per Sec:     8235, Lr: 0.000300
2025-05-29 21:24:03,837 - INFO - joeynmt.training - Epoch   8, Step:    66500, Batch Loss:     1.544185, Batch Acc: 0.562734, Tokens per Sec:     8878, Lr: 0.000300
2025-05-29 21:24:03,838 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:24:03,838 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:24:33,874 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.27, acc:   0.51, generation: 29.9956[sec], evaluation: 0.0000[sec]
2025-05-29 21:24:33,885 - INFO - joeynmt.training - Example #0
2025-05-29 21:24:33,886 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:24:33,886 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:24:33,886 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 're@@', 'alis@@', 'eren', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ter@@', 'e', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gro@@', 'ter@@', 'e', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'kre@@', 'gen', 'van', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'ig@@', 'd', 'is.', '</s>']
2025-05-29 21:24:33,887 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:24:33,887 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:24:33,887 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te realiseren dat de artische ijskaart die drie miljoen jaar de grotere drie miljoen jaar de grotere van de onderste 48 staten had gekregen van 40 procent gegigd is.
2025-05-29 21:24:33,890 - INFO - joeynmt.training - Example #1
2025-05-29 21:24:33,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:24:33,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:24:33,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'ver@@', 'sn@@', 'el@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kken', 'van', 'het', 'ij@@', 'z@@', 'er', 'van', 'het', 'ij@@', 'z@@', 'er', 'van', 'het', 'ij@@', 'z@@', 'er', 'van', 'het', 'ij@@', 'z@@', 'er', 'van', 'het', 'ij@@', 'z@@', 'er@@', 't.', '</s>']
2025-05-29 21:24:33,891 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:24:33,891 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:24:33,891 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de versneling van dit specifieke probleem omdat het niet de dikken van het ijzer van het ijzer van het ijzer van het ijzer van het ijzert.
2025-05-29 21:24:33,892 - INFO - joeynmt.training - Example #2
2025-05-29 21:24:33,892 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:24:33,892 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:24:33,892 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:24:33,893 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:24:33,893 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:24:33,893 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart het hart van onze wereldwijde klimaatsysteem.
2025-05-29 21:24:33,893 - INFO - joeynmt.training - Example #3
2025-05-29 21:24:33,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:24:33,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:24:33,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'k@@', 'ken@@', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:24:33,896 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:24:33,896 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:24:33,896 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schokkende zomers.
2025-05-29 21:24:33,896 - INFO - joeynmt.training - Example #4
2025-05-29 21:24:33,897 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:24:33,897 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:24:33,897 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:24:33,898 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:24:33,898 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:24:33,898 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdje van de afgelopen 25 jaar gebeurd.
2025-05-29 21:24:42,641 - INFO - joeynmt.training - Epoch   8, Step:    66600, Batch Loss:     1.414633, Batch Acc: 0.556774, Tokens per Sec:     7959, Lr: 0.000300
2025-05-29 21:24:51,651 - INFO - joeynmt.training - Epoch   8, Step:    66700, Batch Loss:     1.381703, Batch Acc: 0.558721, Tokens per Sec:     7958, Lr: 0.000300
2025-05-29 21:25:00,522 - INFO - joeynmt.training - Epoch   8, Step:    66800, Batch Loss:     1.686351, Batch Acc: 0.555844, Tokens per Sec:     8120, Lr: 0.000300
2025-05-29 21:25:09,282 - INFO - joeynmt.training - Epoch   8, Step:    66900, Batch Loss:     1.411783, Batch Acc: 0.555529, Tokens per Sec:     8003, Lr: 0.000300
2025-05-29 21:25:18,150 - INFO - joeynmt.training - Epoch   8, Step:    67000, Batch Loss:     1.508066, Batch Acc: 0.552163, Tokens per Sec:     8076, Lr: 0.000300
2025-05-29 21:25:18,150 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:25:18,150 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:25:53,382 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.52, generation: 35.1963[sec], evaluation: 0.0000[sec]
2025-05-29 21:25:53,383 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:25:53,566 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/64500.ckpt
2025-05-29 21:25:53,584 - INFO - joeynmt.training - Example #0
2025-05-29 21:25:53,585 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:25:53,585 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:25:53,585 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'ens', 'van', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'had', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'oor@@', 'z@@', 'aa@@', 'kt', 'is.', '</s>']
2025-05-29 21:25:53,586 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:25:53,586 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:25:53,587 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkijken dat de artische ijskaart die drie miljoen jaar de grootte van de grens van de grens van de onderste 48 staten had gehad om 40 procent te veroorzaakt is.
2025-05-29 21:25:53,587 - INFO - joeynmt.training - Example #1
2025-05-29 21:25:53,587 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:25:53,587 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:25:53,587 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'eil@@', 'ijk@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'men', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 21:25:53,588 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:25:53,589 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:25:53,589 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste steilijkheid van dit specifieke problemen omdat het niet de dikke ijs toont.
2025-05-29 21:25:53,589 - INFO - joeynmt.training - Example #2
2025-05-29 21:25:53,589 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:25:53,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:25:53,590 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'op', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:25:53,590 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:25:53,591 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:25:53,591 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskop is het slaagsysteem van ons wereldwijde klimaatsysteem.
2025-05-29 21:25:53,591 - INFO - joeynmt.training - Example #3
2025-05-29 21:25:53,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:25:53,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:25:53,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'i@@', 'ten', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'i@@', 'ten', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'i@@', 'ten', 'in', 'de', 'win@@', 'ter', 'en', 'l@@', 'oo@@', 'p@@', 't.', '</s>']
2025-05-29 21:25:53,592 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:25:53,593 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:25:53,593 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluit in de winter en sluiten in de winter en sluiten in de winter en sluiten in de winter en loopt.
2025-05-29 21:25:53,593 - INFO - joeynmt.training - Example #4
2025-05-29 21:25:53,593 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:25:53,593 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:25:53,594 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 21:25:53,594 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:25:53,594 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:25:53,595 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift van wat er gebeurde in de laatste 25 jaar.
2025-05-29 21:26:02,345 - INFO - joeynmt.training - Epoch   8, Step:    67100, Batch Loss:     1.467024, Batch Acc: 0.557237, Tokens per Sec:     7890, Lr: 0.000300
2025-05-29 21:26:10,936 - INFO - joeynmt.training - Epoch   8, Step:    67200, Batch Loss:     1.486308, Batch Acc: 0.553416, Tokens per Sec:     8137, Lr: 0.000300
2025-05-29 21:26:19,711 - INFO - joeynmt.training - Epoch   8, Step:    67300, Batch Loss:     1.508887, Batch Acc: 0.550744, Tokens per Sec:     7953, Lr: 0.000300
2025-05-29 21:26:28,342 - INFO - joeynmt.training - Epoch   8, Step:    67400, Batch Loss:     1.394078, Batch Acc: 0.554249, Tokens per Sec:     8063, Lr: 0.000300
2025-05-29 21:26:37,150 - INFO - joeynmt.training - Epoch   8, Step:    67500, Batch Loss:     1.534592, Batch Acc: 0.551077, Tokens per Sec:     8325, Lr: 0.000300
2025-05-29 21:26:37,151 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:26:37,151 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:27:12,115 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.26, acc:   0.51, generation: 34.9269[sec], evaluation: 0.0000[sec]
2025-05-29 21:27:12,282 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/62500.ckpt
2025-05-29 21:27:12,298 - INFO - joeynmt.training - Example #0
2025-05-29 21:27:12,299 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:27:12,299 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:27:12,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'kre@@', 'gen', 'van', '4@@', '0', 'proc@@', 'ent', 'was', 'ge@@', 'sl@@', 'ag@@', 'en.', '</s>']
2025-05-29 21:27:12,300 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:27:12,300 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:27:12,300 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verbeteren dat de arctische ijskappen, die de grootte van de onderste drie miljoen jaar de grootte van de onderste 48 staten had gekregen van 40 procent was geslagen.
2025-05-29 21:27:12,300 - INFO - joeynmt.training - Example #1
2025-05-29 21:27:12,301 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:27:12,301 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:27:12,301 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'ver@@', 'sla@@', 'g', 'van', 'dit', 'ij@@', 's', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's', 'is', 'een', 'be@@', 'et@@', 'je', 'van', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 21:27:12,302 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:27:12,302 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:27:12,302 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste verslag van dit ijs probleem van dit ijs is een beetje van de dikke ijs toont.
2025-05-29 21:27:12,302 - INFO - joeynmt.training - Example #2
2025-05-29 21:27:12,303 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:27:12,303 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:27:12,303 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'men.', '</s>']
2025-05-29 21:27:12,304 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:27:12,304 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:27:12,304 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart het slaagsysteem van onze wereldwijde klimaatsystemen.
2025-05-29 21:27:12,304 - INFO - joeynmt.training - Example #3
2025-05-29 21:27:12,304 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:27:12,304 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:27:12,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'z@@', 'am@@', 'el@@', 'ing', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'z@@', 'am@@', 'el@@', 'd.', '</s>']
2025-05-29 21:27:12,305 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:27:12,305 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:27:12,305 - INFO - joeynmt.training - 	Hypothesis: Ze groeien en in de winter en verzameling in de winter en verzameld.
2025-05-29 21:27:12,306 - INFO - joeynmt.training - Example #4
2025-05-29 21:27:12,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:27:12,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:27:12,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd', 'is.', '</s>']
2025-05-29 21:27:12,307 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:27:12,307 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:27:12,307 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien, is een tijdje van de laatste 25 jaar gebeurd is.
2025-05-29 21:27:20,349 - INFO - joeynmt.training - Epoch   8, Step:    67600, Batch Loss:     1.815758, Batch Acc: 0.555144, Tokens per Sec:     8460, Lr: 0.000300
2025-05-29 21:27:28,300 - INFO - joeynmt.training - Epoch   8, Step:    67700, Batch Loss:     1.525284, Batch Acc: 0.548793, Tokens per Sec:     8842, Lr: 0.000300
2025-05-29 21:27:36,374 - INFO - joeynmt.training - Epoch   8, Step:    67800, Batch Loss:     1.530311, Batch Acc: 0.548945, Tokens per Sec:     8982, Lr: 0.000300
2025-05-29 21:27:44,715 - INFO - joeynmt.training - Epoch   8, Step:    67900, Batch Loss:     1.430235, Batch Acc: 0.554703, Tokens per Sec:     8328, Lr: 0.000300
2025-05-29 21:27:53,641 - INFO - joeynmt.training - Epoch   8, Step:    68000, Batch Loss:     1.548181, Batch Acc: 0.548214, Tokens per Sec:     7748, Lr: 0.000300
2025-05-29 21:27:53,642 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:27:53,642 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:28:28,363 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.27, acc:   0.51, generation: 34.6864[sec], evaluation: 0.0000[sec]
2025-05-29 21:28:28,370 - INFO - joeynmt.training - Example #0
2025-05-29 21:28:28,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:28:28,371 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:28:28,371 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'ver@@', 'kijken', 'naar', 'de', 'ar@@', 'ti@@', 'kel@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'die', 'de', 'gro@@', 'ten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd', 'is.', '</s>']
2025-05-29 21:28:28,372 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:28:28,372 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:28:28,372 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen om te verkijken naar de artikelen dat de artische ijskaart die de groten van de onderste 48 staten van de onderste 48 staten van de onderste 40 procent gegooid is.
2025-05-29 21:28:28,372 - INFO - joeynmt.training - Example #1
2025-05-29 21:28:28,373 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:28:28,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:28:28,373 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'en@@', 'aar@@', 's', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 'z@@', 'er@@', 's,', 'omdat', 'het', 'niet', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 21:28:28,374 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:28:28,374 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:28:28,374 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste stenaars van dit speciale probleem omdat het niet de dikke ijzers, omdat het niet toont.
2025-05-29 21:28:28,374 - INFO - joeynmt.training - Example #2
2025-05-29 21:28:28,375 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:28:28,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:28:28,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's', 'het', 'uit@@', 'no@@', 'dig@@', 'en', 'het', 'ver@@', 'z@@', 'am@@', 'el@@', 'ing', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:28:28,376 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:28:28,376 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:28:28,376 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijs het uitnodigen het verzameling van onze wereldwijde klimaatsysteem.
2025-05-29 21:28:28,376 - INFO - joeynmt.training - Example #3
2025-05-29 21:28:28,376 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:28:28,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:28:28,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:28:28,377 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:28:28,378 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:28:28,378 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluit in de zomers.
2025-05-29 21:28:28,378 - INFO - joeynmt.training - Example #4
2025-05-29 21:28:28,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:28:28,379 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:28:28,379 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'ge@@', 'vol@@', 'gen', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'van', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'van', 'wat', 'er', 'gebeur@@', 'd', 'is.', '</s>']
2025-05-29 21:28:28,380 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:28:28,380 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:28:28,380 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolgen is een tijdschriften van een tijdschriften van wat er gebeurd is.
2025-05-29 21:28:37,495 - INFO - joeynmt.training - Epoch   8, Step:    68100, Batch Loss:     1.438195, Batch Acc: 0.552320, Tokens per Sec:     7680, Lr: 0.000300
2025-05-29 21:28:46,445 - INFO - joeynmt.training - Epoch   8, Step:    68200, Batch Loss:     1.597559, Batch Acc: 0.551263, Tokens per Sec:     7995, Lr: 0.000300
2025-05-29 21:28:55,246 - INFO - joeynmt.training - Epoch   8, Step:    68300, Batch Loss:     1.531844, Batch Acc: 0.549268, Tokens per Sec:     7759, Lr: 0.000300
2025-05-29 21:29:03,881 - INFO - joeynmt.training - Epoch   8, Step:    68400, Batch Loss:     1.497127, Batch Acc: 0.554013, Tokens per Sec:     8210, Lr: 0.000300
2025-05-29 21:29:13,110 - INFO - joeynmt.training - Epoch   8, Step:    68500, Batch Loss:     1.388852, Batch Acc: 0.553769, Tokens per Sec:     7562, Lr: 0.000300
2025-05-29 21:29:13,111 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:29:13,111 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:29:47,992 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.52, generation: 34.8469[sec], evaluation: 0.0000[sec]
2025-05-29 21:29:48,181 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/67500.ckpt
2025-05-29 21:29:48,192 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit_bpe/67500.ckpt
2025-05-29 21:29:48,193 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe\67500.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit_bpe\\67500.ckpt')
2025-05-29 21:29:48,199 - INFO - joeynmt.training - Example #0
2025-05-29 21:29:48,199 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:29:48,200 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:29:48,200 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'g', 'laten', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'at@@', 'uur', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'maakt', 'is', 'gesch@@', 're@@', 'mp@@', 'el', 'voor', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'maakt', 'is.', '</s>']
2025-05-29 21:29:48,201 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:29:48,201 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:29:48,201 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolg laten zien dat de artische ijskapparatuur die de artische ijskappen, die de grens van de onderste 48 staten had gemaakt is geschrempel voor 40 procent gemaakt is.
2025-05-29 21:29:48,201 - INFO - joeynmt.training - Example #1
2025-05-29 21:29:48,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:29:48,202 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:29:48,202 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'dr@@', 'in@@', 'kt', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'aa@@', 't,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'to@@', 'on@@', 't', 'to@@', 'on@@', 't', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 21:29:48,203 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:29:48,203 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:29:48,203 - INFO - joeynmt.training - 	Hypothesis: Maar dat drinkt niet sterk genoeg de eerste staat, omdat het niet de dikke ijs toont toont omdat het niet de dikke van het ijs toont.
2025-05-29 21:29:48,203 - INFO - joeynmt.training - Example #2
2025-05-29 21:29:48,204 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:29:48,204 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:29:48,204 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:29:48,205 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:29:48,205 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:29:48,205 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe het hart van onze wereldwijde klimaatsysteem.
2025-05-29 21:29:48,205 - INFO - joeynmt.training - Example #3
2025-05-29 21:29:48,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:29:48,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:29:48,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'tro@@', 'uw@@', 'en', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:29:48,208 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:29:48,208 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:29:48,208 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en vertrouwen in het zomers.
2025-05-29 21:29:48,208 - INFO - joeynmt.training - Example #4
2025-05-29 21:29:48,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:29:48,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:29:48,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'ti@@', 'me@@', '-@@', 'pro@@', 'f@@', 'ess@@', 'ion@@', 'ele', 're@@', 'gel@@', 's', 'gebeur@@', 'd', 'is', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:29:48,209 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:29:48,209 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:29:48,209 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een time-professionele regels gebeurd is in de afgelopen 25 jaar is gebeurd.
2025-05-29 21:29:57,535 - INFO - joeynmt.training - Epoch   8, Step:    68600, Batch Loss:     1.687092, Batch Acc: 0.549085, Tokens per Sec:     7440, Lr: 0.000300
2025-05-29 21:30:06,868 - INFO - joeynmt.training - Epoch   8, Step:    68700, Batch Loss:     1.412183, Batch Acc: 0.551077, Tokens per Sec:     7434, Lr: 0.000300
2025-05-29 21:30:16,388 - INFO - joeynmt.training - Epoch   8, Step:    68800, Batch Loss:     1.488388, Batch Acc: 0.549735, Tokens per Sec:     7082, Lr: 0.000300
2025-05-29 21:30:25,820 - INFO - joeynmt.training - Epoch   8, Step:    68900, Batch Loss:     1.431290, Batch Acc: 0.554200, Tokens per Sec:     7520, Lr: 0.000300
2025-05-29 21:30:34,858 - INFO - joeynmt.training - Epoch   8, Step:    69000, Batch Loss:     1.427746, Batch Acc: 0.547146, Tokens per Sec:     7547, Lr: 0.000300
2025-05-29 21:30:34,859 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:30:34,859 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:31:05,178 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.24, acc:   0.52, generation: 30.2779[sec], evaluation: 0.0000[sec]
2025-05-29 21:31:05,379 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/63000.ckpt
2025-05-29 21:31:05,396 - INFO - joeynmt.training - Example #0
2025-05-29 21:31:05,397 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:31:05,397 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:31:05,397 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 'z@@', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'at@@', 'uur', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'l@@', 'en@@', 'g@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', 'te', 'ver@@', 'z@@', 'aa@@', 'g@@', 'd', 'te', 'zijn.', '</s>']
2025-05-29 21:31:05,398 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:31:05,398 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:31:05,399 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkijken dat de artische ijzijskapparatuur die de grootte van de lengte van de onderste 48 staten van de onderste 48 staten van de onderste 48 staten om te verzaagd te zijn.
2025-05-29 21:31:05,399 - INFO - joeynmt.training - Example #1
2025-05-29 21:31:05,399 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:31:05,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:31:05,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'ver@@', 'van@@', 'g@@', 'st', 'van', 'dit', 'ij@@', 'z@@', 'er', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'ij@@', 'z@@', 'er', 'is', 'to@@', 'on@@', 't', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'ij@@', 'z@@', 'er', 'is.', '</s>']
2025-05-29 21:31:05,401 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:31:05,401 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:31:05,401 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de vervangst van dit ijzer niet de dikke van ijzer is toont omdat het niet de dikke van ijzer is.
2025-05-29 21:31:05,401 - INFO - joeynmt.training - Example #2
2025-05-29 21:31:05,402 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:31:05,402 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:31:05,402 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'aa@@', 'g@@', 'd', 'van', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:31:05,403 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:31:05,403 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:31:05,403 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het slaagd van de klimaatsysteem.
2025-05-29 21:31:05,403 - INFO - joeynmt.training - Example #3
2025-05-29 21:31:05,403 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:31:05,404 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:31:05,404 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'i@@', 'ten', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:31:05,404 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:31:05,404 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:31:05,404 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en sluiten in de zomers.
2025-05-29 21:31:05,404 - INFO - joeynmt.training - Example #4
2025-05-29 21:31:05,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:31:05,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:31:05,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 'd', 'is', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:31:05,406 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:31:05,406 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:31:05,406 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschrift van wat er gebeurd is in de laatste 25 jaar gebeurd.
2025-05-29 21:31:14,643 - INFO - joeynmt.training - Epoch   8, Step:    69100, Batch Loss:     1.523167, Batch Acc: 0.550898, Tokens per Sec:     7354, Lr: 0.000300
2025-05-29 21:31:23,704 - INFO - joeynmt.training - Epoch   8, Step:    69200, Batch Loss:     1.439724, Batch Acc: 0.550552, Tokens per Sec:     7715, Lr: 0.000300
2025-05-29 21:31:32,727 - INFO - joeynmt.training - Epoch   8, Step:    69300, Batch Loss:     1.552962, Batch Acc: 0.558227, Tokens per Sec:     7837, Lr: 0.000300
2025-05-29 21:31:41,814 - INFO - joeynmt.training - Epoch   8, Step:    69400, Batch Loss:     1.726954, Batch Acc: 0.551269, Tokens per Sec:     7703, Lr: 0.000300
2025-05-29 21:31:50,715 - INFO - joeynmt.training - Epoch   8, Step:    69500, Batch Loss:     1.452654, Batch Acc: 0.547769, Tokens per Sec:     7622, Lr: 0.000300
2025-05-29 21:31:50,716 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:31:50,716 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:32:25,558 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.23, acc:   0.52, generation: 34.8072[sec], evaluation: 0.0000[sec]
2025-05-29 21:32:25,736 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/68500.ckpt
2025-05-29 21:32:25,752 - INFO - joeynmt.training - Example #0
2025-05-29 21:32:25,753 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:32:25,753 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:32:25,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'de', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'st@@', 'aten', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'zijn.', '</s>']
2025-05-29 21:32:25,754 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:32:25,754 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:32:25,755 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee getoonde getoond om te verbeteren dat de artische ijskappen, die de grootte van de onderste 48 staten die de grootte van de onderste 48 staten van de onderste 48 staten staten om 40 procent te zijn.
2025-05-29 21:32:25,755 - INFO - joeynmt.training - Example #1
2025-05-29 21:32:25,755 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:32:25,755 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:32:25,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'ver@@', 'bin@@', 'ding', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'ij@@', 's', 'is', 'niet', 'de', 'di@@', 'kken', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'ij@@', 's', 'is.', '</s>']
2025-05-29 21:32:25,756 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:32:25,756 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:32:25,756 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de verbinding van de ijs van de ijzer van de ijzer van ijs is niet de dikken van de ijzer van ijs is.
2025-05-29 21:32:25,756 - INFO - joeynmt.training - Example #2
2025-05-29 21:32:25,756 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:32:25,756 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:32:25,756 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:32:25,756 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:32:25,757 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:32:25,757 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe van onze wereldwijd klimaatsysteem.
2025-05-29 21:32:25,757 - INFO - joeynmt.training - Example #3
2025-05-29 21:32:25,757 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:32:25,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:32:25,757 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:32:25,758 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:32:25,758 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:32:25,758 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluit in de zomers.
2025-05-29 21:32:25,758 - INFO - joeynmt.training - Example #4
2025-05-29 21:32:25,758 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:32:25,758 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:32:25,758 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'ti@@', '-@@', 'to@@', 't@@', '-@@', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 21:32:25,759 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:32:25,759 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:32:25,759 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een ti-tot-opname wat er gebeurde in de afgelopen 25 jaar is.
2025-05-29 21:32:35,712 - INFO - joeynmt.training - Epoch   8, Step:    69600, Batch Loss:     1.715699, Batch Acc: 0.549815, Tokens per Sec:     6721, Lr: 0.000300
2025-05-29 21:32:45,062 - INFO - joeynmt.training - Epoch   8, Step:    69700, Batch Loss:     1.593931, Batch Acc: 0.548608, Tokens per Sec:     7624, Lr: 0.000300
2025-05-29 21:32:54,529 - INFO - joeynmt.training - Epoch   8, Step:    69800, Batch Loss:     1.497402, Batch Acc: 0.548938, Tokens per Sec:     7324, Lr: 0.000300
2025-05-29 21:33:03,944 - INFO - joeynmt.training - Epoch   8, Step:    69900, Batch Loss:     1.340180, Batch Acc: 0.555222, Tokens per Sec:     7329, Lr: 0.000300
2025-05-29 21:33:13,218 - INFO - joeynmt.training - Epoch   8, Step:    70000, Batch Loss:     1.598482, Batch Acc: 0.551679, Tokens per Sec:     7686, Lr: 0.000300
2025-05-29 21:33:13,219 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:33:13,219 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:33:51,266 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.23, acc:   0.52, generation: 38.0057[sec], evaluation: 0.0000[sec]
2025-05-29 21:33:51,466 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/64000.ckpt
2025-05-29 21:33:51,486 - INFO - joeynmt.training - Example #0
2025-05-29 21:33:51,487 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:33:51,487 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:33:51,487 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'naar', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'die', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0@@', '%', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'ach@@', 't.', '</s>']
2025-05-29 21:33:51,488 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:33:51,488 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:33:51,488 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkijken naar de artische ijskappen, dat de artische ijskappe die de grens van de onderste 48 staten van de onderste 48 staten om 40% van de onderste 40 procent geslacht.
2025-05-29 21:33:51,489 - INFO - joeynmt.training - Example #1
2025-05-29 21:33:51,489 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:33:51,489 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:33:51,489 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'kan@@', 's', 'dat', 'het', 'niet', 'de', 'di@@', 'kken', 'van', 'dit', 'ij@@', 's@@', 'k@@', 'heid', 'van', 'dit', 'ij@@', 's@@', 'ver@@', 'to@@', 'on@@', 't', 'niet', 'de', 'di@@', 'kken', 'van', 'het', 'ij@@', 'z@@', 'er', 'niet', 'uit@@', '.', '</s>']
2025-05-29 21:33:51,490 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:33:51,490 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:33:51,491 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste kans dat het niet de dikken van dit ijskheid van dit ijsvertoont niet de dikken van het ijzer niet uit.
2025-05-29 21:33:51,491 - INFO - joeynmt.training - Example #2
2025-05-29 21:33:51,491 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:33:51,491 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:33:51,491 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'sl@@', 'im@@', 'syste@@', 'em', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:33:51,492 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:33:51,492 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:33:51,492 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart het slimsysteem van onze wereldwijde klimaatsysteem.
2025-05-29 21:33:51,493 - INFO - joeynmt.training - Example #3
2025-05-29 21:33:51,493 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:33:51,493 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:33:51,493 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'i@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:33:51,494 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:33:51,494 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:33:51,494 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluipt in de zomers.
2025-05-29 21:33:51,494 - INFO - joeynmt.training - Example #4
2025-05-29 21:33:51,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:33:51,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:33:51,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'tra@@', 'ff@@', 'er@@', 'ing', 'van', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 21:33:51,496 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:33:51,496 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:33:51,496 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijtraffering van wat er gebeurde in de afgelopen 25 jaar.
2025-05-29 21:34:00,985 - INFO - joeynmt.training - Epoch   8, Step:    70100, Batch Loss:     1.400928, Batch Acc: 0.542589, Tokens per Sec:     7183, Lr: 0.000300
2025-05-29 21:34:10,539 - INFO - joeynmt.training - Epoch   8, Step:    70200, Batch Loss:     1.541446, Batch Acc: 0.553573, Tokens per Sec:     7306, Lr: 0.000300
2025-05-29 21:34:18,953 - INFO - joeynmt.training - Epoch   8, Step:    70300, Batch Loss:     1.535890, Batch Acc: 0.550947, Tokens per Sec:     8314, Lr: 0.000300
2025-05-29 21:34:27,054 - INFO - joeynmt.training - Epoch   8, Step:    70400, Batch Loss:     1.557897, Batch Acc: 0.547938, Tokens per Sec:     8652, Lr: 0.000300
2025-05-29 21:34:35,762 - INFO - joeynmt.training - Epoch   8, Step:    70500, Batch Loss:     1.461069, Batch Acc: 0.554524, Tokens per Sec:     7950, Lr: 0.000300
2025-05-29 21:34:35,763 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:34:35,763 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:35:11,798 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.52, generation: 35.9986[sec], evaluation: 0.0000[sec]
2025-05-29 21:35:11,799 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:35:11,979 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/69000.ckpt
2025-05-29 21:35:11,996 - INFO - joeynmt.training - Example #0
2025-05-29 21:35:11,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:35:11,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:35:11,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'c@@', 'ap@@', 'ac@@', 'iteit', 'van', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'c@@', 'ap@@', 'ac@@', 'iteit', 'is.', '</s>']
2025-05-29 21:35:11,998 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:35:11,998 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:35:11,998 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verbeteren dat de arctische ijskappen, die de artische ijskappen, die de grootte van de onderste 48 staten van de onderste 40 procent gecapaciteit van 40 procent gecapaciteit is.
2025-05-29 21:35:11,998 - INFO - joeynmt.training - Example #1
2025-05-29 21:35:11,999 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:35:11,999 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:35:11,999 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'ver@@', 'n@@', 'ul@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's@@', 'ver@@', 'wij@@', 'der@@', 't.', '</s>']
2025-05-29 21:35:12,000 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:35:12,000 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:35:12,000 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de vernult van dit speciale probleem, omdat het niet de dik van het ijsverwijdert.
2025-05-29 21:35:12,000 - INFO - joeynmt.training - Example #2
2025-05-29 21:35:12,001 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:35:12,001 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:35:12,001 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', ',', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:35:12,002 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:35:12,002 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:35:12,002 - INFO - joeynmt.training - 	Hypothesis: In zekere zin, is de artische ijskappe van onze wereldwijde klimaatsysteem.
2025-05-29 21:35:12,002 - INFO - joeynmt.training - Example #3
2025-05-29 21:35:12,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:35:12,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:35:12,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'l@@', 'aat', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 21:35:12,004 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:35:12,004 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:35:12,004 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en laat zomert.
2025-05-29 21:35:12,004 - INFO - joeynmt.training - Example #4
2025-05-29 21:35:12,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:35:12,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:35:12,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'tra@@', 'p@@', 'ing', 'die', 'ik', 'jullie', 'laten', 'zien', 'wat', 'er', 'gebeur@@', 't.', '</s>']
2025-05-29 21:35:12,006 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:35:12,006 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:35:12,006 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen, is een tijdtraping die ik jullie laten zien wat er gebeurt.
2025-05-29 21:35:21,332 - INFO - joeynmt.training - Epoch   8, Step:    70600, Batch Loss:     1.454017, Batch Acc: 0.548769, Tokens per Sec:     7298, Lr: 0.000300
2025-05-29 21:35:30,682 - INFO - joeynmt.training - Epoch   8, Step:    70700, Batch Loss:     1.444439, Batch Acc: 0.554549, Tokens per Sec:     7675, Lr: 0.000300
2025-05-29 21:35:40,363 - INFO - joeynmt.training - Epoch   8, Step:    70800, Batch Loss:     1.252297, Batch Acc: 0.552359, Tokens per Sec:     7104, Lr: 0.000300
2025-05-29 21:35:49,997 - INFO - joeynmt.training - Epoch   8, Step:    70900, Batch Loss:     1.684840, Batch Acc: 0.552266, Tokens per Sec:     7296, Lr: 0.000300
2025-05-29 21:35:59,194 - INFO - joeynmt.training - Epoch   8, Step:    71000, Batch Loss:     1.607080, Batch Acc: 0.549041, Tokens per Sec:     7566, Lr: 0.000300
2025-05-29 21:35:59,195 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:35:59,195 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:36:37,420 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.19, acc:   0.52, generation: 38.1860[sec], evaluation: 0.0000[sec]
2025-05-29 21:36:37,421 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:36:37,602 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/63500.ckpt
2025-05-29 21:36:37,618 - INFO - joeynmt.training - Example #0
2025-05-29 21:36:37,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:36:37,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:36:37,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'de', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'naar', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'A@@', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'om', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'dur@@', 'ende', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'maakt', 'is.', '</s>']
2025-05-29 21:36:37,620 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:36:37,620 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:36:37,620 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoonde getoond om te verkijken naar de artische ijskappen, die de grootte van de Aarctische ijskappen, om 40 procent gedurende drie miljoen jaar de grootte van de 40 procent gemaakt is.
2025-05-29 21:36:37,620 - INFO - joeynmt.training - Example #1
2025-05-29 21:36:37,621 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:36:37,621 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:36:37,621 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'e,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ap@@', 't', 'van', 'het', 'ij@@', 's@@', 'je', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 21:36:37,622 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:36:37,622 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:36:37,623 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste, omdat het niet de dik van het ijskapt van het ijsje toont.
2025-05-29 21:36:37,623 - INFO - joeynmt.training - Example #2
2025-05-29 21:36:37,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:36:37,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:36:37,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ct@@', 'ie@@', 'ke', 'ij@@', 's@@', 'k@@', 'app@@', 'en', 'het', 'on@@', 'geloo@@', 'f@@', 'lijk', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:36:37,624 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:36:37,625 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:36:37,625 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctieke ijskappen het ongelooflijk klimaatsysteem.
2025-05-29 21:36:37,625 - INFO - joeynmt.training - Example #3
2025-05-29 21:36:37,625 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:36:37,625 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:36:37,625 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'z@@', 'am@@', 'el@@', 'ing', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:36:37,627 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:36:37,627 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:36:37,627 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en verzameling in de zomers.
2025-05-29 21:36:37,627 - INFO - joeynmt.training - Example #4
2025-05-29 21:36:37,628 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:36:37,628 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:36:37,628 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 'd', 'is.', '</s>']
2025-05-29 21:36:37,629 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:36:37,629 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:36:37,629 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen, is een tijdschrift van wat er gebeurd is.
2025-05-29 21:36:46,905 - INFO - joeynmt.training - Epoch   8, Step:    71100, Batch Loss:     1.693519, Batch Acc: 0.549497, Tokens per Sec:     7236, Lr: 0.000300
2025-05-29 21:36:55,949 - INFO - joeynmt.training - Epoch   8, Step:    71200, Batch Loss:     1.344108, Batch Acc: 0.553943, Tokens per Sec:     7658, Lr: 0.000300
2025-05-29 21:37:04,951 - INFO - joeynmt.training - Epoch   8, Step:    71300, Batch Loss:     1.412277, Batch Acc: 0.554826, Tokens per Sec:     7866, Lr: 0.000300
2025-05-29 21:37:13,920 - INFO - joeynmt.training - Epoch   8, Step:    71400, Batch Loss:     1.460364, Batch Acc: 0.555342, Tokens per Sec:     7660, Lr: 0.000300
2025-05-29 21:37:22,956 - INFO - joeynmt.training - Epoch   8, Step:    71500, Batch Loss:     1.598367, Batch Acc: 0.557910, Tokens per Sec:     7870, Lr: 0.000300
2025-05-29 21:37:22,957 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:37:22,957 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:37:55,091 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.23, acc:   0.52, generation: 32.1029[sec], evaluation: 0.0000[sec]
2025-05-29 21:37:55,267 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/69500.ckpt
2025-05-29 21:37:55,280 - INFO - joeynmt.training - Example #0
2025-05-29 21:37:55,281 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:37:55,281 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:37:55,281 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'kijken', 'om', 'te', 'be@@', 'se@@', 'ffen', 'dat', 'de', 'ar@@', 'ct@@', 'a@@', 're@@', ',', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'ond', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'ond', 'van', 'de', 'onder@@', 'kan@@', 's', 'om', 'te', 're@@', 'alis@@', 'eren', 'is.', '</s>']
2025-05-29 21:37:55,282 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:37:55,282 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:37:55,283 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te bekijken om te beseffen dat de arctare, die drie miljoen jaar de grootte van de grond drie miljoen jaar de grootte van de grond van de onderkans om te realiseren is.
2025-05-29 21:37:55,283 - INFO - joeynmt.training - Example #1
2025-05-29 21:37:55,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:37:55,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:37:55,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'kan@@', 's', 'om', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'men', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'en.', '</s>']
2025-05-29 21:37:55,283 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:37:55,284 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:37:55,284 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste kans om dit specifieke problemen omdat het niet de dikke van de dikke ijsen.
2025-05-29 21:37:55,284 - INFO - joeynmt.training - Example #2
2025-05-29 21:37:55,284 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:37:55,284 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:37:55,284 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', 'tu@@', 'igen', 'is', 'de', 'ar@@', 'ct@@', 'a@@', 're@@', '-@@', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'sl@@', 'im@@', 'syste@@', 'em', 'van', 'onze', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:37:55,285 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:37:55,285 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:37:55,285 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigen is de arctare-ijskappe is het slimsysteem van onze wereldklimaatsysteem.
2025-05-29 21:37:55,285 - INFO - joeynmt.training - Example #3
2025-05-29 21:37:55,285 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:37:55,285 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:37:55,285 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'het', 'ver@@', 'oor@@', 'z@@', 'aa@@', 'kt', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:37:55,286 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:37:55,286 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:37:55,286 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en het veroorzaakt in de zomers.
2025-05-29 21:37:55,286 - INFO - joeynmt.training - Example #4
2025-05-29 21:37:55,286 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:37:55,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:37:55,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:37:55,287 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:37:55,287 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:37:55,287 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschriften in de laatste 25 jaar is gebeurd.
2025-05-29 21:38:03,943 - INFO - joeynmt.training - Epoch   8, Step:    71600, Batch Loss:     1.541973, Batch Acc: 0.548179, Tokens per Sec:     7971, Lr: 0.000300
2025-05-29 21:38:13,403 - INFO - joeynmt.training - Epoch   8, Step:    71700, Batch Loss:     1.324436, Batch Acc: 0.548953, Tokens per Sec:     7294, Lr: 0.000300
2025-05-29 21:38:22,703 - INFO - joeynmt.training - Epoch   8, Step:    71800, Batch Loss:     1.623130, Batch Acc: 0.552409, Tokens per Sec:     7658, Lr: 0.000300
2025-05-29 21:38:32,138 - INFO - joeynmt.training - Epoch   8, Step:    71900, Batch Loss:     1.545388, Batch Acc: 0.554190, Tokens per Sec:     7359, Lr: 0.000300
2025-05-29 21:38:41,808 - INFO - joeynmt.training - Epoch   8, Step:    72000, Batch Loss:     1.434792, Batch Acc: 0.552314, Tokens per Sec:     7468, Lr: 0.000300
2025-05-29 21:38:41,810 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:38:41,810 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:39:24,080 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.21, acc:   0.52, generation: 42.2284[sec], evaluation: 0.0000[sec]
2025-05-29 21:39:24,276 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/70000.ckpt
2025-05-29 21:39:24,294 - INFO - joeynmt.training - Example #0
2025-05-29 21:39:24,295 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:39:24,295 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:39:24,295 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'zor@@', 'gen', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'die', 'de', 'gr@@', 'ond', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'ru@@', 'chten', 'voor', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'c@@', 'ontro@@', 'le@@', 'erd', 'is.', '</s>']
2025-05-29 21:39:24,296 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:39:24,296 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:39:24,296 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verzorgen dat de artische ijskappen, die de artische ijskaart die de grond van de onderste 48 staten om 40 procent te verruchten voor 40 procent gecontroleerd is.
2025-05-29 21:39:24,296 - INFO - joeynmt.training - Example #1
2025-05-29 21:39:24,297 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:39:24,297 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:39:24,297 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'ber@@', 'icht', 'l@@', 'aat', 'zien.', '</s>']
2025-05-29 21:39:24,298 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:39:24,298 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:39:24,298 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste van dit speciale probleem, omdat het niet de dik van het ijsje van het ijsbericht laat zien.
2025-05-29 21:39:24,298 - INFO - joeynmt.training - Example #2
2025-05-29 21:39:24,298 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:39:24,298 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:39:24,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:39:24,299 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:39:24,299 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:39:24,300 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart het hart van onze wereldklimaatsysteem.
2025-05-29 21:39:24,300 - INFO - joeynmt.training - Example #3
2025-05-29 21:39:24,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:39:24,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:39:24,300 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lo@@', 't', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:39:24,301 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:39:24,301 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:39:24,301 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slot in de winter en zomers.
2025-05-29 21:39:24,301 - INFO - joeynmt.training - Example #4
2025-05-29 21:39:24,301 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:39:24,302 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:39:24,302 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:39:24,302 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:39:24,303 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:39:24,303 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift van wat er gebeurde in de laatste 25 jaar gebeurd.
2025-05-29 21:39:33,381 - INFO - joeynmt.training - Epoch   8, Step:    72100, Batch Loss:     1.551045, Batch Acc: 0.552115, Tokens per Sec:     7560, Lr: 0.000300
2025-05-29 21:39:42,527 - INFO - joeynmt.training - Epoch   8, Step:    72200, Batch Loss:     1.560432, Batch Acc: 0.548444, Tokens per Sec:     7520, Lr: 0.000300
2025-05-29 21:39:51,425 - INFO - joeynmt.training - Epoch   8, Step:    72300, Batch Loss:     1.486368, Batch Acc: 0.550190, Tokens per Sec:     8071, Lr: 0.000300
2025-05-29 21:40:00,346 - INFO - joeynmt.training - Epoch   8, Step:    72400, Batch Loss:     1.407568, Batch Acc: 0.554509, Tokens per Sec:     7710, Lr: 0.000300
2025-05-29 21:40:08,898 - INFO - joeynmt.training - Epoch   8, Step:    72500, Batch Loss:     1.540638, Batch Acc: 0.552927, Tokens per Sec:     8293, Lr: 0.000300
2025-05-29 21:40:08,899 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:40:08,899 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:40:50,093 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.18, acc:   0.52, generation: 41.1523[sec], evaluation: 0.0000[sec]
2025-05-29 21:40:50,094 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:40:50,274 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/71500.ckpt
2025-05-29 21:40:50,290 - INFO - joeynmt.training - Example #0
2025-05-29 21:40:50,291 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:40:50,291 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:40:50,291 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'ag@@', 'en,', 'om', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'or@@', 'd', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-29 21:40:50,292 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:40:50,292 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:40:50,292 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verzien dat de artische ijskappen, die de artische ijskappen, die de grootte van de onderste 48 staten had geslagen, om 40 procent geslord te verzamelen.
2025-05-29 21:40:50,292 - INFO - joeynmt.training - Example #1
2025-05-29 21:40:50,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:40:50,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:40:50,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'het', 'ij@@', 's@@', 'de', 'van', 'het', 'ij@@', 's@@', 'ver@@', 'tel@@', 't', 'dat', 'het', 'ij@@', 's@@', 'je', 'van', 'de', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'het', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 21:40:50,294 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:40:50,294 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:40:50,294 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van dit speciale probleem van dit speciale probleem van het ijsde van het ijsvertelt dat het ijsje van de ijskaart van het ijsver.
2025-05-29 21:40:50,295 - INFO - joeynmt.training - Example #2
2025-05-29 21:40:50,295 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:40:50,295 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:40:50,295 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:40:50,296 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:40:50,296 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:40:50,296 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart het hart van onze wereldwijde klimaatsysteem.
2025-05-29 21:40:50,297 - INFO - joeynmt.training - Example #3
2025-05-29 21:40:50,297 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:40:50,297 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:40:50,297 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'en', 'ver@@', 'wa@@', 'cht', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'er@@', 'm', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'er@@', 'm', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'er@@', 'm', 'in', 'de', 'win@@', 'ter', 'en', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-29 21:40:50,298 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:40:50,298 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:40:50,299 - INFO - joeynmt.training - 	Hypothesis: Ze groeien en verwacht in de winter en scherm in de winter en scherm in de winter en scherm in de winter en verzamelen.
2025-05-29 21:40:50,299 - INFO - joeynmt.training - Example #4
2025-05-29 21:40:50,299 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:40:50,299 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:40:50,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 't,', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:40:50,300 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:40:50,300 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:40:50,300 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdschrift, wat er gebeurt in de afgelopen 25 jaar is gebeurd.
2025-05-29 21:40:59,611 - INFO - joeynmt.training - Epoch   8, Step:    72600, Batch Loss:     1.462914, Batch Acc: 0.548571, Tokens per Sec:     7062, Lr: 0.000300
2025-05-29 21:41:08,694 - INFO - joeynmt.training - Epoch   8, Step:    72700, Batch Loss:     1.489181, Batch Acc: 0.543768, Tokens per Sec:     7785, Lr: 0.000300
2025-05-29 21:41:17,000 - INFO - joeynmt.training - Epoch   8, Step:    72800, Batch Loss:     1.651293, Batch Acc: 0.553936, Tokens per Sec:     8277, Lr: 0.000300
2025-05-29 21:41:25,328 - INFO - joeynmt.training - Epoch   8, Step:    72900, Batch Loss:     1.659320, Batch Acc: 0.546425, Tokens per Sec:     8468, Lr: 0.000300
2025-05-29 21:41:33,735 - INFO - joeynmt.training - Epoch   8, Step:    73000, Batch Loss:     1.459131, Batch Acc: 0.550742, Tokens per Sec:     8485, Lr: 0.000300
2025-05-29 21:41:33,735 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:41:33,736 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:42:20,315 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.52, generation: 46.5374[sec], evaluation: 0.0000[sec]
2025-05-29 21:42:20,490 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/67000.ckpt
2025-05-29 21:42:20,508 - INFO - joeynmt.training - Example #0
2025-05-29 21:42:20,509 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:42:20,509 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:42:20,509 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'maakt', 'om', 'te', 'kijken', 'naar', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 21:42:20,510 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:42:20,511 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:42:20,511 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen om te zien dat de artische ijskapen die de artische ijskapen die drie miljoen jaar de grootte van de onderste 48 staten had gemaakt om te kijken naar 40 procent geslaagd is.
2025-05-29 21:42:20,511 - INFO - joeynmt.training - Example #1
2025-05-29 21:42:20,511 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:42:20,511 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:42:20,511 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'ap@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 21:42:20,512 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:42:20,513 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:42:20,513 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste stapt van dit speciale probleem van dit speciale probleem toont.
2025-05-29 21:42:20,513 - INFO - joeynmt.training - Example #2
2025-05-29 21:42:20,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:42:20,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:42:20,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'zin@@', ',', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'sl@@', 'ag@@', 'syste@@', 'em', 'het', 'be@@', 'st', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:42:20,514 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:42:20,515 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:42:20,515 - INFO - joeynmt.training - 	Hypothesis: In zekere zin, is de artische ijskapen het slagsysteem het best van onze wereldwijde klimaatsysteem.
2025-05-29 21:42:20,515 - INFO - joeynmt.training - Example #3
2025-05-29 21:42:20,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:42:20,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:42:20,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'cht', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:42:20,516 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:42:20,517 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:42:20,517 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slucht in de zomers.
2025-05-29 21:42:20,517 - INFO - joeynmt.training - Example #4
2025-05-29 21:42:20,517 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:42:20,518 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:42:20,518 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 't,', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 21:42:20,519 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:42:20,519 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:42:20,519 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien, is een tijdschrift, wat er gebeurt in de afgelopen 25 jaar is.
2025-05-29 21:42:29,824 - INFO - joeynmt.training - Epoch   8, Step:    73100, Batch Loss:     1.453757, Batch Acc: 0.554406, Tokens per Sec:     7423, Lr: 0.000300
2025-05-29 21:42:38,800 - INFO - joeynmt.training - Epoch   8, Step:    73200, Batch Loss:     1.548291, Batch Acc: 0.551125, Tokens per Sec:     7559, Lr: 0.000300
2025-05-29 21:42:47,903 - INFO - joeynmt.training - Epoch   8, Step:    73300, Batch Loss:     1.352292, Batch Acc: 0.546262, Tokens per Sec:     7702, Lr: 0.000300
2025-05-29 21:42:56,833 - INFO - joeynmt.training - Epoch   8, Step:    73400, Batch Loss:     1.570333, Batch Acc: 0.551133, Tokens per Sec:     7821, Lr: 0.000300
2025-05-29 21:43:05,395 - INFO - joeynmt.training - Epoch   8, Step:    73500, Batch Loss:     1.537551, Batch Acc: 0.549186, Tokens per Sec:     8282, Lr: 0.000300
2025-05-29 21:43:05,395 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:43:05,396 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:43:42,052 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.18, acc:   0.52, generation: 36.6146[sec], evaluation: 0.0000[sec]
2025-05-29 21:43:42,053 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:43:42,216 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/70500.ckpt
2025-05-29 21:43:42,234 - INFO - joeynmt.training - Example #0
2025-05-29 21:43:42,235 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:43:42,235 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:43:42,235 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'ke@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'die', 'de', 'gr@@', 'ens', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'st@@', 'aa@@', 't.', '</s>']
2025-05-29 21:43:42,236 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:43:42,236 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:43:42,236 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkeken dat de arctische ijskappen, die de arctische ijskappels die de grens 48 staten had geslaagd om 40 procent te verstaat.
2025-05-29 21:43:42,237 - INFO - joeynmt.training - Example #1
2025-05-29 21:43:42,237 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:43:42,237 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:43:42,237 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'op@@', 'en@@', 'st@@', 'and@@', 'pun@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'ver@@', 'tel@@', 't', 'dat', 'het', 'ij@@', 's@@', 'ver@@', 'tel@@', 'd.', '</s>']
2025-05-29 21:43:42,238 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:43:42,238 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:43:42,239 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de openstandpunt van dit speciale probleem omdat het niet de dikke van het ijsvertelt dat het ijsverteld.
2025-05-29 21:43:42,242 - INFO - joeynmt.training - Example #2
2025-05-29 21:43:42,242 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:43:42,242 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:43:42,242 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:43:42,243 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:43:42,243 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:43:42,244 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskaart het hart van ons wereldwijde klimaatsysteem.
2025-05-29 21:43:42,244 - INFO - joeynmt.training - Example #3
2025-05-29 21:43:42,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:43:42,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:43:42,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'z@@', 'om@@', 'er@@', 'ij@@', ',', 'en', 'je', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 21:43:42,245 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:43:42,246 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:43:42,246 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het zomerij, en je zomer.
2025-05-29 21:43:42,246 - INFO - joeynmt.training - Example #4
2025-05-29 21:43:42,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:43:42,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:43:42,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 't,', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 21:43:42,247 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:43:42,248 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:43:42,248 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift, wat er gebeurde in de afgelopen 25 jaar.
2025-05-29 21:43:51,746 - INFO - joeynmt.training - Epoch   8, Step:    73600, Batch Loss:     1.495723, Batch Acc: 0.551339, Tokens per Sec:     7291, Lr: 0.000300
2025-05-29 21:44:01,040 - INFO - joeynmt.training - Epoch   8, Step:    73700, Batch Loss:     1.473434, Batch Acc: 0.555231, Tokens per Sec:     7488, Lr: 0.000300
2025-05-29 21:44:10,185 - INFO - joeynmt.training - Epoch   8, Step:    73800, Batch Loss:     1.340687, Batch Acc: 0.545444, Tokens per Sec:     7366, Lr: 0.000300
2025-05-29 21:44:15,692 - INFO - joeynmt.training - Epoch   8: total training loss 13910.24
2025-05-29 21:44:15,692 - INFO - joeynmt.training - EPOCH 9
2025-05-29 21:44:19,550 - INFO - joeynmt.training - Epoch   9, Step:    73900, Batch Loss:     1.364466, Batch Acc: 0.565504, Tokens per Sec:     8127, Lr: 0.000300
2025-05-29 21:44:29,053 - INFO - joeynmt.training - Epoch   9, Step:    74000, Batch Loss:     1.486140, Batch Acc: 0.565398, Tokens per Sec:     7344, Lr: 0.000300
2025-05-29 21:44:29,053 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:44:29,053 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:45:04,685 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.52, generation: 35.5897[sec], evaluation: 0.0000[sec]
2025-05-29 21:45:04,695 - INFO - joeynmt.training - Example #0
2025-05-29 21:45:04,695 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:45:04,696 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:45:04,696 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'g', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'die', 'voor', 'de', 'n@@', 'aa@@', 'st', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'was', 'voor', 'de', 'n@@', 'oo@@', 'd@@', 'z@@', 'aak', 'van', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 21:45:04,697 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:45:04,697 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:45:04,698 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolg getoond om te verbeteren dat de artische ijskappels die voor de naast drie miljoen jaar de grens van de onderste 48 staten was voor de noodzaak van 40 procent geslaagd is.
2025-05-29 21:45:04,698 - INFO - joeynmt.training - Example #1
2025-05-29 21:45:04,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:45:04,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:45:04,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'kan@@', 's', 'op', 'de', 'ver@@', 'gelijk@@', 'ing', 'van', 'dit', 'ij@@', 's@@', 'ver@@', 'wer@@', 'kt', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ken,', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'ver@@', 'wer@@', 'kt', 'en', 'van', 'het', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'het', 'ij@@', 's@@', 'ver@@', '.', '</s>']
2025-05-29 21:45:04,700 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:45:04,700 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:45:04,700 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste kans op de vergelijking van dit ijsverwerkt omdat het niet de dikken, het ijs van het ijsje van het ijsje van het ijsje van het ijsverwerkt en van het ijskaart van het ijs van het ijskaart van het ijsver.
2025-05-29 21:45:04,700 - INFO - joeynmt.training - Example #2
2025-05-29 21:45:04,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:45:04,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:45:04,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 'ijke', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:45:04,702 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:45:04,702 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:45:04,702 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappelijke hart van onze wereldklimaatsysteem.
2025-05-29 21:45:04,702 - INFO - joeynmt.training - Example #3
2025-05-29 21:45:04,702 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:45:04,702 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:45:04,703 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'om@@', 'er', 'en', 'l@@', 'oo@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 21:45:04,703 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:45:04,703 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:45:04,703 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en somer en loopt in de zomer.
2025-05-29 21:45:04,704 - INFO - joeynmt.training - Example #4
2025-05-29 21:45:04,704 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:45:04,704 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:45:04,704 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'en@@', 'is', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:45:04,705 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:45:04,705 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:45:04,705 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen, is een tijdschrifenis in de afgelopen 25 jaar is gebeurd.
2025-05-29 21:45:12,980 - INFO - joeynmt.training - Epoch   9, Step:    74100, Batch Loss:     1.432743, Batch Acc: 0.564049, Tokens per Sec:     8433, Lr: 0.000300
2025-05-29 21:45:22,220 - INFO - joeynmt.training - Epoch   9, Step:    74200, Batch Loss:     1.460995, Batch Acc: 0.559649, Tokens per Sec:     7492, Lr: 0.000300
2025-05-29 21:45:31,161 - INFO - joeynmt.training - Epoch   9, Step:    74300, Batch Loss:     1.259157, Batch Acc: 0.565291, Tokens per Sec:     7549, Lr: 0.000300
2025-05-29 21:45:40,104 - INFO - joeynmt.training - Epoch   9, Step:    74400, Batch Loss:     1.440021, Batch Acc: 0.561292, Tokens per Sec:     7703, Lr: 0.000300
2025-05-29 21:45:48,840 - INFO - joeynmt.training - Epoch   9, Step:    74500, Batch Loss:     1.537074, Batch Acc: 0.564377, Tokens per Sec:     7858, Lr: 0.000300
2025-05-29 21:45:48,843 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:45:48,844 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:46:32,792 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.21, acc:   0.52, generation: 43.9071[sec], evaluation: 0.0000[sec]
2025-05-29 21:46:32,997 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/73000.ckpt
2025-05-29 21:46:33,013 - INFO - joeynmt.training - Example #0
2025-05-29 21:46:33,014 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:46:33,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:46:33,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', '4@@', '0', 'proc@@', 'ent', 'gesch@@', 'ro@@', 'm@@', 'ing.', '</s>']
2025-05-29 21:46:33,015 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:46:33,015 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:46:33,015 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen getoond om te verkijken dat de artische ijskappen die voor de artische ijskappen van de grootte van de onderste 48 staten van de 40 procent geschroming.
2025-05-29 21:46:33,016 - INFO - joeynmt.training - Example #1
2025-05-29 21:46:33,016 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:46:33,016 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:46:33,016 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'du@@', 'ur@@', 't', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'kan@@', 's', 'om', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-29 21:46:33,017 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:46:33,017 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:46:33,018 - INFO - joeynmt.training - 	Hypothesis: Maar dit duurt niet sterk genoeg de eerste kans om dit speciale probleem te verzamelen.
2025-05-29 21:46:33,018 - INFO - joeynmt.training - Example #2
2025-05-29 21:46:33,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:46:33,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:46:33,019 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'n@@', 'oo@@', 'd@@', 'za@@', 'p', 'het', 'har@@', 't', 'van', 'ons', 'mon@@', 'di@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:46:33,020 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:46:33,020 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:46:33,020 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe noodzap het hart van ons mondiale klimaatsysteem.
2025-05-29 21:46:33,020 - INFO - joeynmt.training - Example #3
2025-05-29 21:46:33,020 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:46:33,021 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:46:33,021 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lo@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 21:46:33,023 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:46:33,023 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:46:33,023 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slot in de zomer.
2025-05-29 21:46:33,023 - INFO - joeynmt.training - Example #4
2025-05-29 21:46:33,023 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:46:33,023 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:46:33,024 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'er@@', 'end', 'van', 'gebeur@@', 'ten@@', 'issen', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 21:46:33,024 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:46:33,025 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:46:33,025 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschriferend van gebeurtenissen in de laatste 25 jaar is.
2025-05-29 21:46:42,335 - INFO - joeynmt.training - Epoch   9, Step:    74600, Batch Loss:     1.513732, Batch Acc: 0.565343, Tokens per Sec:     7323, Lr: 0.000300
2025-05-29 21:46:51,743 - INFO - joeynmt.training - Epoch   9, Step:    74700, Batch Loss:     1.534925, Batch Acc: 0.562557, Tokens per Sec:     7592, Lr: 0.000300
2025-05-29 21:47:01,223 - INFO - joeynmt.training - Epoch   9, Step:    74800, Batch Loss:     1.466764, Batch Acc: 0.569487, Tokens per Sec:     7608, Lr: 0.000300
2025-05-29 21:47:10,629 - INFO - joeynmt.training - Epoch   9, Step:    74900, Batch Loss:     1.390099, Batch Acc: 0.560143, Tokens per Sec:     7605, Lr: 0.000300
2025-05-29 21:47:19,914 - INFO - joeynmt.training - Epoch   9, Step:    75000, Batch Loss:     1.526995, Batch Acc: 0.562491, Tokens per Sec:     7593, Lr: 0.000300
2025-05-29 21:47:19,915 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:47:19,915 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:47:57,388 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.52, generation: 37.4353[sec], evaluation: 0.0000[sec]
2025-05-29 21:47:57,395 - INFO - joeynmt.training - Example #0
2025-05-29 21:47:57,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:47:57,396 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:47:57,396 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 're@@', 'alis@@', 'eren', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'maakt', 'om', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'is.', '</s>']
2025-05-29 21:47:57,397 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:47:57,397 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:47:57,397 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te realiseren dat de artische ijskappen, de arctische ijskappen, die de grootte van de onderste 48 staten had gemaakt om 40 procent van de onderste 40 procent van de onderste 40 procent is.
2025-05-29 21:47:57,398 - INFO - joeynmt.training - Example #1
2025-05-29 21:47:57,398 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:47:57,398 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:47:57,398 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'kan@@', 's', 'dat', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'is', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 21:47:57,399 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:47:57,400 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:47:57,400 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste kans dat specifieke probleem is omdat het niet de dikke dikke van het ijs toont.
2025-05-29 21:47:57,400 - INFO - joeynmt.training - Example #2
2025-05-29 21:47:57,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:47:57,401 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:47:57,401 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em', 'van', 'ons', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:47:57,402 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:47:57,402 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:47:57,402 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het klimaatsysteem van ons wereldklimaatsysteem.
2025-05-29 21:47:57,403 - INFO - joeynmt.training - Example #3
2025-05-29 21:47:57,403 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:47:57,403 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:47:57,403 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 21:47:57,404 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:47:57,404 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:47:57,405 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en sluit in de zomer.
2025-05-29 21:47:57,405 - INFO - joeynmt.training - Example #4
2025-05-29 21:47:57,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:47:57,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:47:57,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'ti@@', 'me@@', '-@@', 'te@@', '-@@', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 21:47:57,406 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:47:57,407 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:47:57,407 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een time-te-opname wat er gebeurde in de laatste 25 jaar.
2025-05-29 21:48:06,782 - INFO - joeynmt.training - Epoch   9, Step:    75100, Batch Loss:     1.331755, Batch Acc: 0.561620, Tokens per Sec:     7627, Lr: 0.000300
2025-05-29 21:48:15,841 - INFO - joeynmt.training - Epoch   9, Step:    75200, Batch Loss:     1.334655, Batch Acc: 0.564483, Tokens per Sec:     7520, Lr: 0.000300
2025-05-29 21:48:24,171 - INFO - joeynmt.training - Epoch   9, Step:    75300, Batch Loss:     1.459549, Batch Acc: 0.563530, Tokens per Sec:     8238, Lr: 0.000300
2025-05-29 21:48:32,349 - INFO - joeynmt.training - Epoch   9, Step:    75400, Batch Loss:     1.372195, Batch Acc: 0.558443, Tokens per Sec:     8338, Lr: 0.000300
2025-05-29 21:48:40,096 - INFO - joeynmt.training - Epoch   9, Step:    75500, Batch Loss:     1.676398, Batch Acc: 0.558492, Tokens per Sec:     8959, Lr: 0.000300
2025-05-29 21:48:40,096 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:48:40,096 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:49:16,478 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.52, generation: 36.3476[sec], evaluation: 0.0000[sec]
2025-05-29 21:49:16,485 - INFO - joeynmt.training - Example #0
2025-05-29 21:49:16,486 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:49:16,486 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:49:16,486 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'ond', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'voor', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'st', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'ar@@', 'ti@@', 'kel', 'ge@@', 'maakt', 'is.', '</s>']
2025-05-29 21:49:16,487 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:49:16,488 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:49:16,488 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond getoond om te bekijken dat de artische ijskaart die drie miljoen jaar de grootte van de onderkant van de onderkant van de onderkant van 40 procent van de onderste 48 staten had geslaagd voor 40 procent van de rest van 40 procent van de artikel gemaakt is.
2025-05-29 21:49:16,488 - INFO - joeynmt.training - Example #1
2025-05-29 21:49:16,488 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:49:16,488 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:49:16,489 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'kan@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'dat', 'het', 'is', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'is.', '</s>']
2025-05-29 21:49:16,490 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:49:16,490 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:49:16,490 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste kant van dit speciale probleem dat het is van het ijs van het ijs van het ijs van het ijs is.
2025-05-29 21:49:16,490 - INFO - joeynmt.training - Example #2
2025-05-29 21:49:16,491 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:49:16,491 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:49:16,491 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:49:16,492 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:49:16,492 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:49:16,492 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart het hart van ons wereldwijde klimaatsysteem.
2025-05-29 21:49:16,493 - INFO - joeynmt.training - Example #3
2025-05-29 21:49:16,493 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:49:16,493 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:49:16,493 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lo@@', 't@@', 'te', 'en', 'ze', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:49:16,494 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:49:16,494 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:49:16,494 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slotte en ze zomers.
2025-05-29 21:49:16,494 - INFO - joeynmt.training - Example #4
2025-05-29 21:49:16,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:49:16,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:49:16,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 21:49:16,496 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:49:16,496 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:49:16,496 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen, is een tijdschrift van wat er gebeurde in de afgelopen 25 jaar is.
2025-05-29 21:49:25,734 - INFO - joeynmt.training - Epoch   9, Step:    75600, Batch Loss:     1.610199, Batch Acc: 0.557254, Tokens per Sec:     7338, Lr: 0.000300
2025-05-29 21:49:35,086 - INFO - joeynmt.training - Epoch   9, Step:    75700, Batch Loss:     1.386987, Batch Acc: 0.558096, Tokens per Sec:     7419, Lr: 0.000300
2025-05-29 21:49:44,288 - INFO - joeynmt.training - Epoch   9, Step:    75800, Batch Loss:     1.554332, Batch Acc: 0.563137, Tokens per Sec:     7439, Lr: 0.000300
2025-05-29 21:49:53,421 - INFO - joeynmt.training - Epoch   9, Step:    75900, Batch Loss:     1.287542, Batch Acc: 0.558128, Tokens per Sec:     7789, Lr: 0.000300
2025-05-29 21:50:02,630 - INFO - joeynmt.training - Epoch   9, Step:    76000, Batch Loss:     1.469440, Batch Acc: 0.557518, Tokens per Sec:     7589, Lr: 0.000300
2025-05-29 21:50:02,631 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:50:02,631 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:50:39,526 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.19, acc:   0.52, generation: 36.8522[sec], evaluation: 0.0000[sec]
2025-05-29 21:50:39,708 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/74500.ckpt
2025-05-29 21:50:39,720 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit_bpe/74500.ckpt
2025-05-29 21:50:39,721 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe\74500.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit_bpe\\74500.ckpt')
2025-05-29 21:50:39,725 - INFO - joeynmt.training - Example #0
2025-05-29 21:50:39,726 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:50:39,726 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:50:39,727 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'de', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'be@@', 'kijk@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 'ten', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'kan@@', 's', 'van', 'de', 'onder@@', 'kan@@', 's', 'had', 'ge@@', 'maa@@', 'kt.', '</s>']
2025-05-29 21:50:39,727 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:50:39,728 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:50:39,728 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoonde gevolgen om te bekijken, dat de artische ijskaarten die voor de artische ijskaart van de grootte van de onderkans van de onderkans had gemaakt.
2025-05-29 21:50:39,728 - INFO - joeynmt.training - Example #1
2025-05-29 21:50:39,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:50:39,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:50:39,729 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'kan@@', 's', 'dat', 'het', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'is', 'om', 'dit', 'te', 'do@@', 'en,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ken.', '</s>']
2025-05-29 21:50:39,729 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:50:39,730 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:50:39,730 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste kans dat het niet sterk genoeg is om dit te doen, omdat het niet de dikken.
2025-05-29 21:50:39,730 - INFO - joeynmt.training - Example #2
2025-05-29 21:50:39,730 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:50:39,730 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:50:39,730 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:50:39,731 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:50:39,732 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:50:39,733 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen het hart van onze wereldwijde klimaatsysteem.
2025-05-29 21:50:39,733 - INFO - joeynmt.training - Example #3
2025-05-29 21:50:39,733 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:50:39,733 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:50:39,733 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'ten', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er@@', 'ij@@', '.', '</s>']
2025-05-29 21:50:39,734 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:50:39,734 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:50:39,734 - INFO - joeynmt.training - 	Hypothesis: Ze groeiten in de winter en sluit in de zomerij.
2025-05-29 21:50:39,734 - INFO - joeynmt.training - Example #4
2025-05-29 21:50:39,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:50:39,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:50:39,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 21:50:39,736 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:50:39,736 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:50:39,736 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift in de laatste 25 jaar.
2025-05-29 21:50:49,437 - INFO - joeynmt.training - Epoch   9, Step:    76100, Batch Loss:     1.281930, Batch Acc: 0.556142, Tokens per Sec:     7052, Lr: 0.000300
2025-05-29 21:50:58,482 - INFO - joeynmt.training - Epoch   9, Step:    76200, Batch Loss:     1.485886, Batch Acc: 0.560011, Tokens per Sec:     7874, Lr: 0.000300
2025-05-29 21:51:08,006 - INFO - joeynmt.training - Epoch   9, Step:    76300, Batch Loss:     1.564624, Batch Acc: 0.559524, Tokens per Sec:     7407, Lr: 0.000300
2025-05-29 21:51:16,976 - INFO - joeynmt.training - Epoch   9, Step:    76400, Batch Loss:     1.373626, Batch Acc: 0.552756, Tokens per Sec:     7827, Lr: 0.000300
2025-05-29 21:51:25,802 - INFO - joeynmt.training - Epoch   9, Step:    76500, Batch Loss:     1.600245, Batch Acc: 0.555101, Tokens per Sec:     7806, Lr: 0.000300
2025-05-29 21:51:25,802 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:51:25,802 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:52:02,913 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.23, acc:   0.52, generation: 37.0713[sec], evaluation: 0.0000[sec]
2025-05-29 21:52:02,919 - INFO - joeynmt.training - Example #0
2025-05-29 21:52:02,920 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:52:02,920 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:52:02,920 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'antwoor@@', 'den', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't@@', 'jes', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 21:52:02,921 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:52:02,922 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:52:02,922 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verantwoorden te zien dat de arctische ijskaartjes die voor de onderste 48 staten van de onderste 40 procent van de onderste 40 procent geslaagd is.
2025-05-29 21:52:02,922 - INFO - joeynmt.training - Example #1
2025-05-29 21:52:02,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:52:02,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:52:02,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'gaat', 'niet', 'om', 'genoe@@', 'g', 'te', 'begin@@', 'nen', 'met', 'het', 'eer@@', 'st@@', 'he@@', 'er@@', 'lijk@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 21:52:02,923 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:52:02,923 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:52:02,924 - INFO - joeynmt.training - 	Hypothesis: Maar dit gaat niet om genoeg te beginnen met het eerstheerlijkheid van dit speciale probleem toont.
2025-05-29 21:52:02,924 - INFO - joeynmt.training - Example #2
2025-05-29 21:52:02,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:52:02,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:52:02,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'on@@', 'dan@@', 'ks', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:52:02,926 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:52:02,926 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:52:02,926 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskaart het ondanks van onze wereldwijd klimaatsysteem.
2025-05-29 21:52:02,927 - INFO - joeynmt.training - Example #3
2025-05-29 21:52:02,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:52:02,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:52:02,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:52:02,928 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:52:02,928 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:52:02,928 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en sluit in de zomers.
2025-05-29 21:52:02,928 - INFO - joeynmt.training - Example #4
2025-05-29 21:52:02,929 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:52:02,929 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:52:02,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 21:52:02,930 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:52:02,930 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:52:02,931 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdje van wat er gebeurde in de afgelopen 25 jaar.
2025-05-29 21:52:11,164 - INFO - joeynmt.training - Epoch   9, Step:    76600, Batch Loss:     1.360157, Batch Acc: 0.560420, Tokens per Sec:     8592, Lr: 0.000300
2025-05-29 21:52:19,468 - INFO - joeynmt.training - Epoch   9, Step:    76700, Batch Loss:     1.431059, Batch Acc: 0.558953, Tokens per Sec:     8430, Lr: 0.000300
2025-05-29 21:52:28,155 - INFO - joeynmt.training - Epoch   9, Step:    76800, Batch Loss:     1.507483, Batch Acc: 0.560879, Tokens per Sec:     8021, Lr: 0.000300
2025-05-29 21:52:37,619 - INFO - joeynmt.training - Epoch   9, Step:    76900, Batch Loss:     1.530547, Batch Acc: 0.560755, Tokens per Sec:     7328, Lr: 0.000300
2025-05-29 21:52:47,030 - INFO - joeynmt.training - Epoch   9, Step:    77000, Batch Loss:     1.362978, Batch Acc: 0.560319, Tokens per Sec:     7411, Lr: 0.000300
2025-05-29 21:52:47,032 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:52:47,032 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:53:23,613 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.20, acc:   0.52, generation: 36.5411[sec], evaluation: 0.0000[sec]
2025-05-29 21:53:23,802 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/72000.ckpt
2025-05-29 21:53:23,817 - INFO - joeynmt.training - Example #0
2025-05-29 21:53:23,818 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:53:23,818 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:53:23,818 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 'z@@', 'er@@', 'c@@', 'ap@@', 'ac@@', 'iteit', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'maakt', 'voor', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 21:53:23,820 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:53:23,821 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:53:23,821 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verbeteren dat de artische ijzercapaciteit die de grootte van de onderste 48 staten had gemaakt voor de grootte van de onderste 40 procent geslaagd is.
2025-05-29 21:53:23,822 - INFO - joeynmt.training - Example #1
2025-05-29 21:53:23,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:53:23,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:53:23,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'ver@@', 'de@@', 'dig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'ij@@', 'z@@', 'er@@', 'uit', 'dat', 'het', 'ij@@', 'z@@', 'er@@', 'uit', 'dat', 'het', 'ij@@', 'z@@', 'er@@', 'uit', 'zi@@', 'en,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'z@@', 'er@@', 'to@@', 'e', 'te', 'laten', 'zien.', '</s>']
2025-05-29 21:53:23,823 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:53:23,823 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:53:23,824 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste verdedigheid van dit speciale probleem van dit ijzeruit dat het ijzeruit dat het ijzeruit zien, omdat het niet de dikke van het ijzertoe te laten zien.
2025-05-29 21:53:23,824 - INFO - joeynmt.training - Example #2
2025-05-29 21:53:23,824 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:53:23,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:53:23,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 'z@@', 'er@@', 's@@', 'k@@', 'op', 'het', 's@@', 'im@@', 'p@@', 'ele', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:53:23,825 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:53:23,825 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:53:23,825 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijzerskop het simpele klimaatsysteem.
2025-05-29 21:53:23,825 - INFO - joeynmt.training - Example #3
2025-05-29 21:53:23,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:53:23,825 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:53:23,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lo@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:53:23,826 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:53:23,826 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:53:23,826 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slot in de zomers.
2025-05-29 21:53:23,826 - INFO - joeynmt.training - Example #4
2025-05-29 21:53:23,826 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:53:23,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:53:23,826 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 21:53:23,827 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:53:23,827 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:53:23,827 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift van wat er gebeurt in de afgelopen 25 jaar.
2025-05-29 21:53:33,229 - INFO - joeynmt.training - Epoch   9, Step:    77100, Batch Loss:     1.560885, Batch Acc: 0.558004, Tokens per Sec:     7175, Lr: 0.000300
2025-05-29 21:53:42,180 - INFO - joeynmt.training - Epoch   9, Step:    77200, Batch Loss:     1.515267, Batch Acc: 0.560156, Tokens per Sec:     7837, Lr: 0.000300
2025-05-29 21:53:51,245 - INFO - joeynmt.training - Epoch   9, Step:    77300, Batch Loss:     1.711410, Batch Acc: 0.561625, Tokens per Sec:     7801, Lr: 0.000300
2025-05-29 21:54:00,366 - INFO - joeynmt.training - Epoch   9, Step:    77400, Batch Loss:     1.352390, Batch Acc: 0.558487, Tokens per Sec:     7956, Lr: 0.000300
2025-05-29 21:54:09,105 - INFO - joeynmt.training - Epoch   9, Step:    77500, Batch Loss:     1.393738, Batch Acc: 0.550147, Tokens per Sec:     8114, Lr: 0.000300
2025-05-29 21:54:09,111 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:54:09,112 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:54:49,902 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.19, acc:   0.52, generation: 40.7493[sec], evaluation: 0.0000[sec]
2025-05-29 21:54:50,086 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/77000.ckpt
2025-05-29 21:54:50,096 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit_bpe/77000.ckpt
2025-05-29 21:54:50,097 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe\77000.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit_bpe\\77000.ckpt')
2025-05-29 21:54:50,103 - INFO - joeynmt.training - Example #0
2025-05-29 21:54:50,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:54:50,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:54:50,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['A@@', 'f@@', 'gel@@', 'open', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'de', 'gro@@', 'ter@@', 'e', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'ha@@', 'd,', 'om', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'te', 'zijn.', '</s>']
2025-05-29 21:54:50,105 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:54:50,105 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:54:50,105 - INFO - joeynmt.training - 	Hypothesis: Afgelopen jaar heb ik deze twee gevolgen om te verbeteren dat de artische ijskappen die de artische ijskappen die de grotere 48 staten had gehad, om 40 procent geslaagd te zijn.
2025-05-29 21:54:50,105 - INFO - joeynmt.training - Example #1
2025-05-29 21:54:50,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:54:50,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:54:50,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'ap@@', 'el@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's', 'is', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'we@@', 'er', 'van', 'het', 'ij@@', 's', 'is.', '</s>']
2025-05-29 21:54:50,107 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:54:50,107 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:54:50,107 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste stapelheid van dit speciale probleem van dit ijs is omdat het niet de dikke van het ijs weer van het ijs is.
2025-05-29 21:54:50,107 - INFO - joeynmt.training - Example #2
2025-05-29 21:54:50,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:54:50,107 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:54:50,107 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'op', 'het', 'sl@@', 'aa@@', 'gende', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:54:50,108 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:54:50,108 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:54:50,108 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskop het slaagende hart van ons wereldwijd klimaatsysteem.
2025-05-29 21:54:50,109 - INFO - joeynmt.training - Example #3
2025-05-29 21:54:50,109 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:54:50,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:54:50,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'cht', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:54:50,110 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:54:50,110 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:54:50,110 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slucht in het zomers.
2025-05-29 21:54:50,110 - INFO - joeynmt.training - Example #4
2025-05-29 21:54:50,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:54:50,111 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:54:50,111 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:54:50,112 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:54:50,112 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:54:50,112 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschriften wat er gebeurde in de afgelopen 25 jaar gebeurd.
2025-05-29 21:54:59,621 - INFO - joeynmt.training - Epoch   9, Step:    77600, Batch Loss:     1.579175, Batch Acc: 0.548786, Tokens per Sec:     7194, Lr: 0.000300
2025-05-29 21:55:09,006 - INFO - joeynmt.training - Epoch   9, Step:    77700, Batch Loss:     1.687083, Batch Acc: 0.555727, Tokens per Sec:     7507, Lr: 0.000300
2025-05-29 21:55:18,292 - INFO - joeynmt.training - Epoch   9, Step:    77800, Batch Loss:     1.473717, Batch Acc: 0.560979, Tokens per Sec:     7602, Lr: 0.000300
2025-05-29 21:55:27,527 - INFO - joeynmt.training - Epoch   9, Step:    77900, Batch Loss:     1.471762, Batch Acc: 0.556122, Tokens per Sec:     7706, Lr: 0.000300
2025-05-29 21:55:36,578 - INFO - joeynmt.training - Epoch   9, Step:    78000, Batch Loss:     1.540495, Batch Acc: 0.562614, Tokens per Sec:     7705, Lr: 0.000300
2025-05-29 21:55:36,578 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:55:36,578 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:56:05,900 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.19, acc:   0.52, generation: 29.2840[sec], evaluation: 0.0000[sec]
2025-05-29 21:56:06,074 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/71000.ckpt
2025-05-29 21:56:06,096 - INFO - joeynmt.training - Example #0
2025-05-29 21:56:06,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:56:06,097 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:56:06,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'voor', 'de', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'te@@', 'erd', 'is.', '</s>']
2025-05-29 21:56:06,099 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:56:06,099 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:56:06,099 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te bekijken dat de artische ijskappen, die de artische ijskappen, die de grootte van de onderste 48 staten had geslaagd voor de 40 procent geslaagteerd is.
2025-05-29 21:56:06,099 - INFO - joeynmt.training - Example #1
2025-05-29 21:56:06,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:56:06,100 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:56:06,100 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'ver@@', 'n@@', 'u@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 21:56:06,101 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:56:06,101 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:56:06,101 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste vernut van dit speciale probleem, omdat het niet de dik van het ijs toont.
2025-05-29 21:56:06,101 - INFO - joeynmt.training - Example #2
2025-05-29 21:56:06,101 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:56:06,101 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:56:06,102 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'het', 'sl@@', 'ag@@', 'syste@@', 'em', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:56:06,102 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:56:06,103 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:56:06,103 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe het slagsysteem van ons wereldwijde klimaatsysteem.
2025-05-29 21:56:06,103 - INFO - joeynmt.training - Example #3
2025-05-29 21:56:06,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:56:06,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:56:06,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'o@@', 'k@@', 'ken@@', 'de', 'en', 'en', 's@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 21:56:06,104 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:56:06,104 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:56:06,104 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schokkende en en somers.
2025-05-29 21:56:06,104 - INFO - joeynmt.training - Example #4
2025-05-29 21:56:06,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:56:06,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:56:06,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:56:06,106 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:56:06,106 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:56:06,106 - INFO - joeynmt.training - 	Hypothesis: De volgende dia ik jullie laten zien is een tijdschrift van wat er gebeurde in de laatste 25 jaar gebeurd.
2025-05-29 21:56:15,731 - INFO - joeynmt.training - Epoch   9, Step:    78100, Batch Loss:     1.430779, Batch Acc: 0.557382, Tokens per Sec:     7094, Lr: 0.000210
2025-05-29 21:56:25,121 - INFO - joeynmt.training - Epoch   9, Step:    78200, Batch Loss:     1.682300, Batch Acc: 0.556376, Tokens per Sec:     7469, Lr: 0.000210
2025-05-29 21:56:34,076 - INFO - joeynmt.training - Epoch   9, Step:    78300, Batch Loss:     1.512740, Batch Acc: 0.560057, Tokens per Sec:     7727, Lr: 0.000210
2025-05-29 21:56:43,148 - INFO - joeynmt.training - Epoch   9, Step:    78400, Batch Loss:     1.391465, Batch Acc: 0.559146, Tokens per Sec:     7720, Lr: 0.000210
2025-05-29 21:56:52,197 - INFO - joeynmt.training - Epoch   9, Step:    78500, Batch Loss:     1.531234, Batch Acc: 0.563769, Tokens per Sec:     7735, Lr: 0.000210
2025-05-29 21:56:52,198 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:56:52,198 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:57:29,274 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.08, acc:   0.52, generation: 37.0361[sec], evaluation: 0.0000[sec]
2025-05-29 21:57:29,275 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:57:29,477 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/78000.ckpt
2025-05-29 21:57:29,494 - INFO - joeynmt.training - Example #0
2025-05-29 21:57:29,494 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:57:29,494 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:57:29,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 'ijke', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'ond', 'van', 'de', 'gr@@', 'ond', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'lan@@', 'den', 'die', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 21:57:29,496 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:57:29,497 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:57:29,497 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen getoond om te bekijken dat de artische ijskappelijke ijskappen, die de grootte van de grond van de grond drie miljoen jaar de grootte van de landen die 40 procent geslaagd is.
2025-05-29 21:57:29,497 - INFO - joeynmt.training - Example #1
2025-05-29 21:57:29,497 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:57:29,497 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:57:29,497 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'kan@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van@@', 'uit', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'ij@@', 's', 'ij@@', 's', 'is', 'ge@@', 'to@@', 'on@@', 'd.', '</s>']
2025-05-29 21:57:29,498 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:57:29,499 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:57:29,499 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste kant van dit speciale probleem van dit speciale probleem vanuit het ijs van het ijs van ijs ijs is getoond.
2025-05-29 21:57:29,499 - INFO - joeynmt.training - Example #2
2025-05-29 21:57:29,500 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:57:29,500 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:57:29,500 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'is', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:57:29,501 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:57:29,501 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:57:29,501 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe is het hart van onze wereldwijd klimaatsysteem.
2025-05-29 21:57:29,501 - INFO - joeynmt.training - Example #3
2025-05-29 21:57:29,502 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:57:29,502 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:57:29,502 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 21:57:29,503 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:57:29,503 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:57:29,503 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluit in de zomer.
2025-05-29 21:57:29,503 - INFO - joeynmt.training - Example #4
2025-05-29 21:57:29,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:57:29,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:57:29,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:57:29,504 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:57:29,504 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:57:29,504 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift in de laatste 25 jaar is gebeurd.
2025-05-29 21:57:38,740 - INFO - joeynmt.training - Epoch   9, Step:    78600, Batch Loss:     1.563878, Batch Acc: 0.564435, Tokens per Sec:     7538, Lr: 0.000210
2025-05-29 21:57:48,249 - INFO - joeynmt.training - Epoch   9, Step:    78700, Batch Loss:     1.221007, Batch Acc: 0.567508, Tokens per Sec:     7495, Lr: 0.000210
2025-05-29 21:57:57,563 - INFO - joeynmt.training - Epoch   9, Step:    78800, Batch Loss:     1.342960, Batch Acc: 0.569899, Tokens per Sec:     7391, Lr: 0.000210
2025-05-29 21:58:06,923 - INFO - joeynmt.training - Epoch   9, Step:    78900, Batch Loss:     1.442814, Batch Acc: 0.559177, Tokens per Sec:     7618, Lr: 0.000210
2025-05-29 21:58:16,183 - INFO - joeynmt.training - Epoch   9, Step:    79000, Batch Loss:     1.459368, Batch Acc: 0.564760, Tokens per Sec:     7396, Lr: 0.000210
2025-05-29 21:58:16,184 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:58:16,184 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:58:55,643 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.07, acc:   0.53, generation: 39.4201[sec], evaluation: 0.0000[sec]
2025-05-29 21:58:55,644 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:58:55,849 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/76000.ckpt
2025-05-29 21:58:55,872 - INFO - joeynmt.training - Example #0
2025-05-29 21:58:55,873 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 21:58:55,873 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 21:58:55,873 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't@@', 'jes', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd', 'is', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd', 'voor', 'de', 'st@@', 'aten', 'van', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd', 'is.', '</s>']
2025-05-29 21:58:55,874 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:58:55,874 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 21:58:55,874 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te bekijken dat de artische ijskaartjes die de artische ijskaart die drie miljoen jaar de grootte van de onderste 40 procent gegooid is gegooid voor de staten van 40 procent gegooid is.
2025-05-29 21:58:55,875 - INFO - joeynmt.training - Example #1
2025-05-29 21:58:55,875 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 21:58:55,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 21:58:55,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'aan@@', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 21:58:55,876 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:58:55,876 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 21:58:55,877 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerst van dit speciale probleem van dit speciale probleem aantoont.
2025-05-29 21:58:55,877 - INFO - joeynmt.training - Example #2
2025-05-29 21:58:55,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 21:58:55,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 21:58:55,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'op', 'het', 'sl@@', 'aa@@', 'g@@', 'd', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 21:58:55,878 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:58:55,878 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 21:58:55,878 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskop het slaagd van onze wereldwijde klimaatsysteem.
2025-05-29 21:58:55,878 - INFO - joeynmt.training - Example #3
2025-05-29 21:58:55,879 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 21:58:55,879 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 21:58:55,879 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 21:58:55,880 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:58:55,880 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 21:58:55,880 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluit in de winter en sluit in de zomer.
2025-05-29 21:58:55,880 - INFO - joeynmt.training - Example #4
2025-05-29 21:58:55,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 21:58:55,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 21:58:55,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'aal@@', 'd', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 21:58:55,882 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:58:55,882 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 21:58:55,882 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrifaald in de laatste 25 jaar gebeurd.
2025-05-29 21:59:05,311 - INFO - joeynmt.training - Epoch   9, Step:    79100, Batch Loss:     1.315897, Batch Acc: 0.564386, Tokens per Sec:     7433, Lr: 0.000210
2025-05-29 21:59:14,760 - INFO - joeynmt.training - Epoch   9, Step:    79200, Batch Loss:     1.543741, Batch Acc: 0.559301, Tokens per Sec:     7430, Lr: 0.000210
2025-05-29 21:59:23,344 - INFO - joeynmt.training - Epoch   9, Step:    79300, Batch Loss:     1.588373, Batch Acc: 0.563451, Tokens per Sec:     8047, Lr: 0.000210
2025-05-29 21:59:31,763 - INFO - joeynmt.training - Epoch   9, Step:    79400, Batch Loss:     1.434798, Batch Acc: 0.560496, Tokens per Sec:     8457, Lr: 0.000210
2025-05-29 21:59:40,000 - INFO - joeynmt.training - Epoch   9, Step:    79500, Batch Loss:     1.431045, Batch Acc: 0.567311, Tokens per Sec:     8393, Lr: 0.000210
2025-05-29 21:59:40,000 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 21:59:40,001 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:00:17,523 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.52, generation: 37.4815[sec], evaluation: 0.0000[sec]
2025-05-29 22:00:17,524 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:00:17,744 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/77500.ckpt
2025-05-29 22:00:17,762 - INFO - joeynmt.training - Example #0
2025-05-29 22:00:17,763 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:00:17,763 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:00:17,763 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'die', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'maakt', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'g@@', 'ig@@', 'd', 'is.', '</s>']
2025-05-29 22:00:17,764 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:00:17,764 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:00:17,764 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te bekijken dat de artische ijskappen die de artische ijskappels die de grens van de onderste 48 staten had gemaakt voor de onderste 40 procent gegigd is.
2025-05-29 22:00:17,764 - INFO - joeynmt.training - Example #1
2025-05-29 22:00:17,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:00:17,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:00:17,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'jes', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'de', 'ij@@', 's@@', 'k@@', 'oor@@', 't@@', 's.', '</s>']
2025-05-29 22:00:17,766 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:00:17,766 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:00:17,766 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerst van dit speciale probleem van dit speciale probleem omdat het niet de dikke ijskjes van het ijsje van de ijskoorts.
2025-05-29 22:00:17,766 - INFO - joeynmt.training - Example #2
2025-05-29 22:00:17,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:00:17,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:00:17,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'op', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:00:17,767 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:00:17,767 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:00:17,767 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskop het slaagsysteem van onze wereldwijde klimaatsysteem.
2025-05-29 22:00:17,767 - INFO - joeynmt.training - Example #3
2025-05-29 22:00:17,768 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:00:17,768 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:00:17,768 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'en', 'en', 's@@', 'om@@', 'er@@', 'eer@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:00:17,769 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:00:17,769 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:00:17,769 - INFO - joeynmt.training - 	Hypothesis: Ze groeien en en somereert in de zomers.
2025-05-29 22:00:17,769 - INFO - joeynmt.training - Example #4
2025-05-29 22:00:17,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:00:17,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:00:17,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'ti@@', 'me@@', '-@@', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:00:17,771 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:00:17,771 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:00:17,771 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een time-opname wat er gebeurde in de laatste 25 jaar gebeurd.
2025-05-29 22:00:27,651 - INFO - joeynmt.training - Epoch   9, Step:    79600, Batch Loss:     1.498374, Batch Acc: 0.561639, Tokens per Sec:     6862, Lr: 0.000210
2025-05-29 22:00:37,665 - INFO - joeynmt.training - Epoch   9, Step:    79700, Batch Loss:     1.460374, Batch Acc: 0.566212, Tokens per Sec:     6995, Lr: 0.000210
2025-05-29 22:00:47,759 - INFO - joeynmt.training - Epoch   9, Step:    79800, Batch Loss:     1.596334, Batch Acc: 0.561075, Tokens per Sec:     6997, Lr: 0.000210
2025-05-29 22:00:57,669 - INFO - joeynmt.training - Epoch   9, Step:    79900, Batch Loss:     1.560495, Batch Acc: 0.565645, Tokens per Sec:     7161, Lr: 0.000210
2025-05-29 22:01:07,817 - INFO - joeynmt.training - Epoch   9, Step:    80000, Batch Loss:     1.392809, Batch Acc: 0.561863, Tokens per Sec:     7103, Lr: 0.000210
2025-05-29 22:01:07,822 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:01:07,824 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:01:50,211 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.03, acc:   0.53, generation: 42.3382[sec], evaluation: 0.0000[sec]
2025-05-29 22:01:50,212 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:01:50,403 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/72500.ckpt
2025-05-29 22:01:50,423 - INFO - joeynmt.training - Example #0
2025-05-29 22:01:50,424 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:01:50,424 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:01:50,424 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'maakt', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'c@@', 'or@@', 'te@@', 'mp@@', 'o', 'van', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'im@@', 'd.', '</s>']
2025-05-29 22:01:50,425 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:01:50,425 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:01:50,425 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen om te bekijken dat de artische ijskappen, dat de artische ijskappen, die de grootte van de onderste 48 staten had gemaakt voor de onderste 40 procent gecortempo van 40 procent geslimd.
2025-05-29 22:01:50,426 - INFO - joeynmt.training - Example #1
2025-05-29 22:01:50,426 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:01:50,426 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:01:50,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'deze', 'proble@@', 'men', 'van', 'deze', 'proble@@', 'em', 'van', 'de', 'ij@@', 's@@', 'ver@@', 'mo@@', 'gen', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'de', 'ij@@', 's@@', 'ver@@', 'wij@@', 'der@@', 't.', '</s>']
2025-05-29 22:01:50,427 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:01:50,427 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:01:50,427 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerst van deze problemen van deze probleem van de ijsvermogen van het ijsje van het ijsje van de ijsverwijdert.
2025-05-29 22:01:50,428 - INFO - joeynmt.training - Example #2
2025-05-29 22:01:50,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:01:50,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:01:50,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'op', 'het', 'ver@@', 'sla@@', 'g', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:01:50,429 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:01:50,429 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:01:50,430 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskop het verslag van onze wereldwijd klimaatsysteem.
2025-05-29 22:01:50,430 - INFO - joeynmt.training - Example #3
2025-05-29 22:01:50,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:01:50,430 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:01:50,430 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 22:01:50,431 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:01:50,432 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:01:50,432 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluit in de zomer.
2025-05-29 22:01:50,432 - INFO - joeynmt.training - Example #4
2025-05-29 22:01:50,432 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:01:50,433 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:01:50,433 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:01:50,434 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:01:50,434 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:01:50,434 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschrift van wat er in de laatste 25 jaar gebeurd.
2025-05-29 22:02:00,403 - INFO - joeynmt.training - Epoch   9, Step:    80100, Batch Loss:     1.415000, Batch Acc: 0.566007, Tokens per Sec:     7123, Lr: 0.000210
2025-05-29 22:02:10,152 - INFO - joeynmt.training - Epoch   9, Step:    80200, Batch Loss:     1.635319, Batch Acc: 0.563207, Tokens per Sec:     7125, Lr: 0.000210
2025-05-29 22:02:19,813 - INFO - joeynmt.training - Epoch   9, Step:    80300, Batch Loss:     1.518331, Batch Acc: 0.564339, Tokens per Sec:     7182, Lr: 0.000210
2025-05-29 22:02:29,756 - INFO - joeynmt.training - Epoch   9, Step:    80400, Batch Loss:     1.396843, Batch Acc: 0.562646, Tokens per Sec:     6783, Lr: 0.000210
2025-05-29 22:02:39,545 - INFO - joeynmt.training - Epoch   9, Step:    80500, Batch Loss:     1.377932, Batch Acc: 0.567783, Tokens per Sec:     7170, Lr: 0.000210
2025-05-29 22:02:39,545 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:02:39,546 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:03:18,385 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.04, acc:   0.53, generation: 38.7997[sec], evaluation: 0.0000[sec]
2025-05-29 22:03:18,573 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/73500.ckpt
2025-05-29 22:03:18,593 - INFO - joeynmt.training - Example #0
2025-05-29 22:03:18,594 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:03:18,594 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:03:18,594 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'om', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 22:03:18,595 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:03:18,595 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:03:18,596 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te bekijken dat de artische ijskappen, dat de artische ijskappen, die de grens van de onderste 48 staten had geslaagd om 40 procent geslaagd is.
2025-05-29 22:03:18,596 - INFO - joeynmt.training - Example #1
2025-05-29 22:03:18,596 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:03:18,596 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:03:18,596 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'to@@', 'e', 'te', 'laten', 'zien', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ken.', '</s>']
2025-05-29 22:03:18,597 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:03:18,597 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:03:18,597 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerst van dit speciale probleem van dit speciale probleem toe te laten zien omdat het niet de dikken.
2025-05-29 22:03:18,598 - INFO - joeynmt.training - Example #2
2025-05-29 22:03:18,598 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:03:18,598 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:03:18,598 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'op', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em', 'van', 'onze', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:03:18,599 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:03:18,599 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:03:18,600 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskop het slaagsysteem van onze wereldklimaatsysteem.
2025-05-29 22:03:18,600 - INFO - joeynmt.training - Example #3
2025-05-29 22:03:18,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:03:18,600 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:03:18,600 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'k@@', 'ru@@', 'i@@', 'p', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:03:18,601 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:03:18,601 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:03:18,601 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en skruip in de zomers.
2025-05-29 22:03:18,602 - INFO - joeynmt.training - Example #4
2025-05-29 22:03:18,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:03:18,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:03:18,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:03:18,603 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:03:18,603 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:03:18,604 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschriften wat er gebeurde in de laatste 25 jaar gebeurd.
2025-05-29 22:03:27,494 - INFO - joeynmt.training - Epoch   9, Step:    80600, Batch Loss:     1.424487, Batch Acc: 0.562302, Tokens per Sec:     7590, Lr: 0.000210
2025-05-29 22:03:36,893 - INFO - joeynmt.training - Epoch   9, Step:    80700, Batch Loss:     1.405950, Batch Acc: 0.560243, Tokens per Sec:     7159, Lr: 0.000210
2025-05-29 22:03:46,618 - INFO - joeynmt.training - Epoch   9, Step:    80800, Batch Loss:     1.441991, Batch Acc: 0.570224, Tokens per Sec:     7344, Lr: 0.000210
2025-05-29 22:03:56,475 - INFO - joeynmt.training - Epoch   9, Step:    80900, Batch Loss:     1.183164, Batch Acc: 0.559565, Tokens per Sec:     6888, Lr: 0.000210
2025-05-29 22:04:06,311 - INFO - joeynmt.training - Epoch   9, Step:    81000, Batch Loss:     1.422215, Batch Acc: 0.568226, Tokens per Sec:     7262, Lr: 0.000210
2025-05-29 22:04:06,313 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:04:06,313 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:04:47,058 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.04, acc:   0.53, generation: 40.7037[sec], evaluation: 0.0000[sec]
2025-05-29 22:04:47,251 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/78500.ckpt
2025-05-29 22:04:47,273 - INFO - joeynmt.training - Example #0
2025-05-29 22:04:47,274 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:04:47,274 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:04:47,274 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'ver@@', 'kijken', 'naar', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'oor@@', 'z@@', 'aa@@', 'kt', 'is.', '</s>']
2025-05-29 22:04:47,275 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:04:47,275 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:04:47,275 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te verkijken naar de arctische ijskappen, dat de arctische ijskappen, die de grens van de onderste 48 staten had geslaagd om 40 procent te veroorzaakt is.
2025-05-29 22:04:47,276 - INFO - joeynmt.training - Example #1
2025-05-29 22:04:47,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:04:47,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:04:47,276 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'eil@@', 'ijk@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's', 'is', 'niet', 'de', 'di@@', 'k@@', 'ker', 'van', 'ij@@', 's@@', 'k@@', 'we@@', 'st@@', 'ie.', '</s>']
2025-05-29 22:04:47,277 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:04:47,277 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:04:47,278 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste steilijkheid van dit speciale probleem van dit ijs is niet de dikker van ijskwestie.
2025-05-29 22:04:47,278 - INFO - joeynmt.training - Example #2
2025-05-29 22:04:47,278 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:04:47,278 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:04:47,278 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:04:47,279 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:04:47,279 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:04:47,279 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskaart het slaagsysteem.
2025-05-29 22:04:47,279 - INFO - joeynmt.training - Example #3
2025-05-29 22:04:47,279 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:04:47,279 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:04:47,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'i@@', 'ten', 'en', 's@@', 'lo@@', 't.', '</s>']
2025-05-29 22:04:47,280 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:04:47,280 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:04:47,281 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluit in de winter en sluiten en slot.
2025-05-29 22:04:47,281 - INFO - joeynmt.training - Example #4
2025-05-29 22:04:47,281 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:04:47,281 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:04:47,281 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 22:04:47,282 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:04:47,282 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:04:47,283 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen, is een tijdschrift van wat er gebeurt in de laatste 25 jaar.
2025-05-29 22:04:57,078 - INFO - joeynmt.training - Epoch   9, Step:    81100, Batch Loss:     1.445974, Batch Acc: 0.562889, Tokens per Sec:     6920, Lr: 0.000210
2025-05-29 22:05:06,909 - INFO - joeynmt.training - Epoch   9, Step:    81200, Batch Loss:     1.454223, Batch Acc: 0.567426, Tokens per Sec:     7060, Lr: 0.000210
2025-05-29 22:05:16,387 - INFO - joeynmt.training - Epoch   9, Step:    81300, Batch Loss:     1.363197, Batch Acc: 0.567452, Tokens per Sec:     7277, Lr: 0.000210
2025-05-29 22:05:25,900 - INFO - joeynmt.training - Epoch   9, Step:    81400, Batch Loss:     1.474376, Batch Acc: 0.562448, Tokens per Sec:     7302, Lr: 0.000210
2025-05-29 22:05:35,414 - INFO - joeynmt.training - Epoch   9, Step:    81500, Batch Loss:     1.361299, Batch Acc: 0.567498, Tokens per Sec:     7391, Lr: 0.000210
2025-05-29 22:05:35,415 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:05:35,415 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:06:11,959 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.01, acc:   0.53, generation: 36.5000[sec], evaluation: 0.0000[sec]
2025-05-29 22:06:11,960 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:06:12,162 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/79000.ckpt
2025-05-29 22:06:12,181 - INFO - joeynmt.training - Example #0
2025-05-29 22:06:12,181 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:06:12,182 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:06:12,182 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'kre@@', 'gen', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'st@@', 'aten', 'te', 'zijn.', '</s>']
2025-05-29 22:06:12,183 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:06:12,183 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:06:12,184 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te bekijken dat de arctische ijskappen, die de arctische ijskappen, die de grootte van de onderste 48 staten had gekregen om 40 procent te verstaten te zijn.
2025-05-29 22:06:12,184 - INFO - joeynmt.training - Example #1
2025-05-29 22:06:12,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:06:12,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:06:12,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'gaat', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'to@@', 'on@@', 't', 'van', 'de', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 'z@@', 'er', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's', 'is', 'het', 'niet', 'zo', 'veel', 'genoe@@', 'g', 'is.', '</s>']
2025-05-29 22:06:12,186 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:06:12,186 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:06:12,186 - INFO - joeynmt.training - 	Hypothesis: Maar dit gaat niet sterk genoeg de eerst van dit speciale probleem omdat het niet de dikke ijs toont van de ijskaart van de ijs van de ijs van de ijskaart van de ijs van de ijs van de ijs van de ijs van de ijzer niet de dikke van de ijs is het niet zo veel genoeg is.
2025-05-29 22:06:12,186 - INFO - joeynmt.training - Example #2
2025-05-29 22:06:12,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:06:12,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:06:12,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:06:12,188 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:06:12,188 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:06:12,188 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappen, het hart van ons wereldklimaatsysteem.
2025-05-29 22:06:12,188 - INFO - joeynmt.training - Example #3
2025-05-29 22:06:12,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:06:12,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:06:12,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'er@@', 'm', 'in', 'de', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 22:06:12,190 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:06:12,190 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:06:12,190 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scherm in de zomert.
2025-05-29 22:06:12,190 - INFO - joeynmt.training - Example #4
2025-05-29 22:06:12,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:06:12,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:06:12,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'er@@', 't@@', 'je', 'dat', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:06:12,192 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:06:12,192 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:06:12,192 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrifertje dat in de laatste 25 jaar gebeurd.
2025-05-29 22:06:22,591 - INFO - joeynmt.training - Epoch   9, Step:    81600, Batch Loss:     1.248714, Batch Acc: 0.572235, Tokens per Sec:     6564, Lr: 0.000210
2025-05-29 22:06:32,566 - INFO - joeynmt.training - Epoch   9, Step:    81700, Batch Loss:     1.402392, Batch Acc: 0.568691, Tokens per Sec:     6870, Lr: 0.000210
2025-05-29 22:06:42,299 - INFO - joeynmt.training - Epoch   9, Step:    81800, Batch Loss:     1.378170, Batch Acc: 0.560596, Tokens per Sec:     7121, Lr: 0.000210
2025-05-29 22:06:52,066 - INFO - joeynmt.training - Epoch   9, Step:    81900, Batch Loss:     1.443846, Batch Acc: 0.559857, Tokens per Sec:     7178, Lr: 0.000210
2025-05-29 22:07:01,844 - INFO - joeynmt.training - Epoch   9, Step:    82000, Batch Loss:     1.481845, Batch Acc: 0.567337, Tokens per Sec:     7094, Lr: 0.000210
2025-05-29 22:07:01,846 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:07:01,846 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:07:34,431 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.02, acc:   0.53, generation: 32.5496[sec], evaluation: 0.0000[sec]
2025-05-29 22:07:34,620 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/79500.ckpt
2025-05-29 22:07:34,636 - INFO - joeynmt.training - Example #0
2025-05-29 22:07:34,638 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:07:34,638 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:07:34,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'se@@', 'ffen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 'ten', 'die', 'voor', 'de', 'n@@', 'aa@@', 'st', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'maakt', 'voor', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-29 22:07:34,639 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:07:34,640 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:07:34,640 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te beseffen dat de arctische ijskaarten die voor de naast drie miljoen jaar de grootte van de grens van de onderste 48 staten had gemaakt voor 48 staten om 40 procent te verzamelen.
2025-05-29 22:07:34,640 - INFO - joeynmt.training - Example #1
2025-05-29 22:07:34,641 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:07:34,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:07:34,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'in@@', 'st@@', 'ant@@', 'ie', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ker@@', '.', '</s>']
2025-05-29 22:07:34,642 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:07:34,642 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:07:34,642 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste instantie van dit speciale probleem omdat het niet de dikker.
2025-05-29 22:07:34,642 - INFO - joeynmt.training - Example #2
2025-05-29 22:07:34,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:07:34,643 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:07:34,643 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:07:34,644 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:07:34,644 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:07:34,644 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart het hart van ons wereldklimaatsysteem.
2025-05-29 22:07:34,645 - INFO - joeynmt.training - Example #3
2025-05-29 22:07:34,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:07:34,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:07:34,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'er@@', 'm', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:07:34,646 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:07:34,646 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:07:34,646 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en scherm in de zomers.
2025-05-29 22:07:34,646 - INFO - joeynmt.training - Example #4
2025-05-29 22:07:34,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:07:34,647 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:07:34,647 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:07:34,648 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:07:34,648 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:07:34,648 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschriften in de laatste 25 jaar is gebeurd.
2025-05-29 22:07:44,019 - INFO - joeynmt.training - Epoch   9, Step:    82100, Batch Loss:     1.545627, Batch Acc: 0.565898, Tokens per Sec:     7320, Lr: 0.000210
2025-05-29 22:07:53,745 - INFO - joeynmt.training - Epoch   9, Step:    82200, Batch Loss:     1.545737, Batch Acc: 0.564731, Tokens per Sec:     7153, Lr: 0.000210
2025-05-29 22:08:03,637 - INFO - joeynmt.training - Epoch   9, Step:    82300, Batch Loss:     1.376705, Batch Acc: 0.563451, Tokens per Sec:     6923, Lr: 0.000210
2025-05-29 22:08:13,296 - INFO - joeynmt.training - Epoch   9, Step:    82400, Batch Loss:     1.640221, Batch Acc: 0.559898, Tokens per Sec:     7166, Lr: 0.000210
2025-05-29 22:08:22,945 - INFO - joeynmt.training - Epoch   9, Step:    82500, Batch Loss:     1.307568, Batch Acc: 0.557416, Tokens per Sec:     7130, Lr: 0.000210
2025-05-29 22:08:22,946 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:08:22,946 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:09:06,700 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.02, acc:   0.53, generation: 43.7121[sec], evaluation: 0.0000[sec]
2025-05-29 22:09:06,982 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/81000.ckpt
2025-05-29 22:09:06,999 - INFO - joeynmt.training - Example #0
2025-05-29 22:09:06,999 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:09:07,000 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:09:07,000 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gr@@', 'ens', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'ge@@', 'ten', 'voor', 'de', 're@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'ar@@', 'ti@@', 'kel', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 22:09:07,001 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:09:07,001 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:09:07,001 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te bekijken dat de artische ijskappen, die de arctische ijskappen, die de grens drie miljoen jaar de grootte van de grens van de onderste 48 staten had geslaagd om 40 procent te vergeten voor de reden van 40 procent van de artikel geslaagd is.
2025-05-29 22:09:07,001 - INFO - joeynmt.training - Example #1
2025-05-29 22:09:07,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:09:07,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:09:07,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'e,', 'maar', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's', 'is', 'niet', 'de', 'di@@', 'k@@', 'ker', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.', '</s>']
2025-05-29 22:09:07,003 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:09:07,003 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:09:07,003 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste, maar het is niet de dikke probleem van dit ijs is niet de dikker van het ijs laat zien.
2025-05-29 22:09:07,003 - INFO - joeynmt.training - Example #2
2025-05-29 22:09:07,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:09:07,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:09:07,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:09:07,005 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:09:07,005 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:09:07,005 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappen, het slaagsysteem van onze wereldwijde klimaatsysteem.
2025-05-29 22:09:07,006 - INFO - joeynmt.training - Example #3
2025-05-29 22:09:07,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:09:07,006 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:09:07,006 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lo@@', 't', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'i@@', 'ten', 'en', 's@@', 'lo@@', 't.', '</s>']
2025-05-29 22:09:07,008 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:09:07,008 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:09:07,008 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en slot in de winter en sluit in de winter en sluiten en slot.
2025-05-29 22:09:07,008 - INFO - joeynmt.training - Example #4
2025-05-29 22:09:07,009 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:09:07,009 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:09:07,009 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:09:07,010 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:09:07,010 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:09:07,010 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschriften in de laatste 25 jaar gebeurd.
2025-05-29 22:09:17,078 - INFO - joeynmt.training - Epoch   9, Step:    82600, Batch Loss:     1.441617, Batch Acc: 0.569507, Tokens per Sec:     7051, Lr: 0.000210
2025-05-29 22:09:26,905 - INFO - joeynmt.training - Epoch   9, Step:    82700, Batch Loss:     1.318536, Batch Acc: 0.560035, Tokens per Sec:     7156, Lr: 0.000210
2025-05-29 22:09:37,138 - INFO - joeynmt.training - Epoch   9, Step:    82800, Batch Loss:     1.640246, Batch Acc: 0.564885, Tokens per Sec:     6837, Lr: 0.000210
2025-05-29 22:09:46,571 - INFO - joeynmt.training - Epoch   9, Step:    82900, Batch Loss:     1.491113, Batch Acc: 0.565809, Tokens per Sec:     7432, Lr: 0.000210
2025-05-29 22:09:56,369 - INFO - joeynmt.training - Epoch   9, Step:    83000, Batch Loss:     1.360850, Batch Acc: 0.556480, Tokens per Sec:     6995, Lr: 0.000210
2025-05-29 22:09:56,372 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:09:56,372 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:10:39,075 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   4.99, acc:   0.53, generation: 42.6632[sec], evaluation: 0.0000[sec]
2025-05-29 22:10:39,077 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:10:39,289 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/80500.ckpt
2025-05-29 22:10:39,310 - INFO - joeynmt.training - Example #0
2025-05-29 22:10:39,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:10:39,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:10:39,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gr@@', 'ond', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'ach@@', 't.', '</s>']
2025-05-29 22:10:39,312 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:10:39,313 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:10:39,313 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te bekijken dat de artische ijskappen, die de artische ijskappen, die de grond van de onderste 48 staten had geslacht.
2025-05-29 22:10:39,313 - INFO - joeynmt.training - Example #1
2025-05-29 22:10:39,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:10:39,313 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:10:39,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's', 'is', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'je', 'van', 'de', 'ij@@', 's@@', 'je', 'van', 'de', 'ij@@', 's@@', 'je', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'ij@@', 's', 'ij@@', 's', 'is.', '</s>']
2025-05-29 22:10:39,315 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:10:39,315 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:10:39,315 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerst van dit speciale probleem van dit ijs is omdat het niet de dikke ijsje van de ijsje van de ijsje van de ijs van de ijzer van ijs ijs is.
2025-05-29 22:10:39,315 - INFO - joeynmt.training - Example #2
2025-05-29 22:10:39,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:10:39,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:10:39,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:10:39,317 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:10:39,317 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:10:39,317 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart het hart van ons wereldwijde klimaatsysteem.
2025-05-29 22:10:39,317 - INFO - joeynmt.training - Example #3
2025-05-29 22:10:39,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:10:39,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:10:39,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:10:39,319 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:10:39,319 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:10:39,319 - INFO - joeynmt.training - 	Hypothesis: Ze groeien en in de winter en sluit in de zomers.
2025-05-29 22:10:39,319 - INFO - joeynmt.training - Example #4
2025-05-29 22:10:39,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:10:39,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:10:39,320 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tijd', 'dat', 'ik', 'jullie', 'laten', 'zien', 'wat', 'er', 'gebeur@@', 't', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:10:39,321 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:10:39,321 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:10:39,321 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijd dat ik jullie laten zien wat er gebeurt in de laatste 25 jaar gebeurd.
2025-05-29 22:10:49,573 - INFO - joeynmt.training - Epoch   9, Step:    83100, Batch Loss:     1.386302, Batch Acc: 0.562832, Tokens per Sec:     6576, Lr: 0.000210
2025-05-29 22:10:50,326 - INFO - joeynmt.training - Epoch   9: total training loss 13577.07
2025-05-29 22:10:50,326 - INFO - joeynmt.training - EPOCH 10
2025-05-29 22:10:59,800 - INFO - joeynmt.training - Epoch  10, Step:    83200, Batch Loss:     1.453218, Batch Acc: 0.579593, Tokens per Sec:     6953, Lr: 0.000210
2025-05-29 22:11:09,676 - INFO - joeynmt.training - Epoch  10, Step:    83300, Batch Loss:     1.245136, Batch Acc: 0.577103, Tokens per Sec:     7286, Lr: 0.000210
2025-05-29 22:11:18,801 - INFO - joeynmt.training - Epoch  10, Step:    83400, Batch Loss:     1.416465, Batch Acc: 0.579445, Tokens per Sec:     7520, Lr: 0.000210
2025-05-29 22:11:27,970 - INFO - joeynmt.training - Epoch  10, Step:    83500, Batch Loss:     1.422565, Batch Acc: 0.578670, Tokens per Sec:     7499, Lr: 0.000210
2025-05-29 22:11:27,971 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:11:27,971 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:12:04,356 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.53, generation: 36.3368[sec], evaluation: 0.0000[sec]
2025-05-29 22:12:04,369 - INFO - joeynmt.training - Example #0
2025-05-29 22:12:04,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:12:04,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:12:04,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'se@@', 'ffen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'die', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'ach@@', 'ts@@', 'ach@@', 't@@', 'ige', 'lan@@', 'den', 'had', 'ge@@', 'sl@@', 'ach@@', 't.', '</s>']
2025-05-29 22:12:04,371 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:12:04,372 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:12:04,372 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te beseffen dat de arctische ijskappels die de grens van de onderste 48 staten had geslachtsachtige landen had geslacht.
2025-05-29 22:12:04,372 - INFO - joeynmt.training - Example #1
2025-05-29 22:12:04,373 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:12:04,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:12:04,373 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'kan@@', 's', 'om', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's', 'te', 'laten', 'zien', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'z@@', 'er', 'niet', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 22:12:04,375 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:12:04,375 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:12:04,375 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste kans om dit speciale probleem van dit ijs te laten zien omdat het niet de dikke van het ijzer niet toont.
2025-05-29 22:12:04,376 - INFO - joeynmt.training - Example #2
2025-05-29 22:12:04,376 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:12:04,376 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:12:04,376 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'op', 'het', 'sl@@', 'aa@@', 'g@@', 'ste', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:12:04,377 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:12:04,377 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:12:04,378 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskop het slaagste klimaatsysteem.
2025-05-29 22:12:04,378 - INFO - joeynmt.training - Example #3
2025-05-29 22:12:04,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:12:04,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:12:04,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 'sch@@', 'rij@@', 'ven', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:12:04,379 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:12:04,379 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:12:04,379 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schrijven in de zomers.
2025-05-29 22:12:04,380 - INFO - joeynmt.training - Example #4
2025-05-29 22:12:04,380 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:12:04,380 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:12:04,380 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'en,', 'is', 'een', 'ti@@', 'me@@', '-@@', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:12:04,381 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:12:04,381 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:12:04,381 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tonen, is een time-opname wat er gebeurde in de afgelopen 25 jaar is gebeurd.
2025-05-29 22:12:14,371 - INFO - joeynmt.training - Epoch  10, Step:    83600, Batch Loss:     1.451499, Batch Acc: 0.581980, Tokens per Sec:     7059, Lr: 0.000210
2025-05-29 22:12:24,341 - INFO - joeynmt.training - Epoch  10, Step:    83700, Batch Loss:     1.351532, Batch Acc: 0.575382, Tokens per Sec:     7104, Lr: 0.000210
2025-05-29 22:12:34,187 - INFO - joeynmt.training - Epoch  10, Step:    83800, Batch Loss:     1.383546, Batch Acc: 0.583245, Tokens per Sec:     7180, Lr: 0.000210
2025-05-29 22:12:43,940 - INFO - joeynmt.training - Epoch  10, Step:    83900, Batch Loss:     1.340706, Batch Acc: 0.580118, Tokens per Sec:     7179, Lr: 0.000210
2025-05-29 22:12:53,887 - INFO - joeynmt.training - Epoch  10, Step:    84000, Batch Loss:     1.279217, Batch Acc: 0.573721, Tokens per Sec:     6918, Lr: 0.000210
2025-05-29 22:12:53,887 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:12:53,887 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:13:35,550 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.04, acc:   0.53, generation: 41.6134[sec], evaluation: 0.0000[sec]
2025-05-29 22:13:35,576 - INFO - joeynmt.training - Example #0
2025-05-29 22:13:35,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:13:35,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:13:35,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'at@@', 'uur', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'ens', 'van', 'de', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'im@@', 'me', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-29 22:13:35,579 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:13:35,579 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:13:35,579 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te bekijken dat de arctische ijskapparatuur die de grootte van de drie miljoen jaar de grootte van de grens van de 48 staten had geslimme geslaagd om 40 procent te verzamelen.
2025-05-29 22:13:35,579 - INFO - joeynmt.training - Example #1
2025-05-29 22:13:35,580 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:13:35,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:13:35,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'e,', 'maar', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'dit', 'ij@@', 's', 'niet', 'de', 'di@@', 'k@@', 'ker', 'van', 'het', 'ij@@', 'z@@', 'er', 'van', 'het', 'ij@@', 'z@@', 'er', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 22:13:35,581 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:13:35,581 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:13:35,581 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste, maar het is niet de dikke van dit ijs niet de dikker van het ijzer van het ijzer toont.
2025-05-29 22:13:35,581 - INFO - joeynmt.training - Example #2
2025-05-29 22:13:35,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:13:35,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:13:35,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'ar@@', 'at@@', 'uur', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:13:35,583 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:13:35,583 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:13:35,583 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapparatuur van ons wereldwijde klimaatsysteem.
2025-05-29 22:13:35,583 - INFO - joeynmt.training - Example #3
2025-05-29 22:13:35,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:13:35,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:13:35,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:13:35,585 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:13:35,586 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:13:35,586 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en sluit in de zomers.
2025-05-29 22:13:35,586 - INFO - joeynmt.training - Example #4
2025-05-29 22:13:35,586 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:13:35,587 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:13:35,587 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 'd', 'is', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:13:35,588 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:13:35,588 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:13:35,588 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschrift van wat er gebeurd is in de laatste 25 jaar is gebeurd.
2025-05-29 22:13:45,633 - INFO - joeynmt.training - Epoch  10, Step:    84100, Batch Loss:     1.386989, Batch Acc: 0.577171, Tokens per Sec:     6928, Lr: 0.000210
2025-05-29 22:13:55,492 - INFO - joeynmt.training - Epoch  10, Step:    84200, Batch Loss:     1.403514, Batch Acc: 0.579917, Tokens per Sec:     7125, Lr: 0.000210
2025-05-29 22:14:05,377 - INFO - joeynmt.training - Epoch  10, Step:    84300, Batch Loss:     1.488064, Batch Acc: 0.570849, Tokens per Sec:     7256, Lr: 0.000210
2025-05-29 22:14:15,199 - INFO - joeynmt.training - Epoch  10, Step:    84400, Batch Loss:     1.455715, Batch Acc: 0.575121, Tokens per Sec:     7023, Lr: 0.000210
2025-05-29 22:14:24,925 - INFO - joeynmt.training - Epoch  10, Step:    84500, Batch Loss:     1.557321, Batch Acc: 0.577916, Tokens per Sec:     7181, Lr: 0.000210
2025-05-29 22:14:24,926 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:14:24,926 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:15:05,070 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.04, acc:   0.53, generation: 40.1029[sec], evaluation: 0.0000[sec]
2025-05-29 22:15:05,084 - INFO - joeynmt.training - Example #0
2025-05-29 22:15:05,084 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:15:05,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:15:05,086 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 're@@', 'alis@@', 'eren', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'had', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-29 22:15:05,087 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:15:05,087 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:15:05,087 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond, om te realiseren dat de arctische ijskappen, die de arctische ijskappen, die de grootte van de onderste 48 staten had gehad om 40 procent te verzamelen.
2025-05-29 22:15:05,088 - INFO - joeynmt.training - Example #1
2025-05-29 22:15:05,089 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:15:05,089 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:15:05,089 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'hei@@', 'd@@', 'spro@@', 'ble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'het', 'ij@@', 's', 'we@@', 'er', 'niet', 'de', 'di@@', 'k', 'van', 'ij@@', 'z@@', 'er', 'is.', '</s>']
2025-05-29 22:15:05,090 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:15:05,091 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:15:05,091 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerstheidsproblemen van dit speciale probleem van het ijs weer niet de dik van ijzer is.
2025-05-29 22:15:05,092 - INFO - joeynmt.training - Example #2
2025-05-29 22:15:05,092 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:15:05,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:15:05,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:15:05,093 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:15:05,093 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:15:05,094 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-29 22:15:05,094 - INFO - joeynmt.training - Example #3
2025-05-29 22:15:05,094 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:15:05,094 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:15:05,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lo@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 22:15:05,095 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:15:05,096 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:15:05,096 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slot in de zomer.
2025-05-29 22:15:05,096 - INFO - joeynmt.training - Example #4
2025-05-29 22:15:05,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:15:05,096 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:15:05,097 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'ti@@', 'me@@', '-@@', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:15:05,098 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:15:05,098 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:15:05,098 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een time-opname wat er gebeurde in de laatste 25 jaar is gebeurd.
2025-05-29 22:15:14,636 - INFO - joeynmt.training - Epoch  10, Step:    84600, Batch Loss:     1.331784, Batch Acc: 0.582827, Tokens per Sec:     7138, Lr: 0.000210
2025-05-29 22:15:23,582 - INFO - joeynmt.training - Epoch  10, Step:    84700, Batch Loss:     1.517917, Batch Acc: 0.580498, Tokens per Sec:     7943, Lr: 0.000210
2025-05-29 22:15:33,699 - INFO - joeynmt.training - Epoch  10, Step:    84800, Batch Loss:     1.393093, Batch Acc: 0.576324, Tokens per Sec:     6843, Lr: 0.000210
2025-05-29 22:15:43,591 - INFO - joeynmt.training - Epoch  10, Step:    84900, Batch Loss:     1.242252, Batch Acc: 0.570121, Tokens per Sec:     6981, Lr: 0.000210
2025-05-29 22:15:53,473 - INFO - joeynmt.training - Epoch  10, Step:    85000, Batch Loss:     1.311499, Batch Acc: 0.578354, Tokens per Sec:     6960, Lr: 0.000210
2025-05-29 22:15:53,476 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:15:53,477 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:16:37,344 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.00, acc:   0.53, generation: 43.8285[sec], evaluation: 0.0000[sec]
2025-05-29 22:16:37,535 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/80000.ckpt
2025-05-29 22:16:37,556 - INFO - joeynmt.training - Example #0
2025-05-29 22:16:37,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:16:37,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:16:37,558 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'voor', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 22:16:37,559 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:16:37,559 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:16:37,559 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te bekijken dat de arctische ijskappen, die de arctische ijskappen, die de grootte van de onderste 48 staten had geslaagd voor 40 procent geslaagd is.
2025-05-29 22:16:37,559 - INFO - joeynmt.training - Example #1
2025-05-29 22:16:37,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:16:37,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:16:37,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'h@@', 'aa@@', 't,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'dit', 'ij@@', 's', 'niet', 'de', 'di@@', 'k@@', 'ker', 'l@@', 'aat', 'zien.', '</s>']
2025-05-29 22:16:37,561 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:16:37,561 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:16:37,561 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eersthaat, omdat het niet de dikke van dit ijs niet de dikker laat zien.
2025-05-29 22:16:37,561 - INFO - joeynmt.training - Example #2
2025-05-29 22:16:37,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:16:37,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:16:37,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:16:37,563 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:16:37,564 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:16:37,564 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskaart het hart van ons wereldwijde klimaatsysteem.
2025-05-29 22:16:37,564 - INFO - joeynmt.training - Example #3
2025-05-29 22:16:37,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:16:37,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:16:37,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'k@@', 'ru@@', 'is@@', 'ing', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:16:37,566 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:16:37,566 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:16:37,566 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en skruising in de zomers.
2025-05-29 22:16:37,566 - INFO - joeynmt.training - Example #4
2025-05-29 22:16:37,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:16:37,567 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:16:37,567 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'ti@@', 'me@@', '-@@', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:16:37,568 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:16:37,569 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:16:37,569 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een time-opname wat er gebeurde in de laatste 25 jaar is gebeurd.
2025-05-29 22:16:47,442 - INFO - joeynmt.training - Epoch  10, Step:    85100, Batch Loss:     1.294878, Batch Acc: 0.571761, Tokens per Sec:     6843, Lr: 0.000210
2025-05-29 22:16:57,249 - INFO - joeynmt.training - Epoch  10, Step:    85200, Batch Loss:     1.417891, Batch Acc: 0.573436, Tokens per Sec:     7011, Lr: 0.000210
2025-05-29 22:17:07,177 - INFO - joeynmt.training - Epoch  10, Step:    85300, Batch Loss:     1.404048, Batch Acc: 0.579419, Tokens per Sec:     6992, Lr: 0.000210
2025-05-29 22:17:16,706 - INFO - joeynmt.training - Epoch  10, Step:    85400, Batch Loss:     1.427836, Batch Acc: 0.572328, Tokens per Sec:     7421, Lr: 0.000210
2025-05-29 22:17:26,179 - INFO - joeynmt.training - Epoch  10, Step:    85500, Batch Loss:     1.455462, Batch Acc: 0.576925, Tokens per Sec:     7679, Lr: 0.000210
2025-05-29 22:17:26,179 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:17:26,179 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:18:03,092 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.03, acc:   0.52, generation: 36.8720[sec], evaluation: 0.0000[sec]
2025-05-29 22:18:03,098 - INFO - joeynmt.training - Example #0
2025-05-29 22:18:03,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:18:03,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:18:03,100 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'ver@@', 'kijken', 'naar', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 'z@@', 'er@@', 'c@@', 'ij@@', 'st@@', 'ige', 'ij@@', 'z@@', 'er', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 'z@@', 'er', 'van', 'de', 'gr@@', 'en@@', 'zen', 'van', 'de', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'om', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'te', 'zijn.', '</s>']
2025-05-29 22:18:03,101 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:18:03,102 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:18:03,102 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen om te verkijken naar de artische ijzercijstige ijzer die voor de artische ijzer van de grenzen van de 48 staten had geslaagd om 40 procent geslaagd te zijn.
2025-05-29 22:18:03,102 - INFO - joeynmt.training - Example #1
2025-05-29 22:18:03,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:18:03,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:18:03,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'v@@', 'aar@@', 'dig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 'z@@', 'er', 'van', 'het', 'ij@@', 'z@@', 'er', 'in', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'de', 'ij@@', 'z@@', 'er', 'van', 'het', 'ij@@', 'z@@', 'er', 'van', 'de', 'eerste', 'proble@@', 'em@@', '.', '</s>']
2025-05-29 22:18:03,104 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:18:03,104 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:18:03,104 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerstvaardigheid van dit speciale probleem, omdat het niet de dikke ijzer van het ijzer in de ijzer van de ijzer van de ijzer van de ijzer van de ijzer van het ijzer van de eerste probleem.
2025-05-29 22:18:03,105 - INFO - joeynmt.training - Example #2
2025-05-29 22:18:03,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:18:03,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:18:03,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'har@@', 't', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:18:03,106 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:18:03,107 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:18:03,107 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart het hart van onze wereldwijde klimaatsysteem.
2025-05-29 22:18:03,107 - INFO - joeynmt.training - Example #3
2025-05-29 22:18:03,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:18:03,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:18:03,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lo@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:18:03,109 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:18:03,109 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:18:03,109 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en slot in de zomers.
2025-05-29 22:18:03,109 - INFO - joeynmt.training - Example #4
2025-05-29 22:18:03,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:18:03,110 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:18:03,110 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'gebeur@@', 'd', 'is', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:18:03,111 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:18:03,111 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:18:03,111 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschriften wat er gebeurd is in de laatste 25 jaar is gebeurd.
2025-05-29 22:18:12,903 - INFO - joeynmt.training - Epoch  10, Step:    85600, Batch Loss:     1.334990, Batch Acc: 0.578199, Tokens per Sec:     7108, Lr: 0.000210
2025-05-29 22:18:23,207 - INFO - joeynmt.training - Epoch  10, Step:    85700, Batch Loss:     1.457039, Batch Acc: 0.579806, Tokens per Sec:     7143, Lr: 0.000210
2025-05-29 22:18:33,058 - INFO - joeynmt.training - Epoch  10, Step:    85800, Batch Loss:     1.312477, Batch Acc: 0.574625, Tokens per Sec:     6950, Lr: 0.000210
2025-05-29 22:18:43,142 - INFO - joeynmt.training - Epoch  10, Step:    85900, Batch Loss:     1.563669, Batch Acc: 0.572128, Tokens per Sec:     7054, Lr: 0.000210
2025-05-29 22:18:53,148 - INFO - joeynmt.training - Epoch  10, Step:    86000, Batch Loss:     1.264924, Batch Acc: 0.569570, Tokens per Sec:     7038, Lr: 0.000210
2025-05-29 22:18:53,149 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:18:53,149 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:19:41,541 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.05, acc:   0.52, generation: 48.3545[sec], evaluation: 0.0000[sec]
2025-05-29 22:19:41,550 - INFO - joeynmt.training - Example #0
2025-05-29 22:19:41,551 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:19:41,551 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:19:41,551 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 's', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 's', 'die', 'de', 'gr@@', 'ond', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'kre@@', 'gen', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'voor', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 're@@', 'den', 'van', 'de', 'ar@@', 'ti@@', 'kel', 'was', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'voor', 'de', 'ar@@', 'ti@@', 'kel@@', '.', '</s>']
2025-05-29 22:19:41,552 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:19:41,553 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:19:41,554 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te bekijken dat de artische ijskapps die de artische ijskapps die de grond de onderste 48 staten had gekregen voor de onderste 48 staten had geslaagd voor 40 procent van de reden van de artikel was geslaagd voor de artikel.
2025-05-29 22:19:41,554 - INFO - joeynmt.training - Example #1
2025-05-29 22:19:41,554 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:19:41,555 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:19:41,555 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'e,', 'omdat', 'het', 'de', 'ver@@', 'n@@', 'u@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 22:19:41,556 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:19:41,556 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:19:41,556 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste, omdat het de vernut van dit speciale probleem toont.
2025-05-29 22:19:41,556 - INFO - joeynmt.training - Example #2
2025-05-29 22:19:41,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:19:41,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:19:41,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:19:41,558 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:19:41,560 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:19:41,560 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe hart van ons globale klimaatsysteem.
2025-05-29 22:19:41,560 - INFO - joeynmt.training - Example #3
2025-05-29 22:19:41,561 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:19:41,561 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:19:41,561 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'im@@', 'p@@', 'el@@', 'weg', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:19:41,562 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:19:41,562 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:19:41,562 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en simpelweg in de zomers.
2025-05-29 22:19:41,562 - INFO - joeynmt.training - Example #4
2025-05-29 22:19:41,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:19:41,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:19:41,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 'd', 'is', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 22:19:41,564 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:19:41,564 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:19:41,564 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift van wat er gebeurd is in de afgelopen 25 jaar is.
2025-05-29 22:19:51,246 - INFO - joeynmt.training - Epoch  10, Step:    86100, Batch Loss:     1.446463, Batch Acc: 0.575669, Tokens per Sec:     7232, Lr: 0.000210
2025-05-29 22:20:01,170 - INFO - joeynmt.training - Epoch  10, Step:    86200, Batch Loss:     1.584814, Batch Acc: 0.571780, Tokens per Sec:     6928, Lr: 0.000210
2025-05-29 22:20:11,365 - INFO - joeynmt.training - Epoch  10, Step:    86300, Batch Loss:     1.680452, Batch Acc: 0.577235, Tokens per Sec:     6895, Lr: 0.000210
2025-05-29 22:20:21,784 - INFO - joeynmt.training - Epoch  10, Step:    86400, Batch Loss:     1.433507, Batch Acc: 0.567982, Tokens per Sec:     6837, Lr: 0.000210
2025-05-29 22:20:32,267 - INFO - joeynmt.training - Epoch  10, Step:    86500, Batch Loss:     1.244560, Batch Acc: 0.575644, Tokens per Sec:     6621, Lr: 0.000210
2025-05-29 22:20:32,268 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:20:32,268 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:21:07,982 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.01, acc:   0.53, generation: 35.6734[sec], evaluation: 0.0000[sec]
2025-05-29 22:21:08,187 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/82500.ckpt
2025-05-29 22:21:08,204 - INFO - joeynmt.training - Example #0
2025-05-29 22:21:08,205 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:21:08,205 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:21:08,205 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'had', 'voor', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'st@@', 'aten', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'lan@@', 'den', 'van', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'groot@@', 'te', 'van', 'de', 'ar@@', 'ti@@', 'kel', 'ge@@', 'maakt', 'is.', '</s>']
2025-05-29 22:21:08,206 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:21:08,206 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:21:08,207 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te bekijken dat de artische ijskappen, die de artische ijskappen, die de grootte van de onderste 48 staten had gehad voor 40 procent van de grootte van de staten van 40 procent van de landen van 40 procent van de grootte van de artikel gemaakt is.
2025-05-29 22:21:08,207 - INFO - joeynmt.training - Example #1
2025-05-29 22:21:08,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:21:08,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:21:08,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em@@', ',', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.', '</s>']
2025-05-29 22:21:08,209 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:21:08,209 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:21:08,209 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerst van dit speciale probleem, omdat het niet de dikke van het ijs laat zien.
2025-05-29 22:21:08,210 - INFO - joeynmt.training - Example #2
2025-05-29 22:21:08,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:21:08,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:21:08,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'op', 'het', 'sl@@', 'aa@@', 'g@@', 'ste', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:21:08,211 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:21:08,211 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:21:08,211 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskop het slaagste klimaatsysteem.
2025-05-29 22:21:08,211 - INFO - joeynmt.training - Example #3
2025-05-29 22:21:08,212 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:21:08,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:21:08,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:21:08,213 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:21:08,213 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:21:08,213 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluit in de zomers.
2025-05-29 22:21:08,213 - INFO - joeynmt.training - Example #4
2025-05-29 22:21:08,214 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:21:08,214 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:21:08,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 'd', 'is', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 22:21:08,215 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:21:08,215 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:21:08,215 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift van wat er gebeurd is in de laatste 25 jaar.
2025-05-29 22:21:18,601 - INFO - joeynmt.training - Epoch  10, Step:    86600, Batch Loss:     1.520400, Batch Acc: 0.573237, Tokens per Sec:     6868, Lr: 0.000210
2025-05-29 22:21:28,922 - INFO - joeynmt.training - Epoch  10, Step:    86700, Batch Loss:     1.376251, Batch Acc: 0.572275, Tokens per Sec:     6742, Lr: 0.000210
2025-05-29 22:21:39,156 - INFO - joeynmt.training - Epoch  10, Step:    86800, Batch Loss:     1.242428, Batch Acc: 0.570272, Tokens per Sec:     6883, Lr: 0.000210
2025-05-29 22:21:49,360 - INFO - joeynmt.training - Epoch  10, Step:    86900, Batch Loss:     1.301649, Batch Acc: 0.576707, Tokens per Sec:     6736, Lr: 0.000210
2025-05-29 22:22:00,879 - INFO - joeynmt.training - Epoch  10, Step:    87000, Batch Loss:     1.327724, Batch Acc: 0.575823, Tokens per Sec:     6084, Lr: 0.000210
2025-05-29 22:22:00,882 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:22:00,882 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:22:48,603 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.03, acc:   0.53, generation: 47.6738[sec], evaluation: 0.0000[sec]
2025-05-29 22:22:48,609 - INFO - joeynmt.training - Example #0
2025-05-29 22:22:48,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:22:48,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:22:48,610 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-29 22:22:48,611 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:22:48,612 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:22:48,612 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkijken dat de arctische ijskappen, die de artische ijskappen, die de grootte van de onderste 48 staten om 40 procent te verzamelen.
2025-05-29 22:22:48,612 - INFO - joeynmt.training - Example #1
2025-05-29 22:22:48,612 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:22:48,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:22:48,613 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'ver@@', 'war@@', 'm@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'het', 'ij@@', 's', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ap@@', '.', '</s>']
2025-05-29 22:22:48,613 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:22:48,615 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:22:48,615 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerstverwarming van dit speciale probleem van het ijs niet de dikke van het ijsje van de ijskap.
2025-05-29 22:22:48,616 - INFO - joeynmt.training - Example #2
2025-05-29 22:22:48,616 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:22:48,616 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:22:48,616 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'op', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:22:48,618 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:22:48,618 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:22:48,618 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskop het slaagsysteem van ons wereldwijde klimaatsysteem.
2025-05-29 22:22:48,618 - INFO - joeynmt.training - Example #3
2025-05-29 22:22:48,618 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:22:48,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:22:48,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'l@@', 'aat', 'je', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:22:48,620 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:22:48,620 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:22:48,620 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en laat je zomers.
2025-05-29 22:22:48,620 - INFO - joeynmt.training - Example #4
2025-05-29 22:22:48,620 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:22:48,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:22:48,620 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 't@@', 'on@@', 'e@@', '-@@', 'op@@', '-@@', 'op@@', 'nam@@', 'es', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:22:48,621 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:22:48,622 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:22:48,622 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik tone-op-opnames wat er gebeurde in de laatste 25 jaar is gebeurd.
2025-05-29 22:22:58,673 - INFO - joeynmt.training - Epoch  10, Step:    87100, Batch Loss:     1.314726, Batch Acc: 0.574125, Tokens per Sec:     6834, Lr: 0.000210
2025-05-29 22:23:09,052 - INFO - joeynmt.training - Epoch  10, Step:    87200, Batch Loss:     1.295884, Batch Acc: 0.576524, Tokens per Sec:     6732, Lr: 0.000210
2025-05-29 22:23:20,095 - INFO - joeynmt.training - Epoch  10, Step:    87300, Batch Loss:     1.312113, Batch Acc: 0.580674, Tokens per Sec:     6331, Lr: 0.000210
2025-05-29 22:23:30,489 - INFO - joeynmt.training - Epoch  10, Step:    87400, Batch Loss:     1.411239, Batch Acc: 0.571453, Tokens per Sec:     6639, Lr: 0.000210
2025-05-29 22:23:40,168 - INFO - joeynmt.training - Epoch  10, Step:    87500, Batch Loss:     1.440317, Batch Acc: 0.576754, Tokens per Sec:     7246, Lr: 0.000210
2025-05-29 22:23:40,169 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:23:40,169 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:24:18,660 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.03, acc:   0.52, generation: 38.4407[sec], evaluation: 0.0000[sec]
2025-05-29 22:24:18,672 - INFO - joeynmt.training - Example #0
2025-05-29 22:24:18,673 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:24:18,673 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:24:18,673 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 're@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'maakt', 'voor', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-29 22:24:18,675 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:24:18,675 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:24:18,675 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen om te bekijken dat de artische ijskappen, die de artische ijskappen, die de reden van de onderste 48 staten had gemaakt voor 40 procent geslaagd is.
2025-05-29 22:24:18,676 - INFO - joeynmt.training - Example #1
2025-05-29 22:24:18,676 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:24:18,676 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:24:18,676 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'st@@', 'eil@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 22:24:18,678 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:24:18,678 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:24:18,678 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste steiling van dit speciale probleem van dit speciale probleem omdat het niet de dikke van het ijs toont.
2025-05-29 22:24:18,678 - INFO - joeynmt.training - Example #2
2025-05-29 22:24:18,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:24:18,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:24:18,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'op', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:24:18,680 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:24:18,680 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:24:18,680 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskop het slaagsysteem van ons wereldwijde klimaatsysteem.
2025-05-29 22:24:18,680 - INFO - joeynmt.training - Example #3
2025-05-29 22:24:18,681 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:24:18,681 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:24:18,681 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lo@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:24:18,682 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:24:18,682 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:24:18,682 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en slot in de zomers.
2025-05-29 22:24:18,682 - INFO - joeynmt.training - Example #4
2025-05-29 22:24:18,683 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:24:18,683 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:24:18,683 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 't,', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 22:24:18,684 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:24:18,685 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:24:18,685 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift, wat er gebeurde in de laatste 25 jaar.
2025-05-29 22:24:28,909 - INFO - joeynmt.training - Epoch  10, Step:    87600, Batch Loss:     1.425009, Batch Acc: 0.577601, Tokens per Sec:     6972, Lr: 0.000147
2025-05-29 22:24:39,189 - INFO - joeynmt.training - Epoch  10, Step:    87700, Batch Loss:     1.355384, Batch Acc: 0.572155, Tokens per Sec:     6948, Lr: 0.000147
2025-05-29 22:24:49,326 - INFO - joeynmt.training - Epoch  10, Step:    87800, Batch Loss:     1.473736, Batch Acc: 0.576954, Tokens per Sec:     6792, Lr: 0.000147
2025-05-29 22:24:59,453 - INFO - joeynmt.training - Epoch  10, Step:    87900, Batch Loss:     1.483879, Batch Acc: 0.574040, Tokens per Sec:     6957, Lr: 0.000147
2025-05-29 22:25:09,343 - INFO - joeynmt.training - Epoch  10, Step:    88000, Batch Loss:     1.470895, Batch Acc: 0.575913, Tokens per Sec:     6922, Lr: 0.000147
2025-05-29 22:25:09,343 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:25:09,343 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:25:49,725 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.95, acc:   0.53, generation: 40.3441[sec], evaluation: 0.0000[sec]
2025-05-29 22:25:49,727 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:25:49,925 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/82000.ckpt
2025-05-29 22:25:49,943 - INFO - joeynmt.training - Example #0
2025-05-29 22:25:49,944 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:25:49,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:25:49,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'ach@@', 't.', '</s>']
2025-05-29 22:25:49,945 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:25:49,945 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:25:49,946 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen gevolgen om te bekijken dat de artische ijskappen, die de artische ijskappels die de grootte van de onderste 48 staten had geslacht.
2025-05-29 22:25:49,946 - INFO - joeynmt.training - Example #1
2025-05-29 22:25:49,946 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:25:49,946 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:25:49,946 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'van', 'het', 'ij@@', 's.', '</s>']
2025-05-29 22:25:49,947 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:25:49,947 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:25:49,948 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerst van dit speciale probleem van dit speciale probleem omdat het niet de dikke van het ijsje van het ijsje van het ijskaart van het ijs.
2025-05-29 22:25:49,948 - INFO - joeynmt.training - Example #2
2025-05-29 22:25:49,948 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:25:49,948 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:25:49,948 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:25:49,949 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:25:49,949 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:25:49,950 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart het hart van ons wereldwijde klimaatsysteem.
2025-05-29 22:25:49,950 - INFO - joeynmt.training - Example #3
2025-05-29 22:25:49,950 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:25:49,950 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:25:49,950 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-29 22:25:49,951 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:25:49,951 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:25:49,951 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluit in de zomer.
2025-05-29 22:25:49,952 - INFO - joeynmt.training - Example #4
2025-05-29 22:25:49,952 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:25:49,952 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:25:49,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:25:49,953 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:25:49,953 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:25:49,954 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdschriften wat er gebeurde in de laatste 25 jaar is gebeurd.
2025-05-29 22:25:59,940 - INFO - joeynmt.training - Epoch  10, Step:    88100, Batch Loss:     1.497974, Batch Acc: 0.571606, Tokens per Sec:     7028, Lr: 0.000147
2025-05-29 22:26:10,117 - INFO - joeynmt.training - Epoch  10, Step:    88200, Batch Loss:     1.348192, Batch Acc: 0.579313, Tokens per Sec:     6969, Lr: 0.000147
2025-05-29 22:26:20,148 - INFO - joeynmt.training - Epoch  10, Step:    88300, Batch Loss:     1.267693, Batch Acc: 0.579388, Tokens per Sec:     6879, Lr: 0.000147
2025-05-29 22:26:29,982 - INFO - joeynmt.training - Epoch  10, Step:    88400, Batch Loss:     1.540771, Batch Acc: 0.581406, Tokens per Sec:     7222, Lr: 0.000147
2025-05-29 22:26:39,871 - INFO - joeynmt.training - Epoch  10, Step:    88500, Batch Loss:     1.375671, Batch Acc: 0.578638, Tokens per Sec:     7083, Lr: 0.000147
2025-05-29 22:26:39,871 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:26:39,872 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:27:20,645 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.93, acc:   0.53, generation: 40.7332[sec], evaluation: 0.0000[sec]
2025-05-29 22:27:20,646 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:27:20,863 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/81500.ckpt
2025-05-29 22:27:20,883 - INFO - joeynmt.training - Example #0
2025-05-29 22:27:20,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:27:20,884 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:27:20,885 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'groot@@', 'te', 'van', 'de', '4@@', '8', 'st@@', 'aten', 'van', 'de', '4@@', '0', 'proc@@', 'ent', 'was', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'voor', '4@@', '0', 'proc@@', 'ent', 'is', 'ge@@', 'g@@', 'oo@@', 'i@@', 'd.', '</s>']
2025-05-29 22:27:20,885 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:27:20,886 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:27:20,886 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen getoond om te verkijken dat de artische ijskappen, die de artische ijskappen, die de grootte van de 48 staten van de 40 procent was geslaagd voor 40 procent is gegooid.
2025-05-29 22:27:20,886 - INFO - joeynmt.training - Example #1
2025-05-29 22:27:20,887 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:27:20,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:27:20,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 22:27:20,888 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:27:20,888 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:27:20,888 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerst van dit speciale probleem van dit speciale probleem toont.
2025-05-29 22:27:20,888 - INFO - joeynmt.training - Example #2
2025-05-29 22:27:20,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:27:20,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:27:20,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:27:20,890 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:27:20,890 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:27:20,890 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart het hart van ons wereldwijde klimaatsysteem.
2025-05-29 22:27:20,890 - INFO - joeynmt.training - Example #3
2025-05-29 22:27:20,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:27:20,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:27:20,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'l@@', 'oo@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:27:20,892 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:27:20,892 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:27:20,892 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en loopt in de zomers.
2025-05-29 22:27:20,893 - INFO - joeynmt.training - Example #4
2025-05-29 22:27:20,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:27:20,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:27:20,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'ti@@', 'me@@', '-@@', 'o@@', '-@@', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 'd', 'is', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 22:27:20,894 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:27:20,894 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:27:20,895 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een time-o-opname wat er gebeurd is in de afgelopen 25 jaar.
2025-05-29 22:27:31,509 - INFO - joeynmt.training - Epoch  10, Step:    88600, Batch Loss:     1.658319, Batch Acc: 0.577052, Tokens per Sec:     6368, Lr: 0.000147
2025-05-29 22:27:41,449 - INFO - joeynmt.training - Epoch  10, Step:    88700, Batch Loss:     1.193534, Batch Acc: 0.579041, Tokens per Sec:     6980, Lr: 0.000147
2025-05-29 22:27:51,049 - INFO - joeynmt.training - Epoch  10, Step:    88800, Batch Loss:     1.381747, Batch Acc: 0.573534, Tokens per Sec:     7238, Lr: 0.000147
2025-05-29 22:28:00,040 - INFO - joeynmt.training - Epoch  10, Step:    88900, Batch Loss:     1.265634, Batch Acc: 0.570771, Tokens per Sec:     7614, Lr: 0.000147
2025-05-29 22:28:09,200 - INFO - joeynmt.training - Epoch  10, Step:    89000, Batch Loss:     1.296687, Batch Acc: 0.578731, Tokens per Sec:     7611, Lr: 0.000147
2025-05-29 22:28:09,201 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:28:09,201 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:28:53,240 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.91, acc:   0.53, generation: 43.9947[sec], evaluation: 0.0000[sec]
2025-05-29 22:28:53,241 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:28:53,486 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/86500.ckpt
2025-05-29 22:28:53,505 - INFO - joeynmt.training - Example #0
2025-05-29 22:28:53,506 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:28:53,506 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:28:53,506 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'gr@@', 'ond', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'en.', '</s>']
2025-05-29 22:28:53,507 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:28:53,507 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:28:53,508 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te bekijken dat de artische ijskappen, die de artische ijskappen, die de grond drie miljoen jaar de grootte van de onderste 40 procent geschrumpen.
2025-05-29 22:28:53,508 - INFO - joeynmt.training - Example #1
2025-05-29 22:28:53,508 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:28:53,508 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:28:53,508 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'ver@@', 'stan@@', 'dig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'z@@', 'er', 'van', 'het', 'ij@@', 's.', '</s>']
2025-05-29 22:28:53,509 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:28:53,510 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:28:53,510 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste verstandigheid van dit speciale probleem van dit ijs is niet de dikke van het ijzer van het ijs.
2025-05-29 22:28:53,510 - INFO - joeynmt.training - Example #2
2025-05-29 22:28:53,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:28:53,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:28:53,511 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 't', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:28:53,512 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:28:53,513 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:28:53,513 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskaart het hart van ons wereldwijde klimaatsysteem.
2025-05-29 22:28:53,513 - INFO - joeynmt.training - Example #3
2025-05-29 22:28:53,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:28:53,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:28:53,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'it', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 22:28:53,515 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:28:53,515 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:28:53,515 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluit in de zomer.
2025-05-29 22:28:53,515 - INFO - joeynmt.training - Example #4
2025-05-29 22:28:53,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:28:53,516 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:28:53,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'ti@@', 'me@@', '-@@', 'op@@', 'nam@@', 'e', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-29 22:28:53,517 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:28:53,517 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:28:53,518 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een time-opname wat er gebeurde in de afgelopen 25 jaar is.
2025-05-29 22:29:03,711 - INFO - joeynmt.training - Epoch  10, Step:    89100, Batch Loss:     1.504044, Batch Acc: 0.580510, Tokens per Sec:     6848, Lr: 0.000147
2025-05-29 22:29:13,975 - INFO - joeynmt.training - Epoch  10, Step:    89200, Batch Loss:     1.475219, Batch Acc: 0.580217, Tokens per Sec:     6891, Lr: 0.000147
2025-05-29 22:29:24,308 - INFO - joeynmt.training - Epoch  10, Step:    89300, Batch Loss:     1.486530, Batch Acc: 0.577917, Tokens per Sec:     6829, Lr: 0.000147
2025-05-29 22:29:34,934 - INFO - joeynmt.training - Epoch  10, Step:    89400, Batch Loss:     1.403190, Batch Acc: 0.574135, Tokens per Sec:     6785, Lr: 0.000147
2025-05-29 22:29:44,618 - INFO - joeynmt.training - Epoch  10, Step:    89500, Batch Loss:     1.370765, Batch Acc: 0.576549, Tokens per Sec:     7063, Lr: 0.000147
2025-05-29 22:29:44,624 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:29:44,625 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:30:32,591 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.92, acc:   0.53, generation: 47.9254[sec], evaluation: 0.0000[sec]
2025-05-29 22:30:32,816 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/85000.ckpt
2025-05-29 22:30:32,834 - INFO - joeynmt.training - Example #0
2025-05-29 22:30:32,835 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:30:32,835 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:30:32,835 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'ver@@', 'kijken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'die', 'de', 'gr@@', 'ens', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'ha@@', 'd,', 'om', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'is.', '</s>']
2025-05-29 22:30:32,837 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:30:32,837 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:30:32,837 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkijken dat de arctische ijskappen, die de arctische ijskappels die de grens 48 staten had gehad, om 40 procent van de onderste 40 procent van de onderste 40 procent is.
2025-05-29 22:30:32,837 - INFO - joeynmt.training - Example #1
2025-05-29 22:30:32,838 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:30:32,838 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:30:32,838 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eerste', 'ver@@', 'van@@', 'gen', 'de', 'eerste', 'kan@@', 's', 'om', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'te', 'laten', 'zien.', '</s>']
2025-05-29 22:30:32,839 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:30:32,839 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:30:32,839 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste vervangen de eerste kans om dit speciale probleem te laten zien.
2025-05-29 22:30:32,839 - INFO - joeynmt.training - Example #2
2025-05-29 22:30:32,840 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:30:32,840 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:30:32,840 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'op', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:30:32,841 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:30:32,841 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:30:32,841 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskop het slaagsysteem van ons wereldwijde klimaatsysteem.
2025-05-29 22:30:32,841 - INFO - joeynmt.training - Example #3
2025-05-29 22:30:32,842 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:30:32,842 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:30:32,842 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'l@@', 'oo@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 22:30:32,843 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:30:32,843 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:30:32,843 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en loopt in de zomer.
2025-05-29 22:30:32,844 - INFO - joeynmt.training - Example #4
2025-05-29 22:30:32,844 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:30:32,844 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:30:32,845 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'de', 'laat@@', 'ste', '2@@', '5', 'j@@', 'aar.', '</s>']
2025-05-29 22:30:32,846 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:30:32,846 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:30:32,846 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje van de laatste 25 jaar.
2025-05-29 22:30:43,200 - INFO - joeynmt.training - Epoch  10, Step:    89600, Batch Loss:     1.444252, Batch Acc: 0.578792, Tokens per Sec:     6559, Lr: 0.000147
2025-05-29 22:30:53,709 - INFO - joeynmt.training - Epoch  10, Step:    89700, Batch Loss:     1.434898, Batch Acc: 0.571461, Tokens per Sec:     6730, Lr: 0.000147
2025-05-29 22:31:04,005 - INFO - joeynmt.training - Epoch  10, Step:    89800, Batch Loss:     1.315835, Batch Acc: 0.573207, Tokens per Sec:     6686, Lr: 0.000147
2025-05-29 22:31:14,675 - INFO - joeynmt.training - Epoch  10, Step:    89900, Batch Loss:     1.453007, Batch Acc: 0.574867, Tokens per Sec:     6663, Lr: 0.000147
2025-05-29 22:31:25,583 - INFO - joeynmt.training - Epoch  10, Step:    90000, Batch Loss:     1.375064, Batch Acc: 0.579682, Tokens per Sec:     6250, Lr: 0.000147
2025-05-29 22:31:25,584 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:31:25,584 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:32:10,293 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.91, acc:   0.53, generation: 44.6619[sec], evaluation: 0.0000[sec]
2025-05-29 22:32:10,294 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:32:10,515 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/83000.ckpt
2025-05-29 22:32:10,537 - INFO - joeynmt.training - Example #0
2025-05-29 22:32:10,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:32:10,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:32:10,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'die', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-29 22:32:10,539 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:32:10,539 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:32:10,540 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te bekijken dat de arctische ijskappen, die de artische ijskappels die de grootte van de onderste 48 staten had geslaagd om 40 procent te verzamelen.
2025-05-29 22:32:10,540 - INFO - joeynmt.training - Example #1
2025-05-29 22:32:10,540 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:32:10,540 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:32:10,540 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'e,', 'voor@@', 'al', 'dat', 'proble@@', 'em', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'is', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'je', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ap@@', '.', '</s>']
2025-05-29 22:32:10,541 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:32:10,541 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:32:10,542 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste, vooral dat probleem speciale probleem is omdat het niet de dikke van het ijsje van het ijsje van het ijsje van het ijskap.
2025-05-29 22:32:10,542 - INFO - joeynmt.training - Example #2
2025-05-29 22:32:10,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:32:10,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:32:10,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:32:10,543 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:32:10,544 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:32:10,544 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het slaagsysteem van ons wereldwijde klimaatsysteem.
2025-05-29 22:32:10,544 - INFO - joeynmt.training - Example #3
2025-05-29 22:32:10,545 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:32:10,545 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:32:10,545 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 't.', '</s>']
2025-05-29 22:32:10,546 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:32:10,546 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:32:10,546 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomert.
2025-05-29 22:32:10,546 - INFO - joeynmt.training - Example #4
2025-05-29 22:32:10,547 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:32:10,547 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:32:10,547 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zien', 'is', 'een', 'ti@@', 'me@@', '-@@', 'tra@@', 'ff@@', 'er@@', 'ing', 'van', 'wat', 'er', 'gebeur@@', 'd', 'is', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:32:10,548 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:32:10,549 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:32:10,549 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een time-traffering van wat er gebeurd is in de laatste 25 jaar is gebeurd.
2025-05-29 22:32:20,666 - INFO - joeynmt.training - Epoch  10, Step:    90100, Batch Loss:     1.352821, Batch Acc: 0.575092, Tokens per Sec:     6659, Lr: 0.000147
2025-05-29 22:32:30,669 - INFO - joeynmt.training - Epoch  10, Step:    90200, Batch Loss:     1.202179, Batch Acc: 0.579339, Tokens per Sec:     7111, Lr: 0.000147
2025-05-29 22:32:40,751 - INFO - joeynmt.training - Epoch  10, Step:    90300, Batch Loss:     1.380843, Batch Acc: 0.573805, Tokens per Sec:     6817, Lr: 0.000147
2025-05-29 22:32:50,746 - INFO - joeynmt.training - Epoch  10, Step:    90400, Batch Loss:     1.383679, Batch Acc: 0.576289, Tokens per Sec:     6955, Lr: 0.000147
2025-05-29 22:33:00,666 - INFO - joeynmt.training - Epoch  10, Step:    90500, Batch Loss:     1.414936, Batch Acc: 0.578556, Tokens per Sec:     7128, Lr: 0.000147
2025-05-29 22:33:00,666 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:33:00,667 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:33:42,975 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.92, acc:   0.53, generation: 42.2709[sec], evaluation: 0.0000[sec]
2025-05-29 22:33:43,275 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/88000.ckpt
2025-05-29 22:33:43,297 - INFO - joeynmt.training - Example #0
2025-05-29 22:33:43,298 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:33:43,298 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:33:43,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['A@@', 'f@@', 'gel@@', 'open', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'die', 'de', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'maakt', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'ach@@', 't.', '</s>']
2025-05-29 22:33:43,300 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:33:43,300 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:33:43,300 - INFO - joeynmt.training - 	Hypothesis: Afgelopen jaar heb ik deze twee gevolgen om te bekijken dat de artische ijskappels die de artische ijskappels die de 48 staten had gemaakt voor de onderste 40 procent geslacht.
2025-05-29 22:33:43,300 - INFO - joeynmt.training - Example #1
2025-05-29 22:33:43,301 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:33:43,301 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:33:43,301 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'e,', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'proble@@', 'em', 'van', 'dit', 'ij@@', 's', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's.', '</s>']
2025-05-29 22:33:43,303 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:33:43,304 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:33:43,304 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste, omdat het niet de dikke probleem van dit ijs is niet de dikke van het ijs.
2025-05-29 22:33:43,304 - INFO - joeynmt.training - Example #2
2025-05-29 22:33:43,304 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:33:43,304 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:33:43,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:33:43,306 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:33:43,306 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:33:43,306 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-29 22:33:43,306 - INFO - joeynmt.training - Example #3
2025-05-29 22:33:43,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:33:43,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:33:43,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'l@@', 'oo@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 22:33:43,308 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:33:43,308 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:33:43,308 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en loopt in de zomer.
2025-05-29 22:33:43,308 - INFO - joeynmt.training - Example #4
2025-05-29 22:33:43,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:33:43,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:33:43,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'ti@@', 'me@@', '-@@', 'tra@@', 'ff@@', 'er@@', 'ing', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:33:43,310 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:33:43,310 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:33:43,310 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een time-traffering in de afgelopen 25 jaar is gebeurd.
2025-05-29 22:33:53,673 - INFO - joeynmt.training - Epoch  10, Step:    90600, Batch Loss:     1.492660, Batch Acc: 0.577385, Tokens per Sec:     6517, Lr: 0.000147
2025-05-29 22:34:05,755 - INFO - joeynmt.training - Epoch  10, Step:    90700, Batch Loss:     1.435233, Batch Acc: 0.575488, Tokens per Sec:     5821, Lr: 0.000147
2025-05-29 22:34:17,599 - INFO - joeynmt.training - Epoch  10, Step:    90800, Batch Loss:     1.457082, Batch Acc: 0.572728, Tokens per Sec:     5689, Lr: 0.000147
2025-05-29 22:34:28,634 - INFO - joeynmt.training - Epoch  10, Step:    90900, Batch Loss:     1.622278, Batch Acc: 0.573161, Tokens per Sec:     6339, Lr: 0.000147
2025-05-29 22:34:39,896 - INFO - joeynmt.training - Epoch  10, Step:    91000, Batch Loss:     1.235924, Batch Acc: 0.579399, Tokens per Sec:     6513, Lr: 0.000147
2025-05-29 22:34:39,897 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:34:39,897 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:35:34,675 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.91, acc:   0.53, generation: 54.7367[sec], evaluation: 0.0000[sec]
2025-05-29 22:35:34,676 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 22:35:34,892 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/88500.ckpt
2025-05-29 22:35:34,915 - INFO - joeynmt.training - Example #0
2025-05-29 22:35:34,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:35:34,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:35:34,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'en,', 'die', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'die', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'om', '4@@', '0', 'proc@@', 'ent', 'te', 'ver@@', 'm@@', 'inder@@', 'en.', '</s>']
2025-05-29 22:35:34,917 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:35:34,918 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:35:34,918 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen getoond om te bekijken dat de artische ijskappen, die de artische ijskappels die de grens van de onderste 48 staten had geslaagd om 40 procent te verminderen.
2025-05-29 22:35:34,918 - INFO - joeynmt.training - Example #1
2025-05-29 22:35:34,918 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:35:34,919 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:35:34,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st@@', 'ver@@', 'v@@', 'u@@', 'il@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's.', '</s>']
2025-05-29 22:35:34,920 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:35:34,920 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:35:34,920 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerstvervuiling van dit speciale probleem omdat het niet de dikke dikke van het ijs.
2025-05-29 22:35:34,920 - INFO - joeynmt.training - Example #2
2025-05-29 22:35:34,921 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:35:34,921 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:35:34,921 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'e', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:35:34,922 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:35:34,922 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:35:34,922 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-29 22:35:34,923 - INFO - joeynmt.training - Example #3
2025-05-29 22:35:34,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:35:34,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:35:34,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'l@@', 'oo@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-29 22:35:34,924 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:35:34,924 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:35:34,924 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en loopt in de zomer.
2025-05-29 22:35:34,925 - INFO - joeynmt.training - Example #4
2025-05-29 22:35:34,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:35:34,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:35:34,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'f@@', 'ten', 'in', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:35:34,926 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:35:34,926 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:35:34,927 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschriften in de afgelopen 25 jaar is gebeurd.
2025-05-29 22:35:46,847 - INFO - joeynmt.training - Epoch  10, Step:    91100, Batch Loss:     1.248091, Batch Acc: 0.576004, Tokens per Sec:     5718, Lr: 0.000147
2025-05-29 22:35:58,344 - INFO - joeynmt.training - Epoch  10, Step:    91200, Batch Loss:     1.481572, Batch Acc: 0.573846, Tokens per Sec:     5937, Lr: 0.000147
2025-05-29 22:36:09,554 - INFO - joeynmt.training - Epoch  10, Step:    91300, Batch Loss:     1.252908, Batch Acc: 0.577265, Tokens per Sec:     6238, Lr: 0.000147
2025-05-29 22:36:21,636 - INFO - joeynmt.training - Epoch  10, Step:    91400, Batch Loss:     1.481513, Batch Acc: 0.576319, Tokens per Sec:     6009, Lr: 0.000147
2025-05-29 22:36:32,487 - INFO - joeynmt.training - Epoch  10, Step:    91500, Batch Loss:     1.417585, Batch Acc: 0.576472, Tokens per Sec:     6458, Lr: 0.000147
2025-05-29 22:36:32,488 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:36:32,488 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:37:15,944 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.92, acc:   0.53, generation: 43.4153[sec], evaluation: 0.0000[sec]
2025-05-29 22:37:15,952 - INFO - joeynmt.training - Example #0
2025-05-29 22:37:15,953 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:37:15,953 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:37:15,953 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd,', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'aar@@', 'ten', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'l@@', 'ag@@', 'ere', 'sta@@', 'd', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'ach@@', 't.', '</s>']
2025-05-29 22:37:15,954 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:37:15,955 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:37:15,955 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond, om te bekijken dat de artische ijskaarten die drie miljoen jaar de grootte van de lagere stad drie miljoen jaar de grootte van de onderste 40 procent geslacht.
2025-05-29 22:37:15,955 - INFO - joeynmt.training - Example #1
2025-05-29 22:37:15,955 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:37:15,956 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:37:15,956 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'to@@', 'on@@', 't.', '</s>']
2025-05-29 22:37:15,957 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:37:15,958 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:37:15,958 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerst van dit speciale probleem van dit speciale probleem toont.
2025-05-29 22:37:15,958 - INFO - joeynmt.training - Example #2
2025-05-29 22:37:15,958 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:37:15,959 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:37:15,959 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 'sl@@', 'aa@@', 'g@@', 'syste@@', 'em', 'van', 'onze', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'men.', '</s>']
2025-05-29 22:37:15,960 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:37:15,960 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:37:15,960 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het slaagsysteem van onze wereldwijde klimaatsystemen.
2025-05-29 22:37:15,960 - INFO - joeynmt.training - Example #3
2025-05-29 22:37:15,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:37:15,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:37:15,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 's@@', 'lu@@', 'i@@', 'ten', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:37:15,963 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:37:15,963 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:37:15,963 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sluiten in de zomers.
2025-05-29 22:37:15,963 - INFO - joeynmt.training - Example #4
2025-05-29 22:37:15,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:37:15,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:37:15,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'ti@@', 'me@@', '-@@', 'tra@@', 'ff@@', 'er@@', 'ing', 'van', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:37:15,965 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:37:15,965 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:37:15,965 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een time-traffering van wat er gebeurde in de laatste 25 jaar is gebeurd.
2025-05-29 22:37:26,001 - INFO - joeynmt.training - Epoch  10, Step:    91600, Batch Loss:     1.398604, Batch Acc: 0.575383, Tokens per Sec:     7042, Lr: 0.000147
2025-05-29 22:37:35,795 - INFO - joeynmt.training - Epoch  10, Step:    91700, Batch Loss:     1.261739, Batch Acc: 0.580353, Tokens per Sec:     7044, Lr: 0.000147
2025-05-29 22:37:46,695 - INFO - joeynmt.training - Epoch  10, Step:    91800, Batch Loss:     1.319230, Batch Acc: 0.575288, Tokens per Sec:     6478, Lr: 0.000147
2025-05-29 22:37:59,231 - INFO - joeynmt.training - Epoch  10, Step:    91900, Batch Loss:     1.296363, Batch Acc: 0.580914, Tokens per Sec:     5630, Lr: 0.000147
2025-05-29 22:38:09,872 - INFO - joeynmt.training - Epoch  10, Step:    92000, Batch Loss:     1.419529, Batch Acc: 0.576160, Tokens per Sec:     6271, Lr: 0.000147
2025-05-29 22:38:09,874 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:38:09,874 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:38:52,668 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.91, acc:   0.53, generation: 42.7547[sec], evaluation: 0.0000[sec]
2025-05-29 22:38:53,483 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe/89500.ckpt
2025-05-29 22:38:53,500 - INFO - joeynmt.training - Example #0
2025-05-29 22:38:53,501 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 'tes', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'gt,', 'um', 'zu', 'ver@@', 'an@@', 'schau@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Mill@@', 'ionen', 'Jahre', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'ru@@', 'mp@@', 'ft', 'ist.']
2025-05-29 22:38:53,501 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Vor@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twee', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'ool@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'open', 'drie', 'miljo@@', 'en', 'jaar', 'ongeveer', 'de', 'groot@@', 'te', 'had', 'van', 'het', 'v@@', 'ast@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'was.']
2025-05-29 22:38:53,502 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Vor@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twee', 'ge@@', 'vol@@', 'gen', 'ge@@', 'to@@', 'ond', 'om', 'te', 'be@@', 'kijken', 'dat', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'app@@', 'el@@', 's', 'die', 'drie', 'miljo@@', 'en', 'jaar', 'de', 'groot@@', 'te', 'van', 'de', 'gr@@', 'ens', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'had', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'om', '4@@', '0', 'proc@@', 'ent', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'te', 'zijn.', '</s>']
2025-05-29 22:38:53,502 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 22:38:53,503 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 22:38:53,503 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen getoond om te bekijken dat de artische ijskappels die drie miljoen jaar de grootte van de grens van de onderste 48 staten had geslaagd om 40 procent geslaagd te zijn.
2025-05-29 22:38:53,503 - INFO - joeynmt.training - Example #1
2025-05-29 22:38:53,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'star@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'spe@@', 'zi@@', 'ellen', 'Proble@@', 'm@@', 's', 'aus,', 'da', 'es', 'nicht', 'die', 'Di@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 22:38:53,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'at', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien.']
2025-05-29 22:38:53,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'genoe@@', 'g', 'de', 'eer@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'proble@@', 'em', 'omdat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'ij@@', 's@@', 'en.', '</s>']
2025-05-29 22:38:53,504 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 22:38:53,504 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 22:38:53,504 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerst van dit speciale probleem van dit speciale probleem omdat het niet de dikke van ijsen.
2025-05-29 22:38:53,505 - INFO - joeynmt.training - Example #2
2025-05-29 22:38:53,505 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sche', 'E@@', 'is@@', 'k@@', 'app@@', 'e', 'das', 'sch@@', 'la@@', 'gende', 'Her@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'alen', 'K@@', 'li@@', 'ma@@', 'syste@@', 'm@@', 's.']
2025-05-29 22:38:53,505 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'ap', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'har@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.']
2025-05-29 22:38:53,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sche', 'ij@@', 's@@', 'k@@', 'op', 'het', 'sl@@', 'ag@@', 'syste@@', 'em', 'het', 'har@@', 't', 'van', 'ons', 'werel@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'syste@@', 'em@@', '.', '</s>']
2025-05-29 22:38:53,506 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 22:38:53,506 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 22:38:53,506 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskop het slagsysteem het hart van ons wereldwijde klimaatsysteem.
2025-05-29 22:38:53,506 - INFO - joeynmt.training - Example #3
2025-05-29 22:38:53,506 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'mp@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 22:38:53,506 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'win@@', 'ter', 'en', 'kr@@', 'im@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 22:38:53,507 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'win@@', 'ter', 'en', 'l@@', 'oo@@', 'pt', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 22:38:53,507 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 22:38:53,507 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 22:38:53,508 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en loopt in de zomers.
2025-05-29 22:38:53,508 - INFO - joeynmt.training - Example #4
2025-05-29 22:38:53,508 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ihnen', 'zei@@', 'ge,', 'ist', 'eine', 'Zei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'pass@@', 'iert', 'ist.']
2025-05-29 22:38:53,508 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 'sn@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'open', '2@@', '5', 'jaar', 'is', 'gebeur@@', 'd.']
2025-05-29 22:38:53,508 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gende', 'di@@', 'a', 'die', 'ik', 'jullie', 'laten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'sch@@', 'ri@@', 'ft', 'van', 'wat', 'er', 'gebeur@@', 'de', 'in', 'de', 'laat@@', 'ste', '2@@', '5', 'jaar', 'gebeur@@', 'd.', '</s>']
2025-05-29 22:38:53,509 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 22:38:53,509 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 22:38:53,509 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdschrift van wat er gebeurde in de laatste 25 jaar gebeurd.
2025-05-29 22:39:03,128 - INFO - joeynmt.training - Epoch  10, Step:    92100, Batch Loss:     1.323218, Batch Acc: 0.571268, Tokens per Sec:     6732, Lr: 0.000147
2025-05-29 22:39:12,608 - INFO - joeynmt.training - Epoch  10, Step:    92200, Batch Loss:     1.370209, Batch Acc: 0.578671, Tokens per Sec:     7585, Lr: 0.000147
2025-05-29 22:39:22,893 - INFO - joeynmt.training - Epoch  10, Step:    92300, Batch Loss:     1.510436, Batch Acc: 0.584292, Tokens per Sec:     6695, Lr: 0.000147
2025-05-29 22:39:26,986 - INFO - joeynmt.training - Epoch  10: total training loss 13066.18
2025-05-29 22:39:26,986 - INFO - joeynmt.training - Training ended after  10 epochs.
2025-05-29 22:39:26,987 - INFO - joeynmt.training - Best validation result (greedy) at step    91000:   4.91 ppl.
2025-05-29 22:39:27,033 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-29 22:39:27,180 - INFO - joeynmt.model - Enc-dec model built.
2025-05-29 22:39:27,359 - INFO - joeynmt.helpers - Load model from C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe\91000.ckpt.
2025-05-29 22:39:27,401 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=1771),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=1736),
	loss_function=None)
2025-05-29 22:39:27,426 - INFO - joeynmt.prediction - Decoding on dev set...
2025-05-29 22:39:27,426 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:39:27,427 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Beam search with beam_size=3, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:40:19,580 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 52.1194[sec], evaluation: 0.0000[sec]
2025-05-29 22:40:19,594 - INFO - joeynmt.prediction - Translations saved to: C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe\00091000.hyps.dev.
2025-05-29 22:40:19,595 - INFO - joeynmt.prediction - Decoding on test set...
2025-05-29 22:40:19,595 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:40:19,595 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=3, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 22:41:36,838 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 77.2058[sec], evaluation: 0.0000[sec]
2025-05-29 22:41:36,850 - INFO - joeynmt.prediction - Translations saved to: C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe\00091000.hyps.test.
