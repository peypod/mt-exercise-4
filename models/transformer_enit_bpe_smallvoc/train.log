2025-05-29 22:58:49,716 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-29 22:58:49,717 - INFO - joeynmt.helpers -                           cfg.name : transformer_enit_config
2025-05-29 22:58:49,717 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-29 22:58:49,718 - INFO - joeynmt.helpers -                     cfg.data.train : data/train.de-nl
2025-05-29 22:58:49,718 - INFO - joeynmt.helpers -                       cfg.data.dev : data/dev.de-nl
2025-05-29 22:58:49,718 - INFO - joeynmt.helpers -                      cfg.data.test : data/test.de-nl
2025-05-29 22:58:49,718 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-29 22:58:49,718 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2025-05-29 22:58:49,719 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-29 22:58:49,719 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-29 22:58:49,719 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-29 22:58:49,719 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : data/bpe_s_vocab.de
2025-05-29 22:58:49,719 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-29 22:58:49,719 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenizer : none
2025-05-29 22:58:49,719 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.num_merges : 2000
2025-05-29 22:58:49,720 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data/small_codes.bpe
2025-05-29 22:58:49,720 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : nl
2025-05-29 22:58:49,720 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-29 22:58:49,720 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-29 22:58:49,720 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-29 22:58:49,720 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : data/bpe_s_vocab.nl
2025-05-29 22:58:49,720 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-29 22:58:49,720 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenizer : none
2025-05-29 22:58:49,721 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.num_merges : 2000
2025-05-29 22:58:49,721 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data/small_codes.bpe
2025-05-29 22:58:49,721 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 3
2025-05-29 22:58:49,721 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-29 22:58:49,721 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-29 22:58:49,721 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-29 22:58:49,721 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-29 22:58:49,721 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-29 22:58:49,722 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-29 22:58:49,722 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-29 22:58:49,722 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-29 22:58:49,722 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-29 22:58:49,722 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-29 22:58:49,722 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-29 22:58:49,722 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-29 22:58:49,723 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-29 22:58:49,723 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-29 22:58:49,723 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-29 22:58:49,723 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-29 22:58:49,723 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-29 22:58:49,723 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-29 22:58:49,723 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/transformer_enit_bpe_smallvoc
2025-05-29 22:58:49,724 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-29 22:58:49,724 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-29 22:58:49,724 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2025-05-29 22:58:49,724 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-29 22:58:49,724 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-29 22:58:49,724 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-29 22:58:49,724 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-29 22:58:49,724 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-29 22:58:49,724 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-29 22:58:49,724 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-29 22:58:49,725 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-29 22:58:49,725 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : False
2025-05-29 22:58:49,725 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-29 22:58:49,725 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-29 22:58:49,725 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-29 22:58:49,725 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-29 22:58:49,725 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-29 22:58:49,726 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-29 22:58:49,726 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-29 22:58:49,726 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-29 22:58:49,726 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-29 22:58:49,726 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-29 22:58:49,726 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-29 22:58:49,726 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-29 22:58:49,727 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-29 22:58:49,727 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-29 22:58:49,727 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-29 22:58:49,727 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-29 22:58:49,727 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-29 22:58:49,727 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-29 22:58:49,727 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-29 22:58:49,778 - INFO - joeynmt.data - Building tokenizer...
2025-05-29 22:58:49,784 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 22:58:49,785 - INFO - joeynmt.tokenizers - nl tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 22:58:49,785 - INFO - joeynmt.data - Loading train set...
2025-05-29 22:58:50,450 - INFO - joeynmt.data - Building vocabulary...
2025-05-29 22:58:50,469 - INFO - joeynmt.data - Loading dev set...
2025-05-29 22:58:50,474 - INFO - joeynmt.data - Loading test set...
2025-05-29 22:58:50,481 - INFO - joeynmt.data - Data loaded.
2025-05-29 22:58:50,481 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=216893, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2025-05-29 22:58:50,481 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1001, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2025-05-29 22:58:50,481 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1779, src_lang=de, trg_lang=nl, has_trg=True, random_subset=-1)
2025-05-29 22:58:50,482 - INFO - joeynmt.data - First training example:
	[SRC] A@@ l G@@ or@@ e@@ : Die A@@ b@@ wen@@ d@@ ung der K@@ l@@ i@@ ma@@ k@@ at@@ a@@ st@@ ro@@ p@@ h@@ e
	[TRG] A@@ l G@@ or@@ e over het af@@ wen@@ den van de kl@@ im@@ aat@@ c@@ r@@ is@@ is
2025-05-29 22:58:50,482 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) s@@ (5) , (6) t@@ (7) e (8) en (9) die
2025-05-29 22:58:50,483 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) en (6) k@@ (7) een (8) e@@ (9) het
2025-05-29 22:58:50,483 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 925
2025-05-29 22:58:50,483 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 906
2025-05-29 22:58:50,514 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-29 22:58:50,942 - INFO - joeynmt.model - Enc-dec model built.
2025-05-29 22:58:50,956 - INFO - joeynmt.model - Total params: 3367936
2025-05-29 22:58:50,956 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2025-05-29 22:58:50,957 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=925),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=906),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-29 22:58:51,119 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2025-05-29 22:58:51,119 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2025-05-29 22:58:51,119 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2025-05-29 22:58:51,119 - INFO - joeynmt.training - EPOCH 1
2025-05-29 22:59:01,313 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.615496, Batch Acc: 0.035240, Tokens per Sec:     7205, Lr: 0.000300
2025-05-29 22:59:08,040 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     3.555670, Batch Acc: 0.055894, Tokens per Sec:    10381, Lr: 0.000300
2025-05-29 22:59:14,767 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.388234, Batch Acc: 0.069903, Tokens per Sec:    10575, Lr: 0.000300
2025-05-29 22:59:21,431 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.171393, Batch Acc: 0.082370, Tokens per Sec:    10902, Lr: 0.000300
2025-05-29 22:59:28,227 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.070099, Batch Acc: 0.095704, Tokens per Sec:    10590, Lr: 0.000300
2025-05-29 22:59:28,227 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 22:59:28,227 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:00:11,485 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.15, ppl:  23.35, acc:   0.10, generation: 43.1925[sec], evaluation: 0.0000[sec]
2025-05-29 23:00:11,486 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:00:11,605 - INFO - joeynmt.training - Example #0
2025-05-29 23:00:11,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:00:11,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:00:11,606 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'be@@', 'l', 'het', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'den', 'van', 'de', 'be@@', 'be@@', 'be@@', 'be@@', 'k@@', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'de', 'de', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@', 'be@@']
2025-05-29 23:00:11,607 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:00:11,607 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:00:11,607 - INFO - joeynmt.training - 	Hypothesis: Ik bel het bebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebeden van de bebebebeken en en en en en en en en de de bebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebebe
2025-05-29 23:00:11,607 - INFO - joeynmt.training - Example #1
2025-05-29 23:00:11,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:00:11,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:00:11,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'is', 'de', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'en', 'van', 'de', 'm@@', 'il@@', 'm@@', 'en', 'van', 'de', 'm@@', 'm@@', 'm@@', 'm@@', 'en', 'van', 'de', 'm@@', 'm@@', 'm@@', 'il@@', 'm@@', 'il@@', 'm@@', 'il@@', 'm@@', 'en', 'van', 'de', 'm@@', 'en', 'van', 'de', 'm@@', 'm@@', 'il@@', 'm@@', 'il@@', 'm@@', 'il@@', 'k@@', 'en', 'van', 'de', 'm@@', 'm@@', 'en', 'van', 'de', 'm@@', 'il@@', 'e', 'b@@', 'u@@', 'u@@', 'u@@', 'den', 'van', 'de', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'en', 'van', 'de', 'b@@', 'u@@', 'den', 'van', 'de', 'm@@', 'il@@', 'd', 'van', 'de', 'm@@', 'm@@', 'm@@', 'm@@', 'm@@', 'en', 'van']
2025-05-29 23:00:11,608 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:00:11,609 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:00:11,609 - INFO - joeynmt.training - 	Hypothesis: Maar het is de mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmen van de milmen van de mmmmen van de mmmilmilmilmen van de men van de mmilmilmilken van de mmen van de mile buuuden van de mmmmmmmmmmmen van de buden van de mild van de mmmmmen van
2025-05-29 23:00:11,609 - INFO - joeynmt.training - Example #2
2025-05-29 23:00:11,609 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:00:11,609 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:00:11,609 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'is', 'de', 'b@@', 'o@@', 'en', 'van', 'de', 'b@@', 'o@@', 'en', 'van', 'de', 'p@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'd', 'van', 'de', 'p@@', 'u@@', 'den', 'van', 'de', 'p@@', 'u@@', 'u@@', 'den', 'van', 'de', 'b@@', 'u@@', 'd', 'van', 'de', 'b@@', 'u@@', 'd', 'van', 'de', 'b@@', 'u@@', 'd', 'van', 'de', 'p@@', 'u@@', 'd', 'van', 'de', 'p@@', 'u@@', 'den', 'van', 'de', 'b@@', 'u@@', 'den', 'van', 'de', 'm@@', 'en', 'van', 'de', 'b@@', 'u@@', 'den', 'van', 'de', 'm@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', 'el@@', '.', '</s>']
2025-05-29 23:00:11,610 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:00:11,610 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:00:11,610 - INFO - joeynmt.training - 	Hypothesis: Het is de boen van de boen van de puuuuuuuuuuuuuuuuuud van de puden van de puuden van de bud van de bud van de bud van de pud van de puden van de buden van de men van de buden van de melelelelelel.
2025-05-29 23:00:11,610 - INFO - joeynmt.training - Example #3
2025-05-29 23:00:11,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:00:11,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:00:11,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'zijn', 'een', 'm@@', 'm@@', 'el@@', 'el@@', '.', '</s>']
2025-05-29 23:00:11,611 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:00:11,611 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:00:11,611 - INFO - joeynmt.training - 	Hypothesis: Ze zijn een mmelel.
2025-05-29 23:00:11,611 - INFO - joeynmt.training - Example #4
2025-05-29 23:00:11,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:00:11,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:00:11,612 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'be@@', 'be@@', 'be@@', 'k@@', 'en', 'de', 'b@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'den', 'van', 'de', 'm@@', 'u@@', 'u@@', 'u@@', 'u@@', 'den', 'van', 'de', 'm@@', 'en', 'en', 'de', 'm@@', 'en', 'de', 'm@@', 'en.', '</s>']
2025-05-29 23:00:11,612 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:00:11,612 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:00:11,612 - INFO - joeynmt.training - 	Hypothesis: De bebebeken de buuuuuuuuuuuuuuuuuuden van de muuuuden van de men en de men de men.
2025-05-29 23:00:18,368 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     2.988572, Batch Acc: 0.114014, Tokens per Sec:    10381, Lr: 0.000300
2025-05-29 23:00:25,503 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     2.851706, Batch Acc: 0.133740, Tokens per Sec:    10421, Lr: 0.000300
2025-05-29 23:00:32,569 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     2.881800, Batch Acc: 0.150483, Tokens per Sec:    10128, Lr: 0.000300
2025-05-29 23:00:39,646 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     2.780902, Batch Acc: 0.163883, Tokens per Sec:    10441, Lr: 0.000300
2025-05-29 23:00:46,716 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     2.756943, Batch Acc: 0.173502, Tokens per Sec:    10453, Lr: 0.000300
2025-05-29 23:00:46,717 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:00:46,717 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:01:24,761 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.78, ppl:  16.14, acc:   0.17, generation: 37.9874[sec], evaluation: 0.0000[sec]
2025-05-29 23:01:24,762 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:01:24,885 - INFO - joeynmt.training - Example #0
2025-05-29 23:01:24,886 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:01:24,886 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:01:24,886 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'ie@@', 'mand', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'v@@', 'ar@@', 'en', 'de', 'v@@', 'ar@@', 'en', 'de', 'v@@', 'ar@@', 'en', 'de', 'v@@', 'ar@@', 'en', 'de', 'de', 'de', 'de', 'm@@', 'il@@', 'j@@', 'ar@@', 'en', 'de', 'v@@', 'ar@@', 'en', 'de', 'de', 'de', 'v@@', 'ar@@', 'en', 'de', 'de', 'ge@@', 'd@@', 'ingen', 'van', 'de', 'de', 'de', 'ge@@', 'be@@', 'ur@@', 'de', 'ge@@', 'be@@', 'ur@@', 'de', 'v@@', 'ar@@', 'd', 'van', 'de', 'ge@@', 'be@@', 'ur@@', 'de', 'v@@', 'ar@@', 'en', 'de', 'v@@', 'ar@@', 'en', 'de', 'v@@', 'el@@', 'e', 'van', 'de', 'p@@', 'o@@', 't', 'van', 'de', 'p@@', 'u@@', 'ur@@', 't', 'van', 'de', 'v@@', 'ar@@', 'ar@@', 'ar@@', 'ar@@', 'ar@@', 'ar@@', 'ar@@', 'en', 'de', 'v@@', 'ar@@', 'en', 'de', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ver@@', 'ander@@', 'en', 'en', 'en', 'en', 'de', 'v@@', 'ar@@', 'en', 'de', 'de', 'de', 'de', 'de', 'de', 'v@@', 'ar@@']
2025-05-29 23:01:24,887 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:01:24,887 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:01:24,887 - INFO - joeynmt.training - 	Hypothesis: Niemand de de de de de de de de de varen de varen de varen de varen de de de de miljaren de varen de de de varen de de gedingen van de de de gebeurde gebeurde vard van de gebeurde varen de varen de vele van de pot van de puurt van de varararararararen de varen de ververververververanderen en en en de varen de de de de de de var
2025-05-29 23:01:24,888 - INFO - joeynmt.training - Example #1
2025-05-29 23:01:24,888 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:01:24,888 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:01:24,888 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'is', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'ge@@', 'be@@', 'be@@', 'be@@', 'gr@@', 'ijk', 'is', 'niet', 'niet', 'ge@@', 'ge@@', 'da@@', 'g', 'van', 'de', 'pro@@', 'c@@', 'e@@', 'st@@', 'aat', 'niet', 'niet', 'niet', 'niet', 'niet']
2025-05-29 23:01:24,889 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:01:24,889 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:01:24,889 - INFO - joeynmt.training - 	Hypothesis: Maar niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet is niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet gebebebegrijk is niet niet gegedag van de procestaat niet niet niet niet niet
2025-05-29 23:01:24,889 - INFO - joeynmt.training - Example #2
2025-05-29 23:01:24,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:01:24,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:01:24,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'm@@', 'id@@', 'del@@', 'en', 'de', 'b@@', 'o@@', 'en', 'de', 'p@@', 'ar@@', 'ar@@', 'i@@', 'i@@', 'p@@', 'p@@', 'p@@', 'p@@', 'o@@', 'e', 'p@@', 'p@@', 'el@@', 'e', 'p@@', 'le@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'u@@', 'den', 'de', 'b@@', 'o@@', 't', 'van', 'de', 'b@@', 'o@@', 't', 'van', 'de', 'p@@', 'ar@@', 'i@@', 'i@@', 'i@@', 'i@@', 'i@@', 'i@@', 'i@@', 'p@@', '.', '</s>']
2025-05-29 23:01:24,890 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:01:24,890 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:01:24,890 - INFO - joeynmt.training - 	Hypothesis: In de middelen de boen de parariippppoe ppele pleuuuuuuuuuden de bot van de bot van de pariiiiiiip.
2025-05-29 23:01:24,891 - INFO - joeynmt.training - Example #3
2025-05-29 23:01:24,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:01:24,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:01:24,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'zijn', 'ge@@', 'be@@', 'ur@@', 't', 'van', 'de', 'm@@', 'id@@', 'del@@', 'en', 'en', 'en', 'en', 'in', 'de', 'p@@', 'el@@', 'el@@', 'e', 'v@@', 'el@@', 'e', 'en', 'de', 'p@@', 'el@@', 'e', 'v@@', 'el@@', 'e', 'en', 'de', 'm@@', 'id@@', 'del@@', 'ijk', 'van', 'de', 'b@@', 'u@@', 'ur@@', '.', '</s>']
2025-05-29 23:01:24,891 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:01:24,891 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:01:24,892 - INFO - joeynmt.training - 	Hypothesis: Ze zijn gebeurt van de middelen en en en in de pelele vele en de pele vele en de middelijk van de buur.
2025-05-29 23:01:24,892 - INFO - joeynmt.training - Example #4
2025-05-29 23:01:24,892 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:01:24,892 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:01:24,892 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'm@@', 'id@@', 'den', 'de', 'de', 'v@@', 'a@@', 'g', 'van', 'de', 'de', 'v@@', 'a@@', 'g', 'van', 'de', 'b@@', 'an@@', 'gr@@', 'ij@@', 'f', 'in', 'de', 'v@@', 'a@@', 'st@@', 'aat', 'van', 'de', 'm@@', 'id@@', 'del@@', 'en', 'van', 'de', 'm@@', 'id@@', 'del@@', 'en', 'in', 'de', 'v@@', 'a@@', 'g', 'van', 'de', 'm@@', 'id@@', 'del@@', 'ijk', 'van', 'de', 'b@@', 'u@@', 'w@@', 'et@@', '.', '</s>']
2025-05-29 23:01:24,892 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:01:24,893 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:01:24,893 - INFO - joeynmt.training - 	Hypothesis: De midden de de vag van de de vag van de bangrijf in de vastaat van de middelen van de middelen in de vag van de middelijk van de buwet.
2025-05-29 23:01:31,566 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     2.725779, Batch Acc: 0.183283, Tokens per Sec:    10719, Lr: 0.000300
2025-05-29 23:01:38,209 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     2.657007, Batch Acc: 0.193710, Tokens per Sec:    10675, Lr: 0.000300
2025-05-29 23:01:45,170 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     2.583417, Batch Acc: 0.198739, Tokens per Sec:    10190, Lr: 0.000300
2025-05-29 23:01:52,379 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     2.625400, Batch Acc: 0.205704, Tokens per Sec:    10116, Lr: 0.000300
2025-05-29 23:01:59,786 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     2.588534, Batch Acc: 0.211226, Tokens per Sec:     9505, Lr: 0.000300
2025-05-29 23:01:59,787 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:01:59,787 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:02:47,457 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.61, ppl:  13.57, acc:   0.21, generation: 47.6174[sec], evaluation: 0.0000[sec]
2025-05-29 23:02:47,458 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:02:47,603 - INFO - joeynmt.training - Example #0
2025-05-29 23:02:47,604 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:02:47,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:02:47,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Het', 'was', 'een', 'ge@@', 'be@@', 'ur@@', 't', 'dat', 'ik', 'een', 'p@@', 'aar', 'p@@', 'ar@@', 'i@@', 'ë@@', 'l@@', 'e', 'p@@', 'lan@@', 'e@@', 'ct@@', 'u@@', 'ur@@', 'en', 'dat', 'de', 'j@@', 'o@@', 'en', 'dat', 'de', 'j@@', 'ar@@', 'en', 'dat', 'de', 'j@@', 'ar@@', 'en', 'de', 'j@@', 'o@@', 'en', 'de', 'j@@', 'ar@@', 'en', 'dat', 'de', 'j@@', 'ar@@', 'en', 'de', 'm@@', 'il@@', 'j@@', 'ar@@', 'en', 'en', 'dat', 'de', 'j@@', 'ar@@', 'en', 'de', 'j@@', 'ar@@', 'en', 'en', 'het', 'pro@@', 'c@@', 'ent', 'van', 'de', 'm@@', 'ar@@', 'en', 'dat', 'ik', 'dat', 'ik', 'dat', 'ik', 'dat', 'het', 'pro@@', 'du@@', 'ct@@', 'u@@', 'ur@@', 'en', 'dat', 'ik', 'dat', 'ik', 'dat', 'ik', 'dat', 'de', 'j@@', 'o@@', 'en', 'dat', 'het', 'pro@@', 'c@@', 'ent', 'van', 'de', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'dat', 'de', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'dat', 'de', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'dat', 'het', 'pro@@']
2025-05-29 23:02:47,605 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:02:47,605 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:02:47,605 - INFO - joeynmt.training - 	Hypothesis: Het was een gebeurt dat ik een paar pariële planectuuren dat de joen dat de jaren dat de jaren de joen de jaren dat de jaren de miljaren en dat de jaren de jaren en het procent van de maren dat ik dat ik dat ik dat het productuuren dat ik dat ik dat ik dat de joen dat het procent van de miljoen dat de miljoen dat de miljoen dat het pro
2025-05-29 23:02:47,605 - INFO - joeynmt.training - Example #1
2025-05-29 23:02:47,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:02:47,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:02:47,606 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'ver@@', 't@@', 'aal', 'van', 'de', 'pro@@', 'ble@@', 'em', 'niet', 'niet', 'niet', 'niet', 'niet', 'ver@@', 'h@@', 'aal', 'ver@@', 't@@', 'ro@@', 'm@@', 'm@@', 'is@@', 'sch@@', 'ien', 'pro@@', 'ble@@', 'em', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet']
2025-05-29 23:02:47,606 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:02:47,606 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:02:47,606 - INFO - joeynmt.training - 	Hypothesis: Maar niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet niet vertaal van de probleem niet niet niet niet niet verhaal vertrommisschien probleem niet niet niet niet niet niet niet niet niet niet niet niet
2025-05-29 23:02:47,606 - INFO - joeynmt.training - Example #2
2025-05-29 23:02:47,607 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:02:47,607 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:02:47,607 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'wer@@', 'eld', 'is', 'de', 'p@@', 'ar@@', 'i@@', 'ë@@', 'n', 'van', 'de', 'p@@', 'ar@@', 'i@@', 'ë@@', 'l@@', 'e', 'p@@', 'ar@@', 'i@@', 'ë@@', 'l@@', 'e', 'p@@', 'p@@', 'ar@@', 'i@@', 'ë@@', 'l@@', 'e', 'p@@', 'p@@', 'ar@@', 'i@@', 'ë@@', 'n', 'van', 'de', 'p@@', 'ar@@', 'i@@', 'ë@@', 'n', 'van', 'de', 'p@@', 'ar@@', 'i@@', 'ë@@', 'l@@', 'e', 'p@@', 'p@@', 'p@@', '.', '</s>']
2025-05-29 23:02:47,608 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:02:47,608 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:02:47,608 - INFO - joeynmt.training - 	Hypothesis: In de wereld is de pariën van de pariële pariële ppariële ppariën van de pariën van de pariële ppp.
2025-05-29 23:02:47,608 - INFO - joeynmt.training - Example #3
2025-05-29 23:02:47,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:02:47,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:02:47,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'zijn', 'in', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'p@@', 'lan@@', 'e@@', 'p@@', 'ar@@', 'i@@', 'z@@', 'al', 'in', 'de', 'p@@', 'lan@@', 'e@@', 'p@@', '.', '</s>']
2025-05-29 23:02:47,609 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:02:47,609 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:02:47,609 - INFO - joeynmt.training - 	Hypothesis: Ze zijn in de de de de de de de planeparizal in de planep.
2025-05-29 23:02:47,610 - INFO - joeynmt.training - Example #4
2025-05-29 23:02:47,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:02:47,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:02:47,610 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'v@@', 'raa@@', 'g', 'ik', 'ver@@', 't@@', 'ellen', 'van', 'de', 'de', 'wer@@', 'eld', 'van', 'de', 'j@@', 'ar@@', 'en', 'ik', 'een', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'j@@', 'ar@@', 'en', 'in', 'de', 'j@@', 'ar@@', 'en', 'in', 'de', 'j@@', 'ar@@', 'en', 'ik', 'een', 'p@@', 'aar', 'k@@', 'rij@@', 'gen', 'van', 'de', 'j@@', 'ar@@', 'en', 'het', 'ver@@', 'ander@@', 'en.', '</s>']
2025-05-29 23:02:47,611 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:02:47,611 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:02:47,611 - INFO - joeynmt.training - 	Hypothesis: De vraag ik vertellen van de de wereld van de jaren ik een gebeurt in de jaren in de jaren in de jaren ik een paar krijgen van de jaren het veranderen.
2025-05-29 23:02:55,894 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     2.449663, Batch Acc: 0.222644, Tokens per Sec:     8466, Lr: 0.000300
2025-05-29 23:03:03,916 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     2.565631, Batch Acc: 0.226380, Tokens per Sec:     9095, Lr: 0.000300
2025-05-29 23:03:11,991 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.510706, Batch Acc: 0.237553, Tokens per Sec:     8806, Lr: 0.000300
2025-05-29 23:03:20,358 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     2.475662, Batch Acc: 0.242849, Tokens per Sec:     8959, Lr: 0.000300
2025-05-29 23:03:28,487 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.370956, Batch Acc: 0.247982, Tokens per Sec:     8888, Lr: 0.000300
2025-05-29 23:03:28,487 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:03:28,487 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:04:16,386 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.49, ppl:  12.01, acc:   0.24, generation: 47.8570[sec], evaluation: 0.0000[sec]
2025-05-29 23:04:16,388 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:04:16,531 - INFO - joeynmt.training - Example #0
2025-05-29 23:04:16,531 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:04:16,531 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:04:16,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'oor', 'een', 'm@@', 'il@@', 'j@@', 'ar@@', 'd', 'ik', 'een', 'p@@', 'ol@@', 'it@@', 'ie@@', 'f', 'ik', 'de', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ke', 'm@@', 'at@@', 'ie@@', 've', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'm@@', 'at@@', 'er@@', 's', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'm@@', 'm@@', '.', '</s>']
2025-05-29 23:04:16,532 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:04:16,533 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:04:16,533 - INFO - joeynmt.training - 	Hypothesis: Voor een miljard ik een politief ik de politieke matieve miljoen miljoen miljoen miljoen miljoen miljoen miljoen maters miljoen mm.
2025-05-29 23:04:16,533 - INFO - joeynmt.training - Example #1
2025-05-29 23:04:16,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:04:16,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:04:16,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'is', 'niet', 'niet', 'niet', 'niet', 'niet', 'niet', 'e@@', 'st@@', 'r@@', 'at@@', 'ie@@', 'f', 'niet', 'e@@', 'ens', 'pro@@', 'ble@@', 'em', 'niet', 'e@@', 'ens', 'pro@@', 'ble@@', 'em', 'niet', 'e@@', 'ens', 'pro@@', 'ble@@', 'em', 'niet', 'niet', 'niet', 'niet', 'e@@', 'ens', 'van', 'de', 'e@@', 'cht', 'niet', 'e@@', 'cht', 'niet', 'e@@', 'cht', 'niet', 'e@@', 'cht', 'van', 'de', 'e@@', 'cht', 'van', 'de', 'ver@@', 'b@@', 'ij@@', '.', '</s>']
2025-05-29 23:04:16,534 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:04:16,535 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:04:16,535 - INFO - joeynmt.training - 	Hypothesis: Maar het is niet niet niet niet niet niet estratief niet eens probleem niet eens probleem niet eens probleem niet niet niet niet eens van de echt niet echt niet echt niet echt van de echt van de verbij.
2025-05-29 23:04:16,535 - INFO - joeynmt.training - Example #2
2025-05-29 23:04:16,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:04:16,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:04:16,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'p@@', 'ar@@', 'ti@@', 'v@@', 'el@@', 'e', 'k@@', 'aar', 'is', 'een', 'p@@', 'ar@@', 'a@@', 'ct@@', 'ie@@', 've', 'p@@', 'ar@@', 'a@@', 'ct@@', 'ie@@', 'f', 'de', 'p@@', 'ar@@', 'a@@', '.', '</s>']
2025-05-29 23:04:16,536 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:04:16,536 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:04:16,536 - INFO - joeynmt.training - 	Hypothesis: In de partivele kaar is een paractieve paractief de para.
2025-05-29 23:04:16,536 - INFO - joeynmt.training - Example #3
2025-05-29 23:04:16,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:04:16,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:04:16,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'z@@', 'al', 'je', 'in', 'de', 'p@@', 'ol@@', 'it@@', 'ie@@', 'k', 'en', 'in', 'de', 'p@@', 'lan@@', 'e@@', 'p@@', '.', '</s>']
2025-05-29 23:04:16,537 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:04:16,538 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:04:16,538 - INFO - joeynmt.training - 	Hypothesis: Ze zal je in de politiek en in de planep.
2025-05-29 23:04:16,538 - INFO - joeynmt.training - Example #4
2025-05-29 23:04:16,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:04:16,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:04:16,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eer@@', 'ste', 'ste', 'ik', 'de', 'ik', 'een', 'be@@', 'et@@', 'je', 'een', 'be@@', 'et@@', 'je', 'een', 'm@@', 'om@@', 'ent', 'jaar', 'gel@@', 'e@@', 'den', 'in', 'de', 'j@@', 'ar@@', 'en', 'jaar', 'gel@@', 'e@@', 'den', 'in', 'de', 'm@@', 'ar@@', 'en', 'jaar', 'gel@@', 'e@@', 'den', 'in', 'de', 'm@@', 'il@@', 'ie@@', 'der@@', 'en.', '</s>']
2025-05-29 23:04:16,539 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:04:16,539 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:04:16,540 - INFO - joeynmt.training - 	Hypothesis: De eerste ste ik de ik een beetje een beetje een moment jaar geleden in de jaren jaar geleden in de maren jaar geleden in de miliederen.
2025-05-29 23:04:24,748 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.407675, Batch Acc: 0.254310, Tokens per Sec:     8616, Lr: 0.000300
2025-05-29 23:04:32,526 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.420089, Batch Acc: 0.259718, Tokens per Sec:     9287, Lr: 0.000300
2025-05-29 23:04:40,363 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.428661, Batch Acc: 0.265217, Tokens per Sec:     9179, Lr: 0.000300
2025-05-29 23:04:47,809 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.511244, Batch Acc: 0.272759, Tokens per Sec:     9587, Lr: 0.000300
2025-05-29 23:04:55,255 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.286185, Batch Acc: 0.276767, Tokens per Sec:     9917, Lr: 0.000300
2025-05-29 23:04:55,255 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:04:55,255 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:05:52,531 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.39, ppl:  10.95, acc:   0.27, generation: 57.2035[sec], evaluation: 0.0000[sec]
2025-05-29 23:05:52,533 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:05:52,718 - INFO - joeynmt.training - Example #0
2025-05-29 23:05:52,719 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:05:52,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:05:52,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'a', 'j@@', 'o@@', 'en', 'ik', 'ik', 'dat', 'ik', 'de', 'v@@', 'raa@@', 'g', 'van', 'de', 'v@@', 'ar@@', 'ing', 'van', 'de', 'v@@', 'ar@@', 'ing', 'van', 'de', 'p@@', 'ap@@', 'an@@', 'an@@', 'an@@', 'is@@', 'eer@@', 'de', 'p@@', 'ap@@', 'an@@', 'an@@', 'n@@', 'a', 'voor', 'de', 'j@@', 'o@@', 'en', 'j@@', 'o@@', 'en', 'jaar', 'gel@@', 'e@@', 'den', 'voor', 'de', 'st@@', 'ap@@', 'p@@', 'el@@', 'e', 'j@@', 'o@@', 'en', 'j@@', 'o@@', 'en', 'de', 'st@@', 're@@', 's@@', 'le@@', 'ch@@', 'ts', 'van', 'de', 'st@@', 'ru@@', 'im@@', 'p@@', 'p@@', 'p@@', 'ar@@', 'it@@', 'eit', 'van', 'de', 'st@@', 'ap@@', 'an@@', 'an@@', '.', '</s>']
2025-05-29 23:05:52,720 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:05:52,721 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:05:52,721 - INFO - joeynmt.training - 	Hypothesis: Na joen ik ik dat ik de vraag van de varing van de varing van de papanananiseerde papananna voor de joen joen jaar geleden voor de stappele joen joen de streslechts van de struimpppariteit van de stapanan.
2025-05-29 23:05:52,721 - INFO - joeynmt.training - Example #1
2025-05-29 23:05:52,721 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:05:52,722 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:05:52,722 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'is', 'niet', 'de', 'b@@', 'u@@', 'i@@', 'ten', 'dat', 'het', 'niet', 'de', 'st@@', 'aat', 'van', 'de', 'pro@@', 'ble@@', 'men', 'van', 'het', 'pro@@', 'ble@@', 'men', 'niet', 'de', 'pro@@', 'ble@@', 'men', 'niet', 'de', 'p@@', 'lan@@', 'e@@', 'el', 'van', 'het', 'pro@@', 'ble@@', 'men', 'niet', 'de', 'p@@', 'lan@@', 'e@@', 'el', 'van', 'het', 'het', 'het', 'het', 'is', 'het', 'niet', 'de', 'p@@', 'ar@@', 'i@@', 'a', 'het', 'ver@@', 'b@@', 'oe@@', 'g', 'van', 'de', 'ver@@', 'b@@', 'oe@@', 'k', 'van', 'de', 're@@', 'gel@@', 'ijk@@', 'heid', 'is', 'niet', 'de', 're@@', 'gel@@', 'ijk@@', 'heid', 'van', 'het', 'pro@@', 'ble@@', 'm@@', 'en.', '</s>']
2025-05-29 23:05:52,723 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:05:52,723 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:05:52,723 - INFO - joeynmt.training - 	Hypothesis: Maar het is niet de buiten dat het niet de staat van de problemen van het problemen niet de problemen niet de planeel van het problemen niet de planeel van het het het het is het niet de paria het verboeg van de verboek van de regelijkheid is niet de regelijkheid van het problemen.
2025-05-29 23:05:52,723 - INFO - joeynmt.training - Example #2
2025-05-29 23:05:52,724 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:05:52,724 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:05:52,724 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'm@@', 'is@@', 'sch@@', 'ien', 'is', 'de', 'p@@', 'ar@@', 'it@@', 'eit', 'van', 'de', 'p@@', 'ap@@', 'it@@', 'eit', 'van', 'onze', 'p@@', 'ar@@', 'i@@', 'p@@', 'o@@', 'c@@', 'o@@', 'sy@@', 'ste@@', 'm@@', 'm@@', 'on@@', 'on@@', 'on@@', 'ge@@', 've@@', 'el@@', '.', '</s>']
2025-05-29 23:05:52,725 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:05:52,725 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:05:52,725 - INFO - joeynmt.training - 	Hypothesis: In de misschien is de pariteit van de papiteit van onze paripocosystemmononongeveel.
2025-05-29 23:05:52,726 - INFO - joeynmt.training - Example #3
2025-05-29 23:05:52,726 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:05:52,726 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:05:52,726 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'z@@', 'al', 'het', 'in', 'de', 'en', 'de', 'en', 'het', 'p@@', 'u@@', 'i@@', 'p@@', '.', '</s>']
2025-05-29 23:05:52,727 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:05:52,727 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:05:52,727 - INFO - joeynmt.training - 	Hypothesis: Ze zal het in de en de en het puip.
2025-05-29 23:05:52,728 - INFO - joeynmt.training - Example #4
2025-05-29 23:05:52,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:05:52,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:05:52,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eer@@', 'ste', 'v@@', 'raa@@', 'g', 'ik', 'het', 'is', 'een', 'b@@', 'ij@@', 'f', 'dat', 'het', 'een', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ke', 'b@@', 'ij@@', 'ken', 'in', 'de', 'j@@', 'ar@@', 'en', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '2@@', '.', '</s>']
2025-05-29 23:05:52,729 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:05:52,729 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:05:52,729 - INFO - joeynmt.training - 	Hypothesis: De eerste vraag ik het is een bijf dat het een politieke bijken in de jaren 22222222222222222222.
2025-05-29 23:06:02,356 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.329336, Batch Acc: 0.278584, Tokens per Sec:     7300, Lr: 0.000300
2025-05-29 23:06:11,795 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.360185, Batch Acc: 0.286500, Tokens per Sec:     7783, Lr: 0.000300
2025-05-29 23:06:20,980 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.390170, Batch Acc: 0.292748, Tokens per Sec:     7948, Lr: 0.000300
2025-05-29 23:06:30,518 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.246441, Batch Acc: 0.291385, Tokens per Sec:     7702, Lr: 0.000300
2025-05-29 23:06:39,687 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.235375, Batch Acc: 0.296324, Tokens per Sec:     7941, Lr: 0.000300
2025-05-29 23:06:39,687 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:06:39,688 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:07:32,225 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.32, ppl:  10.21, acc:   0.29, generation: 52.4857[sec], evaluation: 0.0000[sec]
2025-05-29 23:07:32,227 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:07:32,396 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/500.ckpt
2025-05-29 23:07:32,411 - INFO - joeynmt.training - Example #0
2025-05-29 23:07:32,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:07:32,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:07:32,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'e@@', 'w', 'j@@', 'o@@', 'en', 'ik', 'ik', 'de', 'v@@', 'a@@', 'st@@', 'ische', 'v@@', 'a@@', 'ir@@', 'e', 'ver@@', 'be@@', 'ken@@', 'de', 'dat', 'de', 'p@@', 'ar@@', 'is@@', 'eer@@', 'de', 'voor', 'de', 'p@@', 'ap@@', 'it@@', 'eit', 'voor', 'de', 'p@@', 'ar@@', 'is@@', 'me', 'voor', 'de', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'gel@@', 'e@@', 'den', 'van', 'de', 'j@@', 'o@@', 'en', '2@@', '0', 'jaar', 'gel@@', 'e@@', 'den', 'van', 'de', 'st@@', 'aat', 'van', 'de', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ke', 'j@@', 'ar@@', 'en', 'van', 'de', 'p@@', 'ar@@', 'i@@', 'ë@@', 'n@@', 'e', 'j@@', 'ar@@', 'en', 'van', 'de', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ke', 'j@@', 'ar@@', 'en', 'van', 'de', 'v@@', 'is@@', 'u@@', 'w@@', 'et@@', 'ensch@@', 'ap@@', 'p@@', 'er', 'van', 'de', 'l@@', 'e', 'j@@', 'ar@@', 'en', 'van', 'de', 'l@@', 'e', 'j@@', 'ar@@', 'en', 'van', 'de', 'l@@', 'e', 'j@@', 'ar@@', 'en', 'van', 'de', 'j@@', 'ar@@']
2025-05-29 23:07:32,413 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:07:32,414 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:07:32,414 - INFO - joeynmt.training - 	Hypothesis: New joen ik ik de vastische vaire verbekende dat de pariseerde voor de papiteit voor de parisme voor de miljoen jaar geleden van de joen 20 jaar geleden van de staat van de politieke jaren van de pariëne jaren van de politieke jaren van de visuwetenschapper van de le jaren van de le jaren van de le jaren van de jar
2025-05-29 23:07:32,414 - INFO - joeynmt.training - Example #1
2025-05-29 23:07:32,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:07:32,414 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:07:32,415 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'het', 'niet', 'de', 'st@@', 'aat', 'niet', 'de', 'st@@', 'r@@', 'at@@', 'ie@@', 've', 'pro@@', 'ble@@', 'e@@', 'k', 'dat', 'het', 'pro@@', 'ble@@', 'em', 'is', 'het', 'pro@@', 'ble@@', 'em', 'niet', 'e@@', 'k', 'van', 'de', 'd@@', 'ru@@', 'k@@', 'k@@', 'er', 'van', 'de', 'd@@', 'is@@', 'is@@', 'is@@', 'c@@', 'u@@', 'i@@', 'ten', 'niet', 'de', 'e@@', 'p@@', '.', '</s>']
2025-05-29 23:07:32,416 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:07:32,416 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:07:32,416 - INFO - joeynmt.training - 	Hypothesis: Maar het niet de staat niet de stratieve probleek dat het probleem is het probleem niet ek van de drukker van de disisiscuiten niet de ep.
2025-05-29 23:07:32,416 - INFO - joeynmt.training - Example #2
2025-05-29 23:07:32,416 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:07:32,416 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:07:32,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'e@@', 'chte', 'is', 'de', 'is', 'de', 'e@@', 'ct@@', 'ie@@', 've', 'c@@', 'ar@@', 'is@@', 'is@@', 'eer@@', 'de', 'de', 'p@@', 'sy@@', 'ste@@', 'em', 'van', 'onze', 'k@@', 'w@@', 'al@@', 'i@@', 'ë@@', 'n', 'van', 'onze', 'k@@', 'w@@', 'al@@', 'i@@', 'ë@@', 'n', 'van', 'onze', 'k@@', 'rij@@', 'gen.', '</s>']
2025-05-29 23:07:32,417 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:07:32,418 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:07:32,418 - INFO - joeynmt.training - 	Hypothesis: In de echte is de is de ectieve carisiseerde de psysteem van onze kwaliën van onze kwaliën van onze krijgen.
2025-05-29 23:07:32,418 - INFO - joeynmt.training - Example #3
2025-05-29 23:07:32,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:07:32,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:07:32,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'z@@', 'ich', 'in', 'de', 'p@@', 'in@@', 'in@@', 't@@', 'ro@@', 'e@@', 'p@@', 'er', 'in', 'de', 'p@@', 'o@@', 'st@@', '.', '</s>']
2025-05-29 23:07:32,420 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:07:32,420 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:07:32,420 - INFO - joeynmt.training - 	Hypothesis: Ze zich in de pinintroeper in de post.
2025-05-29 23:07:32,420 - INFO - joeynmt.training - Example #4
2025-05-29 23:07:32,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:07:32,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:07:32,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eer@@', 'ste', 'v@@', 'aa@@', 'k', 'ik', 'een', 'v@@', 'aa@@', 'k', 'van', 'jullie', 'een', 'ge@@', 't@@', 'ro@@', 'u@@', 'w@@', 'en', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', '2@@', '2@@', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'dat', 'is', 'dat', 'is', 'dat', 'het', 'is', 'dat', 'is', 'in', 'de', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'van', 'de', 'v@@', 'en@@', 'u@@', 'ur@@', '.', '</s>']
2025-05-29 23:07:32,422 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:07:32,422 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:07:32,422 - INFO - joeynmt.training - 	Hypothesis: De eerste vaak ik een vaak van jullie een getrouwen in de laatste 25 jaar in de 2225 jaar geleden 25 jaar geleden dat is dat is dat het is dat is in de 25 jaar geleden van de venuur.
2025-05-29 23:07:41,715 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.166966, Batch Acc: 0.303948, Tokens per Sec:     7649, Lr: 0.000300
2025-05-29 23:07:50,544 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.174107, Batch Acc: 0.313257, Tokens per Sec:     8254, Lr: 0.000300
2025-05-29 23:07:59,876 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.171018, Batch Acc: 0.315460, Tokens per Sec:     7618, Lr: 0.000300
2025-05-29 23:08:09,042 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.167850, Batch Acc: 0.316683, Tokens per Sec:     8019, Lr: 0.000300
2025-05-29 23:08:17,831 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.309860, Batch Acc: 0.318881, Tokens per Sec:     8112, Lr: 0.000300
2025-05-29 23:08:17,832 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:08:17,832 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:09:08,349 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.45, acc:   0.31, generation: 50.4679[sec], evaluation: 0.0000[sec]
2025-05-29 23:09:08,350 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:09:08,517 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/1000.ckpt
2025-05-29 23:09:08,532 - INFO - joeynmt.training - Example #0
2025-05-29 23:09:08,533 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:09:08,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:09:08,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'oor', 'het', 'jaar', 'gel@@', 'e@@', 'den', 'dat', 'ik', 'ik', 'heb', 'deze', 'v@@', 'ar@@', 'en', 'ver@@', 'b@@', 'an@@', 'en', 'dat', 'de', 'b@@', 'o@@', 'd@@', 'ingen', 'die', 'de', 'p@@', 'ar@@', 'k@@', 'ap@@', 'pen', 'voor', 'de', 'p@@', 'ar@@', 'k@@', 'am@@', 'p@@', 'ar@@', 'k@@', 'am@@', 'en', 'van', 'de', 're@@', 'ss@@', 'en@@', 'en', 'de', 're@@', 'ss@@', 'en@@', 'en', 'de', 're@@', 'ss@@', 'en@@', 'en', 'van', 'de', 'st@@', 'a@@', 'd', 'van', 'de', 'st@@', 'ru@@', 'ct@@', 'u@@', 'ur', 'van', 'de', 'p@@', 'le@@', 'k', 'van', 'de', 'p@@', 'u@@', 'ur', 'van', 'de', 'p@@', 're@@', 'c@@', 'ies', 'van', 'de', 're@@', 'ë@@', 'r@@', 'en', 'van', 'de', 'b@@', 'il@@', 'j@@', 'o@@', 'en', 'ver@@', 'b@@', 'il@@', 'j@@', 'o@@', 'en', 'ver@@', 't@@', 'on@@', 'd', 'ver@@', 'b@@', 'il@@', 'j@@', 'o@@', 'en', 'van', 'de', 're@@', 'ss@@', 'en@@', 'en', 'ver@@', 't@@', 'ro@@', 'k@@', 'ken', 'van', 'de', 're@@', 'ch@@', 'ter@@', 'en']
2025-05-29 23:09:08,534 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:09:08,534 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:09:08,534 - INFO - joeynmt.training - 	Hypothesis: Voor het jaar geleden dat ik ik heb deze varen verbanen dat de bodingen die de parkappen voor de parkamparkamen van de ressenen de ressenen de ressenen van de stad van de structuur van de plek van de puur van de precies van de reëren van de biljoen verbiljoen vertond verbiljoen van de ressenen vertrokken van de rechteren
2025-05-29 23:09:08,535 - INFO - joeynmt.training - Example #1
2025-05-29 23:09:08,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:09:08,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:09:08,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'e@@', 'ens', 'de', 'st@@', 'ar@@', 'd', 'om', 'de', 'st@@', 'r@@', 'ig@@', 'ig@@', 'ig@@', 'ig@@', 'heid', 'pro@@', 'ble@@', 'em', 'te', 'ver@@', 'b@@', 'ij@@', 'ken', 'van', 'de', 'pro@@', 'ble@@', 'em', 'van', 'de', 'd@@', 'ingen', 'van', 'de', 'd@@', 'is@@', 'c@@', 'u@@', 'ur', 'van', 'de', 'd@@', 'is@@', 'c@@', 'u@@', 'ur', 'van', 'de', 'd@@', 'is@@', 'c@@', 'u@@', 'st@@', '.', '</s>']
2025-05-29 23:09:08,536 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:09:08,536 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:09:08,537 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet eens de stard om de strigigigigheid probleem te verbijken van de probleem van de dingen van de discuur van de discuur van de discust.
2025-05-29 23:09:08,537 - INFO - joeynmt.training - Example #2
2025-05-29 23:09:08,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:09:08,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:09:08,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 's@@', 'n@@', 'el', 'is', 'de', 's@@', 'le@@', 'ch@@', 'ts', 'een', 'p@@', 'ar@@', 'k@@', 'ap@@', 'ar@@', 'is@@', 'me', 'dat', 'onze', 'c@@', 'al@@', 'is@@', 'eer@@', 'de', 'b@@', 'al@@', 'i@@', 'ë@@', '.', '</s>']
2025-05-29 23:09:08,538 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:09:08,538 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:09:08,539 - INFO - joeynmt.training - 	Hypothesis: In de snel is de slechts een parkaparisme dat onze caliseerde balië.
2025-05-29 23:09:08,539 - INFO - joeynmt.training - Example #3
2025-05-29 23:09:08,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:09:08,539 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:09:08,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'in@@', 'st', 'en', 'in', 'het', 'p@@', 'u@@', 'bl@@', 'in@@', 'd@@', 'ru@@', 'k@@', '.', '</s>']
2025-05-29 23:09:08,540 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:09:08,541 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:09:08,541 - INFO - joeynmt.training - 	Hypothesis: Ze winst en in het publindruk.
2025-05-29 23:09:08,541 - INFO - joeynmt.training - Example #4
2025-05-29 23:09:08,541 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:09:08,541 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:09:08,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'eer@@', 'ste', 'v@@', 'aa@@', 'k', 'ik', 'dat', 'ik', 'je', 'een', 'k@@', 'on', 'ver@@', 't@@', 'ellen', 'wat', 'er', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', 'j@@', 'ar@@', 'en', 'jaar', 'gel@@', 'e@@', 'den', 'in', 'de', 'l@@', 'aat@@', 'ste', 'j@@', 'ar@@', 'en', 'jaar', 'gel@@', 'e@@', 'den', 'is.', '</s>']
2025-05-29 23:09:08,542 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:09:08,543 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:09:08,543 - INFO - joeynmt.training - 	Hypothesis: De eerste vaak ik dat ik je een kon vertellen wat er 25 jaar in de laatste jaren jaar geleden in de laatste jaren jaar geleden is.
2025-05-29 23:09:16,817 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     2.167947, Batch Acc: 0.324930, Tokens per Sec:     8171, Lr: 0.000300
2025-05-29 23:09:25,159 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.306572, Batch Acc: 0.327448, Tokens per Sec:     8651, Lr: 0.000300
2025-05-29 23:09:33,554 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.155416, Batch Acc: 0.329780, Tokens per Sec:     8449, Lr: 0.000300
2025-05-29 23:09:42,849 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.240836, Batch Acc: 0.340169, Tokens per Sec:     7555, Lr: 0.000300
2025-05-29 23:09:52,429 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     2.304432, Batch Acc: 0.338907, Tokens per Sec:     7322, Lr: 0.000300
2025-05-29 23:09:52,431 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:09:52,431 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:10:51,429 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.18, ppl:   8.88, acc:   0.32, generation: 58.9421[sec], evaluation: 0.0000[sec]
2025-05-29 23:10:51,431 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:10:51,605 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/1500.ckpt
2025-05-29 23:10:51,618 - INFO - joeynmt.training - Example #0
2025-05-29 23:10:51,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:10:51,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:10:51,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aat', 'het', 'jaar', 'gel@@', 'e@@', 'den', 'dat', 'ik', 'deze', 'v@@', 'is@@', ',', 'dat', 'deze', 'v@@', 'is@@', ',', 'dat', 'de', 're@@', 's@@', 'ul@@', 't@@', 'aat', 'om', 'de', 're@@', 's@@', 'ul@@', 't@@', 'aat', 'voor', 'de', 're@@', 's@@', 'ul@@', 't@@', 'aat', 'voor', 'de', 're@@', 's@@', 'ul@@', 't@@', 'aat', 'van', 'de', 'j@@', 'o@@', 'en', '2@@', '0@@', '0@@', '0@@', '0@@', '0@@', ',', 'de', 'j@@', 'ar@@', 'en', '2@@', '0', 'jaar', 'van', 'de', 'st@@', 'aat', 'van', 'de', 'st@@', 'ru@@', 'im@@', 'te', 'k@@', 'rij@@', 'gen', 'van', 'de', 'st@@', 'ru@@', 'im@@', 'te', 're@@', 'al@@', 'ist@@', 'en.', '</s>']
2025-05-29 23:10:51,620 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:10:51,620 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:10:51,620 - INFO - joeynmt.training - 	Hypothesis: Laat het jaar geleden dat ik deze vis, dat deze vis, dat de resultaat om de resultaat voor de resultaat voor de resultaat van de joen 200000, de jaren 20 jaar van de staat van de struimte krijgen van de struimte realisten.
2025-05-29 23:10:51,620 - INFO - joeynmt.training - Example #1
2025-05-29 23:10:51,621 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:10:51,621 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:10:51,621 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 'st@@', 'aat', 'niet', 'gen@@', 'oe@@', 'g', 'van', 'de', 're@@', 's@@', 'ig@@', 'n@@', 'el@@', 'ijk', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'pro@@', 'ble@@', 'em', 'van', 'de', 'E@@', 'en', 'van', 'de', 'E@@', 'en', 'van', 'de', 'E@@', 'en', 'van', 'de', 'E@@', 'en', 'van', 'de', 'E@@', 'en', 'van', 'de', 'E@@', 'en', 'van', 'de', 'E@@', 'en', 'van', 'de', 'E@@', 'en', 'van', 'de', 'E@@', 'en', 'van', 'de', 'E@@', 'en', 'van', 'de', 'E@@', 'en', 'van', 'de', 'E@@', 'en', 'van', 'de', 'E@@', 'u@@', 'ur', 'pro@@', 'ble@@', 'men', 'van', 'de', 'E@@', 'u@@', 'st@@', 'a@@', 'st@@', 'st@@', 'st@@', 'st@@', '.', '</s>']
2025-05-29 23:10:51,621 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:10:51,621 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:10:51,621 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de staat niet genoeg van de resignelijk probleem van dit probleem van de Een van de Een van de Een van de Een van de Een van de Een van de Een van de Een van de Een van de Een van de Een van de Een van de Euur problemen van de Eustastststst.
2025-05-29 23:10:51,622 - INFO - joeynmt.training - Example #2
2025-05-29 23:10:51,622 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:10:51,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:10:51,622 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 's@@', 'le@@', 'ch@@', 'ts', 'is', 'de', 'E@@', 'en', 'en', 'c@@', 'ap@@', 'p@@', 'ar@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'at@@', 'ie@@', 've', 'c@@', 'ap@@', 'ar@@', 'l@@', 'i@@', 'o@@', 'f@@', '.', '</s>']
2025-05-29 23:10:51,622 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:10:51,622 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:10:51,622 - INFO - joeynmt.training - 	Hypothesis: In de slechts is de Een en capparkapparkapparatieve caparliof.
2025-05-29 23:10:51,623 - INFO - joeynmt.training - Example #3
2025-05-29 23:10:51,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:10:51,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:10:51,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'k@@', 'wa@@', 'm', 'in', 'het', 'p@@', 're@@', 's@@', 'ul@@', 't@@', 'aat', 'in', 'het', 'z@@', 'om@@', '.', '</s>']
2025-05-29 23:10:51,623 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:10:51,623 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:10:51,624 - INFO - joeynmt.training - 	Hypothesis: Ze kwam in het presultaat in het zom.
2025-05-29 23:10:51,624 - INFO - joeynmt.training - Example #4
2025-05-29 23:10:51,625 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:10:51,625 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:10:51,625 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'v@@', 'ij@@', 'f', 'ik', 'de', 'l@@', 'aat@@', 'ste', 'j@@', 'on@@', 'gen', 'dat', 'is', 'een', 'l@@', 'aat@@', 'ste', 'l@@', 'aat@@', 'ste', 'j@@', 'ar@@', 'en', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'is.', '</s>']
2025-05-29 23:10:51,625 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:10:51,626 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:10:51,626 - INFO - joeynmt.training - 	Hypothesis: De volgende vijf ik de laatste jongen dat is een laatste laatste jaren 25 jaar in de laatste 25 jaar geleden is.
2025-05-29 23:11:00,873 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     2.052960, Batch Acc: 0.346037, Tokens per Sec:     7697, Lr: 0.000300
2025-05-29 23:11:09,671 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     2.086707, Batch Acc: 0.348446, Tokens per Sec:     8359, Lr: 0.000300
2025-05-29 23:11:17,960 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     2.062021, Batch Acc: 0.353050, Tokens per Sec:     8903, Lr: 0.000300
2025-05-29 23:11:26,309 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:     2.039870, Batch Acc: 0.359137, Tokens per Sec:     8666, Lr: 0.000300
2025-05-29 23:11:34,650 - INFO - joeynmt.training - Epoch   1, Step:     4500, Batch Loss:     2.119704, Batch Acc: 0.359764, Tokens per Sec:     8723, Lr: 0.000300
2025-05-29 23:11:34,650 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:11:34,650 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:12:16,382 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.12, ppl:   8.30, acc:   0.35, generation: 41.6862[sec], evaluation: 0.0000[sec]
2025-05-29 23:12:16,384 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:12:16,581 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/2000.ckpt
2025-05-29 23:12:16,600 - INFO - joeynmt.training - Example #0
2025-05-29 23:12:16,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:12:16,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:12:16,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E@@', 'en', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ke', 'v@@', 'ar@@', 'en', 'ik', 'deze', 'f@@', 'ol@@', 'ie@@', 'ke', 'v@@', 'en@@', 'kel@@', 'e', 'e@@', 'con@@', 'c@@', 'ap@@', 'an@@', 'te', 'ver@@', 'b@@', 'an@@', 'den', 'dat', 'de', 'e@@', 'cht', 'voor', 'de', 'j@@', 'ar@@', 'en', 'p@@', 'ap@@', 'an@@', 'n@@', 'er', 'van', 'de', 'v@@', 'ar@@', 'en', 'van', 'de', 're@@', 'ss@@', 'ie', 'van', 'de', 'v@@', 'ar@@', 'ing', 'van', 'de', 'St@@', 'an@@', 'n@@', 'er', '5@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'v@@', 'ar@@', 'ing', 'van', 'de', 'v@@', 'a@@', 'st@@', 'ist@@', 'an@@', '.', '</s>']
2025-05-29 23:12:16,602 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:12:16,602 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:12:16,602 - INFO - joeynmt.training - 	Hypothesis: Een politieke varen ik deze folieke venkele econcapante verbanden dat de echt voor de jaren papanner van de varen van de ressie van de varing van de Stanner 50 procent van de varing van de vastistan.
2025-05-29 23:12:16,602 - INFO - joeynmt.training - Example #1
2025-05-29 23:12:16,603 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:12:16,603 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:12:16,603 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 'st@@', 'a@@', 'd', 'gen@@', 'oe@@', 'g', 'de', 'st@@', 'a@@', 'p', 'van', 'de', 'pro@@', 'ble@@', 'em', 'van', 'deze', 'pro@@', 'ble@@', 'em', 'van', 'de', 'pro@@', 'ble@@', 'em', 'van', 'de', 'D@@', 'i@@', 'p@@', 'p@@', 'p@@', 'ar@@', 'i@@', 'di@@', 'c@@', 'en@@', 't.', '</s>']
2025-05-29 23:12:16,604 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:12:16,604 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:12:16,604 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de stad genoeg de stap van de probleem van deze probleem van de probleem van de Dippparidicent.
2025-05-29 23:12:16,605 - INFO - joeynmt.training - Example #2
2025-05-29 23:12:16,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:12:16,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:12:16,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'het', 'z@@', 'it', 'in', 'het', 'sy@@', 'ste@@', 'em', 'is', 'de', 'e@@', 'cht', 'e@@', 'cht', 'e@@', 'cht', 'van', 'onze', 'k@@', 'ap@@', 'p@@', 'ar@@', 'ti@@', 'g', 'van', 'onze', 'c@@', 'l@@', 'i@@', 'o@@', 'sy@@', 'ste@@', 'em', 'van', 'het', 'l@@', 'i@@', 'p@@', 'sy@@', 'ste@@', 'm@@', '.', '</s>']
2025-05-29 23:12:16,606 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:12:16,606 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:12:16,606 - INFO - joeynmt.training - 	Hypothesis: In het zit in het systeem is de echt echt echt van onze kappartig van onze cliosysteem van het lipsystem.
2025-05-29 23:12:16,607 - INFO - joeynmt.training - Example #3
2025-05-29 23:12:16,607 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:12:16,607 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:12:16,607 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'k@@', 'wa@@', 'm', 'in', 'het', 'p@@', 'le@@', 'k', 'van', 'de', 's@@', 'om@@', 'm@@', 'ige', 'p@@', 'le@@', 'k', 'in', 'het', 'sy@@', 'm@@', 'm@@', 'en.', '</s>']
2025-05-29 23:12:16,608 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:12:16,608 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:12:16,608 - INFO - joeynmt.training - 	Hypothesis: Ze kwam in het plek van de sommige plek in het symmen.
2025-05-29 23:12:16,609 - INFO - joeynmt.training - Example #4
2025-05-29 23:12:16,609 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:12:16,609 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:12:16,609 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'v@@', 'la@@', 'k', 'van', 'jullie', 'jullie', 'jullie', 'jullie', 'een', 'c@@', 'ol@@', 'le@@', 'ct@@', 'ie@@', 've', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'dat', 'er', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'is.', '</s>']
2025-05-29 23:12:16,610 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:12:16,610 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:12:16,610 - INFO - joeynmt.training - 	Hypothesis: De volgende vlak van jullie jullie jullie jullie een collectieve 25 jaar in de laatste 25 jaar geleden 25 jaar geleden dat er 25 jaar geleden is.
2025-05-29 23:12:26,272 - INFO - joeynmt.training - Epoch   1, Step:     4600, Batch Loss:     2.054788, Batch Acc: 0.363960, Tokens per Sec:     7254, Lr: 0.000300
2025-05-29 23:12:35,785 - INFO - joeynmt.training - Epoch   1, Step:     4700, Batch Loss:     1.965534, Batch Acc: 0.372830, Tokens per Sec:     7793, Lr: 0.000300
2025-05-29 23:12:45,495 - INFO - joeynmt.training - Epoch   1, Step:     4800, Batch Loss:     2.141500, Batch Acc: 0.370475, Tokens per Sec:     7420, Lr: 0.000300
2025-05-29 23:12:55,027 - INFO - joeynmt.training - Epoch   1, Step:     4900, Batch Loss:     2.123723, Batch Acc: 0.368229, Tokens per Sec:     7495, Lr: 0.000300
2025-05-29 23:13:04,318 - INFO - joeynmt.training - Epoch   1, Step:     5000, Batch Loss:     2.006357, Batch Acc: 0.379019, Tokens per Sec:     7671, Lr: 0.000300
2025-05-29 23:13:04,318 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:13:04,318 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:13:54,268 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.05, ppl:   7.79, acc:   0.37, generation: 49.8990[sec], evaluation: 0.0000[sec]
2025-05-29 23:13:54,270 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:13:54,452 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/2500.ckpt
2025-05-29 23:13:54,467 - INFO - joeynmt.training - Example #0
2025-05-29 23:13:54,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:13:54,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:13:54,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'dit', 'jaar', 'gel@@', 'e@@', 'den', 'dat', 'ik', 'deze', 'v@@', 'ol@@', 'i@@', 'ë@@', 'n@@', 't', 'om', 'te', 'ver@@', 't@@', 'ro@@', 'u@@', 'w@@', 'en', 'om', 'te', 'ma@@', 'ken', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'voor', 'de', 'j@@', 'ar@@', 'en', 'jaar', 'gel@@', 'e@@', 'den', 'van', 'de', 'j@@', 'ar@@', 'en', 'jaar', 'gel@@', 'e@@', 'den', 'van', 'de', '4@@', '0', 'jaar', 'gel@@', 'e@@', 'd', 'van', 'de', 'V@@', 'S', '2@@', '-@@', 'st@@', 'aat', 'de', 'V@@', 'S', 'ha@@', 'd@@', 'den', 'van', 'de', 'V@@', 'S', 'ha@@', 'd@@', 'den', 'van', 'de', 'V@@', 'S', 'was', 'ge@@', 'we@@', 'e@@', 'st@@', '.', '</s>']
2025-05-29 23:13:54,468 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:13:54,469 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:13:54,469 - INFO - joeynmt.training - 	Hypothesis: Ik heb dit jaar geleden dat ik deze voliënt om te vertrouwen om te maken te begrijpen voor de jaren jaar geleden van de jaren jaar geleden van de 40 jaar geled van de VS 2-staat de VS hadden van de VS hadden van de VS was geweest.
2025-05-29 23:13:54,469 - INFO - joeynmt.training - Example #1
2025-05-29 23:13:54,469 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:13:54,469 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:13:54,469 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'aat', 'gen@@', 'oe@@', 'g', 'van', 'de', 're@@', 's@@', 'ul@@', 't@@', 'ig@@', 'heid', 'van', 'de', 're@@', 's@@', 'ig@@', 'heid', 'van', 'dit', 'pro@@', 'ble@@', 'em@@', ',', 'het', 'niet', 'de', 'd@@', 'oo@@', 'k@@', ',', 'het', 'niet', 'de', 'd@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie@@', 'k', 'van', 'de', 'd@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie@@', 'u@@', 'w@@', '.', '</s>']
2025-05-29 23:13:54,470 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:13:54,470 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:13:54,470 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet staat genoeg van de resultigheid van de resigheid van dit probleem, het niet de dook, het niet de discussiek van de discussieuw.
2025-05-29 23:13:54,470 - INFO - joeynmt.training - Example #2
2025-05-29 23:13:54,471 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:13:54,471 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:13:54,471 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'z@@', 'in@@', 'e', 'is', 'de', 'ar@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'ti@@', 'sch@@', 'e', 'e@@', 'p@@', 't', 'het', 'p@@', 'ap@@', 'e', 'van', 'onze', 'h@@', 'ar@@', 't', 'van', 'onze', 'k@@', 'le@@', 'ur@@', 'en', 'van', 'de', 'k@@', 'le@@', 'ur@@', 'en', 'van', 'de', 'k@@', 'le@@', 'ur@@', 'en', 'van', 'de', 'm@@', 'is@@', 'sch@@', 'ien', 'e@@', 'p@@', 'sy@@', 'ste@@', 'em', 'is', 'de', 'm@@', '.', '</s>']
2025-05-29 23:13:54,472 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:13:54,472 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:13:54,472 - INFO - joeynmt.training - 	Hypothesis: In de zine is de arkappartische ept het pape van onze hart van onze kleuren van de kleuren van de kleuren van de misschien epsysteem is de m.
2025-05-29 23:13:54,472 - INFO - joeynmt.training - Example #3
2025-05-29 23:13:54,472 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:13:54,472 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:13:54,472 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'we@@', 'er', 'in', 'de', 'w@@', 'in@@', 'nen', 'en', 'in', 'de', 'z@@', 'om@@', '.', '</s>']
2025-05-29 23:13:54,473 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:13:54,473 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:13:54,473 - INFO - joeynmt.training - 	Hypothesis: Ze weer in de winnen en in de zom.
2025-05-29 23:13:54,473 - INFO - joeynmt.training - Example #4
2025-05-29 23:13:54,473 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:13:54,474 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:13:54,474 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'v@@', 'on@@', 'd', 'ik', 'de', 'l@@', 'aat@@', 'ste', 'is', 'een', 'c@@', 'ont@@', 'mo@@', 'et@@', 'te', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'is.', '</s>']
2025-05-29 23:13:54,474 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:13:54,474 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:13:54,475 - INFO - joeynmt.training - 	Hypothesis: De volgende vond ik de laatste is een contmoette in de laatste 25 jaar in de laatste 25 jaar geleden in de laatste 25 jaar geleden is.
2025-05-29 23:14:03,849 - INFO - joeynmt.training - Epoch   1, Step:     5100, Batch Loss:     2.007312, Batch Acc: 0.383856, Tokens per Sec:     7738, Lr: 0.000300
2025-05-29 23:14:13,047 - INFO - joeynmt.training - Epoch   1, Step:     5200, Batch Loss:     2.129815, Batch Acc: 0.385674, Tokens per Sec:     7807, Lr: 0.000300
2025-05-29 23:14:22,522 - INFO - joeynmt.training - Epoch   1, Step:     5300, Batch Loss:     1.964856, Batch Acc: 0.389265, Tokens per Sec:     7868, Lr: 0.000300
2025-05-29 23:14:31,221 - INFO - joeynmt.training - Epoch   1, Step:     5400, Batch Loss:     1.817280, Batch Acc: 0.392412, Tokens per Sec:     8620, Lr: 0.000300
2025-05-29 23:14:39,897 - INFO - joeynmt.training - Epoch   1, Step:     5500, Batch Loss:     1.879447, Batch Acc: 0.400623, Tokens per Sec:     8399, Lr: 0.000300
2025-05-29 23:14:39,898 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:14:39,898 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:15:33,669 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.01, ppl:   7.46, acc:   0.38, generation: 53.7149[sec], evaluation: 0.0000[sec]
2025-05-29 23:15:33,670 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:15:33,847 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/3000.ckpt
2025-05-29 23:15:33,864 - INFO - joeynmt.training - Example #0
2025-05-29 23:15:33,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:15:33,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:15:33,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'en', 'dat', 'ik', 'het', 'jaar', 'gel@@', 'e@@', 'den', 'dat', 'ik', 'de', 'v@@', 'ol@@', 'ie@@', 'ë@@', 'n', 'te', 'ver@@', 't@@', 'on@@', 'en', 'dat', 'de', 'wer@@', 'k@@', 'ing', 'van', 'de', 'wer@@', 'k@@', ',', 'de', 'k@@', 'ap@@', 'en,', 'de', 'k@@', 'rij@@', 'gen', 'dat', 'de', 'v@@', 'raa@@', 'g@@', 'd', 'van', 'de', '2@@', '8', 'jaar', 'gel@@', 'e@@', 'den', 'van', 'de', 'V@@', 'S', '2@@', '8', 'pro@@', 'c@@', 'ent', 'van', 'de', 'V@@', 'S', 'ge@@', 'z@@', 'ich@@', 'te', 'ver@@', 'v@@', 'ra@@', 'ch@@', 'ten', 'van', 'de', 'V@@', 'S', 'v@@', 'ar@@', 'en', 'k@@', 'on', 'ge@@', 'st@@', 'el@@', 'd.', '</s>']
2025-05-29 23:15:33,866 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:15:33,867 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:15:33,867 - INFO - joeynmt.training - 	Hypothesis: Voren dat ik het jaar geleden dat ik de volieën te vertonen dat de werking van de werk, de kapen, de krijgen dat de vraagd van de 28 jaar geleden van de VS 28 procent van de VS gezichte vervrachten van de VS varen kon gesteld.
2025-05-29 23:15:33,867 - INFO - joeynmt.training - Example #1
2025-05-29 23:15:33,867 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:15:33,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:15:33,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ar@@', 't', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'ver@@', 'z@@', 'oe@@', 'k', 'van', 'dit', 'pro@@', 'ble@@', 'em', 'is', 'het', 'niet', 'de', 're@@', 's@@', 'ul@@', 't@@', 'aat', 'van', 'de', 'd@@', 'ie@@', 'p@@', 'e', 'pro@@', 'ble@@', 'm@@', 'en.', '</s>']
2025-05-29 23:15:33,869 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:15:33,869 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:15:33,869 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet start genoeg de eerste verzoek van dit probleem is het niet de resultaat van de diepe problemen.
2025-05-29 23:15:33,869 - INFO - joeynmt.training - Example #2
2025-05-29 23:15:33,870 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:15:33,870 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:15:33,870 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'de', 'w@@', 'in@@', 't', 'is', 'de', 'ar@@', 'm@@', 'at@@', 'er@@', 'i@@', 'aal', 'dat', 'onze', 'p@@', 'le@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'e', 'k@@', 'ap@@', 'p@@', 'el@@', 'e', 'c@@', 'l@@', 'i@@', 'ë@@', 'r@@', 'en', 'van', 'onze', 'k@@', 'le@@', 'ur@@', 'en', 'en', 'van', 'onze', 'k@@', 'le@@', 'ur@@', 'en.', '</s>']
2025-05-29 23:15:33,871 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:15:33,871 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:15:33,871 - INFO - joeynmt.training - 	Hypothesis: In de wint is de armateriaal dat onze plekappele kappele cliëren van onze kleuren en van onze kleuren.
2025-05-29 23:15:33,871 - INFO - joeynmt.training - Example #3
2025-05-29 23:15:33,872 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:15:33,872 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:15:33,872 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'k@@', 'wa@@', 'm', 'in', 'het', 'z@@', 'om@@', 'er', 'en', 'en', 'p@@', 're@@', 'c@@', 'at@@', 'ie.', '</s>']
2025-05-29 23:15:33,873 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:15:33,873 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:15:33,873 - INFO - joeynmt.training - 	Hypothesis: Ze kwam in het zomer en en precatie.
2025-05-29 23:15:33,873 - INFO - joeynmt.training - Example #4
2025-05-29 23:15:33,874 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:15:33,874 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:15:33,874 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'v@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'zien', 'dat', 'ik', 'een', 'c@@', 'ent@@', 'r@@', 'a', 'in', 'de', '2@@', '5', 'jaar', 'in', 'de', '2@@', '5', 'jaar', 'in', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'van', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'van', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'van', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'l@@', 'aat@@', 'ste', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste']
2025-05-29 23:15:33,875 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:15:33,875 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:15:33,875 - INFO - joeynmt.training - 	Hypothesis: De volgende volie die ik jullie zien dat ik een centra in de 25 jaar in de 25 jaar in 25 jaar geleden in de laatste 25 jaar geleden van 25 jaar geleden van 25 jaar geleden van 25 jaar in de laatste 25 jaar in de laatste 25 jaar in de laatste 25 jaar laatste in de laatste 25 jaar in de laatste 25 jaar in de laatste 25 jaar in de laatste 25 jaar in de 25 jaar in de laatste
2025-05-29 23:15:43,816 - INFO - joeynmt.training - Epoch   1, Step:     5600, Batch Loss:     1.881319, Batch Acc: 0.403106, Tokens per Sec:     7330, Lr: 0.000300
2025-05-29 23:15:53,490 - INFO - joeynmt.training - Epoch   1, Step:     5700, Batch Loss:     1.831378, Batch Acc: 0.399016, Tokens per Sec:     7445, Lr: 0.000300
2025-05-29 23:16:03,215 - INFO - joeynmt.training - Epoch   1, Step:     5800, Batch Loss:     1.920239, Batch Acc: 0.400169, Tokens per Sec:     7313, Lr: 0.000300
2025-05-29 23:16:12,831 - INFO - joeynmt.training - Epoch   1, Step:     5900, Batch Loss:     1.964185, Batch Acc: 0.405662, Tokens per Sec:     7499, Lr: 0.000300
2025-05-29 23:16:23,094 - INFO - joeynmt.training - Epoch   1, Step:     6000, Batch Loss:     1.999483, Batch Acc: 0.408132, Tokens per Sec:     6833, Lr: 0.000300
2025-05-29 23:16:23,095 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:16:23,095 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:17:26,744 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.19, acc:   0.39, generation: 63.5916[sec], evaluation: 0.0000[sec]
2025-05-29 23:17:26,745 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:17:26,913 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/3500.ckpt
2025-05-29 23:17:26,927 - INFO - joeynmt.training - Example #0
2025-05-29 23:17:26,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:17:26,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:17:26,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'ol@@', 'gen@@', 's', 'jaar', 'gel@@', 'e@@', 'den', 'die', 'ik', 'deze', 'v@@', 'ol@@', 'ie@@', 'ë@@', 'n', 'die', 'ik', 'de', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'wer@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'e@@', 'c@@', 'ap@@', 'p@@', 'el@@', 'e', 'j@@', 'ar@@', 'en', 'jaar', 'gel@@', 'e@@', 'den', 'die', 'j@@', 'ar@@', 'en', 'jaar', 'gel@@', 'e@@', 'den', 'die', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'V@@', 'S', 'was', 'de', 'V@@', 'S', 'v@@', 'a@@', 'st@@', 'or@@', 'te', 'ver@@', 'v@@', 'aa@@', 'k', 'van', 'de', 'v@@', 'aa@@', 'k', 'van', 'de', 'V@@', 'S', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-29 23:17:26,929 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:17:26,929 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:17:26,930 - INFO - joeynmt.training - 	Hypothesis: Volgens jaar geleden die ik deze volieën die ik de wereldwijde werkappelijke ecappele jaren jaar geleden die jaren jaar geleden die de reden van de reden van de VS was de VS vastorte vervaak van de vaak van de VS gebeurd.
2025-05-29 23:17:26,930 - INFO - joeynmt.training - Example #1
2025-05-29 23:17:26,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:17:26,930 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:17:26,930 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 'p@@', 're@@', 's@@', 'ul@@', 't@@', 'aten', 'van', 'de', 'p@@', 'le@@', 'k', 'van', 'dit', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'd@@', 'oo@@', 'k@@', ',', 'het', 'niet', 'de', 'd@@', 'ie@@', 'p@@', '.', '</s>']
2025-05-29 23:17:26,931 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:17:26,931 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:17:26,931 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de presultaten van de plek van dit probleem van dit probleem dat het niet de dook, het niet de diep.
2025-05-29 23:17:26,931 - INFO - joeynmt.training - Example #2
2025-05-29 23:17:26,932 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:17:26,932 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:17:26,932 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'het', 'z@@', 'in@@', 'e', 'is', 'de', 'ar@@', 'm@@', 'at@@', 'ie@@', 've', 'e@@', 'c@@', 'ap@@', 'p@@', 'e', 'en', 'het', 's@@', 'la@@', 'g', 'van', 'onze', 'k@@', 'le@@', 'ur@@', 'en', 'van', 'onze', 'c@@', 'l@@', 'i@@', 'ë@@', 'r@@', 'en', 'sy@@', 'ste@@', 'm@@', '.', '</s>']
2025-05-29 23:17:26,933 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:17:26,933 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:17:26,933 - INFO - joeynmt.training - 	Hypothesis: In het zine is de armatieve ecappe en het slag van onze kleuren van onze cliëren system.
2025-05-29 23:17:26,933 - INFO - joeynmt.training - Example #3
2025-05-29 23:17:26,934 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:17:26,934 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:17:26,934 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'be@@', 'do@@', 'en', 'in', 'het', 'z@@', 'om@@', 'p@@', 'el@@', '.', '</s>']
2025-05-29 23:17:26,935 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:17:26,935 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:17:26,935 - INFO - joeynmt.training - 	Hypothesis: Ze bedoen in het zompel.
2025-05-29 23:17:26,935 - INFO - joeynmt.training - Example #4
2025-05-29 23:17:26,936 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:17:26,936 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:17:26,936 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'v@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aat@@', 'ste', 'p@@', 're@@', 'c@@', 'en@@', 'te', 'l@@', 'aten', 'zien', 'wat', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'dat', 'er', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'is.', '</s>']
2025-05-29 23:17:26,937 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:17:26,937 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:17:26,937 - INFO - joeynmt.training - 	Hypothesis: De volgende volie die ik jullie laatste precente laten zien wat in de laatste 25 jaar geleden dat er 25 jaar geleden is.
2025-05-29 23:17:36,273 - INFO - joeynmt.training - Epoch   1, Step:     6100, Batch Loss:     1.787646, Batch Acc: 0.408504, Tokens per Sec:     7539, Lr: 0.000300
2025-05-29 23:17:44,574 - INFO - joeynmt.training - Epoch   1, Step:     6200, Batch Loss:     1.854539, Batch Acc: 0.414656, Tokens per Sec:     8924, Lr: 0.000300
2025-05-29 23:17:52,408 - INFO - joeynmt.training - Epoch   1, Step:     6300, Batch Loss:     1.937157, Batch Acc: 0.414049, Tokens per Sec:     9234, Lr: 0.000300
2025-05-29 23:18:00,278 - INFO - joeynmt.training - Epoch   1, Step:     6400, Batch Loss:     1.823631, Batch Acc: 0.415145, Tokens per Sec:     9171, Lr: 0.000300
2025-05-29 23:18:08,421 - INFO - joeynmt.training - Epoch   1, Step:     6500, Batch Loss:     1.843525, Batch Acc: 0.419935, Tokens per Sec:     9115, Lr: 0.000300
2025-05-29 23:18:08,422 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:18:08,422 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:19:05,994 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.92, acc:   0.40, generation: 57.5214[sec], evaluation: 0.0000[sec]
2025-05-29 23:19:05,996 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:19:06,218 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/4000.ckpt
2025-05-29 23:19:06,234 - INFO - joeynmt.training - Example #0
2025-05-29 23:19:06,235 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:19:06,236 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:19:06,236 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'f@@', 'ol@@', 'ie', 'jaar', 'gel@@', 'e@@', 'den', 'die', 'ik', 'de', 'wer@@', 'k@@', ',', 'om', 'te', 'ver@@', 't@@', 'on@@', 'en', 'dat', 'de', 'wer@@', 'k@@', 'ten', 'dat', 'de', 'wer@@', 'kt', 'dat', 'de', 'wer@@', 'k@@', ',', 'die', 'voor', 'de', 're@@', 'den', 'van', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'lan@@', 'ge', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'gel@@', 's', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'gel@@', 's', 'ge@@', 'gev@@', 'ens', 'van', 'de', 're@@', 's@@', 'ul@@', 't@@', 'aten', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'gel@@', 's', 'ge@@', 'zien', 'dat', 'ik', 'deze', 'ge@@', 'to@@', 'on@@', 'd', 'dat', 'de', 're@@', 'gel@@', 's', 'de', 're@@', 'den', 'van', 'de', 're@@', 'gel@@', 's', 'die', 'ik', 'ik', 'de']
2025-05-29 23:19:06,237 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:19:06,237 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:19:06,237 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze folie jaar geleden die ik de werk, om te vertonen dat de werkten dat de werkt dat de werk, die voor de reden van drie miljoen jaar lange reden van de reden van de reden van de reden van de regels van de reden van de reden van de regels gegevens van de resultaten van de reden van de reden van de regels gezien dat ik deze getoond dat de regels de reden van de regels die ik ik de
2025-05-29 23:19:06,237 - INFO - joeynmt.training - Example #1
2025-05-29 23:19:06,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:19:06,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:19:06,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ar@@', 't', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'de', 're@@', 's@@', 'ul@@', 't@@', 'ig@@', 'heid', 'van', 'deze', 'so@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'd@@', 'ie@@', 'p@@', '.', '</s>']
2025-05-29 23:19:06,239 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:19:06,239 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:19:06,239 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet start genoeg de aarde de resultigheid van deze sociale probleem dat het niet de diep.
2025-05-29 23:19:06,240 - INFO - joeynmt.training - Example #2
2025-05-29 23:19:06,240 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:19:06,240 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:19:06,240 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'het', 's@@', 'le@@', 'ch@@', 'ts', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'e@@', 'p', 'van', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'ge@@', 'vol@@', 'g@@', 'lo@@', 'b@@', 'ale', 'k@@', 'eu@@', 'w@@', 'en', 'van', 'onze', 'k@@', 'le@@', 'ef@@', 'tij@@', 'd.', '</s>']
2025-05-29 23:19:06,241 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:19:06,241 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:19:06,242 - INFO - joeynmt.training - 	Hypothesis: In het slechts is de artische ep van het slagen van onze gevolglobale keuwen van onze kleeftijd.
2025-05-29 23:19:06,242 - INFO - joeynmt.training - Example #3
2025-05-29 23:19:06,242 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:19:06,242 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:19:06,242 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'we@@', 'ten', 'in', 'het', 'woor@@', 'd', 'van', 'de', 'p@@', 'ub@@', 'lie@@', 'k', 'in', 'het', 'S@@', 'om@@', 'm@@', 'ige', 'in', 'het', 'z@@', 'om@@', '.', '</s>']
2025-05-29 23:19:06,243 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:19:06,243 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:19:06,244 - INFO - joeynmt.training - 	Hypothesis: Ze weten in het woord van de publiek in het Sommige in het zom.
2025-05-29 23:19:06,244 - INFO - joeynmt.training - Example #4
2025-05-29 23:19:06,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:19:06,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:19:06,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'ik', 'de', 'vol@@', 'gen@@', 'de', 'ik', 'jullie', 'l@@', 'aat@@', 'ste', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'van', 'de', 'l@@', 'aat@@', 'ste', 'v@@', 'ol@@', 'ie', 'is.', '</s>']
2025-05-29 23:19:06,245 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:19:06,246 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:19:06,246 - INFO - joeynmt.training - 	Hypothesis: De volgende ik de volgende ik jullie laatste gebeurt in de laatste 25 jaar in de laatste 25 jaar 25 jaar in de laatste 25 jaar geleden 25 jaar geleden 25 jaar geleden van de laatste volie is.
2025-05-29 23:19:15,764 - INFO - joeynmt.training - Epoch   1, Step:     6600, Batch Loss:     1.931479, Batch Acc: 0.421042, Tokens per Sec:     7455, Lr: 0.000300
2025-05-29 23:19:25,610 - INFO - joeynmt.training - Epoch   1, Step:     6700, Batch Loss:     1.953762, Batch Acc: 0.424503, Tokens per Sec:     7395, Lr: 0.000300
2025-05-29 23:19:35,223 - INFO - joeynmt.training - Epoch   1, Step:     6800, Batch Loss:     1.806982, Batch Acc: 0.424376, Tokens per Sec:     7551, Lr: 0.000300
2025-05-29 23:19:45,178 - INFO - joeynmt.training - Epoch   1, Step:     6900, Batch Loss:     2.028816, Batch Acc: 0.424732, Tokens per Sec:     7125, Lr: 0.000300
2025-05-29 23:19:54,831 - INFO - joeynmt.training - Epoch   1, Step:     7000, Batch Loss:     2.046092, Batch Acc: 0.428927, Tokens per Sec:     7404, Lr: 0.000300
2025-05-29 23:19:54,832 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:19:54,832 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:20:52,490 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.71, acc:   0.41, generation: 57.6022[sec], evaluation: 0.0000[sec]
2025-05-29 23:20:52,491 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:20:52,682 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/4500.ckpt
2025-05-29 23:20:52,697 - INFO - joeynmt.training - Example #0
2025-05-29 23:20:52,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:20:52,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:20:52,698 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'dit', 'jaar', 'gel@@', 'e@@', 'den', 'dat', 'ik', 'deze', 'v@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'ijk', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en', 'dat', 'de', 'wer@@', 'kel@@', 'ijk', 'e@@', 'ens', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'gel@@', 'e@@', 'den', 'de', 'b@@', 'o@@', 'ss@@', 'en,', 'v@@', 'a@@', 'st@@', ',', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 'wa@@', 'cht@@', 'ige', 'st@@', 'a@@', 'p', 'te', 'ver@@', 't@@', 'ro@@', 'u@@', 'w@@', 'en.', '</s>']
2025-05-29 23:20:52,699 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:20:52,700 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:20:52,700 - INFO - joeynmt.training - 	Hypothesis: Ik heb dit jaar geleden dat ik deze volië getoond om te verzamelijk te verzamelen dat de werkelijk eens drie miljoen jaar geleden de bossen, vast, 40 procent had om 40 procent te verwachtige stap te vertrouwen.
2025-05-29 23:20:52,700 - INFO - joeynmt.training - Example #1
2025-05-29 23:20:52,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:20:52,701 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:20:52,701 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ar@@', 't', 'de', 'p@@', 're@@', 'st@@', 'en@@', 'aar@@', 't@@', 'sch@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'pro@@', 'ble@@', 'em', 'dat', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'e', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'e', 'van', 'de', 'e@@', 'is', 'het', 'niet', 'de', 'di@@', 'c@@', 'e', 'van', 'de', 'e@@', 'is', 'het', 'niet', 'de', 'ge@@', 'wel@@', 'd.', '</s>']
2025-05-29 23:20:52,702 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:20:52,702 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:20:52,702 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet start de prestenaartschappelijke probleem dat is het niet de dike probleem dat het niet de dike van de eis het niet de dice van de eis het niet de geweld.
2025-05-29 23:20:52,702 - INFO - joeynmt.training - Example #2
2025-05-29 23:20:52,702 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:20:52,703 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:20:52,703 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'et@@', 'ensch@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'e@@', 'chte', 'e@@', 'is@@', 'c@@', 'ap@@', 'p@@', 'e', 'e@@', 'is@@', 'c@@', 'ap@@', 'p@@', 'e', 'sch@@', 'a@@', 'p', 'van', 'de', 'k@@', 'le@@', 'ur@@', 'en', 'en', 'c@@', 'l@@', 'i@@', 'sy@@', 'ste@@', 'm@@', 'en.', '</s>']
2025-05-29 23:20:52,710 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:20:52,710 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:20:52,710 - INFO - joeynmt.training - 	Hypothesis: In wetenschappelijke echte eiscappe eiscappe schap van de kleuren en clisystemen.
2025-05-29 23:20:52,711 - INFO - joeynmt.training - Example #3
2025-05-29 23:20:52,711 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:20:52,711 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:20:52,711 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'k@@', 'wa@@', 'm', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 'en', 's@@', 'om@@', 'm@@', 'ige', 'in', 'het', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', '.', '</s>']
2025-05-29 23:20:52,712 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:20:52,712 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:20:52,713 - INFO - joeynmt.training - 	Hypothesis: Ze kwam in het winter en en sommige in het zomer in de zom.
2025-05-29 23:20:52,713 - INFO - joeynmt.training - Example #4
2025-05-29 23:20:52,714 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:20:52,714 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:20:52,714 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie,', 'die', 'ik', 'l@@', 'aat@@', 'ste', 'ge@@', 'e@@', 'f', 'is', 'een', 'c@@', 'ont@@', 'ro@@', 'l@@', 'e', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-29 23:20:52,716 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:20:52,716 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:20:52,716 - INFO - joeynmt.training - 	Hypothesis: De volgende folie, die ik laatste geef is een controle in de laatste 25 jaar geleden 25 jaar geleden 25 jaar geleden gebeurt.
2025-05-29 23:21:02,148 - INFO - joeynmt.training - Epoch   1, Step:     7100, Batch Loss:     1.680036, Batch Acc: 0.432418, Tokens per Sec:     7611, Lr: 0.000300
2025-05-29 23:21:11,215 - INFO - joeynmt.training - Epoch   1, Step:     7200, Batch Loss:     1.949495, Batch Acc: 0.429806, Tokens per Sec:     7929, Lr: 0.000300
2025-05-29 23:21:19,686 - INFO - joeynmt.training - Epoch   1, Step:     7300, Batch Loss:     1.946351, Batch Acc: 0.437391, Tokens per Sec:     8546, Lr: 0.000300
2025-05-29 23:21:28,281 - INFO - joeynmt.training - Epoch   1, Step:     7400, Batch Loss:     1.872017, Batch Acc: 0.430498, Tokens per Sec:     8082, Lr: 0.000300
2025-05-29 23:21:36,865 - INFO - joeynmt.training - Epoch   1, Step:     7500, Batch Loss:     1.757568, Batch Acc: 0.432982, Tokens per Sec:     8454, Lr: 0.000300
2025-05-29 23:21:36,866 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:21:36,866 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:22:23,258 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.59, acc:   0.42, generation: 46.3406[sec], evaluation: 0.0000[sec]
2025-05-29 23:22:23,259 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:22:23,435 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/5000.ckpt
2025-05-29 23:22:23,448 - INFO - joeynmt.training - Example #0
2025-05-29 23:22:23,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:22:23,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:22:23,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'deze', 'f@@', 'ol@@', 'ie', 'die', 'v@@', 'a@@', 'st@@', 'ische', 'ge@@', 'to@@', 'on@@', 'd', 'dat', 'de', 'wer@@', 'k@@', 'ing', 'van', 'de', 'wer@@', 'k@@', 'ap@@', 'p@@', 'en,', 'de', 'wer@@', 'k@@', 'ten', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'ss@@', 'en@@', 'en', 'j@@', 'ar@@', 'en', 'jaar', 'de', 'st@@', 'a@@', 'd', 'van', 'de', 'gr@@', 'en@@', 'zen', 'van', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'St@@', 'aten', 'ha@@', 'd@@', 'den', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'gr@@', 'on@@', 'd', 'van', 'de', 'V@@', 'S', 'is', 'is', 'ge@@', 'be@@', 'ur@@', 'de', 'van', 'de', 'c@@', 'ent@@', 'ru@@', 'm', 'is.', '</s>']
2025-05-29 23:22:23,450 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:22:23,450 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:22:23,451 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze folie die ik deze folie die vastische getoond dat de werking van de werkappen, de werkten van de reden van de ressenen jaren jaar de stad van de grenzen van de Verenigde Staten hadden 40 procent van de grond van de VS is is gebeurde van de centrum is.
2025-05-29 23:22:23,451 - INFO - joeynmt.training - Example #1
2025-05-29 23:22:23,451 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:22:23,451 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:22:23,451 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 'aar@@', 'de', 'van', 'de', 'aar@@', 'de', 'uit@@', 'st@@', 'ar@@', 't', 'van', 'de', 'aar@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'er', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'e@@', 'is', 'het', 'niet', 'de', 'di@@', 'ck@@', '.', '</s>']
2025-05-29 23:22:23,452 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:22:23,452 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:22:23,452 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de aarde van de aarde uitstart van de aarheid van dit speciale probleem dat er niet de dicke van het eis het niet de dick.
2025-05-29 23:22:23,453 - INFO - joeynmt.training - Example #2
2025-05-29 23:22:23,453 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:22:23,453 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:22:23,453 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'e@@', 'e@@', 'ct@@', 'ie@@', 'k@@', 'ap@@', 'p@@', 'e', 'e@@', 'is@@', 'c@@', 'ap@@', 'e', 'e@@', 'is@@', 'c@@', 'ap@@', 'e', 'k@@', 'ap@@', 'p@@', 'el@@', 'e', 'c@@', 'ap@@', 'e', 'sy@@', 'ste@@', 'm@@', 'en.', '</s>']
2025-05-29 23:22:23,454 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:22:23,454 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:22:23,454 - INFO - joeynmt.training - 	Hypothesis: In zekere is de artische eectiekappe eiscape eiscape kappele cape systemen.
2025-05-29 23:22:23,455 - INFO - joeynmt.training - Example #3
2025-05-29 23:22:23,455 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:22:23,455 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:22:23,455 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'v@@', 'aa@@', 'k', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 's@@', 'om@@', '.', '</s>']
2025-05-29 23:22:23,456 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:22:23,456 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:22:23,456 - INFO - joeynmt.training - 	Hypothesis: Ze vaak in het winter en som.
2025-05-29 23:22:23,456 - INFO - joeynmt.training - Example #4
2025-05-29 23:22:23,457 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:22:23,457 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:22:23,457 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'c@@', 'ont@@', 'mo@@', 'et@@', 'te', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-29 23:22:23,458 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:22:23,458 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:22:23,458 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik laten zien, is een contmoette in de laatste 25 jaar in de laatste 25 jaar gebeurt.
2025-05-29 23:22:32,324 - INFO - joeynmt.training - Epoch   1, Step:     7600, Batch Loss:     1.782569, Batch Acc: 0.434582, Tokens per Sec:     7976, Lr: 0.000300
2025-05-29 23:22:42,520 - INFO - joeynmt.training - Epoch   1, Step:     7700, Batch Loss:     1.735907, Batch Acc: 0.443819, Tokens per Sec:     7001, Lr: 0.000300
2025-05-29 23:22:52,174 - INFO - joeynmt.training - Epoch   1, Step:     7800, Batch Loss:     1.777452, Batch Acc: 0.442758, Tokens per Sec:     7505, Lr: 0.000300
2025-05-29 23:23:01,708 - INFO - joeynmt.training - Epoch   1, Step:     7900, Batch Loss:     1.859681, Batch Acc: 0.442506, Tokens per Sec:     7595, Lr: 0.000300
2025-05-29 23:23:11,157 - INFO - joeynmt.training - Epoch   1, Step:     8000, Batch Loss:     1.697402, Batch Acc: 0.440235, Tokens per Sec:     7577, Lr: 0.000300
2025-05-29 23:23:11,157 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:23:11,158 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:24:01,278 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.40, acc:   0.43, generation: 50.0691[sec], evaluation: 0.0000[sec]
2025-05-29 23:24:01,279 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:24:01,440 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/5500.ckpt
2025-05-29 23:24:01,457 - INFO - joeynmt.training - Example #0
2025-05-29 23:24:01,457 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:24:01,457 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:24:01,457 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'v@@', 'aa@@', 'k', 'dat', 'ik', 'deze', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'dat', 'de', 'wer@@', 'k@@', 't,', 'om', 'te', 'ver@@', 'k@@', 'eer@@', 'd', 'te', 'ver@@', 'ken@@', 'n@@', 'i@@', 've@@', 'a@@', 'u', 'van', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'ige', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'jaar', 'gel@@', 'e@@', 'g@@', 'd', 'dat', 'de', 'st@@', 'an@@', 'da@@', 'ar@@', 'd', 'van', 'de']
2025-05-29 23:24:01,458 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:24:01,459 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:24:01,459 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze vaak dat ik deze folië getoond dat de werkt, om te verkeerd te verkenniveau van drie miljoen jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jarige jaren jaren jaar gelegd dat de standaard van de
2025-05-29 23:24:01,459 - INFO - joeynmt.training - Example #1
2025-05-29 23:24:01,459 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:24:01,460 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:24:01,460 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'niet', 'de', 'eer@@', 'ste', 'ver@@', 'st@@', 'op@@', 'p@@', 'el@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'am@@', 'er', 'niet', 'de', 'di@@', 'k@@', 'am@@', 'er', 'van', 'de', 'e@@', 'is', 'het', 'e@@', 'is', 'het', 'niet', 'de', 'di@@', 'a@@', '.', '</s>']
2025-05-29 23:24:01,461 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:24:01,461 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:24:01,461 - INFO - joeynmt.training - 	Hypothesis: Maar dit speciale probleem niet de eerste verstoppeling van dit speciale probleem is het niet de dikamer niet de dikamer van de eis het eis het niet de dia.
2025-05-29 23:24:01,461 - INFO - joeynmt.training - Example #2
2025-05-29 23:24:01,461 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:24:01,462 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:24:01,462 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'k@@', 'er', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'e@@', 'p@@', 'p@@', 'e', 'e@@', 'is@@', 'c@@', 'ap@@', 'p@@', 'e', 'en', 'het', 'l@@', 'ag@@', 'e', 'en', 'de', 'kl@@', 'im@@', 'aat@@', 'ver@@', 's@@', 'la@@', 'gen', 'van', 'onze', 'kl@@', 'im@@', 'aat@@', 's.', '</s>']
2025-05-29 23:24:01,463 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:24:01,463 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:24:01,463 - INFO - joeynmt.training - 	Hypothesis: In zeker is de artische eppe eiscappe en het lage en de klimaatverslagen van onze klimaats.
2025-05-29 23:24:01,463 - INFO - joeynmt.training - Example #3
2025-05-29 23:24:01,463 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:24:01,463 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:24:01,464 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'k@@', 'wa@@', 'm', 'in', 'het', 'woor@@', 'den', 'en', 's@@', 'om@@', 'm@@', 'ige', 'p@@', 're@@', 'c@@', 'ies', 'in', 'het', 'S@@', 'om@@', 'm@@', 'ige', 'p@@', 're@@', 'c@@', 'ies', 'van', 'de', 'S@@', 'om@@', 'm@@', 'ige', 'p@@', 're@@', 'c@@', 'ies', 'in', 'het', 'z@@', 'om@@', '.', '</s>']
2025-05-29 23:24:01,464 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:24:01,465 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:24:01,465 - INFO - joeynmt.training - 	Hypothesis: Ze kwam in het woorden en sommige precies in het Sommige precies van de Sommige precies in het zom.
2025-05-29 23:24:01,465 - INFO - joeynmt.training - Example #4
2025-05-29 23:24:01,465 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:24:01,465 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:24:01,465 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'vol@@', 'gen@@', 'de', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'dat', 'ik', 'een', 'c@@', 'r@@', 'r@@', 'on@@', 'd@@', 'om', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'gel@@', 'e@@', 'den', '2@@', '5', 'jaar', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', 'f@@', 'o@@', 'to@@', "'s", 'van', 'de', 'l@@', 'aat@@', 'ste', 'de@@', 'el@@', '.', '</s>']
2025-05-29 23:24:01,466 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:24:01,466 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:24:01,467 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende ik jullie laten zien dat ik een crrondom de laatste 25 jaar in de laatste 25 jaar in de laatste 25 jaar in de laatste 25 jaar geleden 25 jaar laatste 25 jaar in de laatste foto's van de laatste deel.
2025-05-29 23:24:10,617 - INFO - joeynmt.training - Epoch   1, Step:     8100, Batch Loss:     1.712940, Batch Acc: 0.440149, Tokens per Sec:     7803, Lr: 0.000300
2025-05-29 23:24:19,744 - INFO - joeynmt.training - Epoch   1, Step:     8200, Batch Loss:     1.904037, Batch Acc: 0.442303, Tokens per Sec:     7892, Lr: 0.000300
2025-05-29 23:24:28,786 - INFO - joeynmt.training - Epoch   1, Step:     8300, Batch Loss:     1.866460, Batch Acc: 0.449469, Tokens per Sec:     8005, Lr: 0.000300
2025-05-29 23:24:37,245 - INFO - joeynmt.training - Epoch   1, Step:     8400, Batch Loss:     1.772194, Batch Acc: 0.443162, Tokens per Sec:     8675, Lr: 0.000300
2025-05-29 23:24:45,448 - INFO - joeynmt.training - Epoch   1, Step:     8500, Batch Loss:     1.663510, Batch Acc: 0.449550, Tokens per Sec:     8825, Lr: 0.000300
2025-05-29 23:24:45,449 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:24:45,449 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:25:29,080 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.27, acc:   0.43, generation: 43.5838[sec], evaluation: 0.0000[sec]
2025-05-29 23:25:29,081 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:25:29,243 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/6000.ckpt
2025-05-29 23:25:29,258 - INFO - joeynmt.training - Example #0
2025-05-29 23:25:29,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:25:29,260 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:25:29,260 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 't@@', 'on@@', 'en', 'die', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'dat', 'de', 'wer@@', 'kt', 'dat', 'de', 'wer@@', 'kt', 'dat', 'de', 'wer@@', 'kt', 'dat', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'en@@', 'zen', 'van', 'de', 're@@', 'den', 'van', 'de', 're@@', 'den', 'van', 'de', 'gr@@', 'on@@', 'd', 'van', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'St@@', 'at@@', 'en,', 'ha@@', 'd', 'ge@@', 'be@@', 'ur@@', 'de', 'p@@', 'ag@@', 'in@@', 'a', 'ge@@', 'be@@', 'ur@@', 'de', 'p@@', 'aal@@', 'de', 'st@@', 'aat', 'ge@@', 't@@', 'ro@@', 'u@@', 'w@@', 'en', 'van', 'de', 're@@', 'den', 'van', 'de', 'gro@@', 'ot@@', 'ste', 'p@@', 'ar@@', 'a@@', '.', '</s>']
2025-05-29 23:25:29,261 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:25:29,261 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:25:29,261 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze folië getonen die twee folië dat de werkt dat de werkt dat de werkt dat de reden van de reden van de reden van de grenzen van de reden van de reden van de grond van de Verenigde Staten, had gebeurde pagina gebeurde paalde staat getrouwen van de reden van de grootste para.
2025-05-29 23:25:29,261 - INFO - joeynmt.training - Example #1
2025-05-29 23:25:29,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:25:29,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:25:29,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k', 'niet', 'st@@', 'ar@@', 't', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'd@@', 'st@@', 'o@@', 'k@@', 'ig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'van', 'de', 'di@@', 'ck@@', 's', 'van', 'de', 'di@@', 'ck@@', 's', 'van', 'de', 'di@@', 'ck@@', 's', 'van', 'de', 'di@@', 'ck@@', 's', 'van', 'de', 'e@@', 'is', 'het', 'niet', 'de', 'e@@', 'is', 'het', 'niet', 'de', 'me@@', 'e@@', 'st', 'van', 'de', 'ver@@', 't@@', 'ro@@', 'k@@', 'ken', 'van', 'de', 'aar@@', 'd@@', 'ige', 'pro@@', 'ble@@', 'em@@', '.', '</s>']
2025-05-29 23:25:29,263 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:25:29,263 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:25:29,264 - INFO - joeynmt.training - 	Hypothesis: Maar dit druk niet start genoeg de aardstokigheid van dit specifieke probleem van de dicks van de dicks van de dicks van de dicks van de eis het niet de eis het niet de meest van de vertrokken van de aardige probleem.
2025-05-29 23:25:29,264 - INFO - joeynmt.training - Example #2
2025-05-29 23:25:29,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:25:29,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:25:29,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'het', 'w@@', 'et@@', 'ensch@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'e@@', 'is@@', 'c@@', 'o@@', 'f@@', 'e', 'van', 'onze', 'e@@', 'c@@', 'ap@@', 'e', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'c@@', 'ap@@', 'e', 'c@@', 'ap@@', 'e', 'sy@@', 'ste@@', 'm@@', 'en.', '</s>']
2025-05-29 23:25:29,266 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:25:29,266 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:25:29,267 - INFO - joeynmt.training - 	Hypothesis: In het wetenschappelijke eiscofe van onze ecape van onze wereldwijde cape cape systemen.
2025-05-29 23:25:29,267 - INFO - joeynmt.training - Example #3
2025-05-29 23:25:29,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:25:29,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:25:29,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'k@@', 'wa@@', 'm', 'in', 'het', 'woor@@', 'd', 'en', 's@@', 'om@@', 'm@@', 'ige', 'p@@', 're@@', 's.', '</s>']
2025-05-29 23:25:29,268 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:25:29,269 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:25:29,269 - INFO - joeynmt.training - 	Hypothesis: Ze kwam in het woord en sommige pres.
2025-05-29 23:25:29,269 - INFO - joeynmt.training - Example #4
2025-05-29 23:25:29,269 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:25:29,270 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:25:29,270 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'dat', 'ik', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'is.', '</s>']
2025-05-29 23:25:29,271 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:25:29,271 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:25:29,271 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien dat ik een tijdperk in de laatste 25 jaar gebeurt is.
2025-05-29 23:25:38,525 - INFO - joeynmt.training - Epoch   1, Step:     8600, Batch Loss:     1.765133, Batch Acc: 0.448941, Tokens per Sec:     7756, Lr: 0.000300
2025-05-29 23:25:48,226 - INFO - joeynmt.training - Epoch   1, Step:     8700, Batch Loss:     1.673829, Batch Acc: 0.456748, Tokens per Sec:     7526, Lr: 0.000300
2025-05-29 23:25:57,367 - INFO - joeynmt.training - Epoch   1, Step:     8800, Batch Loss:     1.868734, Batch Acc: 0.445104, Tokens per Sec:     7891, Lr: 0.000300
2025-05-29 23:26:06,572 - INFO - joeynmt.training - Epoch   1, Step:     8900, Batch Loss:     1.696903, Batch Acc: 0.453042, Tokens per Sec:     7821, Lr: 0.000300
2025-05-29 23:26:15,840 - INFO - joeynmt.training - Epoch   1, Step:     9000, Batch Loss:     1.770050, Batch Acc: 0.450526, Tokens per Sec:     7825, Lr: 0.000300
2025-05-29 23:26:15,840 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:26:15,841 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:27:00,596 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.17, acc:   0.44, generation: 44.6975[sec], evaluation: 0.0000[sec]
2025-05-29 23:27:00,597 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:27:00,818 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/6500.ckpt
2025-05-29 23:27:00,836 - INFO - joeynmt.training - Example #0
2025-05-29 23:27:00,837 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:27:00,837 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:27:00,837 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ik', 'deze', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'ander@@', 'en', 'dat', 'de', 'wer@@', 'k@@', 'ten', 'dat', 'de', 'wer@@', 'k@@', 't,', 'die', 'voor', 'de', 's@@', 'n@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gr@@', 'en@@', 'zen', 'van', 'de', 'v@@', 'a@@', 'st@@', 'at@@', 'ten', 'van', 'de', 're@@', 'den', 'van', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'St@@', 'at@@', 'en,', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 't@@', 'ell@@', 'en,', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 'ken@@', 'n@@', 'en.', '</s>']
2025-05-29 23:27:00,842 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:27:00,842 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:27:00,842 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb ik deze folië getoond om te veranderen dat de werkten dat de werkt, die voor de snappen, die voor de grenzen van de vastatten van de reden van de Verenigde Staten, om 40 procent te vertellen, om 40 procent te verkennen.
2025-05-29 23:27:00,842 - INFO - joeynmt.training - Example #1
2025-05-29 23:27:00,843 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:27:00,843 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:27:00,843 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ar@@', 't', 'de', 'p@@', 're@@', 'c@@', 'en@@', 'ti@@', 'on@@', 'el@@', 'e', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'er', 'niet', 'de', 'di@@', 'k@@', 'er', 'niet', 'de', 'di@@', 'k@@', 'er', 'niet', 'de', 'di@@', 'k@@', 'er', 'niet', 'de', 'di@@', 'k@@', 'er', 'van', 'de', 'di@@', 'k@@', 'er', 'van', 'de', 'di@@', 'k@@', 'er', 'niet', 'de', 'di@@', 'k@@', 'er', 'van', 'de', 'di@@', 'k@@', 'er', 'niet', 'de', 'di@@', 'k@@', 'er', 'van', 'de', 'di@@', 'k@@', 'er', 'niet', 'de', 'di@@', 'k@@', 'er', 'van', 'de', 'di@@', 'k@@', 'er', 'niet', 'de', 'aar@@', 't', 'van', 'de', 're@@', 's@@', 'le@@', 'ch@@', 'ts', 'van', 'de', 'di@@', 'a@@', 'st@@', 'h@@', 'oe@@', 'l', 'de', 'p@@', 'u@@', 'z@@', 'z@@', 'ig@@', 'heid', 'van', 'de', 'di@@', 'k@@', 'er', 'niet', 'de', 'di@@', 'c@@', 'e', 'pro@@', 'ble@@', 'em', 'van', 'de', 'di@@', 'k@@', 'er', 'niet', 'de', 'di@@']
2025-05-29 23:27:00,844 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:27:00,844 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:27:00,845 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet start de precentionele probleem dat het niet de diker niet de diker niet de diker niet de diker niet de diker van de diker van de diker niet de diker van de diker niet de diker van de diker niet de diker van de diker niet de aart van de reslechts van de diasthoel de puzzigheid van de diker niet de dice probleem van de diker niet de di
2025-05-29 23:27:00,845 - INFO - joeynmt.training - Example #2
2025-05-29 23:27:00,845 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:27:00,845 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:27:00,845 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'in@@', 'kel@@', 's', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'e@@', 'p@@', 'p@@', 'e', 'p@@', 're@@', 'c@@', 'ap@@', 'p@@', 'e', 'van', 'onze', 'ge@@', 'vol@@', 'g@@', 'lo@@', 'b@@', 'ale', 'c@@', 'ap@@', 'ac@@', 'it@@', 'eit', 'van', 'onze', 'c@@', 'l@@', 'i@@', 'ë@@', 'n@@', 'te@@', 'm@@', '.', '</s>']
2025-05-29 23:27:00,846 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:27:00,846 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:27:00,846 - INFO - joeynmt.training - 	Hypothesis: In winkels is de artische eppe precappe van onze gevolglobale capaciteit van onze cliëntem.
2025-05-29 23:27:00,846 - INFO - joeynmt.training - Example #3
2025-05-29 23:27:00,847 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:27:00,847 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:27:00,847 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'we@@', 'ten', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 's@@', 'om@@', 'm@@', 'ige', 'en', 's@@', 'om@@', '.', '</s>']
2025-05-29 23:27:00,848 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:27:00,848 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:27:00,848 - INFO - joeynmt.training - 	Hypothesis: Ze weten in het winter en sommige en som.
2025-05-29 23:27:00,848 - INFO - joeynmt.training - Example #4
2025-05-29 23:27:00,849 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:27:00,849 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:27:00,849 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie,', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'wat', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'wat', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-29 23:27:00,850 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:27:00,850 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:27:00,850 - INFO - joeynmt.training - 	Hypothesis: De volgende folie, die ik je laat zien wat in de laatste 25 jaar wat in de laatste 25 jaar in de laatste 25 jaar gebeurt.
2025-05-29 23:27:10,005 - INFO - joeynmt.training - Epoch   1, Step:     9100, Batch Loss:     1.812187, Batch Acc: 0.458827, Tokens per Sec:     7542, Lr: 0.000300
2025-05-29 23:27:18,941 - INFO - joeynmt.training - Epoch   1, Step:     9200, Batch Loss:     1.804053, Batch Acc: 0.454874, Tokens per Sec:     8213, Lr: 0.000300
2025-05-29 23:27:27,799 - INFO - joeynmt.training - Epoch   1, Step:     9300, Batch Loss:     1.740076, Batch Acc: 0.452953, Tokens per Sec:     8088, Lr: 0.000300
2025-05-29 23:27:36,383 - INFO - joeynmt.training - Epoch   1, Step:     9400, Batch Loss:     1.828133, Batch Acc: 0.455972, Tokens per Sec:     8369, Lr: 0.000300
2025-05-29 23:27:44,483 - INFO - joeynmt.training - Epoch   1, Step:     9500, Batch Loss:     1.828984, Batch Acc: 0.466028, Tokens per Sec:     9002, Lr: 0.000300
2025-05-29 23:27:44,484 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:27:44,484 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:28:35,395 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.04, acc:   0.44, generation: 50.8559[sec], evaluation: 0.0000[sec]
2025-05-29 23:28:35,396 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:28:35,563 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/7000.ckpt
2025-05-29 23:28:35,581 - INFO - joeynmt.training - Example #0
2025-05-29 23:28:35,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:28:35,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:28:35,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'en', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'k@@', 'ijk@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'e@@', 'du@@', 'i@@', 'del@@', 'ijk', 'dat', 'de', 'n@@', 'an@@', 'da@@', 'ar@@', 'n@@', 'a', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'n@@', 'i@@', 've@@', 'a@@', 'u', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'be@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'V@@', 'S', 'ge@@', 'da@@', 'an@@', '.', '</s>']
2025-05-29 23:28:35,583 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:28:35,583 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:28:35,583 - INFO - joeynmt.training - 	Hypothesis: Voren jaar heb ik deze twee folië getoond om te verkijken, dat de artische eduidelijk dat de nandaarna drie miljoen jaar de niveau van 40 procent van 40 procent van de beste 40 procent van 40 procent van de VS gedaan.
2025-05-29 23:28:35,584 - INFO - joeynmt.training - Example #1
2025-05-29 23:28:35,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:28:35,585 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:28:35,585 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ar@@', 't', 'de', 'st@@', 'ar@@', 't', 'de', 'aar@@', 'st@@', 'h@@', 'oe@@', 'l', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ij@@', 'ken', 'van', 'de', 'di@@', 'k@@', 'ij@@', 'ken', 'van', 'de', 'di@@', 'k@@', 'ij@@', 'ken', 'van', 'de', 'di@@', 'k@@', 'ij@@', 'ken', 'van', 'de', 'di@@', 'k@@', 'w@@', 'al@@', 'en.', '</s>']
2025-05-29 23:28:35,585 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:28:35,585 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:28:35,585 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet start de start de aarsthoel van dit specifieke probleem dat het niet de dikijken van de dikijken van de dikijken van de dikijken van de dikwalen.
2025-05-29 23:28:35,585 - INFO - joeynmt.training - Example #2
2025-05-29 23:28:35,586 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:28:35,586 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:28:35,586 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'is@@', 'sel@@', 'ijke', 'e@@', 'ct@@', 'ie@@', 'f', 'het', 's@@', 'la@@', 'gen', 'van', 'de', 's@@', 'la@@', 'gen', 'van', 'onze', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'st@@', 'o@@', 'f@@', 'al@@', 'en', 'van', 'onze', 'kl@@', 'im@@', 'aat@@', 'st@@', 'sy@@', 'ste@@', 'm@@', '.', '</s>']
2025-05-29 23:28:35,586 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:28:35,586 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:28:35,586 - INFO - joeynmt.training - 	Hypothesis: In wisselijke ectief het slagen van de slagen van onze globale klimaatstofalen van onze klimaatstsystem.
2025-05-29 23:28:35,587 - INFO - joeynmt.training - Example #3
2025-05-29 23:28:35,587 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:28:35,587 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:28:35,587 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'we@@', 'ten', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 's@@', 'om@@', 'm@@', 'p@@', 'el@@', '.', '</s>']
2025-05-29 23:28:35,587 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:28:35,588 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:28:35,588 - INFO - joeynmt.training - 	Hypothesis: Ze weten in het winter en sommpel.
2025-05-29 23:28:35,588 - INFO - joeynmt.training - Example #4
2025-05-29 23:28:35,588 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:28:35,588 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:28:35,588 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'n@@', 'am@@', 'e', 'van', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'is.', '</s>']
2025-05-29 23:28:35,589 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:28:35,589 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:28:35,589 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien, is een tijdperk in de afgelopname van de afgelopen 25 jaar gebeurt is.
2025-05-29 23:28:45,130 - INFO - joeynmt.training - Epoch   1, Step:     9600, Batch Loss:     1.637359, Batch Acc: 0.459910, Tokens per Sec:     7319, Lr: 0.000300
2025-05-29 23:28:54,844 - INFO - joeynmt.training - Epoch   1, Step:     9700, Batch Loss:     1.684388, Batch Acc: 0.463193, Tokens per Sec:     7482, Lr: 0.000300
2025-05-29 23:29:04,064 - INFO - joeynmt.training - Epoch   1, Step:     9800, Batch Loss:     1.753392, Batch Acc: 0.460567, Tokens per Sec:     7756, Lr: 0.000300
2025-05-29 23:29:13,093 - INFO - joeynmt.training - Epoch   1, Step:     9900, Batch Loss:     1.580775, Batch Acc: 0.458352, Tokens per Sec:     7741, Lr: 0.000300
2025-05-29 23:29:22,810 - INFO - joeynmt.training - Epoch   1, Step:    10000, Batch Loss:     1.679797, Batch Acc: 0.462485, Tokens per Sec:     7510, Lr: 0.000300
2025-05-29 23:29:22,811 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:29:22,811 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:30:10,385 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.95, acc:   0.45, generation: 47.5346[sec], evaluation: 0.0000[sec]
2025-05-29 23:30:10,386 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:30:10,552 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/7500.ckpt
2025-05-29 23:30:10,564 - INFO - joeynmt.training - Example #0
2025-05-29 23:30:10,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:30:10,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:30:10,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'dit', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'v@@', 'ol@@', 'i@@', 'ë', 'ge@@', 't@@', 'on@@', 'en', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'den', 'dat', 'de', 'wer@@', 'k@@', 'ing', 'van', 'de', 'wer@@', 'k@@', 'ne@@', 'mer@@', 's', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'j@@', 'aar@@', ',', 'die', 'voor', 'de', 'st@@', 'at@@', 'ten', 'van', 'de', 'V@@', 'S', 'te', 'be@@', 'st@@', 'aan', 'dat', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'is.', '</s>']
2025-05-29 23:30:10,567 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:30:10,568 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:30:10,568 - INFO - joeynmt.training - 	Hypothesis: Ik heb dit jaar heb ik deze twee volië getonen om te verbeelden dat de werking van de werknemers drie miljoen jaar, die voor de statten van de VS te bestaan dat 40 procent van 40 procent van 40 procent van 40 procent is.
2025-05-29 23:30:10,568 - INFO - joeynmt.training - Example #1
2025-05-29 23:30:10,569 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:30:10,569 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:30:10,569 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k', 'niet', 'st@@', 'ar@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ra@@', 'ch@@', 'ti@@', 'g', 'pro@@', 'ble@@', 'em', 'van', 'het', 'e@@', 'c@@', 'te@@', 'er@@', 'd.', '</s>']
2025-05-29 23:30:10,570 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:30:10,570 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:30:10,570 - INFO - joeynmt.training - 	Hypothesis: Maar dit druk niet stark genoeg de aarde van dit specifieke probleem dat het niet de dikrachtig probleem van het ecteerd.
2025-05-29 23:30:10,570 - INFO - joeynmt.training - Example #2
2025-05-29 23:30:10,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:30:10,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:30:10,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'e@@', 'is@@', 'c@@', 'ap@@', 'p@@', 'e', 'e@@', 'is@@', 'c@@', 'ap@@', 'p@@', 'e', 'e@@', 'is@@', 'c@@', 'ap@@', 'p@@', 'e', 'e@@', 'ct@@', 'ie@@', 'f', 'sy@@', 'ste@@', 'm@@', '.', '</s>']
2025-05-29 23:30:10,572 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:30:10,572 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:30:10,572 - INFO - joeynmt.training - 	Hypothesis: In zekere eiscappe eiscappe eiscappe ectief system.
2025-05-29 23:30:10,572 - INFO - joeynmt.training - Example #3
2025-05-29 23:30:10,573 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:30:10,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:30:10,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'we@@', 'et', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'het', 'z@@', 'om@@', 'mer@@', '.', '</s>']
2025-05-29 23:30:10,574 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:30:10,574 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:30:10,574 - INFO - joeynmt.training - 	Hypothesis: Ze weet in het winter en scheppt in het zommer.
2025-05-29 23:30:10,574 - INFO - joeynmt.training - Example #4
2025-05-29 23:30:10,575 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:30:10,575 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:30:10,575 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-29 23:30:10,576 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:30:10,576 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:30:10,576 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laat zien is een tijdje in de laatste 25 jaar in de laatste 25 jaar gebeurd.
2025-05-29 23:30:19,547 - INFO - joeynmt.training - Epoch   1, Step:    10100, Batch Loss:     1.752678, Batch Acc: 0.459237, Tokens per Sec:     7716, Lr: 0.000300
2025-05-29 23:30:28,476 - INFO - joeynmt.training - Epoch   1, Step:    10200, Batch Loss:     1.830864, Batch Acc: 0.464350, Tokens per Sec:     8158, Lr: 0.000300
2025-05-29 23:30:36,986 - INFO - joeynmt.training - Epoch   1, Step:    10300, Batch Loss:     1.618975, Batch Acc: 0.468381, Tokens per Sec:     8457, Lr: 0.000300
2025-05-29 23:30:44,824 - INFO - joeynmt.training - Epoch   1, Step:    10400, Batch Loss:     1.598605, Batch Acc: 0.474207, Tokens per Sec:     9550, Lr: 0.000300
2025-05-29 23:30:52,671 - INFO - joeynmt.training - Epoch   1, Step:    10500, Batch Loss:     1.744387, Batch Acc: 0.461430, Tokens per Sec:     9272, Lr: 0.000300
2025-05-29 23:30:52,671 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:30:52,671 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:31:33,325 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.87, acc:   0.45, generation: 40.6016[sec], evaluation: 0.0000[sec]
2025-05-29 23:31:33,326 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:31:33,540 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/8000.ckpt
2025-05-29 23:31:33,555 - INFO - joeynmt.training - Example #0
2025-05-29 23:31:33,555 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:31:33,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:31:33,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'p@@', 'ol@@', 'ie@@', 'k', 'dat', 'de', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en']
2025-05-29 23:31:33,557 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:31:33,557 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:31:33,557 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb ik deze twee poliek dat de miljoen jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren jaren
2025-05-29 23:31:33,557 - INFO - joeynmt.training - Example #1
2025-05-29 23:31:33,558 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:31:33,558 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:31:33,558 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ar@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'st@@', 'ier@@', 'ven', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', '.', '</s>']
2025-05-29 23:31:33,559 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:31:33,559 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:31:33,559 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet stark genoeg de aarstierven probleem dat het speciale probleem speciale probleem dat het niet de dick.
2025-05-29 23:31:33,559 - INFO - joeynmt.training - Example #2
2025-05-29 23:31:33,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:31:33,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:31:33,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'et@@', 'ensch@@', 'a@@', 'p', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'e', 'van', 'onze', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'm@@', 'en.', '</s>']
2025-05-29 23:31:33,561 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:31:33,561 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:31:33,561 - INFO - joeynmt.training - 	Hypothesis: In wetenschap is de artische Eiskape van onze globale klimaatsystemen.
2025-05-29 23:31:33,561 - INFO - joeynmt.training - Example #3
2025-05-29 23:31:33,561 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:31:33,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:31:33,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'kom@@', 'en', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 'en', 's@@', 'om@@', 'm@@', 'ige', 'en', 's@@', 'om@@', 'm@@', 'ige', 'van', 'de', 'z@@', 'om@@', 'mer@@', '.', '</s>']
2025-05-29 23:31:33,563 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:31:33,563 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:31:33,563 - INFO - joeynmt.training - 	Hypothesis: Ze komen in het winter en en sommige en sommige van de zommer.
2025-05-29 23:31:33,563 - INFO - joeynmt.training - Example #4
2025-05-29 23:31:33,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:31:33,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:31:33,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie,', 'is', 'een', 'tij@@', 'd@@', 'je', 'die', 'ik', 'jullie', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-29 23:31:33,565 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:31:33,565 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:31:33,565 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende folie, is een tijdje die ik jullie laatste 25 jaar.
2025-05-29 23:31:40,385 - INFO - joeynmt.training - Epoch   1: total training loss 22548.02
2025-05-29 23:31:40,385 - INFO - joeynmt.training - EPOCH 2
2025-05-29 23:31:42,676 - INFO - joeynmt.training - Epoch   2, Step:    10600, Batch Loss:     1.761364, Batch Acc: 0.476277, Tokens per Sec:     8890, Lr: 0.000300
2025-05-29 23:31:51,986 - INFO - joeynmt.training - Epoch   2, Step:    10700, Batch Loss:     1.729632, Batch Acc: 0.476840, Tokens per Sec:     7691, Lr: 0.000300
2025-05-29 23:32:00,700 - INFO - joeynmt.training - Epoch   2, Step:    10800, Batch Loss:     1.724843, Batch Acc: 0.476054, Tokens per Sec:     8075, Lr: 0.000300
2025-05-29 23:32:09,427 - INFO - joeynmt.training - Epoch   2, Step:    10900, Batch Loss:     1.909652, Batch Acc: 0.479391, Tokens per Sec:     8508, Lr: 0.000300
2025-05-29 23:32:18,142 - INFO - joeynmt.training - Epoch   2, Step:    11000, Batch Loss:     1.731398, Batch Acc: 0.474237, Tokens per Sec:     8089, Lr: 0.000300
2025-05-29 23:32:18,142 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:32:18,142 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:33:01,533 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.84, acc:   0.45, generation: 43.3432[sec], evaluation: 0.0000[sec]
2025-05-29 23:33:01,534 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:33:01,695 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/8500.ckpt
2025-05-29 23:33:01,712 - INFO - joeynmt.training - Example #0
2025-05-29 23:33:01,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:33:01,713 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:33:01,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ke', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ke', 'e@@', 'chte', 'e@@', 'is@@', 'k@@', 'ap@@', 'e,', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'e,', 'die', 'voor', 'de', 'b@@', 'as@@', 'is', 'van', 'de', 'on@@', 'der', 'de', 'on@@', 'der', 'de', 'on@@', 'der', 'de', 'on@@', 'der', 'de', '1@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'ge@@', 'be@@', 'ur@@', 'de', 'ge@@', 's@@', 'n@@', 'ap@@', 'p@@', 'ar@@', 'te@@', 'm@@', 'p@@', 'el@@', '.', '</s>']
2025-05-29 23:33:01,714 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:33:01,715 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:33:01,716 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb ik deze twee politieke politieke echte eiskape, de artische Eiskape, die voor de basis van de onder de onder de onder de onder de 10 procent gebeurde gebeurde gesnappartempel.
2025-05-29 23:33:01,716 - INFO - joeynmt.training - Example #1
2025-05-29 23:33:01,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:33:01,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:33:01,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ar@@', 't', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'st@@', 'ier@@', 'f', 'de', 'ver@@', 'st@@', 'op@@', 'p@@', 'el@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'niet', 'de', 'di@@', 'ck@@', ',', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', '.', '</s>']
2025-05-29 23:33:01,717 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:33:01,717 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:33:01,718 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet start genoeg de aarstierf de verstoppeling van dit speciale probleem niet de dick, dat het niet de dick.
2025-05-29 23:33:01,718 - INFO - joeynmt.training - Example #2
2025-05-29 23:33:01,718 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:33:01,718 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:33:01,718 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'in@@', 'kel@@', 's', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'e@@', 'p@@', 'e', 'e@@', 'c@@', 'ap@@', 'e', 'van', 'onze', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'st@@', '.', '</s>']
2025-05-29 23:33:01,719 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:33:01,719 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:33:01,719 - INFO - joeynmt.training - 	Hypothesis: In winkels is de artische epe ecape van onze globale klimaatst.
2025-05-29 23:33:01,720 - INFO - joeynmt.training - Example #3
2025-05-29 23:33:01,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:33:01,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:33:01,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'm@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', 'p@@', '.', '</s>']
2025-05-29 23:33:01,721 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:33:01,721 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:33:01,721 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schemppppppp.
2025-05-29 23:33:01,721 - INFO - joeynmt.training - Example #4
2025-05-29 23:33:01,722 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:33:01,722 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:33:01,722 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ou@@', 't', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-29 23:33:01,723 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:33:01,723 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:33:01,723 - INFO - joeynmt.training - 	Hypothesis: De volgende fout die ik jullie laten zien wat er in de laatste 25 jaar gebeurt in de laatste 25 jaar gebeurt.
2025-05-29 23:33:10,458 - INFO - joeynmt.training - Epoch   2, Step:    11100, Batch Loss:     1.584441, Batch Acc: 0.475003, Tokens per Sec:     8267, Lr: 0.000300
2025-05-29 23:33:19,138 - INFO - joeynmt.training - Epoch   2, Step:    11200, Batch Loss:     1.634390, Batch Acc: 0.478738, Tokens per Sec:     8266, Lr: 0.000300
2025-05-29 23:33:27,829 - INFO - joeynmt.training - Epoch   2, Step:    11300, Batch Loss:     1.723300, Batch Acc: 0.476964, Tokens per Sec:     8159, Lr: 0.000300
2025-05-29 23:33:36,413 - INFO - joeynmt.training - Epoch   2, Step:    11400, Batch Loss:     1.694860, Batch Acc: 0.484568, Tokens per Sec:     8428, Lr: 0.000300
2025-05-29 23:33:45,438 - INFO - joeynmt.training - Epoch   2, Step:    11500, Batch Loss:     1.834774, Batch Acc: 0.484287, Tokens per Sec:     8043, Lr: 0.000300
2025-05-29 23:33:45,438 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:33:45,439 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:34:34,513 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.74, acc:   0.46, generation: 49.0203[sec], evaluation: 0.0000[sec]
2025-05-29 23:34:34,514 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:34:34,716 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/9000.ckpt
2025-05-29 23:34:34,735 - INFO - joeynmt.training - Example #0
2025-05-29 23:34:34,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:34:34,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:34:34,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'e@@', 'ens', 'ge@@', 't@@', 'ro@@', 'du@@', 'c@@', 'eer@@', 'd', 'ge@@', 't@@', 'ro@@', 'du@@', 'c@@', 'eer@@', 'd', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'e@@', 'v@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'be@@', 'el@@', 'd@@', 'ing', 'van', 'de', 'V@@', 'an@@', 'n@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'hel@@', 'e', '4@@', '8', 'st@@', 'at@@', 'ten', 'ha@@', 'd', 'ge@@', 'be@@', 'ur@@', 'de', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'be@@', 'gr@@', 'ij@@', 'p@@', 'en.', '</s>']
2025-05-29 23:34:34,737 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:34:34,737 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:34:34,738 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee eens getroduceerd getroduceerd dat de artische eviskappen, die voor de beelding van de Vanne miljoen jaar de hele 48 statten had gebeurde om 40 procent te begrijpen.
2025-05-29 23:34:34,738 - INFO - joeynmt.training - Example #1
2025-05-29 23:34:34,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:34:34,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:34:34,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k', 'niet', 'st@@', 'ar@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'st@@', 'aat', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'de', 'di@@', 'ck@@', '.', '</s>']
2025-05-29 23:34:34,739 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:34:34,739 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:34:34,740 - INFO - joeynmt.training - 	Hypothesis: Maar dit druk niet stark genoeg de aarstaat van dit speciale probleem van dit speciale probleem van de dick.
2025-05-29 23:34:34,740 - INFO - joeynmt.training - Example #2
2025-05-29 23:34:34,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:34:34,740 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:34:34,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'et@@', 'ensch@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'e@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'e@@', 'en@@', 'vo@@', 'u@@', 'dig@@', 'de', 'kl@@', 'im@@', 'aat@@', 'ver@@', 'ander@@', 'ing', 'van', 'onze', 'kl@@', 'im@@', 'aat@@', 'ver@@', '.', '</s>']
2025-05-29 23:34:34,741 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:34:34,741 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:34:34,741 - INFO - joeynmt.training - 	Hypothesis: In wetenschappelijke eiskappe Eiskappe eenvoudigde klimaatverandering van onze klimaatver.
2025-05-29 23:34:34,742 - INFO - joeynmt.training - Example #3
2025-05-29 23:34:34,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:34:34,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:34:34,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'kom@@', 'st', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 'p@@', 'p@@', 'el@@', '.', '</s>']
2025-05-29 23:34:34,743 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:34:34,743 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:34:34,743 - INFO - joeynmt.training - 	Hypothesis: Ze komst in de winter en scheppppel.
2025-05-29 23:34:34,743 - INFO - joeynmt.training - Example #4
2025-05-29 23:34:34,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:34:34,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:34:34,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'dat', 'ik', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'is.', '</s>']
2025-05-29 23:34:34,745 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:34:34,745 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:34:34,745 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien dat ik een tijdperk van wat in de laatste 25 jaar gebeurt is.
2025-05-29 23:34:43,710 - INFO - joeynmt.training - Epoch   2, Step:    11600, Batch Loss:     1.565703, Batch Acc: 0.477517, Tokens per Sec:     8018, Lr: 0.000300
2025-05-29 23:34:52,096 - INFO - joeynmt.training - Epoch   2, Step:    11700, Batch Loss:     1.492752, Batch Acc: 0.479058, Tokens per Sec:     8669, Lr: 0.000300
2025-05-29 23:35:00,152 - INFO - joeynmt.training - Epoch   2, Step:    11800, Batch Loss:     1.790719, Batch Acc: 0.482237, Tokens per Sec:     9047, Lr: 0.000300
2025-05-29 23:35:07,505 - INFO - joeynmt.training - Epoch   2, Step:    11900, Batch Loss:     1.541010, Batch Acc: 0.478492, Tokens per Sec:     9902, Lr: 0.000300
2025-05-29 23:35:14,887 - INFO - joeynmt.training - Epoch   2, Step:    12000, Batch Loss:     1.782273, Batch Acc: 0.484542, Tokens per Sec:     9815, Lr: 0.000300
2025-05-29 23:35:14,888 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:35:14,888 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:36:14,921 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.71, acc:   0.46, generation: 59.9788[sec], evaluation: 0.0000[sec]
2025-05-29 23:36:14,922 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:36:15,427 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/9500.ckpt
2025-05-29 23:36:15,442 - INFO - joeynmt.training - Example #0
2025-05-29 23:36:15,443 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:36:15,443 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:36:15,443 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'ik', 'deze', 'f@@', 'ol@@', 'i@@', 'ë', 'om', 'te', 'ver@@', 't@@', 'ro@@', 'k@@', 'ken', 'dat', 'de', 'ar@@', 'ti@@', 'c@@', 'ent@@', 'p@@', ',', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'c@@', 'ent@@', 'ru@@', 'm', 'van', 'de', 'be@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'pro@@', 'c@@', 'ent', 'van', 'de', 'be@@', 't@@', 'al@@', 'en', 'ge@@', 'me@@', 'ensch@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'e@@', 'kt@@', 'ri@@', 'c@@', 'ent', 'van', 'de', 'be@@', 'v@@', 'aa@@']
2025-05-29 23:36:15,444 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:36:15,445 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:36:15,445 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze folië getoond ik deze folië om te vertrokken dat de articentp, die voor de articentrum van de beste 40 procent van 40 procent van 40 procent van 40 procent van 40 procent van 40 procent van 40 procent van 40 procent van 40 procent procent van 40 procent procent van de betalen gemeenschappelijke ektricent van de bevaa
2025-05-29 23:36:15,445 - INFO - joeynmt.training - Example #1
2025-05-29 23:36:15,445 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:36:15,445 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:36:15,445 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ar@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'van', 'de', 'aar@@', 'de', 'van', 'het', 'pro@@', 'ble@@', 'em', 'van', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'niet', 'de', 'di@@', 'ck@@', '.', '</s>']
2025-05-29 23:36:15,446 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:36:15,446 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:36:15,446 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet stark genoeg de aarde van de aarde van het probleem van het speciale probleem niet de dick.
2025-05-29 23:36:15,446 - INFO - joeynmt.training - Example #2
2025-05-29 23:36:15,446 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:36:15,446 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:36:15,447 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'et@@', 's@@', 'b@@', 'aar', 'is', 'de', 'ar@@', 'ti@@', 'c@@', 'ap@@', 'p@@', 'e', 'E@@', 'is@@', 'c@@', 'ap@@', 'p@@', 'e', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'onze', 'g@@', 'lo@@', 'b@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'st@@', '.', '</s>']
2025-05-29 23:36:15,447 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:36:15,448 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:36:15,448 - INFO - joeynmt.training - 	Hypothesis: In wetsbaar is de articappe Eiscappe van onze wereldwijd onze globale klimaatst.
2025-05-29 23:36:15,448 - INFO - joeynmt.training - Example #3
2025-05-29 23:36:15,448 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:36:15,448 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:36:15,448 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 'p@@', 'p@@', 'in', 'het', 'z@@', 'om@@', 'mer@@', '.', '</s>']
2025-05-29 23:36:15,449 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:36:15,449 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:36:15,449 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en scheppppin het zommer.
2025-05-29 23:36:15,449 - INFO - joeynmt.training - Example #4
2025-05-29 23:36:15,450 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:36:15,450 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:36:15,450 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'dat', 'ik', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'is.', '</s>']
2025-05-29 23:36:15,451 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:36:15,451 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:36:15,451 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien dat ik een tijdperk van wat in de laatste 25 jaar gebeurt is.
2025-05-29 23:36:24,924 - INFO - joeynmt.training - Epoch   2, Step:    12100, Batch Loss:     1.697854, Batch Acc: 0.480824, Tokens per Sec:     7222, Lr: 0.000300
2025-05-29 23:36:33,810 - INFO - joeynmt.training - Epoch   2, Step:    12200, Batch Loss:     1.643873, Batch Acc: 0.480378, Tokens per Sec:     7951, Lr: 0.000300
2025-05-29 23:36:43,201 - INFO - joeynmt.training - Epoch   2, Step:    12300, Batch Loss:     1.633850, Batch Acc: 0.482525, Tokens per Sec:     7851, Lr: 0.000300
2025-05-29 23:36:52,645 - INFO - joeynmt.training - Epoch   2, Step:    12400, Batch Loss:     1.565507, Batch Acc: 0.483258, Tokens per Sec:     7607, Lr: 0.000300
2025-05-29 23:37:01,936 - INFO - joeynmt.training - Epoch   2, Step:    12500, Batch Loss:     1.774475, Batch Acc: 0.483030, Tokens per Sec:     7647, Lr: 0.000300
2025-05-29 23:37:01,937 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:37:01,937 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:37:50,319 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.59, acc:   0.46, generation: 48.3386[sec], evaluation: 0.0000[sec]
2025-05-29 23:37:50,320 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:37:50,488 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/10000.ckpt
2025-05-29 23:37:50,510 - INFO - joeynmt.training - Example #0
2025-05-29 23:37:50,511 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:37:50,511 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:37:50,511 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'k@@', 'ijk@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'c@@', 'e@@', 's,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'c@@', 'e@@', 's,', 'die', 'voor', 'de', 'n@@', 'aa@@', 'd', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'j@@', 'ar@@', 'en', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-29 23:37:50,512 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:37:50,513 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:37:50,513 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee getoond ik deze twee getoond om te verkijken, dat de artices, die voor de artices, die voor de naad drie miljoen jaren 40 procent gebeurde van 40 procent gebeurt.
2025-05-29 23:37:50,513 - INFO - joeynmt.training - Example #1
2025-05-29 23:37:50,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:37:50,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:37:50,513 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'het', 'niet', 'st@@', 'ar@@', 't', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'de', 'ver@@', 'st@@', 'op@@', 'p@@', 'el@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'het', 'E@@', 'is@@', 'es', 'van', 'het', 'E@@', 'is@@', 'es', 'van', 'het', 'E@@', 'is@@', 'e@@', 's.', '</s>']
2025-05-29 23:37:50,514 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:37:50,514 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:37:50,514 - INFO - joeynmt.training - 	Hypothesis: Maar dit is het niet start genoeg de aarde de verstoppeling van dit speciale probleem van het Eises van het Eises van het Eises.
2025-05-29 23:37:50,514 - INFO - joeynmt.training - Example #2
2025-05-29 23:37:50,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:37:50,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:37:50,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'et@@', 'ensch@@', 'ap@@', 'p@@', 'el@@', 'ijk', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'e@@', 'e@@', 'en@@', 'vo@@', 'u@@', 'w@@', 't', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'st@@', '.', '</s>']
2025-05-29 23:37:50,515 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:37:50,515 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:37:50,515 - INFO - joeynmt.training - 	Hypothesis: In wetenschappelijk is de artische eeenvouwt onze wereldwijd van onze wereldwijde klimaatst.
2025-05-29 23:37:50,515 - INFO - joeynmt.training - Example #3
2025-05-29 23:37:50,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:37:50,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:37:50,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'e@@', 'p@@', 't', 'in', 'het', 'z@@', 'om@@', 'mer@@', '.', '</s>']
2025-05-29 23:37:50,516 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:37:50,516 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:37:50,516 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en scheept in het zommer.
2025-05-29 23:37:50,516 - INFO - joeynmt.training - Example #4
2025-05-29 23:37:50,516 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:37:50,517 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:37:50,517 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'dat', 'ik', 'jullie', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-29 23:37:50,517 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:37:50,517 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:37:50,518 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laat zien dat ik jullie laatste 25 jaar gebeurt.
2025-05-29 23:38:00,042 - INFO - joeynmt.training - Epoch   2, Step:    12600, Batch Loss:     1.724644, Batch Acc: 0.480076, Tokens per Sec:     7390, Lr: 0.000300
2025-05-29 23:38:08,854 - INFO - joeynmt.training - Epoch   2, Step:    12700, Batch Loss:     1.615333, Batch Acc: 0.488578, Tokens per Sec:     8362, Lr: 0.000300
2025-05-29 23:38:17,113 - INFO - joeynmt.training - Epoch   2, Step:    12800, Batch Loss:     1.576954, Batch Acc: 0.485713, Tokens per Sec:     8784, Lr: 0.000300
2025-05-29 23:38:25,179 - INFO - joeynmt.training - Epoch   2, Step:    12900, Batch Loss:     1.720269, Batch Acc: 0.489402, Tokens per Sec:     8681, Lr: 0.000300
2025-05-29 23:38:33,059 - INFO - joeynmt.training - Epoch   2, Step:    13000, Batch Loss:     1.619425, Batch Acc: 0.488237, Tokens per Sec:     9058, Lr: 0.000300
2025-05-29 23:38:33,059 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:38:33,059 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:39:18,958 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.55, acc:   0.47, generation: 45.8552[sec], evaluation: 0.0000[sec]
2025-05-29 23:39:18,959 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:39:19,130 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/10500.ckpt
2025-05-29 23:39:19,141 - INFO - joeynmt.training - Example #0
2025-05-29 23:39:19,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:39:19,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:39:19,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'dat', 'de', 'wer@@', 'k@@', 'ing', 'van', 'de', 'wer@@', 'k@@', 'ing', 'van', 'de', 'wer@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'en', 'die', 'voor', 'de', 'wer@@', 'k@@', 'ing', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'V@@', 'S', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'te', 'ver@@', 'k@@', 'rij@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 'k@@', 'rij@@', 'gen', 'dat', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'wer@@', 'k@@', 't.', '</s>']
2025-05-29 23:39:19,143 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:39:19,143 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:39:19,143 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb ik deze twee getoond dat de werking van de werking van de werkappelen die voor de werking van de grootte van de grootte van de grootte van de VS 40 procent van 40 procent gebeurde grootte van 40 procent gebeurde te verkrijgen om 40 procent te verkrijgen dat de grootte van de grootte van de werkt.
2025-05-29 23:39:19,144 - INFO - joeynmt.training - Example #1
2025-05-29 23:39:19,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:39:19,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:39:19,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'het', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'ver@@', 'st@@', 'h@@', 'aal@@', ',', 'dat', 'het', 'niet', 'de', 'aar@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'el@@', 'e', 'pro@@', 'ble@@', 'em', 'van', 'het', 'E@@', 'is@@', 'e@@', 'st', 'van', 'de', 'e@@', 'chte', 'pro@@', 'ble@@', 'em@@', '.', '</s>']
2025-05-29 23:39:19,145 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:39:19,145 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:39:19,145 - INFO - joeynmt.training - 	Hypothesis: Maar dit is het niet genoeg de aarde versthaal, dat het niet de aarde van dit speciele probleem van het Eisest van de echte probleem.
2025-05-29 23:39:19,146 - INFO - joeynmt.training - Example #2
2025-05-29 23:39:19,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:39:19,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:39:19,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'et@@', 'ensch@@', 'ap@@', 'p@@', 'el@@', 'ijk', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'e@@', 'p@@', ',', 'de', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'st@@', '.', '</s>']
2025-05-29 23:39:19,147 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:39:19,147 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:39:19,147 - INFO - joeynmt.training - 	Hypothesis: In wetenschappelijk is de artische ep, de slagen van onze wereldwijde klimaatst.
2025-05-29 23:39:19,147 - INFO - joeynmt.training - Example #3
2025-05-29 23:39:19,147 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:39:19,148 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:39:19,148 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'k@@', 'wa@@', 'm', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 23:39:19,148 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:39:19,149 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:39:19,149 - INFO - joeynmt.training - 	Hypothesis: Ze kwam in het winter en scheept in de zomers.
2025-05-29 23:39:19,149 - INFO - joeynmt.training - Example #4
2025-05-29 23:39:19,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:39:19,149 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:39:19,149 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-29 23:39:19,150 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:39:19,150 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:39:19,151 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien is een tijdperk van de laatste 25 jaar gebeurd.
2025-05-29 23:39:27,426 - INFO - joeynmt.training - Epoch   2, Step:    13100, Batch Loss:     1.681810, Batch Acc: 0.485276, Tokens per Sec:     8615, Lr: 0.000300
2025-05-29 23:39:35,559 - INFO - joeynmt.training - Epoch   2, Step:    13200, Batch Loss:     1.683365, Batch Acc: 0.488270, Tokens per Sec:     8759, Lr: 0.000300
2025-05-29 23:39:44,173 - INFO - joeynmt.training - Epoch   2, Step:    13300, Batch Loss:     1.738306, Batch Acc: 0.494233, Tokens per Sec:     8487, Lr: 0.000300
2025-05-29 23:39:53,287 - INFO - joeynmt.training - Epoch   2, Step:    13400, Batch Loss:     1.707144, Batch Acc: 0.491100, Tokens per Sec:     7830, Lr: 0.000300
2025-05-29 23:40:02,423 - INFO - joeynmt.training - Epoch   2, Step:    13500, Batch Loss:     1.738178, Batch Acc: 0.485253, Tokens per Sec:     7849, Lr: 0.000300
2025-05-29 23:40:02,423 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:40:02,424 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:41:01,529 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.51, acc:   0.47, generation: 59.0548[sec], evaluation: 0.0000[sec]
2025-05-29 23:41:01,530 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:41:01,711 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/11000.ckpt
2025-05-29 23:41:01,734 - INFO - joeynmt.training - Example #0
2025-05-29 23:41:01,734 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:41:01,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:41:01,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'k@@', 'ap@@', 'p@@', 'el@@', 's', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'n@@', 'el', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', 'j@@', 'ar@@', 'en', '4@@', '8', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'g', 'te', 'st@@', 'op@@', 'p@@', 'en.', '</s>']
2025-05-29 23:41:01,736 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:41:01,736 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:41:01,736 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee kappels getoond om te verkijken dat de artische ijskap, die voor de artische ijsnel drie miljoen jaren jaren jaren jaren 48 procent gebeurde om 40 procent te geslag te stoppen.
2025-05-29 23:41:01,736 - INFO - joeynmt.training - Example #1
2025-05-29 23:41:01,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:41:01,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:41:01,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 'ken', 'niet', 'st@@', 'ar@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'ver@@', 'st@@', 'op@@', 'p@@', 'el@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'el@@', 'e', 'pro@@', 'ble@@', 'men', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'k@@', 'e', 'van', 'de', 'ij@@', 's@@', 'ver@@', 'l@@', 'op@@', 'en.', '</s>']
2025-05-29 23:41:01,737 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:41:01,738 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:41:01,738 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukken niet stark genoeg de verstoppeling van dit speciele problemen dat het niet de dikke van de ijsverlopen.
2025-05-29 23:41:01,738 - INFO - joeynmt.training - Example #2
2025-05-29 23:41:01,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:41:01,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:41:01,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'inn@@', 'e', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'onze', 'wer@@', 'eld', 'onze', 'ge@@', 'vol@@', 'g', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'st@@', '.', '</s>']
2025-05-29 23:41:01,740 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:41:01,740 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:41:01,741 - INFO - joeynmt.training - 	Hypothesis: In zekere zinne is de artische ijskape van onze wereld onze gevolg van onze wereldwijde klimaatst.
2025-05-29 23:41:01,741 - INFO - joeynmt.training - Example #3
2025-05-29 23:41:01,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:41:01,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:41:01,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'k@@', 'wa@@', 'm', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 's@@', 'om@@', 'm@@', 'ige', 'en', 's@@', 'om@@', 'm@@', 'ige', 'van', 'de', 'z@@', 'om@@', 'er', 'van', 'de', 'z@@', 'om@@', 'er', 'van', 'de', 'w@@', 'in@@', 'kel@@', '.', '</s>']
2025-05-29 23:41:01,742 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:41:01,742 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:41:01,742 - INFO - joeynmt.training - 	Hypothesis: Ze kwam in het winter en sommige en sommige van de zomer van de zomer van de winkel.
2025-05-29 23:41:01,743 - INFO - joeynmt.training - Example #4
2025-05-29 23:41:01,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:41:01,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:41:01,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-29 23:41:01,744 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:41:01,744 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:41:01,744 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien is een tijdje in de laatste 25 jaar gebeurd.
2025-05-29 23:41:10,816 - INFO - joeynmt.training - Epoch   2, Step:    13600, Batch Loss:     1.594182, Batch Acc: 0.485540, Tokens per Sec:     8073, Lr: 0.000300
2025-05-29 23:41:19,460 - INFO - joeynmt.training - Epoch   2, Step:    13700, Batch Loss:     1.723247, Batch Acc: 0.488354, Tokens per Sec:     8610, Lr: 0.000300
2025-05-29 23:41:27,520 - INFO - joeynmt.training - Epoch   2, Step:    13800, Batch Loss:     1.479001, Batch Acc: 0.488118, Tokens per Sec:     8839, Lr: 0.000300
2025-05-29 23:41:35,509 - INFO - joeynmt.training - Epoch   2, Step:    13900, Batch Loss:     1.529963, Batch Acc: 0.493327, Tokens per Sec:     8883, Lr: 0.000300
2025-05-29 23:41:43,593 - INFO - joeynmt.training - Epoch   2, Step:    14000, Batch Loss:     1.555611, Batch Acc: 0.493603, Tokens per Sec:     8753, Lr: 0.000300
2025-05-29 23:41:43,593 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:41:43,594 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:42:24,561 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.48, acc:   0.47, generation: 40.6137[sec], evaluation: 0.0000[sec]
2025-05-29 23:42:24,562 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:42:24,744 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/11500.ckpt
2025-05-29 23:42:24,760 - INFO - joeynmt.training - Example #0
2025-05-29 23:42:24,761 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:42:24,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:42:24,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'u@@', 'd@@', 'de', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'p@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'ander@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'c@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'en', 'j@@', 'ar@@', 'en', 'jaar', 'de', 'st@@', 'at@@', 'ten', 'van', 'de', 'Ver@@', 'en@@', 'ig@@', 'de', 'St@@', 'at@@', 'en,', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'is.', '</s>']
2025-05-29 23:42:24,762 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:42:24,762 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:42:24,762 - INFO - joeynmt.training - 	Hypothesis: Ludde jaar heb ik deze twee polië getoond om te veranderen dat de artische Eiskappen, die voor de articappen, die voor de grootte van de onderen jaren jaar de statten van de Verenigde Staten, om 40 procent gebeurde is.
2025-05-29 23:42:24,763 - INFO - joeynmt.training - Example #1
2025-05-29 23:42:24,763 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:42:24,763 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:42:24,763 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 'k@@', 'ig', 'het', 'ver@@', 'st@@', 'r@@', 'el@@', 'ing', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'e', 'pro@@', 'ble@@', 'em', 'van', 'het', 'E@@', 'is@@', '.', '</s>']
2025-05-29 23:42:24,764 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:42:24,764 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:42:24,764 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukkig het verstreling van dit speciale probleem van dit speciale probleem dat het niet de dike probleem van het Eis.
2025-05-29 23:42:24,764 - INFO - joeynmt.training - Example #2
2025-05-29 23:42:24,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:42:24,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:42:24,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'e@@', 'en@@', 'vo@@', 'u@@', 'dig', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'ge@@', 'maa@@', 'kt', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'in', 'het', 'ge@@', 'vo@@', 'el@@', 'd.', '</s>']
2025-05-29 23:42:24,766 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:42:24,766 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:42:24,766 - INFO - joeynmt.training - 	Hypothesis: In zekere eenvoudig is de artische ijskape hart van onze wereldwijd gemaakt van onze wereldwijd van onze wereldwijd van onze wereldwijd in het gevoeld.
2025-05-29 23:42:24,766 - INFO - joeynmt.training - Example #3
2025-05-29 23:42:24,767 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:42:24,767 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:42:24,767 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'w@@', 'aaro@@', 'm', 'het', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 'p@@', '.', '</s>']
2025-05-29 23:42:24,768 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:42:24,768 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:42:24,768 - INFO - joeynmt.training - 	Hypothesis: Ze waarom het in het winter en scheppp.
2025-05-29 23:42:24,768 - INFO - joeynmt.training - Example #4
2025-05-29 23:42:24,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:42:24,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:42:24,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'vol@@', 'gen@@', 'de', 'ik', 'jullie', 't@@', 'on@@', 'en', '2@@', '5', 'jaar', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-29 23:42:24,770 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:42:24,770 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:42:24,770 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende ik jullie tonen 25 jaar is een tijdperk in de laatste 25 jaar gebeurd.
2025-05-29 23:42:33,981 - INFO - joeynmt.training - Epoch   2, Step:    14100, Batch Loss:     1.625933, Batch Acc: 0.489584, Tokens per Sec:     7710, Lr: 0.000300
2025-05-29 23:42:43,221 - INFO - joeynmt.training - Epoch   2, Step:    14200, Batch Loss:     1.481034, Batch Acc: 0.495996, Tokens per Sec:     7663, Lr: 0.000300
2025-05-29 23:42:52,444 - INFO - joeynmt.training - Epoch   2, Step:    14300, Batch Loss:     1.905827, Batch Acc: 0.488051, Tokens per Sec:     7964, Lr: 0.000300
2025-05-29 23:43:01,551 - INFO - joeynmt.training - Epoch   2, Step:    14400, Batch Loss:     1.565954, Batch Acc: 0.498623, Tokens per Sec:     8055, Lr: 0.000300
2025-05-29 23:43:10,697 - INFO - joeynmt.training - Epoch   2, Step:    14500, Batch Loss:     1.686582, Batch Acc: 0.490295, Tokens per Sec:     8039, Lr: 0.000300
2025-05-29 23:43:10,698 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:43:10,698 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:43:53,967 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.42, acc:   0.47, generation: 43.2246[sec], evaluation: 0.0000[sec]
2025-05-29 23:43:53,968 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:43:54,137 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/12000.ckpt
2025-05-29 23:43:54,153 - INFO - joeynmt.training - Example #0
2025-05-29 23:43:54,154 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:43:54,154 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:43:54,154 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'van', 'deze', 'twe@@', 'e', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ke', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ke', 'ge@@', 'da@@', 'an@@', ',', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'm@@', 'id@@', 'del@@', 'en.', '</s>']
2025-05-29 23:43:54,155 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:43:54,155 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:43:54,155 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee van deze twee politieke politieke gedaan, dat de artische ijskappen, die voor de miljoen jaar de grootte van de grootte van de grootte van 40 procent had om 40 procent van 40 procent van 40 procent gesmiddelen.
2025-05-29 23:43:54,155 - INFO - joeynmt.training - Example #1
2025-05-29 23:43:54,156 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:43:54,156 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:43:54,156 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 'k@@', 'ig', 'niet', 'st@@', 'ar@@', 't', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'st@@', 'ar@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'm@@', 'en,', 'wan@@', 't', 'het', 'niet', 'de', 'di@@', 'k@@', 'er', 'niet', 'de', 'di@@', 'k@@', 'er', 'van', 'de', 'ij@@', 's@@', 'ge@@', 'be@@', 'ur@@', 't', 'van', 'de', 'E@@', 'is@@', 'sen', 'van', 'de', 'E@@', 'is@@', 'es', 'van', 'de', 'E@@', 'is@@', 'es', 'van', 'de', 'E@@', 'is@@', 'es', 'l@@', 'ijk@@', 't', 'van', 'de', 'aar@@', 'de', 'van', 'de', 'aar@@', 'st@@', 'ar@@', 't', 'van', 'de', 'aar@@', 'st@@', 'ar@@', 't', 'van', 'het', 'ij@@', 's@@', 'be@@', 'st@@', 'el@@', 'heid', 'van', 'de', 'uit@@', 'st@@', 'ar@@', 't', 'van', 'de', 'E@@', 'is@@', 'es', 'van', 'de', 'E@@', 'is@@', 'es', 'van', 'de', 'ij@@', 's@@', 'ge@@', 'be@@', 'ur@@', 'de', 'niet', 'in', 'de', 'e@@', 'en@@', 'kom@@', 'en', 'van', 'de', 'e@@', 'c@@', 'o@@', 'er@@']
2025-05-29 23:43:54,157 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:43:54,158 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:43:54,158 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukkig niet start genoeg de aarstart van dit speciale problemen, want het niet de diker niet de diker van de ijsgebeurt van de Eissen van de Eises van de Eises van de Eises lijkt van de aarde van de aarstart van de aarstart van het ijsbestelheid van de uitstart van de Eises van de Eises van de ijsgebeurde niet in de eenkomen van de ecoer
2025-05-29 23:43:54,158 - INFO - joeynmt.training - Example #2
2025-05-29 23:43:54,158 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:43:54,159 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:43:54,159 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'e', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'is', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'ver@@', 'ander@@', 'ing', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'ver@@', 'ander@@', 'ing', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'h@@', 'oe@@', 've@@', 'el@@', 'heid', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'ar@@', 'ti@@', 'c@@', 'ap@@', 'p@@', 'ij', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'e@@', 'p@@', 'en.', '</s>']
2025-05-29 23:43:54,160 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:43:54,160 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:43:54,160 - INFO - joeynmt.training - 	Hypothesis: In zekere zine is de artische ijskape is het slagende hart van onze wereldwijde klimaatverandering van onze wereldwijde van onze wereldwijde van onze wereldwijde van onze wereldwijde van onze wereldwijde klimaatverandering van onze wereldwijde hoeveelheid van onze wereldwijde wereldwijde wereldwijde articappij is de artische epen.
2025-05-29 23:43:54,160 - INFO - joeynmt.training - Example #3
2025-05-29 23:43:54,161 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:43:54,161 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:43:54,161 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 's@@', 'om@@', 'm@@', 'ige', 'en', 's@@', 'om@@', 'm@@', 'ige', 'en', 's@@', 'om@@', 'm@@', 'ige', 'p@@', 'o@@', 'sit@@', 'ie', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'en', 's@@', 'om@@', 'm@@', 'ige', 'en', 's@@', 'n@@', 'el', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'en', 's@@', 'om@@', 'm@@', 'ige', 'en', 's@@', 'om@@', 'm@@', 'ige', 'en', 's@@', 'om@@', '.', '</s>']
2025-05-29 23:43:54,162 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:43:54,162 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:43:54,162 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en sommige en sommige en sommige positie in de winter en en sommige en snel in de winter en en sommige en sommige en som.
2025-05-29 23:43:54,162 - INFO - joeynmt.training - Example #4
2025-05-29 23:43:54,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:43:54,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:43:54,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ou@@', 't', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'dat', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-29 23:43:54,164 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:43:54,164 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:43:54,164 - INFO - joeynmt.training - 	Hypothesis: De volgende fout die ik jullie laat zien dat ik jullie laat zien wat er in de laatste 25 jaar gebeurd.
2025-05-29 23:44:02,435 - INFO - joeynmt.training - Epoch   2, Step:    14600, Batch Loss:     1.681387, Batch Acc: 0.491319, Tokens per Sec:     8761, Lr: 0.000300
2025-05-29 23:44:11,646 - INFO - joeynmt.training - Epoch   2, Step:    14700, Batch Loss:     1.452069, Batch Acc: 0.497007, Tokens per Sec:     7718, Lr: 0.000300
2025-05-29 23:44:20,529 - INFO - joeynmt.training - Epoch   2, Step:    14800, Batch Loss:     1.524105, Batch Acc: 0.489012, Tokens per Sec:     8033, Lr: 0.000300
2025-05-29 23:44:29,280 - INFO - joeynmt.training - Epoch   2, Step:    14900, Batch Loss:     1.441678, Batch Acc: 0.499110, Tokens per Sec:     8153, Lr: 0.000300
2025-05-29 23:44:37,469 - INFO - joeynmt.training - Epoch   2, Step:    15000, Batch Loss:     1.497144, Batch Acc: 0.491052, Tokens per Sec:     8625, Lr: 0.000300
2025-05-29 23:44:37,470 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:44:37,470 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:45:31,111 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.37, acc:   0.48, generation: 53.5788[sec], evaluation: 0.0000[sec]
2025-05-29 23:45:31,112 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:45:31,294 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/12500.ckpt
2025-05-29 23:45:31,310 - INFO - joeynmt.training - Example #0
2025-05-29 23:45:31,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:45:31,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:45:31,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'p@@', 'ol@@', 'it@@', 'ie@@', '-@@', 'jaar', 'gel@@', 'e@@', 'den', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'E@@', 'is@@', 'c@@', 'ap@@', 'p@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'be@@', 'ste', 'j@@', 'aar@@', ',', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ha@@', 'd', 'ge@@', 's@@', 'm@@', 'id@@', 'del@@', 'd', 'ha@@', 'd', 'ge@@', 's@@', 'm@@', 'p@@', 'el@@', 'd,', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'm@@', 'p@@', 'ar@@', 'aat', 'is.', '</s>']
2025-05-29 23:45:31,312 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:45:31,312 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:45:31,312 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee politie-jaar geleden dat de artische Eiscappen, dat de artische ijskappen, de grootte van de beste jaar, de grootte van 40 procent had gesmiddeld had gesmpeld, om 40 procent te gesmparaat is.
2025-05-29 23:45:31,312 - INFO - joeynmt.training - Example #1
2025-05-29 23:45:31,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:45:31,313 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:45:31,313 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 'uit@@', 'z@@', 'onder@@', 'd', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'van', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', ',', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'e', 'van', 'de', 'E@@', 'is@@', 'es', 'van', 'de', 'E@@', 'is@@', ',', 'dat', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ra@@', 'ch@@', 'ti@@', 'g', 'l@@', 'ijk@@', 't', 'zi@@', 'en.', '</s>']
2025-05-29 23:45:31,314 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:45:31,314 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:45:31,314 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de uitzonderd genoeg de aarde van het speciale probleem van het speciale probleem dat het niet de dik, dat het niet de dike van de Eises van de Eis, dat is het niet de dikrachtig lijkt zien.
2025-05-29 23:45:31,314 - INFO - joeynmt.training - Example #2
2025-05-29 23:45:31,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:45:31,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:45:31,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'et@@', 'ensch@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'E@@', 'is@@', 'c@@', 'ap@@', 'p@@', 'en,', 'is', 'de', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'st@@', '.', '</s>']
2025-05-29 23:45:31,315 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:45:31,316 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:45:31,316 - INFO - joeynmt.training - 	Hypothesis: In wetenschappelijke Eiscappen, is de slagen van onze wereldwijde klimaatst.
2025-05-29 23:45:31,316 - INFO - joeynmt.training - Example #3
2025-05-29 23:45:31,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:45:31,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:45:31,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'v@@', 'on@@', 'den', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 's@@', 'om@@', 'm@@', 'ige', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 23:45:31,316 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:45:31,317 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:45:31,317 - INFO - joeynmt.training - 	Hypothesis: Ze vonden in het winter en sommige zomers.
2025-05-29 23:45:31,317 - INFO - joeynmt.training - Example #4
2025-05-29 23:45:31,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:45:31,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:45:31,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'vol@@', 'gen@@', 'de', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'dat', 'ik', 'een', 'tij@@', 'd@@', 'je', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'n@@', 'am@@', 'e', 'van', 'de', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-29 23:45:31,318 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:45:31,318 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:45:31,318 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende ik jullie laat zien dat ik een tijdje wat er in de afgelopname van de 25 jaar gebeurd.
2025-05-29 23:45:41,066 - INFO - joeynmt.training - Epoch   2, Step:    15100, Batch Loss:     1.686257, Batch Acc: 0.492932, Tokens per Sec:     7192, Lr: 0.000300
2025-05-29 23:45:50,134 - INFO - joeynmt.training - Epoch   2, Step:    15200, Batch Loss:     1.786520, Batch Acc: 0.493615, Tokens per Sec:     7885, Lr: 0.000300
2025-05-29 23:45:59,253 - INFO - joeynmt.training - Epoch   2, Step:    15300, Batch Loss:     1.742348, Batch Acc: 0.494825, Tokens per Sec:     7788, Lr: 0.000300
2025-05-29 23:46:08,365 - INFO - joeynmt.training - Epoch   2, Step:    15400, Batch Loss:     1.591376, Batch Acc: 0.496683, Tokens per Sec:     8024, Lr: 0.000300
2025-05-29 23:46:17,735 - INFO - joeynmt.training - Epoch   2, Step:    15500, Batch Loss:     1.618944, Batch Acc: 0.495971, Tokens per Sec:     7895, Lr: 0.000300
2025-05-29 23:46:17,735 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:46:17,735 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:47:11,564 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.32, acc:   0.48, generation: 53.7901[sec], evaluation: 0.0000[sec]
2025-05-29 23:47:11,565 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:47:11,733 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/13000.ckpt
2025-05-29 23:47:11,751 - INFO - joeynmt.training - Example #0
2025-05-29 23:47:11,752 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:47:11,752 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:47:11,752 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ke', 'e@@', 'en@@', 's@@', '-@@', 'j@@', 'ar@@', 'en', 'jaar', 'gel@@', 'e@@', 'g@@', 'd', 'jaar', 'de', 're@@', 'den', 'van', 'de', 'b@@', 'an@@', 'g', 'van', 'de', 'gr@@', 'on@@', 'd', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ha@@', 'd', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ha@@', 'd', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'is.', '</s>']
2025-05-29 23:47:11,753 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:47:11,754 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:47:11,754 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee getoond jaar heb ik deze twee politieke eens-jaren jaar gelegd jaar de reden van de bang van de grond drie miljoen jaar de grootte van 40 procent had 40 procent had 40 procent had om 40 procent is.
2025-05-29 23:47:11,754 - INFO - joeynmt.training - Example #1
2025-05-29 23:47:11,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:47:11,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:47:11,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ar@@', 't', 'st@@', 'ier@@', ',', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'd@@', 'ige', 'pro@@', 'ble@@', 'em', 'dat', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', '.', '</s>']
2025-05-29 23:47:11,756 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:47:11,756 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:47:11,756 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet start stier, niet genoeg de aardige probleem dat speciale probleem dat het niet de dick.
2025-05-29 23:47:11,756 - INFO - joeynmt.training - Example #2
2025-05-29 23:47:11,756 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:47:11,756 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:47:11,756 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'et@@', 'ensch@@', 'ap@@', ',', 'is', 'de', 'ar@@', 'ti@@', 'c@@', 'ap@@', 'e', 'e@@', 'en@@', 'vo@@', 'u@@', 'dig@@', 'en', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'st@@', '.', '</s>']
2025-05-29 23:47:11,757 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:47:11,757 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:47:11,757 - INFO - joeynmt.training - 	Hypothesis: In wetenschap, is de articape eenvoudigen van onze wereldwijd onze wereldwijd van onze wereldwijd klimaatst.
2025-05-29 23:47:11,758 - INFO - joeynmt.training - Example #3
2025-05-29 23:47:11,758 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:47:11,758 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:47:11,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 's@@', 'n@@', 'el', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 's@@', 'n@@', 'el@@', '.', '</s>']
2025-05-29 23:47:11,767 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:47:11,767 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:47:11,768 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en snel in de winter en snel.
2025-05-29 23:47:11,768 - INFO - joeynmt.training - Example #4
2025-05-29 23:47:11,768 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:47:11,768 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:47:11,768 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'vol@@', 'gen@@', 'de', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'dat', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-29 23:47:11,771 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:47:11,771 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:47:11,771 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende ik jullie laat zien dat ik jullie laten zien in de laatste 25 jaar gebeurd is.
2025-05-29 23:47:20,623 - INFO - joeynmt.training - Epoch   2, Step:    15600, Batch Loss:     1.560706, Batch Acc: 0.496023, Tokens per Sec:     7840, Lr: 0.000300
2025-05-29 23:47:28,951 - INFO - joeynmt.training - Epoch   2, Step:    15700, Batch Loss:     1.769386, Batch Acc: 0.496344, Tokens per Sec:     8375, Lr: 0.000300
2025-05-29 23:47:37,159 - INFO - joeynmt.training - Epoch   2, Step:    15800, Batch Loss:     1.317891, Batch Acc: 0.496793, Tokens per Sec:     8852, Lr: 0.000300
2025-05-29 23:47:45,194 - INFO - joeynmt.training - Epoch   2, Step:    15900, Batch Loss:     1.465974, Batch Acc: 0.491829, Tokens per Sec:     8889, Lr: 0.000300
2025-05-29 23:47:52,620 - INFO - joeynmt.training - Epoch   2, Step:    16000, Batch Loss:     1.710871, Batch Acc: 0.504026, Tokens per Sec:     9703, Lr: 0.000300
2025-05-29 23:47:52,620 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:47:52,620 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:48:42,553 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.29, acc:   0.48, generation: 49.8787[sec], evaluation: 0.0000[sec]
2025-05-29 23:48:42,554 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:48:42,750 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/13500.ckpt
2025-05-29 23:48:42,765 - INFO - joeynmt.training - Example #0
2025-05-29 23:48:42,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:48:42,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:48:42,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'be@@', 'ur@@', 'de', 'ge@@', 'vol@@', 'g', 'om', 'te', 'ver@@', 'ander@@', 'en', 'te', 'ver@@', 'ander@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'c@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'an@@', 'n@@', 'et@@', 'wer@@', 'k@@', 'ing', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'te', 'ver@@', 'sp@@', 'rei@@', 'd', 'is.', '</s>']
2025-05-29 23:48:42,768 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:48:42,768 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:48:42,768 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb ik deze twee gebeurde gevolg om te veranderen te veranderen dat de articappen, die voor annetwerking van de grootte van 40 procent gebeurde de grootte van 40 procent gebeurde te verspreid is.
2025-05-29 23:48:42,768 - INFO - joeynmt.training - Example #1
2025-05-29 23:48:42,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:48:42,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:48:42,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ar@@', 't', 'st@@', 'on@@', 'd', 'de', 'aar@@', 'de', 'de', 'van', 'de', 'aar@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'de', 'di@@', 'k@@', 'e', 'van', 'de', 'di@@', 'k@@', 'e', 'van', 'de', 'e@@', 'is@@', '.', '</s>']
2025-05-29 23:48:42,770 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:48:42,770 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:48:42,770 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet start stond de aarde de van de aarde van dit speciale probleem van de dike van de dike van de eis.
2025-05-29 23:48:42,770 - INFO - joeynmt.training - Example #2
2025-05-29 23:48:42,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:48:42,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:48:42,771 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'et@@', 'ensch@@', 'ap@@', 'pen', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'e', 'is', 'het', 's@@', 'le@@', 'ch@@', 'ts', 'onze', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-29 23:48:42,772 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:48:42,772 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:48:42,772 - INFO - joeynmt.training - 	Hypothesis: In wetenschappen is de artische Eiskape is het slechts onze klimaatsysteem.
2025-05-29 23:48:42,772 - INFO - joeynmt.training - Example #3
2025-05-29 23:48:42,772 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:48:42,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:48:42,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'de', 'z@@', 'om@@', 'er', 'en', 'de', 'z@@', 'om@@', 'er', 'van', 'de', 'z@@', 'om@@', 'er', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 23:48:42,774 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:48:42,774 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:48:42,774 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomer en zomer in de zomer en de zomer en de zomer van de zomer en zomer in de zomer en de zomers.
2025-05-29 23:48:42,774 - INFO - joeynmt.training - Example #4
2025-05-29 23:48:42,774 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:48:42,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:48:42,775 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-29 23:48:42,776 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:48:42,776 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:48:42,776 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laat zien is een tijdperk van wat er in de laatste 25 jaar gebeurt.
2025-05-29 23:48:52,154 - INFO - joeynmt.training - Epoch   2, Step:    16100, Batch Loss:     1.459179, Batch Acc: 0.497120, Tokens per Sec:     7469, Lr: 0.000300
2025-05-29 23:49:01,380 - INFO - joeynmt.training - Epoch   2, Step:    16200, Batch Loss:     1.738556, Batch Acc: 0.498011, Tokens per Sec:     7822, Lr: 0.000300
2025-05-29 23:49:10,734 - INFO - joeynmt.training - Epoch   2, Step:    16300, Batch Loss:     1.655740, Batch Acc: 0.498200, Tokens per Sec:     7662, Lr: 0.000300
2025-05-29 23:49:19,765 - INFO - joeynmt.training - Epoch   2, Step:    16400, Batch Loss:     1.743126, Batch Acc: 0.491813, Tokens per Sec:     8088, Lr: 0.000300
2025-05-29 23:49:29,220 - INFO - joeynmt.training - Epoch   2, Step:    16500, Batch Loss:     1.556704, Batch Acc: 0.505533, Tokens per Sec:     7761, Lr: 0.000300
2025-05-29 23:49:29,220 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:49:29,221 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:50:19,610 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.48, generation: 50.3528[sec], evaluation: 0.0000[sec]
2025-05-29 23:50:19,611 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:50:19,801 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/14000.ckpt
2025-05-29 23:50:19,819 - INFO - joeynmt.training - Example #0
2025-05-29 23:50:19,820 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:50:19,820 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:50:19,820 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'l@@', 'aat', 'deze', 'twe@@', 'e', 'ge@@', 'be@@', 'ur@@', 'de', 'ik', 'die', 'twe@@', 'e', 'ge@@', 'be@@', 'ur@@', 'de', 'van', 'de', 'wer@@', 'kel@@', 'ijke', 'e@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'wer@@', 'kel@@', 'ijke', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 's', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'on@@', 'der', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'on@@', 'der', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'van', 'de', 'on@@', 'der', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'ru@@', 'm@@', 'p@@', '.', '</s>']
2025-05-29 23:50:19,821 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:50:19,821 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:50:19,821 - INFO - joeynmt.training - 	Hypothesis: Ik laat deze twee gebeurde ik die twee gebeurde van de werkelijke eiskappen, die voor de werkelijke ijskappels die voor de grootte van de onder 40 procent van de onder 40 procent gebeurde van de onder 40 procent gesrump.
2025-05-29 23:50:19,821 - INFO - joeynmt.training - Example #1
2025-05-29 23:50:19,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:50:19,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:50:19,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ar@@', 't', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'pro@@', 'ble@@', 'em', 'van', 'het', 'ge@@', 'vo@@', 'el', 'van', 'het', 'ge@@', 'spe@@', 'ci@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'e', 'van', 'het', 'ij@@', 's@@', 'le@@', 'ch@@', 't.', '</s>']
2025-05-29 23:50:19,823 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:50:19,823 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:50:19,823 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet start genoeg de eerste probleem van het gevoel van het gespeciciale probleem dat het niet de dike van het ijslecht.
2025-05-29 23:50:19,823 - INFO - joeynmt.training - Example #2
2025-05-29 23:50:19,824 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:50:19,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:50:19,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'e@@', 'p@@', 't', 'dat', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'st@@', '.', '</s>']
2025-05-29 23:50:19,825 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:50:19,825 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:50:19,825 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ept dat slagen van onze wereldwijde klimaatst.
2025-05-29 23:50:19,825 - INFO - joeynmt.training - Example #3
2025-05-29 23:50:19,826 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:50:19,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:50:19,826 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'a@@', 'p', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 'en.', '</s>']
2025-05-29 23:50:19,827 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:50:19,827 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:50:19,827 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en scheppt in de winter en zich in de winter en zich in de winter en scheppt in de winter en scheppt in de winter en scheppt in de winter en schap in de winter en scheppt in de winter en en schept in de winter en zomeren.
2025-05-29 23:50:19,827 - INFO - joeynmt.training - Example #4
2025-05-29 23:50:19,828 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:50:19,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:50:19,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'vol@@', 'gen@@', 'de', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'dat', 'ik', 'een', 'tij@@', 'd@@', 'je', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-29 23:50:19,829 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:50:19,829 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:50:19,829 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende ik jullie laat zien dat ik een tijdje laatste 25 jaar gebeurt in de laatste 25 jaar gebeurd.
2025-05-29 23:50:29,126 - INFO - joeynmt.training - Epoch   2, Step:    16600, Batch Loss:     1.492150, Batch Acc: 0.507597, Tokens per Sec:     7519, Lr: 0.000300
2025-05-29 23:50:38,165 - INFO - joeynmt.training - Epoch   2, Step:    16700, Batch Loss:     1.533172, Batch Acc: 0.501404, Tokens per Sec:     7956, Lr: 0.000300
2025-05-29 23:50:46,382 - INFO - joeynmt.training - Epoch   2, Step:    16800, Batch Loss:     1.539290, Batch Acc: 0.503672, Tokens per Sec:     8870, Lr: 0.000300
2025-05-29 23:50:54,477 - INFO - joeynmt.training - Epoch   2, Step:    16900, Batch Loss:     1.621663, Batch Acc: 0.507671, Tokens per Sec:     8770, Lr: 0.000300
2025-05-29 23:51:02,568 - INFO - joeynmt.training - Epoch   2, Step:    17000, Batch Loss:     1.466521, Batch Acc: 0.501694, Tokens per Sec:     8827, Lr: 0.000300
2025-05-29 23:51:02,569 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:51:02,569 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:51:50,571 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.48, generation: 47.9558[sec], evaluation: 0.0000[sec]
2025-05-29 23:51:50,572 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:51:50,746 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/14500.ckpt
2025-05-29 23:51:50,765 - INFO - joeynmt.training - Example #0
2025-05-29 23:51:50,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:51:50,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:51:50,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'be@@', 'ur@@', 't', 'om', 'te', 'ver@@', 'ander@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'voor', 'de', 'ar@@', 'ti@@', 'c@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'ge@@', 'wel@@', 'd@@', 'ige', 'ge@@', 'd@@', 'ige', 'ge@@', 'p@@', 'le@@', 'e@@', 'g@@', 'd', 'ha@@', 'd', 'ge@@', 'be@@', 'ur@@', 'de', 'ge@@', 'd@@', 'ra@@', 'g', 'van', 'de', 'be@@', 'd@@', 'oe@@', 'l', 'van', 'de', 'vol@@', 'gen@@', 'de', 'ge@@', 'gev@@', 'ens', 'van', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'j@@']
2025-05-29 23:51:50,768 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:51:50,768 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:51:50,768 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb ik deze twee folië gebeurt om te veranderen dat de artische ijskap, voor de artice ijskap, drie miljoen jaar de grootte van 40 procent gebeurde om 40 procent te bekijken van 40 procent gebeurde geweldige gedige gepleegd had gebeurde gedrag van de bedoel van de volgende gegevens van de afgelopen j
2025-05-29 23:51:50,768 - INFO - joeynmt.training - Example #1
2025-05-29 23:51:50,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:51:50,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:51:50,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ar@@', 't', 'gen@@', 'oe@@', 'g', 'het', 'niet', 'st@@', 'ar@@', 't', 'het', 'niet', 'in', 'het', 'ge@@', 'vo@@', 'el', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'e', 'van', 'de', 'ij@@', 's@@', 'le@@', 'ch@@', 'ts', 'van', 'de', 'ij@@', 's@@', 'le@@', 'ch@@', 't.', '</s>']
2025-05-29 23:51:50,770 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:51:50,770 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:51:50,770 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet start genoeg het niet start het niet in het gevoel van dit speciale probleem dat het niet de dike van de ijslechts van de ijslecht.
2025-05-29 23:51:50,770 - INFO - joeynmt.training - Example #2
2025-05-29 23:51:50,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:51:50,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:51:50,771 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'e', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-29 23:51:50,772 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:51:50,772 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:51:50,772 - INFO - joeynmt.training - 	Hypothesis: In zekere zine is de artische ijskape het slagen van onze wereldwijde klimaatsysteem.
2025-05-29 23:51:50,772 - INFO - joeynmt.training - Example #3
2025-05-29 23:51:50,772 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:51:50,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:51:50,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 23:51:50,774 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:51:50,774 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:51:50,774 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schept in het zomers.
2025-05-29 23:51:50,774 - INFO - joeynmt.training - Example #4
2025-05-29 23:51:50,774 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:51:50,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:51:50,775 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie,', 'die', 'ik', 'z@@', 'al', 'je', 'l@@', 'aten', 'zien', 'wat', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-29 23:51:50,775 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:51:50,776 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:51:50,776 - INFO - joeynmt.training - 	Hypothesis: De volgende folie, die ik zal je laten zien wat in de laatste 25 jaar in de laatste 25 jaar gebeurd.
2025-05-29 23:51:59,769 - INFO - joeynmt.training - Epoch   2, Step:    17100, Batch Loss:     1.538382, Batch Acc: 0.505495, Tokens per Sec:     7598, Lr: 0.000300
2025-05-29 23:52:08,739 - INFO - joeynmt.training - Epoch   2, Step:    17200, Batch Loss:     1.506525, Batch Acc: 0.496284, Tokens per Sec:     8028, Lr: 0.000300
2025-05-29 23:52:16,957 - INFO - joeynmt.training - Epoch   2, Step:    17300, Batch Loss:     1.567560, Batch Acc: 0.504455, Tokens per Sec:     8837, Lr: 0.000300
2025-05-29 23:52:25,175 - INFO - joeynmt.training - Epoch   2, Step:    17400, Batch Loss:     1.624939, Batch Acc: 0.505387, Tokens per Sec:     9069, Lr: 0.000300
2025-05-29 23:52:33,272 - INFO - joeynmt.training - Epoch   2, Step:    17500, Batch Loss:     1.549877, Batch Acc: 0.507897, Tokens per Sec:     9018, Lr: 0.000300
2025-05-29 23:52:33,272 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:52:33,273 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:53:26,543 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.18, acc:   0.49, generation: 53.2231[sec], evaluation: 0.0000[sec]
2025-05-29 23:53:26,544 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:53:26,718 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/15000.ckpt
2025-05-29 23:53:26,736 - INFO - joeynmt.training - Example #0
2025-05-29 23:53:26,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:53:26,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:53:26,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'k@@', 'ijk@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 's', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'j@@', 'ar@@', 'en', 'jaar', 'die', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd@@', 'den', 'ge@@', 'be@@', 'ur@@', 'de', 'van', '4@@', '8', 'st@@', 'aat', 'ha@@', 'd', 'ge@@', 'be@@', 'ur@@', 'de', 'v@@', 'el@@', 'e', '4@@', '8', 'st@@', 'aa@@', 't.', '</s>']
2025-05-29 23:53:26,738 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:53:26,738 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:53:26,738 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb ik deze twee folië gegetoond om te kijken, dat de artische ijskappels die voor de grootte van de jaren jaar die 48 staten hadden gebeurde van 48 staat had gebeurde vele 48 staat.
2025-05-29 23:53:26,739 - INFO - joeynmt.training - Example #1
2025-05-29 23:53:26,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:53:26,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:53:26,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'pro@@', 'ble@@', 'em', 'van', 'de', 'e@@', 's@@', 'm@@', 'id@@', 'del@@', 'en', 'van', 'de', 'e@@', 'is@@', 'es', 'van', 'de', 'e@@', 's@@', 'n@@', 'el@@', 'heid', 'van', 'de', 'e@@', 's@@', 'i@@', 'ë@@', 'l@@', 'e', 'pro@@', 'ble@@', 'em', 'van', 'de', 'e@@', 's@@', 'm@@', 'id@@', 'del@@', 'en', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'd@@', 'ru@@', 'k@@', 't.', '</s>']
2025-05-29 23:53:26,747 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:53:26,747 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:53:26,747 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de aarde van dit speciale probleem van dit speciale probleem dat het niet de dicke probleem van de esmiddelen van de eises van de esnelheid van de esiële probleem van de esmiddelen van dit speciale probleem van dit speciale probleem van dit speciale probleem dat het niet de drukt.
2025-05-29 23:53:26,748 - INFO - joeynmt.training - Example #2
2025-05-29 23:53:26,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:53:26,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:53:26,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'c@@', 'a@@', 'p', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'en', 'dat', 'het', 's@@', 'la@@', 'g', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-29 23:53:26,749 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:53:26,749 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:53:26,749 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de articap is de artische en dat het slag van onze wereldwijde klimaatsysteem.
2025-05-29 23:53:26,750 - INFO - joeynmt.training - Example #3
2025-05-29 23:53:26,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:53:26,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:53:26,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'k@@', 'wa@@', 'm', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'k@@', 'ra@@', 'cht', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't.', '</s>']
2025-05-29 23:53:26,755 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:53:26,755 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:53:26,755 - INFO - joeynmt.training - 	Hypothesis: Ze kwam in de winter en scheppt in de zomer en scheppt in de winter en de kracht in de winter en scheppt.
2025-05-29 23:53:26,755 - INFO - joeynmt.training - Example #4
2025-05-29 23:53:26,756 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:53:26,756 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:53:26,756 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie,', 'die', 'ik', 'l@@', 'aten', 'zien', 'dat', 'ik', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-29 23:53:26,756 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:53:26,757 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:53:26,757 - INFO - joeynmt.training - 	Hypothesis: De volgende folie, die ik laten zien dat ik een tijdperk van wat er in de laatste 25 jaar gebeurt.
2025-05-29 23:53:35,597 - INFO - joeynmt.training - Epoch   2, Step:    17600, Batch Loss:     1.589036, Batch Acc: 0.506253, Tokens per Sec:     7782, Lr: 0.000300
2025-05-29 23:53:44,643 - INFO - joeynmt.training - Epoch   2, Step:    17700, Batch Loss:     1.761188, Batch Acc: 0.495898, Tokens per Sec:     8019, Lr: 0.000300
2025-05-29 23:53:52,953 - INFO - joeynmt.training - Epoch   2, Step:    17800, Batch Loss:     1.634606, Batch Acc: 0.499210, Tokens per Sec:     8381, Lr: 0.000300
2025-05-29 23:54:01,018 - INFO - joeynmt.training - Epoch   2, Step:    17900, Batch Loss:     1.582250, Batch Acc: 0.507204, Tokens per Sec:     9260, Lr: 0.000300
2025-05-29 23:54:09,007 - INFO - joeynmt.training - Epoch   2, Step:    18000, Batch Loss:     1.427563, Batch Acc: 0.504809, Tokens per Sec:     9111, Lr: 0.000300
2025-05-29 23:54:09,007 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:54:09,007 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:54:52,971 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.15, acc:   0.49, generation: 43.9213[sec], evaluation: 0.0000[sec]
2025-05-29 23:54:52,972 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:54:53,142 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/15500.ckpt
2025-05-29 23:54:53,159 - INFO - joeynmt.training - Example #0
2025-05-29 23:54:53,160 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:54:53,160 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:54:53,160 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 's', 'die', 'voor', 'de', 'wer@@', 'k@@', 'ne@@', 'mer@@', 's', 'die', 'voor', 'on@@', 'der', 'de', 'gro@@', 'ot@@', 'ste', '4@@', '8', 'st@@', 'aten', 'hebben', 'ge@@', 'be@@', 'ur@@', 'de', 'van', 'de', 'V@@', 'S', '4@@', '8', 'st@@', 'aat', 'ge@@', 'be@@', 'ur@@', 'de', 'van', 'de', 'V@@', 'S', 'en', '4@@', '8', 'st@@', 'aat', 'is.', '</s>']
2025-05-29 23:54:53,161 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:54:53,161 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:54:53,162 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folië getoond om te bekijken dat de artische ijskappels die voor de werknemers die voor onder de grootste 48 staten hebben gebeurde van de VS 48 staat gebeurde van de VS en 48 staat is.
2025-05-29 23:54:53,162 - INFO - joeynmt.training - Example #1
2025-05-29 23:54:53,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:54:53,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:54:53,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'st@@', 'ar@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 're@@', 'c@@', 'ies', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', ',', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', '.', '</s>']
2025-05-29 23:54:53,163 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:54:53,163 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:54:53,164 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet stark genoeg de precies van dit specifieke probleem dat het niet de dick, dat het niet de dick.
2025-05-29 23:54:53,164 - INFO - joeynmt.training - Example #2
2025-05-29 23:54:53,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:54:53,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:54:53,164 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'e', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-29 23:54:53,165 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:54:53,166 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:54:53,166 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape Eiskape van onze wereldwijde klimaatsysteem.
2025-05-29 23:54:53,166 - INFO - joeynmt.training - Example #3
2025-05-29 23:54:53,166 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:54:53,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:54:53,166 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 23:54:53,167 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:54:53,167 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:54:53,167 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en scheppt in het zomers.
2025-05-29 23:54:53,167 - INFO - joeynmt.training - Example #4
2025-05-29 23:54:53,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:54:53,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:54:53,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie,', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-29 23:54:53,168 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:54:53,169 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:54:53,169 - INFO - joeynmt.training - 	Hypothesis: De volgende folie, die ik jullie laten zien is een tijdperk in de laatste 25 jaar gebeurd is.
2025-05-29 23:55:02,361 - INFO - joeynmt.training - Epoch   2, Step:    18100, Batch Loss:     1.431161, Batch Acc: 0.509648, Tokens per Sec:     7616, Lr: 0.000300
2025-05-29 23:55:11,621 - INFO - joeynmt.training - Epoch   2, Step:    18200, Batch Loss:     1.467519, Batch Acc: 0.507507, Tokens per Sec:     7798, Lr: 0.000300
2025-05-29 23:55:20,773 - INFO - joeynmt.training - Epoch   2, Step:    18300, Batch Loss:     1.426425, Batch Acc: 0.506862, Tokens per Sec:     7740, Lr: 0.000300
2025-05-29 23:55:29,777 - INFO - joeynmt.training - Epoch   2, Step:    18400, Batch Loss:     1.531915, Batch Acc: 0.507002, Tokens per Sec:     7804, Lr: 0.000300
2025-05-29 23:55:38,966 - INFO - joeynmt.training - Epoch   2, Step:    18500, Batch Loss:     1.541807, Batch Acc: 0.502118, Tokens per Sec:     7656, Lr: 0.000300
2025-05-29 23:55:38,968 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:55:38,968 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:56:38,958 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.15, acc:   0.49, generation: 59.9425[sec], evaluation: 0.0000[sec]
2025-05-29 23:56:38,959 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:56:39,127 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/16000.ckpt
2025-05-29 23:56:39,143 - INFO - joeynmt.training - Example #0
2025-05-29 23:56:39,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:56:39,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:56:39,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'voor', 'de', 'onder@@', 'en', '4@@', '8', 'u@@', 'ur', 'van', 'de', 'on@@', 'der', '4@@', '8', 'u@@', 'ur', 'van', 'de', 'on@@', 'der', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'be@@', 'ur@@', 'de', 'on@@', 'der', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'on@@', 'der', '4@@', '8', 'st@@', 'aten', 'is.', '</s>']
2025-05-29 23:56:39,145 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:56:39,145 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:56:39,145 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folië getoond om te verkijken dat de artische ijskappe, die voor de onderen 48 uur van de onder 48 uur van de onder 48 staten had gebeurde onder 40 procent van 40 procent van de onder 48 staten is.
2025-05-29 23:56:39,146 - INFO - joeynmt.training - Example #1
2025-05-29 23:56:39,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:56:39,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:56:39,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 're@@', 's@@', 'ul@@', 't@@', 'aat', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'het', 'ij@@', 's@@', 'be@@', 'te@@', 'ken@@', 't', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'ij@@', 's@@', 'be@@', 'te@@', 'ken@@', 't', 'het', 'niet', 'de', 'd@@', 'ie@@', 'p@@', 'er', 'van', 'het', 'ij@@', 's@@', 'be@@', 'te@@', 'ken@@', 'is', 'van', 'het', 'ij@@', 's@@', 'be@@', 'we@@', 'e@@', 'st@@', '.', '</s>']
2025-05-29 23:56:39,147 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:56:39,147 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:56:39,147 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de eerste presultaat van dit speciale probleem van het ijsbetekent het niet de dicke van het ijsbetekent het niet de dieper van het ijsbetekenis van het ijsbeweest.
2025-05-29 23:56:39,147 - INFO - joeynmt.training - Example #2
2025-05-29 23:56:39,148 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:56:39,148 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:56:39,148 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'E@@', 'is@@', 'c@@', 'ap@@', 'p@@', 'e', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em', 'is.', '</s>']
2025-05-29 23:56:39,149 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:56:39,149 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:56:39,149 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische Eiscappe van onze wereldwijde klimaatsysteem van onze wereldwijde klimaatsysteem is.
2025-05-29 23:56:39,149 - INFO - joeynmt.training - Example #3
2025-05-29 23:56:39,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:56:39,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:56:39,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'en.', '</s>']
2025-05-29 23:56:39,151 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:56:39,151 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:56:39,151 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppt in de winter en de winter en de winter en de winter en de winter en scheppt in de winter en de winter en de winter en de winter en de winter en de winter en de winter en de winter en de winter en de winter en de winter en de winter en de winter en de winter en de winter en schepen.
2025-05-29 23:56:39,151 - INFO - joeynmt.training - Example #4
2025-05-29 23:56:39,151 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:56:39,151 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:56:39,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie,', 'is', 'een', 'tij@@', 'd@@', 's@@', 'k@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-29 23:56:39,152 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:56:39,152 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:56:39,153 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende folie, is een tijdskopen 25 jaar gebeurde in de laatste 25 jaar gebeurd.
2025-05-29 23:56:47,248 - INFO - joeynmt.training - Epoch   2, Step:    18600, Batch Loss:     1.502074, Batch Acc: 0.510840, Tokens per Sec:     8943, Lr: 0.000300
2025-05-29 23:56:55,075 - INFO - joeynmt.training - Epoch   2, Step:    18700, Batch Loss:     1.638507, Batch Acc: 0.508127, Tokens per Sec:     9101, Lr: 0.000300
2025-05-29 23:57:02,490 - INFO - joeynmt.training - Epoch   2, Step:    18800, Batch Loss:     1.770298, Batch Acc: 0.510020, Tokens per Sec:     9860, Lr: 0.000300
2025-05-29 23:57:09,981 - INFO - joeynmt.training - Epoch   2, Step:    18900, Batch Loss:     1.721341, Batch Acc: 0.515828, Tokens per Sec:     9845, Lr: 0.000300
2025-05-29 23:57:17,780 - INFO - joeynmt.training - Epoch   2, Step:    19000, Batch Loss:     1.967752, Batch Acc: 0.507784, Tokens per Sec:     9416, Lr: 0.000300
2025-05-29 23:57:17,780 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:57:17,780 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:58:05,071 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.49, generation: 47.2418[sec], evaluation: 0.0000[sec]
2025-05-29 23:58:05,072 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:58:05,335 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/16500.ckpt
2025-05-29 23:58:05,349 - INFO - joeynmt.training - Example #0
2025-05-29 23:58:05,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:58:05,350 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:58:05,350 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'to@@', 'on@@', 'de', 'twe@@', 'e', 'ke@@', 'er', 'to@@', 'on@@', 'de', 'ge@@', 've@@', 'er', 'to@@', 'on@@', 'de', 'ge@@', 've@@', 'er', 'van', 'de', 'ar@@', 'ti@@', 'c@@', 'a@@', ',', 'dat', 'de', 'ar@@', 'ti@@', 'c@@', 'ul@@', 't@@', 'aten', 'die', 'voor', 'de', 'eer@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'V@@', 'S', 'die', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'V@@', 'S', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'V@@', 'S', 'is.', '</s>']
2025-05-29 23:58:05,351 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:58:05,352 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:58:05,352 - INFO - joeynmt.training - 	Hypothesis: Ik toonde twee keer toonde geveer toonde geveer van de artica, dat de articultaten die voor de eerste 40 procent van de VS die de grootte van de VS 40 procent van 40 procent van 40 procent gebeurde van 40 procent van de VS is.
2025-05-29 23:58:05,352 - INFO - joeynmt.training - Example #1
2025-05-29 23:58:05,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:58:05,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:58:05,353 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'd@@', 'ige', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'het', 'ij@@', 's@@', 'be@@', 'st@@', 'on@@', 'd', 'van', 'het', 'ij@@', 's@@', 'be@@', 'st@@', 'on@@', 'd.', '</s>']
2025-05-29 23:58:05,353 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:58:05,354 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:58:05,354 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de aardige probleem van dit speciale probleem van het ijsbestond van het ijsbestond.
2025-05-29 23:58:05,354 - INFO - joeynmt.training - Example #2
2025-05-29 23:58:05,354 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:58:05,354 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:58:05,354 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'et@@', 'ensch@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'is', 'de', 'ar@@', 'ti@@', 'c@@', 'a@@', 'p', 'het', 's@@', 'la@@', 'g', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-29 23:58:05,355 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:58:05,355 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:58:05,356 - INFO - joeynmt.training - 	Hypothesis: In wetenschappelijke ijskape is de articap het slag van onze wereldwijde klimaatsysteem.
2025-05-29 23:58:05,356 - INFO - joeynmt.training - Example #3
2025-05-29 23:58:05,356 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:58:05,356 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:58:05,356 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 23:58:05,357 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:58:05,357 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:58:05,357 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schept in de zomers.
2025-05-29 23:58:05,357 - INFO - joeynmt.training - Example #4
2025-05-29 23:58:05,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:58:05,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:58:05,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'dat', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-29 23:58:05,359 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:58:05,359 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:58:05,359 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien dat ik jullie laten zien wat er in de laatste 25 jaar gebeurt in de laatste 25 jaar gebeurd.
2025-05-29 23:58:14,398 - INFO - joeynmt.training - Epoch   2, Step:    19100, Batch Loss:     1.422322, Batch Acc: 0.505486, Tokens per Sec:     7534, Lr: 0.000300
2025-05-29 23:58:24,388 - INFO - joeynmt.training - Epoch   2, Step:    19200, Batch Loss:     1.519755, Batch Acc: 0.508270, Tokens per Sec:     6991, Lr: 0.000300
2025-05-29 23:58:34,169 - INFO - joeynmt.training - Epoch   2, Step:    19300, Batch Loss:     1.625007, Batch Acc: 0.500931, Tokens per Sec:     7413, Lr: 0.000300
2025-05-29 23:58:43,509 - INFO - joeynmt.training - Epoch   2, Step:    19400, Batch Loss:     1.688125, Batch Acc: 0.508449, Tokens per Sec:     7805, Lr: 0.000300
2025-05-29 23:58:54,390 - INFO - joeynmt.training - Epoch   2, Step:    19500, Batch Loss:     1.803046, Batch Acc: 0.514737, Tokens per Sec:     6664, Lr: 0.000300
2025-05-29 23:58:54,392 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-29 23:58:54,392 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 23:59:43,800 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.05, acc:   0.49, generation: 49.3639[sec], evaluation: 0.0000[sec]
2025-05-29 23:59:43,801 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 23:59:43,978 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/17000.ckpt
2025-05-29 23:59:43,988 - INFO - joeynmt.training - Example #0
2025-05-29 23:59:43,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-29 23:59:43,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-29 23:59:43,990 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 't@@', 'ellen', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '8@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'ha@@', 'd', 'ge@@', 'ï@@', 'n@@', 'v@@', 'l@@', 'oe@@', 'd', 'is.', '</s>']
2025-05-29 23:59:43,991 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 23:59:43,991 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-29 23:59:43,991 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb ik deze twee getoond om te vertellen dat de artische ijskappen, die voor de artische ijskappen, die voor de grootte van de grootte van 40 procent van 480 procent van 40 procent geslagen had geïnvloed is.
2025-05-29 23:59:43,991 - INFO - joeynmt.training - Example #1
2025-05-29 23:59:43,992 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-29 23:59:43,992 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-29 23:59:43,992 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'de', 'is', 'het', 'p@@', 'un@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'pro@@', 'ble@@', 'em', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-29 23:59:43,993 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 23:59:43,993 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-29 23:59:43,993 - INFO - joeynmt.training - 	Hypothesis: Maar dit specifiek genoeg de aarde de is het punt van dit speciale probleem dat het niet de dicke probleem laat zien.
2025-05-29 23:59:43,993 - INFO - joeynmt.training - Example #2
2025-05-29 23:59:43,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-29 23:59:43,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-29 23:59:43,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-29 23:59:43,995 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 23:59:43,995 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-29 23:59:43,995 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe hart van onze wereldwijde klimaatsysteem.
2025-05-29 23:59:43,995 - INFO - joeynmt.training - Example #3
2025-05-29 23:59:43,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-29 23:59:43,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-29 23:59:43,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', 'z@@', 'om@@', 'er', 'in', 'het', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-29 23:59:43,996 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 23:59:43,997 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-29 23:59:43,997 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schept in de zomer zomer in het zomer in de zomers.
2025-05-29 23:59:43,997 - INFO - joeynmt.training - Example #4
2025-05-29 23:59:43,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-29 23:59:43,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-29 23:59:43,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie,', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'gen', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-29 23:59:43,998 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 23:59:43,998 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-29 23:59:43,998 - INFO - joeynmt.training - 	Hypothesis: De volgende folie, die ik laat zien is een tijdragen wat er in de laatste 25 jaar gebeurd.
2025-05-29 23:59:52,621 - INFO - joeynmt.training - Epoch   2, Step:    19600, Batch Loss:     1.686799, Batch Acc: 0.510869, Tokens per Sec:     8131, Lr: 0.000300
2025-05-30 00:00:01,081 - INFO - joeynmt.training - Epoch   2, Step:    19700, Batch Loss:     1.531354, Batch Acc: 0.520630, Tokens per Sec:     8367, Lr: 0.000300
2025-05-30 00:00:09,395 - INFO - joeynmt.training - Epoch   2, Step:    19800, Batch Loss:     1.580810, Batch Acc: 0.508807, Tokens per Sec:     8631, Lr: 0.000300
2025-05-30 00:00:18,143 - INFO - joeynmt.training - Epoch   2, Step:    19900, Batch Loss:     1.663536, Batch Acc: 0.509651, Tokens per Sec:     8160, Lr: 0.000300
2025-05-30 00:00:27,126 - INFO - joeynmt.training - Epoch   2, Step:    20000, Batch Loss:     1.503899, Batch Acc: 0.515360, Tokens per Sec:     8136, Lr: 0.000300
2025-05-30 00:00:27,127 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:00:27,127 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:01:12,471 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.03, acc:   0.49, generation: 45.3047[sec], evaluation: 0.0000[sec]
2025-05-30 00:01:12,472 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:01:12,646 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/17500.ckpt
2025-05-30 00:01:12,654 - INFO - joeynmt.training - Example #0
2025-05-30 00:01:12,655 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:01:12,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:01:12,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 't@@', 'on@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'on@@', 'ge@@', 've@@', 'er', '4@@', '8', 'st@@', 'aat', 'ge@@', 's@@', 'm@@', 'p@@', 'el@@', 'de', 'van', '4@@', '8@@', '4@@', '%', 'van', '4@@', '8', 'st@@', 'aat', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:01:12,657 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:01:12,657 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:01:12,657 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb ik deze twee getoond om te vertonen dat de artische ijskappen, die voor de artische ijskappen, die voor ongeveer 48 staat gesmpelde van 484% van 48 staat gebeurd.
2025-05-30 00:01:12,657 - INFO - joeynmt.training - Example #1
2025-05-30 00:01:12,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:01:12,658 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:01:12,658 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 're@@', 'c@@', 'ies', 'van', 'het', 'ij@@', 's@@', 'le@@', 'ch@@', 'ts', 'dat', 'het', 'niet', 'de', 'd@@', 'ru@@', 'k', 'van', 'het', 'ij@@', 's@@', 'be@@', 'st@@', 'on@@', 'd.', '</s>']
2025-05-30 00:01:12,659 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:01:12,659 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:01:12,659 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de precies van het ijslechts dat het niet de druk van het ijsbestond.
2025-05-30 00:01:12,659 - INFO - joeynmt.training - Example #2
2025-05-30 00:01:12,659 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:01:12,659 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:01:12,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'nen', 'is', 'de', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:01:12,660 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:01:12,661 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:01:12,661 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijnen is de slagen van onze wereldwijde klimaatsysteem.
2025-05-30 00:01:12,661 - INFO - joeynmt.training - Example #3
2025-05-30 00:01:12,661 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:01:12,661 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:01:12,661 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:01:12,662 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:01:12,662 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:01:12,662 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in het winter en schept in het zomers.
2025-05-30 00:01:12,663 - INFO - joeynmt.training - Example #4
2025-05-30 00:01:12,663 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:01:12,663 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:01:12,663 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 't@@', '-@@', 'j@@', 'ar@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:01:12,664 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:01:12,664 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:01:12,664 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende gevolg is een tijdrapport-jaren 25 jaar gebeurd.
2025-05-30 00:01:20,573 - INFO - joeynmt.training - Epoch   2, Step:    20100, Batch Loss:     1.509205, Batch Acc: 0.509315, Tokens per Sec:     8932, Lr: 0.000300
2025-05-30 00:01:28,889 - INFO - joeynmt.training - Epoch   2, Step:    20200, Batch Loss:     1.492463, Batch Acc: 0.516347, Tokens per Sec:     8800, Lr: 0.000300
2025-05-30 00:01:37,274 - INFO - joeynmt.training - Epoch   2, Step:    20300, Batch Loss:     1.470692, Batch Acc: 0.512203, Tokens per Sec:     8431, Lr: 0.000300
2025-05-30 00:01:45,725 - INFO - joeynmt.training - Epoch   2, Step:    20400, Batch Loss:     1.430250, Batch Acc: 0.507361, Tokens per Sec:     8439, Lr: 0.000300
2025-05-30 00:01:53,992 - INFO - joeynmt.training - Epoch   2, Step:    20500, Batch Loss:     1.491051, Batch Acc: 0.509252, Tokens per Sec:     8317, Lr: 0.000300
2025-05-30 00:01:53,993 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:01:53,993 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:02:46,079 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.02, acc:   0.49, generation: 52.0370[sec], evaluation: 0.0000[sec]
2025-05-30 00:02:46,081 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:02:46,238 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/18000.ckpt
2025-05-30 00:02:46,253 - INFO - joeynmt.training - Example #0
2025-05-30 00:02:46,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:02:46,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:02:46,254 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'l@@', 'aten', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'ar@@', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'st@@', 'at@@', 'ten', 'ge@@', 'be@@', 'ur@@', 'de', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:02:46,255 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:02:46,255 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:02:46,256 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folië laten zien dat de arctische ijskapen die ararctische ijskapen die voor de grootte van de grootte van de grootte van 40 statten gebeurde er gebeurd is.
2025-05-30 00:02:46,256 - INFO - joeynmt.training - Example #1
2025-05-30 00:02:46,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:02:46,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:02:46,256 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 'd@@', 'ru@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'st@@', 'h@@', 'aa@@', 'p@@', 'ig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'ij@@', 's@@', 'ge@@', 'be@@', 'ur@@', 't', 'van', 'het', 'ij@@', 's@@', 'ge@@', 'be@@', 'ur@@', 't', 'van', 'het', 'ij@@', 's@@', 'le@@', 'ch@@', 't.', '</s>']
2025-05-30 00:02:46,258 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:02:46,258 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:02:46,258 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de druk genoeg de eerste sthaapigheid van dit speciale probleem dat het niet de dicke van het ijsgebeurt van het ijsgebeurt van het ijslecht.
2025-05-30 00:02:46,258 - INFO - joeynmt.training - Example #2
2025-05-30 00:02:46,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:02:46,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:02:46,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:02:46,260 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:02:46,260 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:02:46,260 - INFO - joeynmt.training - 	Hypothesis: In zekere zin de artische ijskape ijs het slagen van onze wereldwijde klimaatsysteem.
2025-05-30 00:02:46,260 - INFO - joeynmt.training - Example #3
2025-05-30 00:02:46,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:02:46,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:02:46,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:02:46,262 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:02:46,262 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:02:46,262 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zomers.
2025-05-30 00:02:46,262 - INFO - joeynmt.training - Example #4
2025-05-30 00:02:46,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:02:46,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:02:46,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g@@', 'd', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'gen', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:02:46,263 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:02:46,264 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:02:46,264 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende gevolgd is een tijdragen wat er in de laatste 25 jaar gebeurd is.
2025-05-30 00:02:55,188 - INFO - joeynmt.training - Epoch   2, Step:    20600, Batch Loss:     1.492858, Batch Acc: 0.513567, Tokens per Sec:     7940, Lr: 0.000300
2025-05-30 00:03:04,127 - INFO - joeynmt.training - Epoch   2, Step:    20700, Batch Loss:     1.584900, Batch Acc: 0.513703, Tokens per Sec:     8038, Lr: 0.000300
2025-05-30 00:03:13,086 - INFO - joeynmt.training - Epoch   2, Step:    20800, Batch Loss:     1.505849, Batch Acc: 0.517774, Tokens per Sec:     8023, Lr: 0.000300
2025-05-30 00:03:22,333 - INFO - joeynmt.training - Epoch   2, Step:    20900, Batch Loss:     1.358823, Batch Acc: 0.514607, Tokens per Sec:     7900, Lr: 0.000300
2025-05-30 00:03:31,246 - INFO - joeynmt.training - Epoch   2, Step:    21000, Batch Loss:     1.524898, Batch Acc: 0.513913, Tokens per Sec:     8249, Lr: 0.000300
2025-05-30 00:03:31,247 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:03:31,247 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:04:24,024 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   4.98, acc:   0.50, generation: 52.7249[sec], evaluation: 0.0000[sec]
2025-05-30 00:04:24,024 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:04:24,181 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/18500.ckpt
2025-05-30 00:04:24,188 - INFO - joeynmt.training - Example #0
2025-05-30 00:04:24,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:04:24,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:04:24,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'ies', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 't@@', 'on@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:04:24,190 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:04:24,190 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:04:24,190 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb ik deze twee folies getoond om te vertonen dat de artische ijskappen die voor de grootte van de grootte van de grootte van de grootte van de grootte van 40 procent gebeurd is.
2025-05-30 00:04:24,190 - INFO - joeynmt.training - Example #1
2025-05-30 00:04:24,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:04:24,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:04:24,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'ver@@', 'st@@', 'ar@@', 'd', 'gen@@', 'oe@@', 'g', 'de', 'di@@', 'k@@', ',', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'de', 'di@@', 'ck@@', '-@@', 'di@@', 'ck@@', 'e', 'van', 'de', 'ij@@', 's@@', 'ge@@', 'st@@', 'el@@', 'd.', '</s>']
2025-05-30 00:04:24,191 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:04:24,192 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:04:24,192 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de verstard genoeg de dik, dat het speciale probleem niet de dicke van de dick-dicke van de ijsgesteld.
2025-05-30 00:04:24,192 - INFO - joeynmt.training - Example #2
2025-05-30 00:04:24,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:04:24,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:04:24,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's', 'ij@@', 's', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:04:24,193 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:04:24,193 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:04:24,193 - INFO - joeynmt.training - 	Hypothesis: In zekere ijskape ijs ijs is de artische ijskape van onze wereldwijde klimaatsysteem.
2025-05-30 00:04:24,194 - INFO - joeynmt.training - Example #3
2025-05-30 00:04:24,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:04:24,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:04:24,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:04:24,195 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:04:24,195 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:04:24,195 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schept in het zomers.
2025-05-30 00:04:24,195 - INFO - joeynmt.training - Example #4
2025-05-30 00:04:24,196 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:04:24,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:04:24,196 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie,', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-30 00:04:24,197 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:04:24,197 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:04:24,197 - INFO - joeynmt.training - 	Hypothesis: De volgende folie, die ik jullie laat zien wat er gebeurde in de afgelopen 25 jaar gebeurt.
2025-05-30 00:04:32,863 - INFO - joeynmt.training - Epoch   2, Step:    21100, Batch Loss:     1.595074, Batch Acc: 0.514507, Tokens per Sec:     8169, Lr: 0.000300
2025-05-30 00:04:40,337 - INFO - joeynmt.training - Epoch   2: total training loss 17055.67
2025-05-30 00:04:40,337 - INFO - joeynmt.training - EPOCH 3
2025-05-30 00:04:41,598 - INFO - joeynmt.training - Epoch   3, Step:    21200, Batch Loss:     1.255901, Batch Acc: 0.530443, Tokens per Sec:     7923, Lr: 0.000300
2025-05-30 00:04:50,095 - INFO - joeynmt.training - Epoch   3, Step:    21300, Batch Loss:     1.495196, Batch Acc: 0.526660, Tokens per Sec:     8428, Lr: 0.000300
2025-05-30 00:04:58,534 - INFO - joeynmt.training - Epoch   3, Step:    21400, Batch Loss:     1.476775, Batch Acc: 0.524056, Tokens per Sec:     8488, Lr: 0.000300
2025-05-30 00:05:07,001 - INFO - joeynmt.training - Epoch   3, Step:    21500, Batch Loss:     1.394660, Batch Acc: 0.525560, Tokens per Sec:     8426, Lr: 0.000300
2025-05-30 00:05:07,002 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:05:07,002 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:05:52,493 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.00, acc:   0.50, generation: 45.4421[sec], evaluation: 0.0000[sec]
2025-05-30 00:05:52,655 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/19000.ckpt
2025-05-30 00:05:52,669 - INFO - joeynmt.training - Example #0
2025-05-30 00:05:52,670 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:05:52,670 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:05:52,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'aten', 'aten', 'zien', 'dat', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 't@@', 'on@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'c@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd@@', 'den', '4@@', '8', 'st@@', 'aat', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 00:05:52,671 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:05:52,672 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:05:52,672 - INFO - joeynmt.training - 	Hypothesis: Laten aten zien dat ik deze twee getoond om te vertonen dat de artische ijskappen, die voor de articappen, die voor de grootte van de 40 procent van 48 staten hadden 48 staat gebeuren.
2025-05-30 00:05:52,672 - INFO - joeynmt.training - Example #1
2025-05-30 00:05:52,672 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:05:52,673 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:05:52,673 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'spe@@', 'ci@@', 'ale', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'ij@@', 's@@', 'be@@', 'st@@', 'aat', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'de', 'ij@@', 's@@', 'ge@@', 'be@@', 'ur@@', 't', 'van', 'de', 'ij@@', 's@@', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-30 00:05:52,674 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:05:52,674 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:05:52,674 - INFO - joeynmt.training - 	Hypothesis: Maar dit speciale niet sterk genoeg de eerste van het ijsbestaat van dit speciale probleem van de ijsgebeurt van de ijsgebeurt.
2025-05-30 00:05:52,674 - INFO - joeynmt.training - Example #2
2025-05-30 00:05:52,674 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:05:52,675 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:05:52,675 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 's@@', 'la@@', 'g', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:05:52,676 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:05:52,677 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:05:52,677 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape het slag van onze wereldwijde klimaatsysteem.
2025-05-30 00:05:52,677 - INFO - joeynmt.training - Example #3
2025-05-30 00:05:52,677 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:05:52,677 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:05:52,677 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:05:52,678 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:05:52,678 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:05:52,679 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomers en zomers.
2025-05-30 00:05:52,679 - INFO - joeynmt.training - Example #4
2025-05-30 00:05:52,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:05:52,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:05:52,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g', 'is', 'een', 'tijd', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:05:52,680 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:05:52,681 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:05:52,681 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende gevolg is een tijd van de laatste 25 jaar gebeurt in de laatste 25 jaar gebeurd.
2025-05-30 00:06:01,390 - INFO - joeynmt.training - Epoch   3, Step:    21600, Batch Loss:     1.665444, Batch Acc: 0.525878, Tokens per Sec:     8099, Lr: 0.000300
2025-05-30 00:06:10,467 - INFO - joeynmt.training - Epoch   3, Step:    21700, Batch Loss:     1.429511, Batch Acc: 0.527957, Tokens per Sec:     8021, Lr: 0.000300
2025-05-30 00:06:19,647 - INFO - joeynmt.training - Epoch   3, Step:    21800, Batch Loss:     1.467939, Batch Acc: 0.525275, Tokens per Sec:     7798, Lr: 0.000300
2025-05-30 00:06:29,019 - INFO - joeynmt.training - Epoch   3, Step:    21900, Batch Loss:     1.664474, Batch Acc: 0.520427, Tokens per Sec:     7700, Lr: 0.000300
2025-05-30 00:06:37,947 - INFO - joeynmt.training - Epoch   3, Step:    22000, Batch Loss:     1.416966, Batch Acc: 0.520823, Tokens per Sec:     8144, Lr: 0.000300
2025-05-30 00:06:37,947 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:06:37,947 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:07:23,863 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.95, acc:   0.50, generation: 45.8760[sec], evaluation: 0.0000[sec]
2025-05-30 00:07:23,865 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:07:24,035 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/19500.ckpt
2025-05-30 00:07:24,055 - INFO - joeynmt.training - Example #0
2025-05-30 00:07:24,055 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:07:24,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:07:24,056 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'vol@@', 'gen@@', 's', 'van', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'be@@', 'ur@@', 'de', 'er', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-30 00:07:24,057 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:07:24,058 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:07:24,058 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde volgens van de artische ijskappe, die artische ijskappe, die voor de grootte van 48 staten van 48 staten had 48 staten had 48 staten had gebeurde er 40 procent gebeurt.
2025-05-30 00:07:24,058 - INFO - joeynmt.training - Example #1
2025-05-30 00:07:24,058 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:07:24,058 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:07:24,058 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 're@@', 's@@', 'ul@@', 't@@', 'aat', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'er', 'niet', 'de', 'di@@', 'k@@', 'er', 'niet', 'de', 'di@@', 'k@@', 'er', 'van', 'de', 'ij@@', 's@@', 'le@@', 'ch@@', 'ts', 'van', 'de', 'ij@@', 's@@', 'ge@@', 'vol@@', 'g', 'van', 'de', 'ij@@', 's@@', 'le@@', 'ch@@', 'ts', 'van', 'het', 'ij@@', 's@@', 'ge@@', 'vo@@', 'el@@', 'd.', '</s>']
2025-05-30 00:07:24,059 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:07:24,060 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:07:24,060 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de resultaat van dit speciale probleem dat het niet de diker niet de diker niet de diker van de ijslechts van de ijsgevolg van de ijslechts van het ijsgevoeld.
2025-05-30 00:07:24,060 - INFO - joeynmt.training - Example #2
2025-05-30 00:07:24,060 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:07:24,060 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:07:24,060 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'wer@@', 'k@@', 'ne@@', 'em@@', 't', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'z@@', 'ich', 's@@', 'le@@', 'ch@@', 'ts', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'z@@', 'en.', '</s>']
2025-05-30 00:07:24,061 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:07:24,061 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:07:24,062 - INFO - joeynmt.training - 	Hypothesis: In zekere zin het werkneemt de artische ijskape zich slechts van onze wereldwijzen.
2025-05-30 00:07:24,062 - INFO - joeynmt.training - Example #3
2025-05-30 00:07:24,062 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:07:24,062 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:07:24,062 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'g@@', 'aat', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 's@@', 'la@@', 'p@@', 'p@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:07:24,064 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:07:24,064 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:07:24,064 - INFO - joeynmt.training - 	Hypothesis: Ze gaat in de winter en slapppt in de zomers.
2025-05-30 00:07:24,064 - INFO - joeynmt.training - Example #4
2025-05-30 00:07:24,065 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:07:24,065 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:07:24,065 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'vol@@', 'gen@@', 'de', 'vol@@', 'gen@@', 'de', 'vol@@', 'gen@@', 'de', '2@@', '5', 'jaar', 'is', 'een', 'p@@', 'aar', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:07:24,066 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:07:24,066 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:07:24,066 - INFO - joeynmt.training - 	Hypothesis: De volgende volgende volgende volgende 25 jaar is een paar 25 jaar gebeurt in de laatste 25 jaar gebeurd.
2025-05-30 00:07:33,043 - INFO - joeynmt.training - Epoch   3, Step:    22100, Batch Loss:     1.576264, Batch Acc: 0.533426, Tokens per Sec:     7826, Lr: 0.000300
2025-05-30 00:07:42,016 - INFO - joeynmt.training - Epoch   3, Step:    22200, Batch Loss:     1.632349, Batch Acc: 0.519073, Tokens per Sec:     7871, Lr: 0.000300
2025-05-30 00:07:50,890 - INFO - joeynmt.training - Epoch   3, Step:    22300, Batch Loss:     1.378155, Batch Acc: 0.525063, Tokens per Sec:     7991, Lr: 0.000300
2025-05-30 00:08:00,061 - INFO - joeynmt.training - Epoch   3, Step:    22400, Batch Loss:     1.504750, Batch Acc: 0.524438, Tokens per Sec:     7757, Lr: 0.000300
2025-05-30 00:08:09,058 - INFO - joeynmt.training - Epoch   3, Step:    22500, Batch Loss:     1.468613, Batch Acc: 0.525020, Tokens per Sec:     7550, Lr: 0.000300
2025-05-30 00:08:09,058 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:08:09,059 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:09:02,008 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.98, acc:   0.50, generation: 52.8972[sec], evaluation: 0.0000[sec]
2025-05-30 00:09:02,183 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/20000.ckpt
2025-05-30 00:09:02,199 - INFO - joeynmt.training - Example #0
2025-05-30 00:09:02,200 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:09:02,200 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:09:02,200 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'het', 'jaar', 'van', 'het', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'van', 'de', 'twe@@', 'e', 'van', 'de', 'wer@@', 'k@@', 'ing', 'van', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'nen', 'die', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', '4@@', '8', 'st@@', 'aat', 'om', '4@@', '8', 'st@@', 'aat', 'te', 'be@@', 'st@@', 'ur@@', 'en', '4@@', '8', 'st@@', 'aat', 'om', '4@@', '8', 'te', 'be@@', 'gr@@', 'ij@@', 'p@@', 'en.', '</s>']
2025-05-30 00:09:02,200 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:09:02,200 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:09:02,200 - INFO - joeynmt.training - 	Hypothesis: Ik heb het jaar van het jaar heb ik deze twee van de twee van de werking van de artische ijnen die de artische ijskap, die voor de grootte van de 48 staat om 48 staat te besturen 48 staat om 48 te begrijpen.
2025-05-30 00:09:02,201 - INFO - joeynmt.training - Example #1
2025-05-30 00:09:02,201 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:09:02,201 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:09:02,201 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'ij@@', 's', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 't.', '</s>']
2025-05-30 00:09:02,201 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:09:02,201 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:09:02,202 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van het ijs van dit speciale probleem is dat het niet de dikke van de ijskracht.
2025-05-30 00:09:02,202 - INFO - joeynmt.training - Example #2
2025-05-30 00:09:02,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:09:02,202 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:09:02,202 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'je', 'z@@', 'in@@', 'e', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'nen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'st@@', '.', '</s>']
2025-05-30 00:09:02,202 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:09:02,202 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:09:02,203 - INFO - joeynmt.training - 	Hypothesis: In zekere zin je zine is de artische ijnen van onze wereldwijde klimaatst.
2025-05-30 00:09:02,203 - INFO - joeynmt.training - Example #3
2025-05-30 00:09:02,203 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:09:02,203 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:09:02,203 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:09:02,203 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:09:02,203 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:09:02,204 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppt in de zomers.
2025-05-30 00:09:02,204 - INFO - joeynmt.training - Example #4
2025-05-30 00:09:02,204 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:09:02,204 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:09:02,204 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'm@@', 'om@@', 'ent', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-30 00:09:02,204 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:09:02,204 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:09:02,204 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een moment in de laatste 25 jaar gebeurt in de laatste 25 jaar gebeurt.
2025-05-30 00:09:11,296 - INFO - joeynmt.training - Epoch   3, Step:    22600, Batch Loss:     1.438229, Batch Acc: 0.519755, Tokens per Sec:     7661, Lr: 0.000300
2025-05-30 00:09:20,104 - INFO - joeynmt.training - Epoch   3, Step:    22700, Batch Loss:     1.498983, Batch Acc: 0.524877, Tokens per Sec:     8230, Lr: 0.000300
2025-05-30 00:09:28,909 - INFO - joeynmt.training - Epoch   3, Step:    22800, Batch Loss:     1.449246, Batch Acc: 0.528306, Tokens per Sec:     7742, Lr: 0.000300
2025-05-30 00:09:37,581 - INFO - joeynmt.training - Epoch   3, Step:    22900, Batch Loss:     1.607278, Batch Acc: 0.521807, Tokens per Sec:     8387, Lr: 0.000300
2025-05-30 00:09:46,186 - INFO - joeynmt.training - Epoch   3, Step:    23000, Batch Loss:     1.547123, Batch Acc: 0.523049, Tokens per Sec:     8408, Lr: 0.000300
2025-05-30 00:09:46,186 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:09:46,187 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:10:29,308 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.91, acc:   0.50, generation: 43.0717[sec], evaluation: 0.0000[sec]
2025-05-30 00:10:29,309 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:10:29,484 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/20500.ckpt
2025-05-30 00:10:29,500 - INFO - joeynmt.training - Example #0
2025-05-30 00:10:29,500 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:10:29,501 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:10:29,501 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'et', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ke@@', 'er', 'die', 'twe@@', 'e', 'di@@', 'a', 'l@@', 'aat', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'ge@@', 'zon@@', 'd@@', 'hei@@', 'd@@', 's@@', 'z@@', 'or@@', 'g', 'is.', '</s>']
2025-05-30 00:10:29,502 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:10:29,502 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:10:29,502 - INFO - joeynmt.training - 	Hypothesis: Let heb ik deze twee keer die twee dia laat zien dat de artische ijskappen, dat de artische ijskappen, die voor de grootte van de grootte van de grootte van de 40 procent gebeurde om 40 procent gebeurde gezondheidszorg is.
2025-05-30 00:10:29,503 - INFO - joeynmt.training - Example #1
2025-05-30 00:10:29,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:10:29,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:10:29,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijk', 'gen@@', 'oe@@', 'g', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', ',', 'wan@@', 't', 'het', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', ',', 'wan@@', 't', 'het', 'het', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'zi@@', 'en.', '</s>']
2025-05-30 00:10:29,504 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:10:29,504 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:10:29,504 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van het ijskappelijk genoeg is dat het niet de dik, want het het niet de dikke dik, want het het het is niet de dikke ijs zien.
2025-05-30 00:10:29,505 - INFO - joeynmt.training - Example #2
2025-05-30 00:10:29,505 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:10:29,505 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:10:29,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'is', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:10:29,506 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:10:29,506 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:10:29,506 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape is het slagen van onze wereldwijde klimaatsysteem.
2025-05-30 00:10:29,507 - INFO - joeynmt.training - Example #3
2025-05-30 00:10:29,507 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:10:29,507 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:10:29,507 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er', 'van', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:10:29,508 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:10:29,508 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:10:29,508 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomer in de zomer in de zomer van de winter en zomer in de winter en zomer in de winter en zomers.
2025-05-30 00:10:29,508 - INFO - joeynmt.training - Example #4
2025-05-30 00:10:29,509 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:10:29,509 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:10:29,509 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:10:29,510 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:10:29,510 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:10:29,511 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdperk van wat er gebeurd in de laatste 25 jaar gebeurd is.
2025-05-30 00:10:38,400 - INFO - joeynmt.training - Epoch   3, Step:    23100, Batch Loss:     1.606077, Batch Acc: 0.528292, Tokens per Sec:     8006, Lr: 0.000300
2025-05-30 00:10:47,395 - INFO - joeynmt.training - Epoch   3, Step:    23200, Batch Loss:     1.466474, Batch Acc: 0.521128, Tokens per Sec:     7914, Lr: 0.000300
2025-05-30 00:10:56,376 - INFO - joeynmt.training - Epoch   3, Step:    23300, Batch Loss:     1.433378, Batch Acc: 0.528877, Tokens per Sec:     7896, Lr: 0.000300
2025-05-30 00:11:05,219 - INFO - joeynmt.training - Epoch   3, Step:    23400, Batch Loss:     1.571488, Batch Acc: 0.522906, Tokens per Sec:     8012, Lr: 0.000300
2025-05-30 00:11:14,120 - INFO - joeynmt.training - Epoch   3, Step:    23500, Batch Loss:     1.435266, Batch Acc: 0.525315, Tokens per Sec:     8221, Lr: 0.000300
2025-05-30 00:11:14,121 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:11:14,121 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:12:10,699 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.92, acc:   0.50, generation: 56.5389[sec], evaluation: 0.0000[sec]
2025-05-30 00:12:10,861 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/21500.ckpt
2025-05-30 00:12:10,875 - INFO - joeynmt.training - Example #0
2025-05-30 00:12:10,876 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:12:10,876 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:12:10,876 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'het', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'ie', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'k@@', 'ijk@@', 'en@@', ':', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'voor', 'de', 'ar@@', 'ti@@', 'c@@', 'ap@@', 'p@@', 'e,', 'die', 'voor', 'on@@', 'ge@@', 've@@', 'er', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'onder@@', 'ste@@', 'un@@', 'en', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-30 00:12:10,877 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:12:10,877 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:12:10,877 - INFO - joeynmt.training - 	Hypothesis: Ik heb het jaar heb ik deze twee folie getoond om te verkijken: de artische ijskappen, voor de articappe, die voor ongeveer 40 procent van de ondersteunen van 40 procent gebeurde geslaagd is.
2025-05-30 00:12:10,877 - INFO - joeynmt.training - Example #1
2025-05-30 00:12:10,878 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:12:10,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:12:10,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'd@@', 'ru@@', 'k@@', 'k@@', 'ing', 'van', 'het', 'ij@@', 's@@', 'e@@', 'er', 'niet', 'de', 'di@@', 'ck@@', '.', '</s>']
2025-05-30 00:12:10,879 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:12:10,879 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:12:10,879 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet genoeg genoeg de eerste van het speciale probleem dat het niet de drukking van het ijseer niet de dick.
2025-05-30 00:12:10,879 - INFO - joeynmt.training - Example #2
2025-05-30 00:12:10,879 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:12:10,880 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:12:10,880 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'wer@@', 'k@@', ',', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 's@@', 'la@@', 'gen', 'van', 'de', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:12:10,880 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:12:10,881 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:12:10,881 - INFO - joeynmt.training - 	Hypothesis: In zekere zin het werk, de artische ijskape het slagen van de wereldwijd van klimaatsysteem.
2025-05-30 00:12:10,881 - INFO - joeynmt.training - Example #3
2025-05-30 00:12:10,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:12:10,881 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:12:10,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:12:10,882 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:12:10,882 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:12:10,882 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomers.
2025-05-30 00:12:10,882 - INFO - joeynmt.training - Example #4
2025-05-30 00:12:10,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:12:10,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:12:10,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'op@@', 'n@@', 'am@@', 'e', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:12:10,883 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:12:10,883 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:12:10,883 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien is een tijdrappopname wat er gebeurd.
2025-05-30 00:12:19,419 - INFO - joeynmt.training - Epoch   3, Step:    23600, Batch Loss:     1.447142, Batch Acc: 0.522099, Tokens per Sec:     8151, Lr: 0.000300
2025-05-30 00:12:28,098 - INFO - joeynmt.training - Epoch   3, Step:    23700, Batch Loss:     1.649455, Batch Acc: 0.529071, Tokens per Sec:     8097, Lr: 0.000300
2025-05-30 00:12:36,785 - INFO - joeynmt.training - Epoch   3, Step:    23800, Batch Loss:     1.604090, Batch Acc: 0.524970, Tokens per Sec:     8512, Lr: 0.000300
2025-05-30 00:12:45,618 - INFO - joeynmt.training - Epoch   3, Step:    23900, Batch Loss:     1.454849, Batch Acc: 0.526406, Tokens per Sec:     8092, Lr: 0.000300
2025-05-30 00:12:54,545 - INFO - joeynmt.training - Epoch   3, Step:    24000, Batch Loss:     1.575941, Batch Acc: 0.525273, Tokens per Sec:     7987, Lr: 0.000300
2025-05-30 00:12:54,546 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:12:54,546 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:13:50,324 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.88, acc:   0.50, generation: 55.7365[sec], evaluation: 0.0000[sec]
2025-05-30 00:13:50,325 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:13:50,508 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/21000.ckpt
2025-05-30 00:13:50,523 - INFO - joeynmt.training - Example #0
2025-05-30 00:13:50,524 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:13:50,524 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:13:50,524 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'k@@', 'eer@@', 'd', 'te', 'ver@@', 'k@@', 'op@@', 'p@@', 'el@@', 'ing', 'te', 'be@@', 'k@@', 'ijk@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'on@@', 'ge@@', 've@@', 'er', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'ge@@', 's@@', 'lo@@', 'ten', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'ge@@', 's@@', 'lo@@', 'ten', 'te', 'ge@@', 's@@', 'lo@@', 'ten', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'ge@@', 's@@', 'lo@@', 'ten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 'v@@', 'aa@@', 'k', 'te', 'ver@@', 'k@@', 'op@@', 'p@@', 'el@@', 'de', 'van', 'de', 'twe@@', 'e', 'van', 'de', 'on@@', 'gel@@', 'u@@', 'i@@', 'd', 'van', 'de', 'twe@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'die', 'we', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de']
2025-05-30 00:13:50,525 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:13:50,525 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:13:50,526 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb ik deze twee folië getoond om te verkeerd te verkoppeling te bekijken, die voor de grootte van de ongeveer 40 procent gegesloten van 40 procent gegesloten te gesloten van 40 procent gegesloten om 40 procent te vervaak te verkoppelde van de twee van de ongeluid van de twee miljoen jaar die we de grootte van de
2025-05-30 00:13:50,526 - INFO - joeynmt.training - Example #1
2025-05-30 00:13:50,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:13:50,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:13:50,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 'ken', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'pro@@', 'ble@@', 'men', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'men', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', '.', '</s>']
2025-05-30 00:13:50,527 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:13:50,527 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:13:50,528 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukken niet sterk genoeg de eerste problemen van dit speciale problemen uit, omdat het niet de dick.
2025-05-30 00:13:50,528 - INFO - joeynmt.training - Example #2
2025-05-30 00:13:50,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:13:50,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:13:50,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'de', 'wer@@', 'k@@', ',', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:13:50,529 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:13:50,529 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:13:50,530 - INFO - joeynmt.training - 	Hypothesis: In zekere zin de werk, de artische ijskape hart van onze wereldwijd klimaatsysteem.
2025-05-30 00:13:50,530 - INFO - joeynmt.training - Example #3
2025-05-30 00:13:50,530 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:13:50,530 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:13:50,530 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:13:50,532 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:13:50,532 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:13:50,532 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zomers.
2025-05-30 00:13:50,532 - INFO - joeynmt.training - Example #4
2025-05-30 00:13:50,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:13:50,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:13:50,533 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'te@@', 'ken@@', 'is', 'een', 'te@@', 'ken@@', 'is', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:13:50,534 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:13:50,534 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:13:50,534 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien is een tekenis een tekenis in de afgelopen 25 jaar gebeurd is.
2025-05-30 00:13:59,626 - INFO - joeynmt.training - Epoch   3, Step:    24100, Batch Loss:     1.498765, Batch Acc: 0.524472, Tokens per Sec:     7752, Lr: 0.000300
2025-05-30 00:14:08,603 - INFO - joeynmt.training - Epoch   3, Step:    24200, Batch Loss:     1.550842, Batch Acc: 0.529103, Tokens per Sec:     7958, Lr: 0.000300
2025-05-30 00:14:17,663 - INFO - joeynmt.training - Epoch   3, Step:    24300, Batch Loss:     1.529184, Batch Acc: 0.531346, Tokens per Sec:     7837, Lr: 0.000300
2025-05-30 00:14:25,815 - INFO - joeynmt.training - Epoch   3, Step:    24400, Batch Loss:     1.442444, Batch Acc: 0.526860, Tokens per Sec:     8757, Lr: 0.000300
2025-05-30 00:14:34,738 - INFO - joeynmt.training - Epoch   3, Step:    24500, Batch Loss:     1.627275, Batch Acc: 0.518760, Tokens per Sec:     8117, Lr: 0.000300
2025-05-30 00:14:34,738 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:14:34,738 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:15:20,120 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.86, acc:   0.50, generation: 45.3357[sec], evaluation: 0.0000[sec]
2025-05-30 00:15:20,121 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:15:20,287 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/22500.ckpt
2025-05-30 00:15:20,301 - INFO - joeynmt.training - Example #0
2025-05-30 00:15:20,303 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:15:20,303 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:15:20,303 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'ies', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'c@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'on@@', 'ge@@', 've@@', 'er', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'er', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'st@@', 'op@@', 't', 'is.', '</s>']
2025-05-30 00:15:20,304 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:15:20,304 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:15:20,304 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folies getoond om te verantische ijskappen, dat de artice ijskappen, die voor de grootte van de ongeveer 40 procent gebeurde er 40 procent gestopt is.
2025-05-30 00:15:20,304 - INFO - joeynmt.training - Example #1
2025-05-30 00:15:20,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:15:20,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:15:20,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'de', 'd@@', 'ru@@', 'kt', 'niet', 'st@@', 'ar@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'ver@@', 'st@@', 'el@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'ck@@', '-@@', 'p@@', 'un@@', 't', 'van', 'het', 'ij@@', 's@@', 'ge@@', 'ven', 'van', 'het', 'ij@@', 's@@', 'ge@@', 'e@@', 'st@@', '.', '</s>']
2025-05-30 00:15:20,306 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:15:20,306 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:15:20,306 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet de drukt niet stark genoeg de verstelde van dit speciale probleem uit, want het is niet de dick-punt van het ijsgeven van het ijsgeest.
2025-05-30 00:15:20,306 - INFO - joeynmt.training - Example #2
2025-05-30 00:15:20,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:15:20,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:15:20,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'ig@@', ',', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:15:20,308 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:15:20,308 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:15:20,308 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuig, de artische ijskappe hart van onze wereldwijde klimaatsysteem.
2025-05-30 00:15:20,308 - INFO - joeynmt.training - Example #3
2025-05-30 00:15:20,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:15:20,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:15:20,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:15:20,309 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:15:20,309 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:15:20,309 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomers.
2025-05-30 00:15:20,309 - INFO - joeynmt.training - Example #4
2025-05-30 00:15:20,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:15:20,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:15:20,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'p@@', 'le@@', 'k', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:15:20,310 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:15:20,310 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:15:20,310 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laten zien, is een tijdrappplek in de afgelopen 25 jaar gebeurd.
2025-05-30 00:15:28,912 - INFO - joeynmt.training - Epoch   3, Step:    24600, Batch Loss:     1.936638, Batch Acc: 0.516762, Tokens per Sec:     8032, Lr: 0.000300
2025-05-30 00:15:37,188 - INFO - joeynmt.training - Epoch   3, Step:    24700, Batch Loss:     1.488969, Batch Acc: 0.527618, Tokens per Sec:     8862, Lr: 0.000300
2025-05-30 00:15:45,730 - INFO - joeynmt.training - Epoch   3, Step:    24800, Batch Loss:     1.581058, Batch Acc: 0.523401, Tokens per Sec:     8522, Lr: 0.000300
2025-05-30 00:15:54,540 - INFO - joeynmt.training - Epoch   3, Step:    24900, Batch Loss:     1.354599, Batch Acc: 0.529493, Tokens per Sec:     8038, Lr: 0.000300
2025-05-30 00:16:03,002 - INFO - joeynmt.training - Epoch   3, Step:    25000, Batch Loss:     1.354126, Batch Acc: 0.529010, Tokens per Sec:     8477, Lr: 0.000300
2025-05-30 00:16:03,003 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:16:03,003 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:16:56,838 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.84, acc:   0.51, generation: 53.7894[sec], evaluation: 0.0000[sec]
2025-05-30 00:16:56,839 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:16:57,009 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/22000.ckpt
2025-05-30 00:16:57,016 - INFO - joeynmt.training - Example #0
2025-05-30 00:16:57,016 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:16:57,017 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:16:57,017 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'k@@', 'ijk@@', 'en,', 'om', 'te', 'ver@@', 'an@@', 'der', 'te', 'be@@', 'gr@@', 'ij@@', 'p@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'c@@', 'ul@@', 'p', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'de', 'gro@@', 'ot@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 't', 'te', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 00:16:57,018 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:16:57,018 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:16:57,018 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verankijken, om te verander te begrijpen, die voor de articulp die voor de onderste 48 staten, de grootste 48 staten, om 48 staten, om 48 staten had 40 procent geslagen van 40 procent gebeurt te gebeuren.
2025-05-30 00:16:57,018 - INFO - joeynmt.training - Example #1
2025-05-30 00:16:57,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:16:57,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:16:57,019 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'ver@@', 'vol@@', 'gen@@', 's', 'de', 'ver@@', 'vol@@', 'gen@@', 's', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'de', 'ij@@', 's@@', 'ge@@', 'st@@', 'el@@', 'd.', '</s>']
2025-05-30 00:16:57,020 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:16:57,020 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:16:57,020 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de vervolgens de vervolgens van dit speciale probleem uit, want het het niet de dicke van de ijsgesteld.
2025-05-30 00:16:57,020 - INFO - joeynmt.training - Example #2
2025-05-30 00:16:57,020 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:16:57,020 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:16:57,020 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 't', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:16:57,021 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:16:57,021 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:16:57,022 - INFO - joeynmt.training - 	Hypothesis: In zekere ijskape ijt de artische ijskape het slagen van onze wereldwijde klimaatsysteem.
2025-05-30 00:16:57,022 - INFO - joeynmt.training - Example #3
2025-05-30 00:16:57,022 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:16:57,022 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:16:57,022 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:16:57,023 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:16:57,023 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:16:57,023 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomers in de winter en zomers.
2025-05-30 00:16:57,023 - INFO - joeynmt.training - Example #4
2025-05-30 00:16:57,024 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:16:57,024 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:16:57,024 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'dat', 'ik', 'jullie', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 'te@@', 'm@@', 'p@@', 'el@@', 'ing', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:16:57,025 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:16:57,025 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:16:57,025 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien dat ik jullie een tijdrapportempeling in de afgelopen 25 jaar gebeurd.
2025-05-30 00:17:05,957 - INFO - joeynmt.training - Epoch   3, Step:    25100, Batch Loss:     1.500072, Batch Acc: 0.529858, Tokens per Sec:     7903, Lr: 0.000300
2025-05-30 00:17:14,559 - INFO - joeynmt.training - Epoch   3, Step:    25200, Batch Loss:     1.353090, Batch Acc: 0.530763, Tokens per Sec:     8273, Lr: 0.000300
2025-05-30 00:17:23,645 - INFO - joeynmt.training - Epoch   3, Step:    25300, Batch Loss:     1.494811, Batch Acc: 0.529314, Tokens per Sec:     8049, Lr: 0.000300
2025-05-30 00:17:32,197 - INFO - joeynmt.training - Epoch   3, Step:    25400, Batch Loss:     1.408705, Batch Acc: 0.528742, Tokens per Sec:     8172, Lr: 0.000300
2025-05-30 00:17:40,940 - INFO - joeynmt.training - Epoch   3, Step:    25500, Batch Loss:     1.628271, Batch Acc: 0.529119, Tokens per Sec:     8014, Lr: 0.000300
2025-05-30 00:17:40,941 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:17:40,941 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:18:47,367 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.85, acc:   0.51, generation: 66.3716[sec], evaluation: 0.0000[sec]
2025-05-30 00:18:47,539 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/23500.ckpt
2025-05-30 00:18:47,556 - INFO - joeynmt.training - Example #0
2025-05-30 00:18:47,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:18:47,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:18:47,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'ie', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'der', 'te', 'ver@@', 'an@@', 'der', 'te', 'ver@@', 'an@@', 'der', 'voor', 'an@@', 'n@@', 'd', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'ste', 'p@@', 'at@@', 'r@@', 'on@@', 'en', 'de', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'm@@', 'p@@', 'er', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'ge@@', 'gev@@', 'ens', '4@@', '0@@', '%', 'ge@@', 's@@', 'm@@', 'p@@', 'er', 'is.', '</s>']
2025-05-30 00:18:47,558 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:18:47,558 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:18:47,558 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folie getoond om te verander te verander te verander voor annd drie miljoen jaar de grootste patronen de 40 procent van 40 procent gesmper jaar gebeurde gegevens 40% gesmper is.
2025-05-30 00:18:47,558 - INFO - joeynmt.training - Example #1
2025-05-30 00:18:47,558 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:18:47,559 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:18:47,559 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'd@@', 'ru@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'de', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'b@@', 'aar', 'uit@@', 'en@@', 'gew@@', 'oo@@', 'n', 'van', 'het', 'ij@@', 's@@', 'b@@', 'aar', 'is.', '</s>']
2025-05-30 00:18:47,559 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:18:47,559 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:18:47,560 - INFO - joeynmt.training - 	Hypothesis: Maar dat druk genoeg de aarde de van het specifieke probleem uit, want het het niet de dikke van het ijsbaar uitengewoon van het ijsbaar is.
2025-05-30 00:18:47,560 - INFO - joeynmt.training - Example #2
2025-05-30 00:18:47,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:18:47,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:18:47,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:18:47,561 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:18:47,561 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:18:47,561 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 00:18:47,562 - INFO - joeynmt.training - Example #3
2025-05-30 00:18:47,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:18:47,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:18:47,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 's@@', 'ru@@', 'im@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:18:47,563 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:18:47,564 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:18:47,564 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en sruimpt in de winter en zomers.
2025-05-30 00:18:47,564 - INFO - joeynmt.training - Example #4
2025-05-30 00:18:47,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:18:47,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:18:47,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'en@@', 'st@@', ',', 'is', 'een', 'te@@', 'ken@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:18:47,565 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:18:47,565 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:18:47,565 - INFO - joeynmt.training - 	Hypothesis: De volgende dienst, is een tekent in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurd is.
2025-05-30 00:18:56,179 - INFO - joeynmt.training - Epoch   3, Step:    25600, Batch Loss:     1.572664, Batch Acc: 0.529727, Tokens per Sec:     8162, Lr: 0.000300
2025-05-30 00:19:04,518 - INFO - joeynmt.training - Epoch   3, Step:    25700, Batch Loss:     1.669289, Batch Acc: 0.521101, Tokens per Sec:     8485, Lr: 0.000300
2025-05-30 00:19:12,395 - INFO - joeynmt.training - Epoch   3, Step:    25800, Batch Loss:     1.476764, Batch Acc: 0.531267, Tokens per Sec:     8980, Lr: 0.000300
2025-05-30 00:19:20,015 - INFO - joeynmt.training - Epoch   3, Step:    25900, Batch Loss:     1.697467, Batch Acc: 0.524363, Tokens per Sec:     9534, Lr: 0.000300
2025-05-30 00:19:27,632 - INFO - joeynmt.training - Epoch   3, Step:    26000, Batch Loss:     1.533241, Batch Acc: 0.529112, Tokens per Sec:     9994, Lr: 0.000300
2025-05-30 00:19:27,632 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:19:27,632 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:20:10,808 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.56, ppl:   4.78, acc:   0.51, generation: 43.1308[sec], evaluation: 0.0000[sec]
2025-05-30 00:20:10,809 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:20:10,988 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/23000.ckpt
2025-05-30 00:20:10,999 - INFO - joeynmt.training - Example #0
2025-05-30 00:20:11,000 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:20:11,000 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:20:11,000 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'de', 'ge@@', 'vol@@', 'g', 'om', 'te', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 't', 'is.', '</s>']
2025-05-30 00:20:11,001 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:20:11,001 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:20:11,001 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde de gevolg om te kijken dat de arctische ijskappen, die voor de miljoen jaar de grootte van de grootte van de grootte van 40 procent van 40 procent van 40 procent van 40 procent gebeurt is.
2025-05-30 00:20:11,001 - INFO - joeynmt.training - Example #1
2025-05-30 00:20:11,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:20:11,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:20:11,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'is', 'van', 'de', 'aar@@', 'de', 'van', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'er', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'er', 'van', 'het', 'ij@@', 's@@', 'e@@', 'p@@', '.', '</s>']
2025-05-30 00:20:11,003 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:20:11,003 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:20:11,003 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aarde is van de aarde van het speciale probleem uit, omdat het niet de diker uit, want het is niet de diker van het ijsep.
2025-05-30 00:20:11,004 - INFO - joeynmt.training - Example #2
2025-05-30 00:20:11,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:20:11,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:20:11,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'het', 's@@', 'la@@', 'gen', 'van', 'de', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:20:11,005 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:20:11,005 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:20:11,005 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe het slagen van de wereldwijde klimaatsysteem.
2025-05-30 00:20:11,005 - INFO - joeynmt.training - Example #3
2025-05-30 00:20:11,006 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:20:11,007 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:20:11,007 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 's@@', 'n@@', 'el', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 's@@', 'n@@', 'el', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 's@@', 'n@@', 'el', 'en', 's@@', 'n@@', 'el', 'en', 's@@', 'n@@', 'el', 'gro@@', 'ei@@', 'en.', '</s>']
2025-05-30 00:20:11,007 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:20:11,008 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:20:11,008 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en snel in de winter en snel in de winter en zomer in de winter en snel en snel en snel groeien.
2025-05-30 00:20:11,008 - INFO - joeynmt.training - Example #4
2025-05-30 00:20:11,008 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:20:11,008 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:20:11,009 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'gen', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'is', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:20:11,009 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:20:11,010 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:20:11,010 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdragen van de laatste 25 jaar is in de afgelopen 25 jaar is gebeurd is.
2025-05-30 00:20:19,588 - INFO - joeynmt.training - Epoch   3, Step:    26100, Batch Loss:     1.568575, Batch Acc: 0.529047, Tokens per Sec:     8393, Lr: 0.000300
2025-05-30 00:20:28,319 - INFO - joeynmt.training - Epoch   3, Step:    26200, Batch Loss:     1.557406, Batch Acc: 0.526786, Tokens per Sec:     8358, Lr: 0.000300
2025-05-30 00:20:37,466 - INFO - joeynmt.training - Epoch   3, Step:    26300, Batch Loss:     1.456441, Batch Acc: 0.528669, Tokens per Sec:     7779, Lr: 0.000300
2025-05-30 00:20:47,048 - INFO - joeynmt.training - Epoch   3, Step:    26400, Batch Loss:     1.339980, Batch Acc: 0.530753, Tokens per Sec:     7429, Lr: 0.000300
2025-05-30 00:20:56,177 - INFO - joeynmt.training - Epoch   3, Step:    26500, Batch Loss:     1.502724, Batch Acc: 0.528718, Tokens per Sec:     7861, Lr: 0.000300
2025-05-30 00:20:56,200 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:20:56,201 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:21:44,807 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.82, acc:   0.51, generation: 48.5609[sec], evaluation: 0.0000[sec]
2025-05-30 00:21:44,982 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/24000.ckpt
2025-05-30 00:21:44,998 - INFO - joeynmt.training - Example #0
2025-05-30 00:21:44,999 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:21:45,000 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:21:45,000 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'den', 'te', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'en', 'die', 'voor', 'de', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'lo@@', 'ten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'da@@', 'an', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'st@@', 'a@@', 'f', 'te', 'k@@', 'ij@@', 'ken', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'lo@@', 'ten', 'te', 'ver@@', 't@@', 'ro@@', 'k@@', 'ken', 'en', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'z@@', 'et', 'in', 'de', 'st@@', 'aat', 'st@@', 'aat', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 't@@']
2025-05-30 00:21:45,001 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:21:45,001 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:21:45,001 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb ik deze twee dia toonde getoond om te verbeelden te kijken dat de arctische ijskappelen die voor de miljoen jaar de grootte van de onderste 40 procent gesloten om 40 procent te gedaan om 40 procent te staf te kijken van 40 procent gesloten te vertrokken en 40 procent gezet in de staat staat getoond om te vert
2025-05-30 00:21:45,001 - INFO - joeynmt.training - Example #1
2025-05-30 00:21:45,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:21:45,002 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:21:45,002 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'k@@', 'ra@@', 'cht', 'van', 'de', 'k@@', 'ra@@', 'cht', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'k@@', 'er', 'uit@@', 'ein@@', 'del@@', 'ijk', 'gen@@', 'oe@@', 'g', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 't.', '</s>']
2025-05-30 00:21:45,003 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:21:45,003 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:21:45,003 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de kracht van de kracht van dit speciale probleem is het niet de dikker uiteindelijk genoeg van de ijskracht.
2025-05-30 00:21:45,003 - INFO - joeynmt.training - Example #2
2025-05-30 00:21:45,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:21:45,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:21:45,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 's', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:21:45,005 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:21:45,005 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:21:45,005 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappels het slagen van onze wereldwijde klimaatsysteem.
2025-05-30 00:21:45,005 - INFO - joeynmt.training - Example #3
2025-05-30 00:21:45,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:21:45,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:21:45,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:21:45,006 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:21:45,006 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:21:45,007 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomers.
2025-05-30 00:21:45,007 - INFO - joeynmt.training - Example #4
2025-05-30 00:21:45,007 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:21:45,007 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:21:45,007 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'k@@', 'ran@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:21:45,008 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:21:45,008 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:21:45,009 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een krant in de laatste 25 jaar gebeurd is.
2025-05-30 00:21:53,833 - INFO - joeynmt.training - Epoch   3, Step:    26600, Batch Loss:     1.456008, Batch Acc: 0.530454, Tokens per Sec:     7779, Lr: 0.000300
2025-05-30 00:22:02,658 - INFO - joeynmt.training - Epoch   3, Step:    26700, Batch Loss:     1.554445, Batch Acc: 0.530253, Tokens per Sec:     7942, Lr: 0.000300
2025-05-30 00:22:11,446 - INFO - joeynmt.training - Epoch   3, Step:    26800, Batch Loss:     1.369454, Batch Acc: 0.530501, Tokens per Sec:     8114, Lr: 0.000300
2025-05-30 00:22:20,420 - INFO - joeynmt.training - Epoch   3, Step:    26900, Batch Loss:     1.362825, Batch Acc: 0.523595, Tokens per Sec:     7693, Lr: 0.000300
2025-05-30 00:22:29,377 - INFO - joeynmt.training - Epoch   3, Step:    27000, Batch Loss:     1.471140, Batch Acc: 0.528698, Tokens per Sec:     7983, Lr: 0.000300
2025-05-30 00:22:29,377 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:22:29,377 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:23:16,738 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.79, acc:   0.51, generation: 47.3155[sec], evaluation: 0.0000[sec]
2025-05-30 00:23:16,909 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/24500.ckpt
2025-05-30 00:23:16,924 - INFO - joeynmt.training - Example #0
2025-05-30 00:23:16,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:23:16,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:23:16,926 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ke', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'sch@@', 'u@@', 'i@@', 'v@@', 'er', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'die', 'voor', 'on@@', 'der', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 's', 'die', 'on@@', 'der', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'is', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 00:23:16,927 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:23:16,928 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:23:16,928 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee politieke getoond om te veranschuiver te begrijpen die voor onder de artische ijskappels die onder 40 procent van 40 procent van 40 procent is om 40 procent te gebeuren.
2025-05-30 00:23:16,928 - INFO - joeynmt.training - Example #1
2025-05-30 00:23:16,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:23:16,929 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:23:16,929 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'k@@', 'ra@@', 'cht', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', '.', '</s>']
2025-05-30 00:23:16,929 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:23:16,930 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:23:16,930 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de kracht van dit speciale probleem van dit speciale probleem uit, omdat het niet de dick.
2025-05-30 00:23:16,930 - INFO - joeynmt.training - Example #2
2025-05-30 00:23:16,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:23:16,930 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:23:16,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:23:16,931 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:23:16,932 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:23:16,932 - INFO - joeynmt.training - 	Hypothesis: In zekere ijzondere ijzondere ijzondere ijzondere ijzondere klimaatsysteem.
2025-05-30 00:23:16,932 - INFO - joeynmt.training - Example #3
2025-05-30 00:23:16,932 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:23:16,932 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:23:16,932 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:23:16,933 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:23:16,933 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:23:16,933 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schept in zomers.
2025-05-30 00:23:16,933 - INFO - joeynmt.training - Example #4
2025-05-30 00:23:16,934 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:23:16,934 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:23:16,934 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'p@@', 'er', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:23:16,936 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:23:16,936 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:23:16,937 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een tijdrappper 25 jaar gebeurd is.
2025-05-30 00:23:25,952 - INFO - joeynmt.training - Epoch   3, Step:    27100, Batch Loss:     1.392769, Batch Acc: 0.535812, Tokens per Sec:     7906, Lr: 0.000300
2025-05-30 00:23:35,053 - INFO - joeynmt.training - Epoch   3, Step:    27200, Batch Loss:     1.536203, Batch Acc: 0.537707, Tokens per Sec:     8108, Lr: 0.000300
2025-05-30 00:23:44,018 - INFO - joeynmt.training - Epoch   3, Step:    27300, Batch Loss:     1.440590, Batch Acc: 0.534696, Tokens per Sec:     7943, Lr: 0.000300
2025-05-30 00:23:52,802 - INFO - joeynmt.training - Epoch   3, Step:    27400, Batch Loss:     1.397021, Batch Acc: 0.530372, Tokens per Sec:     8228, Lr: 0.000300
2025-05-30 00:24:01,610 - INFO - joeynmt.training - Epoch   3, Step:    27500, Batch Loss:     1.389755, Batch Acc: 0.531807, Tokens per Sec:     8037, Lr: 0.000300
2025-05-30 00:24:01,611 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:24:01,611 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:24:47,320 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.79, acc:   0.51, generation: 45.6630[sec], evaluation: 0.0000[sec]
2025-05-30 00:24:47,495 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/25500.ckpt
2025-05-30 00:24:47,509 - INFO - joeynmt.training - Example #0
2025-05-30 00:24:47,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:24:47,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:24:47,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'den', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 's', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'de', 'gro@@', 'ot@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', '4@@', '8', 'st@@', 'at@@', 'ten', '4@@', '8', 'st@@', 'at@@', 'ten', 'van', '4@@', '%', 'van', '4@@', '%', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'is.', '</s>']
2025-05-30 00:24:47,511 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:24:47,511 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:24:47,511 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folië getoond om te veranden dat de artische ijskappe ijskappels die voor de grootste 48 staten, de grootste 48 staten, 48 statten 48 statten van 4% van 4% van 40 procent is.
2025-05-30 00:24:47,511 - INFO - joeynmt.training - Example #1
2025-05-30 00:24:47,512 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:24:47,512 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:24:47,512 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'is', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 'z@@', 'is@@', '.', '</s>']
2025-05-30 00:24:47,513 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:24:47,513 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:24:47,513 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aarde is dat het speciale probleem van dit speciale probleem van het ijskracht van de ijzis.
2025-05-30 00:24:47,513 - INFO - joeynmt.training - Example #2
2025-05-30 00:24:47,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:24:47,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:24:47,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'w@@', 'et@@', 's@@', 'en@@', 'd@@', 'heid', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:24:47,515 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:24:47,515 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:24:47,515 - INFO - joeynmt.training - 	Hypothesis: In wetsendheid is de artische ijskape het slagen van onze wereldwijde klimaatsysteem.
2025-05-30 00:24:47,515 - INFO - joeynmt.training - Example #3
2025-05-30 00:24:47,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:24:47,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:24:47,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'ver@@', 'z@@', 'oe@@', 'ken', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:24:47,516 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:24:47,516 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:24:47,517 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en verzoeken in de winter en zomers.
2025-05-30 00:24:47,518 - INFO - joeynmt.training - Example #4
2025-05-30 00:24:47,518 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:24:47,518 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:24:47,518 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:24:47,519 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:24:47,519 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:24:47,519 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien is een tijdperk in de laatste 25 jaar gebeurd is.
2025-05-30 00:24:56,571 - INFO - joeynmt.training - Epoch   3, Step:    27600, Batch Loss:     1.479408, Batch Acc: 0.525158, Tokens per Sec:     8105, Lr: 0.000300
2025-05-30 00:25:07,446 - INFO - joeynmt.training - Epoch   3, Step:    27700, Batch Loss:     1.368236, Batch Acc: 0.531693, Tokens per Sec:     6736, Lr: 0.000300
2025-05-30 00:25:16,461 - INFO - joeynmt.training - Epoch   3, Step:    27800, Batch Loss:     1.646099, Batch Acc: 0.521335, Tokens per Sec:     8059, Lr: 0.000300
2025-05-30 00:25:25,415 - INFO - joeynmt.training - Epoch   3, Step:    27900, Batch Loss:     1.500330, Batch Acc: 0.538917, Tokens per Sec:     7891, Lr: 0.000300
2025-05-30 00:25:34,381 - INFO - joeynmt.training - Epoch   3, Step:    28000, Batch Loss:     1.387421, Batch Acc: 0.528845, Tokens per Sec:     7877, Lr: 0.000300
2025-05-30 00:25:34,382 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:25:34,385 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:26:30,158 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.79, acc:   0.51, generation: 55.7222[sec], evaluation: 0.0000[sec]
2025-05-30 00:26:30,322 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/25000.ckpt
2025-05-30 00:26:30,339 - INFO - joeynmt.training - Example #0
2025-05-30 00:26:30,339 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:26:30,340 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:26:30,340 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'k@@', 'ijk@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'sch@@', 'aal@@', 'de', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'st@@', 'at@@', 'ten', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'g', 'is.', '</s>']
2025-05-30 00:26:30,341 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:26:30,341 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:26:30,341 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folië getoond om te kijken, dat de arctische ijskappen, die voor de schaalde van de grootte van de grootte van de grootte van 40 statten van 40 procent geslag is.
2025-05-30 00:26:30,341 - INFO - joeynmt.training - Example #1
2025-05-30 00:26:30,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:26:30,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:26:30,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'de', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'is', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', 'dat', 'het', 'niet', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 00:26:30,343 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:26:30,343 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:26:30,343 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aarde de van het specifiek van dit specifieke probleem is het niet de dicke van het ijs laat zien dat het niet laat zien.
2025-05-30 00:26:30,343 - INFO - joeynmt.training - Example #2
2025-05-30 00:26:30,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:26:30,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:26:30,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'dat', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'ver@@', 'ander@@', 'ing', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'ver@@', '.', '</s>']
2025-05-30 00:26:30,345 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:26:30,345 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:26:30,345 - INFO - joeynmt.training - 	Hypothesis: In zekere zin de arctische ijskape dat slagen van onze wereldwijde klimaatverandering van onze wereldwijde klimaatver.
2025-05-30 00:26:30,346 - INFO - joeynmt.training - Example #3
2025-05-30 00:26:30,346 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:26:30,346 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:26:30,346 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 's@@', 'ru@@', 'im@@', 'te', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:26:30,347 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:26:30,347 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:26:30,347 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en sruimte in de zomers.
2025-05-30 00:26:30,347 - INFO - joeynmt.training - Example #4
2025-05-30 00:26:30,348 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:26:30,348 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:26:30,348 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'f@@', 'ol@@', 'ie', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'gen', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:26:30,349 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:26:30,350 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:26:30,350 - INFO - joeynmt.training - 	Hypothesis: De volgende folie die ik jullie laten zien is een tijdragen wat er in de laatste 25 jaar gebeurd is.
2025-05-30 00:26:39,542 - INFO - joeynmt.training - Epoch   3, Step:    28100, Batch Loss:     1.369424, Batch Acc: 0.532503, Tokens per Sec:     7582, Lr: 0.000300
2025-05-30 00:26:49,049 - INFO - joeynmt.training - Epoch   3, Step:    28200, Batch Loss:     1.509306, Batch Acc: 0.529118, Tokens per Sec:     7616, Lr: 0.000300
2025-05-30 00:26:58,127 - INFO - joeynmt.training - Epoch   3, Step:    28300, Batch Loss:     1.561962, Batch Acc: 0.535102, Tokens per Sec:     8041, Lr: 0.000300
2025-05-30 00:27:07,059 - INFO - joeynmt.training - Epoch   3, Step:    28400, Batch Loss:     1.539991, Batch Acc: 0.534251, Tokens per Sec:     8106, Lr: 0.000300
2025-05-30 00:27:15,876 - INFO - joeynmt.training - Epoch   3, Step:    28500, Batch Loss:     1.396120, Batch Acc: 0.529650, Tokens per Sec:     8186, Lr: 0.000300
2025-05-30 00:27:15,877 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:27:15,877 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:28:08,369 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.56, ppl:   4.75, acc:   0.51, generation: 52.4542[sec], evaluation: 0.0000[sec]
2025-05-30 00:28:08,370 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:28:08,537 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/26500.ckpt
2025-05-30 00:28:08,557 - INFO - joeynmt.training - Example #0
2025-05-30 00:28:08,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:28:08,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:28:08,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ge@@', 've@@', 'er', 'van', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'm@@', 'id@@', 'del@@', 'de', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'm@@', 'p@@', 'er', 'is.', '</s>']
2025-05-30 00:28:08,558 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:28:08,559 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:28:08,559 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde geveer van de arctische ijskappen, die voor de artische ijskappen, die voor de grootte van de 40 procent gesmiddelde 40 procent gesmper is.
2025-05-30 00:28:08,559 - INFO - joeynmt.training - Example #1
2025-05-30 00:28:08,559 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:28:08,559 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:28:08,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'n@@', 't@@', 'aal', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'ij@@', 's', 'niet', 'de', 'di@@', 'k@@', 'er', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 00:28:08,560 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:28:08,561 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:28:08,561 - INFO - joeynmt.training - 	Hypothesis: Maar dit specifiek genoeg de ntaal van het specifiek probleem van dit specifieke probleem uit, omdat het ijs niet de diker laat zien.
2025-05-30 00:28:08,561 - INFO - joeynmt.training - Example #2
2025-05-30 00:28:08,561 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:28:08,561 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:28:08,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:28:08,562 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:28:08,563 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:28:08,563 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappen, het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 00:28:08,563 - INFO - joeynmt.training - Example #3
2025-05-30 00:28:08,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:28:08,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:28:08,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:28:08,564 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:28:08,564 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:28:08,564 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomers.
2025-05-30 00:28:08,565 - INFO - joeynmt.training - Example #4
2025-05-30 00:28:08,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:28:08,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:28:08,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 't@@', 'oo@@', 'n', 'die', 'ik', 't@@', 'oo@@', 'n', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'p@@', 'er', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:28:08,566 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:28:08,566 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:28:08,566 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik toon die ik toon is een tijdrappper 25 jaar gebeurd.
2025-05-30 00:28:16,882 - INFO - joeynmt.training - Epoch   3, Step:    28600, Batch Loss:     1.440088, Batch Acc: 0.533867, Tokens per Sec:     8690, Lr: 0.000300
2025-05-30 00:28:24,985 - INFO - joeynmt.training - Epoch   3, Step:    28700, Batch Loss:     1.501964, Batch Acc: 0.533604, Tokens per Sec:     9131, Lr: 0.000300
2025-05-30 00:28:32,944 - INFO - joeynmt.training - Epoch   3, Step:    28800, Batch Loss:     1.445282, Batch Acc: 0.536751, Tokens per Sec:     9004, Lr: 0.000300
2025-05-30 00:28:41,219 - INFO - joeynmt.training - Epoch   3, Step:    28900, Batch Loss:     1.470748, Batch Acc: 0.527346, Tokens per Sec:     8721, Lr: 0.000300
2025-05-30 00:28:50,164 - INFO - joeynmt.training - Epoch   3, Step:    29000, Batch Loss:     1.411449, Batch Acc: 0.529752, Tokens per Sec:     8292, Lr: 0.000300
2025-05-30 00:28:50,165 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:28:50,165 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:29:42,527 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.55, ppl:   4.73, acc:   0.51, generation: 52.3096[sec], evaluation: 0.0000[sec]
2025-05-30 00:29:42,529 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:29:42,697 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/27500.ckpt
2025-05-30 00:29:42,715 - INFO - joeynmt.training - Example #0
2025-05-30 00:29:42,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:29:42,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:29:42,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'den', 'te', 'be@@', 'gr@@', 'ij@@', 'p@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'o@@', 'ach@@', 'en', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'g', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'ste', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'm@@', 'p@@', 'un@@', 't', 'is.', '</s>']
2025-05-30 00:29:42,718 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:29:42,718 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:29:42,718 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folië getoond om te veranden te begrijpen, dat de arcoachen die voor de artig miljoen jaar de grootste van 40 procent had om 40 procent gesmpunt is.
2025-05-30 00:29:42,718 - INFO - joeynmt.training - Example #1
2025-05-30 00:29:42,719 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:29:42,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:29:42,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'n@@', 'u@@', 'ur', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'k@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', '.', '</s>']
2025-05-30 00:29:42,720 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:29:42,720 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:29:42,720 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet sterk genoeg de nuur van dit speciale probleem uit, omdat het niet de dikkke probleem uit.
2025-05-30 00:29:42,720 - INFO - joeynmt.training - Example #2
2025-05-30 00:29:42,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:29:42,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:29:42,721 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:29:42,721 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:29:42,722 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:29:42,722 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape hart van onze wereldwijde klimaatsysteem.
2025-05-30 00:29:42,722 - INFO - joeynmt.training - Example #3
2025-05-30 00:29:42,722 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:29:42,722 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:29:42,722 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:29:42,723 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:29:42,723 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:29:42,724 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomers.
2025-05-30 00:29:42,724 - INFO - joeynmt.training - Example #4
2025-05-30 00:29:42,724 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:29:42,724 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:29:42,724 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'p@@', 'op@@', 'n@@', 'am@@', 'e', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:29:42,725 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:29:42,725 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:29:42,726 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik je laat zien is een tijdrapppopname wat er in de laatste 25 jaar gebeurd is.
2025-05-30 00:29:52,341 - INFO - joeynmt.training - Epoch   3, Step:    29100, Batch Loss:     1.491159, Batch Acc: 0.535337, Tokens per Sec:     7408, Lr: 0.000300
2025-05-30 00:30:01,350 - INFO - joeynmt.training - Epoch   3, Step:    29200, Batch Loss:     1.482322, Batch Acc: 0.523082, Tokens per Sec:     7986, Lr: 0.000300
2025-05-30 00:30:10,518 - INFO - joeynmt.training - Epoch   3, Step:    29300, Batch Loss:     1.591278, Batch Acc: 0.542860, Tokens per Sec:     7688, Lr: 0.000300
2025-05-30 00:30:19,622 - INFO - joeynmt.training - Epoch   3, Step:    29400, Batch Loss:     1.481143, Batch Acc: 0.530996, Tokens per Sec:     7766, Lr: 0.000300
2025-05-30 00:30:28,508 - INFO - joeynmt.training - Epoch   3, Step:    29500, Batch Loss:     1.554759, Batch Acc: 0.536351, Tokens per Sec:     8316, Lr: 0.000300
2025-05-30 00:30:28,508 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:30:28,509 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:31:14,183 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.54, ppl:   4.69, acc:   0.52, generation: 45.6272[sec], evaluation: 0.0000[sec]
2025-05-30 00:31:14,184 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:31:14,348 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/28000.ckpt
2025-05-30 00:31:14,364 - INFO - joeynmt.training - Example #0
2025-05-30 00:31:14,365 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:31:14,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:31:14,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'on@@', 'nen', 'te', 'be@@', 'gr@@', 'ij@@', 'p@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'ste', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'st@@', 'aat', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'm@@', 'p@@', 't', 'is.', '</s>']
2025-05-30 00:31:14,366 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:31:14,367 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:31:14,368 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te begonnen te begrijpen, dat de artische ijskappen, die voor de miljoen jaar de grootste van 40 procent van 40 procent staat om 40 procent te gesmpt is.
2025-05-30 00:31:14,368 - INFO - joeynmt.training - Example #1
2025-05-30 00:31:14,368 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:31:14,368 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:31:14,368 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'n@@', 'eer@@', 'st@@', ',', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'er', 'niet', 'de', 'di@@', 'k@@', 'k@@', 'er', 'uit@@', '.', '</s>']
2025-05-30 00:31:14,369 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:31:14,370 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:31:14,370 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aarde neerst, dat het speciale probleem er niet de dikker uit.
2025-05-30 00:31:14,370 - INFO - joeynmt.training - Example #2
2025-05-30 00:31:14,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:31:14,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:31:14,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'st@@', 'el@@', 'sel@@', '.', '</s>']
2025-05-30 00:31:14,371 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:31:14,372 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:31:14,372 - INFO - joeynmt.training - 	Hypothesis: In zekere zin de artische ijskape ijs het slagende hart van onze wereldwijde klimaatstelsel.
2025-05-30 00:31:14,372 - INFO - joeynmt.training - Example #3
2025-05-30 00:31:14,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:31:14,372 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:31:14,372 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:31:14,373 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:31:14,373 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:31:14,374 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zomers.
2025-05-30 00:31:14,374 - INFO - joeynmt.training - Example #4
2025-05-30 00:31:14,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:31:14,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:31:14,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'dat', 'een', 'tij@@', 'd@@', 'ra@@', 'gen', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:31:14,375 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:31:14,375 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:31:14,375 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik jullie laat zien dat een tijdragen wat er in de afgelopen 25 jaar gebeurd is.
2025-05-30 00:31:23,195 - INFO - joeynmt.training - Epoch   3, Step:    29600, Batch Loss:     1.351295, Batch Acc: 0.533745, Tokens per Sec:     8180, Lr: 0.000300
2025-05-30 00:31:32,232 - INFO - joeynmt.training - Epoch   3, Step:    29700, Batch Loss:     1.533553, Batch Acc: 0.534256, Tokens per Sec:     7854, Lr: 0.000300
2025-05-30 00:31:41,380 - INFO - joeynmt.training - Epoch   3, Step:    29800, Batch Loss:     1.641433, Batch Acc: 0.531656, Tokens per Sec:     7877, Lr: 0.000300
2025-05-30 00:31:50,419 - INFO - joeynmt.training - Epoch   3, Step:    29900, Batch Loss:     1.596376, Batch Acc: 0.535753, Tokens per Sec:     7877, Lr: 0.000300
2025-05-30 00:31:59,361 - INFO - joeynmt.training - Epoch   3, Step:    30000, Batch Loss:     1.502510, Batch Acc: 0.529095, Tokens per Sec:     7913, Lr: 0.000300
2025-05-30 00:31:59,362 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:31:59,362 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:32:43,684 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.54, ppl:   4.69, acc:   0.52, generation: 44.2867[sec], evaluation: 0.0000[sec]
2025-05-30 00:32:43,685 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:32:43,862 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/27000.ckpt
2025-05-30 00:32:43,876 - INFO - joeynmt.training - Example #0
2025-05-30 00:32:43,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:32:43,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:32:43,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'l@@', 'aat', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'voor', 'de', 'be@@', 'ste', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-30 00:32:43,878 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:32:43,878 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:32:43,878 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folië laat zien dat de arctische ijskap, die artische ijskap, die voor de beste van de grootte van de 40 procent van de 40 procent van 40 procent gebeurt.
2025-05-30 00:32:43,878 - INFO - joeynmt.training - Example #1
2025-05-30 00:32:43,879 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:32:43,879 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:32:43,879 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'de', 'n@@', 'st@@', 'a@@', 'p', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', '-@@', 'k@@', 'a@@', 'p', 'van', 'de', 'ij@@', 's@@', 's', 'van', 'de', 'ij@@', 's@@', 'en.', '</s>']
2025-05-30 00:32:43,880 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:32:43,880 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:32:43,880 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aarde de nstap van dit specifieke probleem uit, omdat het niet de dick-kap van de ijss van de ijsen.
2025-05-30 00:32:43,880 - INFO - joeynmt.training - Example #2
2025-05-30 00:32:43,880 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:32:43,880 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:32:43,881 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'uit@@', 'z@@', 'onder@@', 'l@@', 'ijke', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:32:43,881 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:32:43,881 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:32:43,882 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape uitzonderlijke klimaatsysteem.
2025-05-30 00:32:43,882 - INFO - joeynmt.training - Example #3
2025-05-30 00:32:43,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:32:43,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:32:43,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'e@@', 'en@@', 's.', '</s>']
2025-05-30 00:32:43,883 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:32:43,883 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:32:43,883 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zeens.
2025-05-30 00:32:43,884 - INFO - joeynmt.training - Example #4
2025-05-30 00:32:43,884 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:32:43,884 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:32:43,884 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'k@@', 'ran@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:32:43,885 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:32:43,885 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:32:43,885 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik jullie laten zien, is een krant in de laatste 25 jaar gebeurt in de laatste 25 jaar gebeurd.
2025-05-30 00:32:52,294 - INFO - joeynmt.training - Epoch   3, Step:    30100, Batch Loss:     1.548444, Batch Acc: 0.537538, Tokens per Sec:     8293, Lr: 0.000300
2025-05-30 00:33:00,721 - INFO - joeynmt.training - Epoch   3, Step:    30200, Batch Loss:     1.415431, Batch Acc: 0.539151, Tokens per Sec:     9034, Lr: 0.000300
2025-05-30 00:33:08,721 - INFO - joeynmt.training - Epoch   3, Step:    30300, Batch Loss:     1.424988, Batch Acc: 0.539585, Tokens per Sec:     8922, Lr: 0.000300
2025-05-30 00:33:17,057 - INFO - joeynmt.training - Epoch   3, Step:    30400, Batch Loss:     1.619494, Batch Acc: 0.534815, Tokens per Sec:     8420, Lr: 0.000300
2025-05-30 00:33:25,665 - INFO - joeynmt.training - Epoch   3, Step:    30500, Batch Loss:     1.396338, Batch Acc: 0.534787, Tokens per Sec:     8570, Lr: 0.000300
2025-05-30 00:33:25,665 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:33:25,666 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:34:17,335 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.55, ppl:   4.69, acc:   0.52, generation: 51.6191[sec], evaluation: 0.0000[sec]
2025-05-30 00:34:17,509 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/26000.ckpt
2025-05-30 00:34:17,525 - INFO - joeynmt.training - Example #0
2025-05-30 00:34:17,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:34:17,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:34:17,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'den', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 00:34:17,526 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:34:17,527 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:34:17,527 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folië getoond om te veranden dat de artische ijskap, die voor de artische ijskap, die voor de grootte van de onderste 40 procent staten.
2025-05-30 00:34:17,527 - INFO - joeynmt.training - Example #1
2025-05-30 00:34:17,527 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:34:17,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:34:17,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'is', 'het', 'n@@', 'eer@@', 'st@@', 'e,', 'het', 'ge@@', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'er', 'uit@@', '.', '</s>']
2025-05-30 00:34:17,527 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:34:17,528 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:34:17,528 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aarde is het neerste, het gespeciale probleem uit, omdat het niet de diker uit.
2025-05-30 00:34:17,528 - INFO - joeynmt.training - Example #2
2025-05-30 00:34:17,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:34:17,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:34:17,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'man@@', 'ier', 'om', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'st@@', 'el@@', '.', '</s>']
2025-05-30 00:34:17,529 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:34:17,529 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:34:17,529 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape ijskape ijzondere manier om onze wereldwijde klimaatstel.
2025-05-30 00:34:17,530 - INFO - joeynmt.training - Example #3
2025-05-30 00:34:17,530 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:34:17,530 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:34:17,530 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:34:17,531 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:34:17,531 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:34:17,531 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich in de zomers.
2025-05-30 00:34:17,531 - INFO - joeynmt.training - Example #4
2025-05-30 00:34:17,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:34:17,532 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:34:17,532 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'ff@@', 'er@@', 'a@@', 'de@@', 'm@@', ',', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:34:17,533 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:34:17,533 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:34:17,533 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdrafferadem, wat er in de laatste 25 jaar gebeurd.
2025-05-30 00:34:26,451 - INFO - joeynmt.training - Epoch   3, Step:    30600, Batch Loss:     1.653405, Batch Acc: 0.532664, Tokens per Sec:     7980, Lr: 0.000300
2025-05-30 00:34:35,416 - INFO - joeynmt.training - Epoch   3, Step:    30700, Batch Loss:     1.571421, Batch Acc: 0.528126, Tokens per Sec:     8171, Lr: 0.000300
2025-05-30 00:34:44,480 - INFO - joeynmt.training - Epoch   3, Step:    30800, Batch Loss:     1.382991, Batch Acc: 0.536627, Tokens per Sec:     8162, Lr: 0.000300
2025-05-30 00:34:53,419 - INFO - joeynmt.training - Epoch   3, Step:    30900, Batch Loss:     1.450316, Batch Acc: 0.537477, Tokens per Sec:     8165, Lr: 0.000300
2025-05-30 00:35:02,330 - INFO - joeynmt.training - Epoch   3, Step:    31000, Batch Loss:     1.454046, Batch Acc: 0.534410, Tokens per Sec:     8299, Lr: 0.000300
2025-05-30 00:35:02,331 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:35:02,331 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:35:51,102 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.54, ppl:   4.66, acc:   0.52, generation: 48.7256[sec], evaluation: 0.0000[sec]
2025-05-30 00:35:51,103 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:35:51,275 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/28500.ckpt
2025-05-30 00:35:51,304 - INFO - joeynmt.training - Example #0
2025-05-30 00:35:51,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:35:51,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:35:51,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'g', 'is.', '</s>']
2025-05-30 00:35:51,307 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:35:51,307 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:35:51,307 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee folië getoond om te kijken dat de artische ijskape ijskape ijskape ijskape ijs van de onderste 40 procent van 40 procent van 40 procent van 40 procent geslag is.
2025-05-30 00:35:51,307 - INFO - joeynmt.training - Example #1
2025-05-30 00:35:51,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:35:51,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:35:51,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'is', 'van', 'deze', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'e', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 'ti@@', 'g', 'to@@', 'on@@', 't.', '</s>']
2025-05-30 00:35:51,308 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:35:51,308 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:35:51,309 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de aarde is van deze specifiek van dit specifiek probleem uit, omdat het niet de dikke dike van de ijskrachtig toont.
2025-05-30 00:35:51,309 - INFO - joeynmt.training - Example #2
2025-05-30 00:35:51,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:35:51,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:35:51,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'st@@', '.', '</s>']
2025-05-30 00:35:51,310 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:35:51,310 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:35:51,311 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape ijs het slagende hart van onze wereldwijde klimaatst.
2025-05-30 00:35:51,311 - INFO - joeynmt.training - Example #3
2025-05-30 00:35:51,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:35:51,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:35:51,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'aa@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:35:51,312 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:35:51,312 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:35:51,313 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zaampt in de zomers.
2025-05-30 00:35:51,313 - INFO - joeynmt.training - Example #4
2025-05-30 00:35:51,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:35:51,313 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:35:51,313 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'dat', 'ik', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'p@@', 'op@@', 'n@@', 'am@@', 'e', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:35:51,314 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:35:51,314 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:35:51,314 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien dat ik een tijdrapppopname van de laatste 25 jaar gebeurd.
2025-05-30 00:36:00,181 - INFO - joeynmt.training - Epoch   3, Step:    31100, Batch Loss:     1.446401, Batch Acc: 0.544313, Tokens per Sec:     8006, Lr: 0.000300
2025-05-30 00:36:08,983 - INFO - joeynmt.training - Epoch   3, Step:    31200, Batch Loss:     1.511977, Batch Acc: 0.534300, Tokens per Sec:     7722, Lr: 0.000300
2025-05-30 00:36:18,058 - INFO - joeynmt.training - Epoch   3, Step:    31300, Batch Loss:     1.309981, Batch Acc: 0.535686, Tokens per Sec:     7858, Lr: 0.000300
2025-05-30 00:36:26,833 - INFO - joeynmt.training - Epoch   3, Step:    31400, Batch Loss:     1.495662, Batch Acc: 0.534043, Tokens per Sec:     8082, Lr: 0.000300
2025-05-30 00:36:34,842 - INFO - joeynmt.training - Epoch   3, Step:    31500, Batch Loss:     1.420519, Batch Acc: 0.535820, Tokens per Sec:     9009, Lr: 0.000300
2025-05-30 00:36:34,843 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:36:34,843 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:37:21,214 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.64, acc:   0.52, generation: 46.3219[sec], evaluation: 0.0000[sec]
2025-05-30 00:37:21,215 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:37:21,375 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/29000.ckpt
2025-05-30 00:37:21,392 - INFO - joeynmt.training - Example #0
2025-05-30 00:37:21,392 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:37:21,393 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:37:21,393 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'vol@@', 'gen', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'c@@', 'a@@', 'de@@', 'm@@', 'ische', 'ij@@', 'z@@', 'onder@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'voor', 'de', 'onder@@', 'ste', 'van', 'de', 'onder@@', 'ste', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'm@@', 'p@@', 'er', 'is.', '</s>']
2025-05-30 00:37:21,394 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:37:21,394 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:37:21,394 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolgen om te verbeteren dat de articademische ijzondere ijskapen die voor de onderste van de onderste van de grootte van de grootte van de 40 procent gesmper is.
2025-05-30 00:37:21,394 - INFO - joeynmt.training - Example #1
2025-05-30 00:37:21,395 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:37:21,395 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:37:21,395 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'het', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'e', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 00:37:21,396 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:37:21,396 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:37:21,396 - INFO - joeynmt.training - 	Hypothesis: Maar dit is het niet sterk genoeg de eerste van dit specifiek van dit specifiek uit, omdat het niet de dike van het ijs laat zien.
2025-05-30 00:37:21,397 - INFO - joeynmt.training - Example #2
2025-05-30 00:37:21,397 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:37:21,397 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:37:21,397 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'ig@@', 'l@@', 'ijke', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:37:21,398 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:37:21,398 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:37:21,398 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuiglijke ijskape ijzondere ijzondere klimaatsysteem.
2025-05-30 00:37:21,398 - INFO - joeynmt.training - Example #3
2025-05-30 00:37:21,398 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:37:21,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:37:21,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'g@@', ',', 'en', 'z@@', 'or@@', 'g@@', 'aan@@', '.', '</s>']
2025-05-30 00:37:21,400 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:37:21,400 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:37:21,400 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zorg, en zorgaan.
2025-05-30 00:37:21,400 - INFO - joeynmt.training - Example #4
2025-05-30 00:37:21,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:37:21,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:37:21,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'di@@', 'en@@', 'st@@', 'ri@@', 'b@@', 'u@@', 'i@@', 'ten', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:37:21,401 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:37:21,401 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:37:21,402 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsdienstribuiten in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurd.
2025-05-30 00:37:29,547 - INFO - joeynmt.training - Epoch   3, Step:    31600, Batch Loss:     1.603078, Batch Acc: 0.538233, Tokens per Sec:     8554, Lr: 0.000300
2025-05-30 00:37:37,488 - INFO - joeynmt.training - Epoch   3, Step:    31700, Batch Loss:     1.417617, Batch Acc: 0.533830, Tokens per Sec:     8973, Lr: 0.000300
2025-05-30 00:37:46,104 - INFO - joeynmt.training - Epoch   3, Step:    31800, Batch Loss:     1.418345, Batch Acc: 0.541127, Tokens per Sec:     8254, Lr: 0.000300
2025-05-30 00:37:48,530 - INFO - joeynmt.training - Epoch   3: total training loss 15881.84
2025-05-30 00:37:48,531 - INFO - joeynmt.training - EPOCH 4
2025-05-30 00:37:55,041 - INFO - joeynmt.training - Epoch   4, Step:    31900, Batch Loss:     1.407693, Batch Acc: 0.554679, Tokens per Sec:     8183, Lr: 0.000300
2025-05-30 00:38:04,269 - INFO - joeynmt.training - Epoch   4, Step:    32000, Batch Loss:     1.575653, Batch Acc: 0.550590, Tokens per Sec:     7886, Lr: 0.000300
2025-05-30 00:38:04,269 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:38:04,269 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:38:50,558 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.63, acc:   0.52, generation: 46.2429[sec], evaluation: 0.0000[sec]
2025-05-30 00:38:50,559 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:38:50,718 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/30500.ckpt
2025-05-30 00:38:50,735 - INFO - joeynmt.training - Example #0
2025-05-30 00:38:50,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:38:50,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:38:50,737 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 't', 'om', 'te', 'ver@@', 'an@@', 'der', 'te', 'k@@', 'ijk@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'aat', 'te', 'ge@@', 's@@', 'me@@', 'ensch@@', 'ap@@', 'p@@', 'er', 'is', '4@@', '%', 'ge@@', 's@@', 'm@@', 'p@@', 'u@@', 'ur', 'ge@@', 's@@', 'm@@', 'p@@', 'u@@', 'ur', 'is.', '</s>']
2025-05-30 00:38:50,738 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:38:50,738 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:38:50,739 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toont om te verander te kijken, dat de artische ijskape ijskape ijskape ijskape 48 staten, om 48 staat te gesmeenschapper is 4% gesmpuur gesmpuur is.
2025-05-30 00:38:50,739 - INFO - joeynmt.training - Example #1
2025-05-30 00:38:50,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:38:50,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:38:50,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'st@@', 'h@@', 'af@@', 'gel@@', 'op@@', 'en', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'j@@', 'es', 'van', 'de', 'ij@@', 's@@', 'j@@', 'es', 'van', 'de', 'ij@@', 's@@', 'j@@', 'es', 'van', 'de', 'ij@@', 's@@', 'j@@', 'es', 'zi@@', 'en.', '</s>']
2025-05-30 00:38:50,740 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:38:50,740 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:38:50,740 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste sthafgelopen van dit speciale probleem uit, omdat het niet de dikke van de ijsjes van de ijsjes van de ijsjes van de ijsjes zien.
2025-05-30 00:38:50,741 - INFO - joeynmt.training - Example #2
2025-05-30 00:38:50,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:38:50,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:38:50,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'z@@', 'oe@@', 'k', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:38:50,742 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:38:50,742 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:38:50,742 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape ijzondere zoek van onze wereldwijde klimaatsysteem.
2025-05-30 00:38:50,742 - INFO - joeynmt.training - Example #3
2025-05-30 00:38:50,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:38:50,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:38:50,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:38:50,744 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:38:50,744 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:38:50,744 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en scheppt in de zomers.
2025-05-30 00:38:50,744 - INFO - joeynmt.training - Example #4
2025-05-30 00:38:50,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:38:50,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:38:50,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:38:50,745 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:38:50,746 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:38:50,746 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdperk in de laatste 25 jaar gebeurd.
2025-05-30 00:39:00,223 - INFO - joeynmt.training - Epoch   4, Step:    32100, Batch Loss:     1.400540, Batch Acc: 0.551473, Tokens per Sec:     7765, Lr: 0.000300
2025-05-30 00:39:09,129 - INFO - joeynmt.training - Epoch   4, Step:    32200, Batch Loss:     1.398340, Batch Acc: 0.543576, Tokens per Sec:     8157, Lr: 0.000300
2025-05-30 00:39:17,924 - INFO - joeynmt.training - Epoch   4, Step:    32300, Batch Loss:     1.598166, Batch Acc: 0.546226, Tokens per Sec:     8225, Lr: 0.000300
2025-05-30 00:39:27,085 - INFO - joeynmt.training - Epoch   4, Step:    32400, Batch Loss:     1.437490, Batch Acc: 0.547725, Tokens per Sec:     7946, Lr: 0.000300
2025-05-30 00:39:36,064 - INFO - joeynmt.training - Epoch   4, Step:    32500, Batch Loss:     1.478355, Batch Acc: 0.538339, Tokens per Sec:     8041, Lr: 0.000300
2025-05-30 00:39:36,065 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:39:36,066 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:40:22,118 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.63, acc:   0.52, generation: 46.0081[sec], evaluation: 0.0000[sec]
2025-05-30 00:40:22,119 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:40:22,291 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/29500.ckpt
2025-05-30 00:40:22,309 - INFO - joeynmt.training - Example #0
2025-05-30 00:40:22,310 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:40:22,310 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:40:22,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'der', 'te', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'c@@', 'ul@@', 't@@', 'ur@@', 'en', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8@@', '0@@', '%', 'van', '4@@', '0@@', '%', 'ge@@', 's@@', 'me@@', 'e@@', 'st', 'ge@@', 's@@', 'lo@@', 'ten', 'ha@@', 'd', 'ge@@', 's@@', 'lo@@', 'ten', 'om', '4@@', '0@@', '%', 'ge@@', 's@@', 'lo@@', 'ten', 'te', 'ge@@', 's@@', 'lo@@', 'ten', 'in', 'de', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 's@@', 'lo@@', 'ten', 'in', 'de', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 's@@', 'lo@@', 'ten', 'te', 'ge@@', 's@@', 'lo@@', 'ten', 'dat', 'de', 'ar@@', 'c@@', 'ent@@', 'r@@', 'aal', 'van', 'de', 'st@@', 'aten', 'van', 'de', 'onder@@']
2025-05-30 00:40:22,311 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:40:22,312 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:40:22,312 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te verander te kijken dat de arcticulturen voor de grootte van drie miljoenen jaar de grootte van de onderste 480% van 40% gesmeest gesloten had gesloten om 40% gesloten te gesloten in de staten had gesloten in de staten had gesloten te gesloten dat de arcentraal van de staten van de onder
2025-05-30 00:40:22,312 - INFO - joeynmt.training - Example #1
2025-05-30 00:40:22,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:40:22,313 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:40:22,313 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'p@@', 'un@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'de', 'ij@@', 's@@', 'es', 'van', 'het', 'ij@@', 's', 'van', 'de', 'ij@@', 's@@', 'es', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'heid', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's@@', 'heid', 'van', 'het', 'ij@@', 's@@', 'es', 'l@@', 'aten', 'zi@@', 'en.', '</s>']
2025-05-30 00:40:22,314 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:40:22,314 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:40:22,314 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van het punt van dit speciale probleem, omdat het niet de dikke van het ijs van de ijses van het ijs van de ijses van het ijs laat zien van het ijs laat zien dat het niet de dikracht van het ijsheid van het ijs van het ijs van het ijs van het ijs van het ijs van het ijsheid van het ijses laten zien.
2025-05-30 00:40:22,315 - INFO - joeynmt.training - Example #2
2025-05-30 00:40:22,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:40:22,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:40:22,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'c@@', 'ul@@', 't@@', 'es', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'st@@', '.', '</s>']
2025-05-30 00:40:22,316 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:40:22,316 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:40:22,316 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de articultes van onze wereldwijde hart van onze wereldwijde klimaatst.
2025-05-30 00:40:22,316 - INFO - joeynmt.training - Example #3
2025-05-30 00:40:22,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:40:22,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:40:22,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 's@@', 'm@@', 'p@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:40:22,319 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:40:22,319 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:40:22,319 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en smper in de zomers.
2025-05-30 00:40:22,319 - INFO - joeynmt.training - Example #4
2025-05-30 00:40:22,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:40:22,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:40:22,320 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ver@@', 't@@', 'ellen', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:40:22,321 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:40:22,321 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:40:22,322 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je tonen is een tijdsvertellen wat er in de laatste 25 jaar gebeurd.
2025-05-30 00:40:31,093 - INFO - joeynmt.training - Epoch   4, Step:    32600, Batch Loss:     1.456708, Batch Acc: 0.549247, Tokens per Sec:     7947, Lr: 0.000300
2025-05-30 00:40:40,028 - INFO - joeynmt.training - Epoch   4, Step:    32700, Batch Loss:     1.426984, Batch Acc: 0.547481, Tokens per Sec:     8088, Lr: 0.000300
2025-05-30 00:40:49,045 - INFO - joeynmt.training - Epoch   4, Step:    32800, Batch Loss:     1.385624, Batch Acc: 0.544614, Tokens per Sec:     7932, Lr: 0.000300
2025-05-30 00:40:58,052 - INFO - joeynmt.training - Epoch   4, Step:    32900, Batch Loss:     1.415521, Batch Acc: 0.548008, Tokens per Sec:     8294, Lr: 0.000300
2025-05-30 00:41:06,845 - INFO - joeynmt.training - Epoch   4, Step:    33000, Batch Loss:     1.433334, Batch Acc: 0.541575, Tokens per Sec:     7826, Lr: 0.000300
2025-05-30 00:41:06,845 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:41:06,846 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:41:57,294 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.64, acc:   0.52, generation: 50.4018[sec], evaluation: 0.0000[sec]
2025-05-30 00:41:57,456 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/30000.ckpt
2025-05-30 00:41:57,472 - INFO - joeynmt.training - Example #0
2025-05-30 00:41:57,473 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:41:57,473 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:41:57,473 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë@@', ',', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'on@@', 'der', 'de', 'onder@@', 'ste', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', '4@@', '8', 'st@@', 'aten', 'van', '4@@', '8@@', '0@@', '%', 'van', '4@@', '8@@', '%', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'm@@', 'p@@', 'er', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'm@@', 'p@@', 'un@@', 't', 'is.', '</s>']
2025-05-30 00:41:57,474 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:41:57,475 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:41:57,475 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folië, getoond om te verbeteren dat de arctische ijskappen, die voor onder de onderste van de onderste 48 staten van 48 staten van 480% van 48% van 40 procent gesmper van 40 procent gesmpunt is.
2025-05-30 00:41:57,475 - INFO - joeynmt.training - Example #1
2025-05-30 00:41:57,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:41:57,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:41:57,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ingen', 'van', 'dit', 'spe@@', 'ci@@', 'aal', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'e', 'd@@', 'ingen', 'zi@@', 'en.', '</s>']
2025-05-30 00:41:57,476 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:41:57,477 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:41:57,477 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de dingen van dit speciaal probleem uit, omdat het niet de dike dingen zien.
2025-05-30 00:41:57,477 - INFO - joeynmt.training - Example #2
2025-05-30 00:41:57,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:41:57,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:41:57,478 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'is.', '</s>']
2025-05-30 00:41:57,478 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:41:57,478 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:41:57,479 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape ijskape hart van onze wereldwijd van onze wereldwijd van onze wereldwijd is.
2025-05-30 00:41:57,479 - INFO - joeynmt.training - Example #3
2025-05-30 00:41:57,479 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:41:57,479 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:41:57,479 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 00:41:57,480 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:41:57,480 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:41:57,480 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schept in de zomer.
2025-05-30 00:41:57,480 - INFO - joeynmt.training - Example #4
2025-05-30 00:41:57,480 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:41:57,480 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:41:57,481 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 't@@', 'r@@', 'ein@@', ',', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:41:57,481 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:41:57,481 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:41:57,482 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik jullie laten zien, is een tijdrapportrein, wat er gebeurd is.
2025-05-30 00:42:06,211 - INFO - joeynmt.training - Epoch   4, Step:    33100, Batch Loss:     1.296584, Batch Acc: 0.539716, Tokens per Sec:     8085, Lr: 0.000300
2025-05-30 00:42:14,364 - INFO - joeynmt.training - Epoch   4, Step:    33200, Batch Loss:     1.395520, Batch Acc: 0.542675, Tokens per Sec:     8704, Lr: 0.000300
2025-05-30 00:42:23,004 - INFO - joeynmt.training - Epoch   4, Step:    33300, Batch Loss:     1.467223, Batch Acc: 0.547255, Tokens per Sec:     8545, Lr: 0.000300
2025-05-30 00:42:32,022 - INFO - joeynmt.training - Epoch   4, Step:    33400, Batch Loss:     1.365826, Batch Acc: 0.545042, Tokens per Sec:     7938, Lr: 0.000300
2025-05-30 00:42:41,040 - INFO - joeynmt.training - Epoch   4, Step:    33500, Batch Loss:     1.469954, Batch Acc: 0.548037, Tokens per Sec:     7706, Lr: 0.000300
2025-05-30 00:42:41,045 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:42:41,046 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:43:32,410 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.62, acc:   0.52, generation: 51.3201[sec], evaluation: 0.0000[sec]
2025-05-30 00:43:32,411 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:43:32,591 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/31000.ckpt
2025-05-30 00:43:32,607 - INFO - joeynmt.training - Example #0
2025-05-30 00:43:32,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:43:32,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:43:32,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ct@@', 'ie@@', 'f', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'die', 'voor', 'an@@', 'n@@', 'et@@', 'te', 'voor', 'an@@', 'n@@', 'et@@', 'te', 'van', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'be@@', 't@@', 'ro@@', 'k@@', 'ken', 'ha@@', 'd', 'ge@@', 'ï@@', 'n@@', 'ter@@', 'ess@@', 'eer@@', 'd', 'is.', '</s>']
2025-05-30 00:43:32,609 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:43:32,609 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:43:32,609 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verbeteren dat de arctief te begrijpen die voor annette voor annette van drie miljoen jaar de grootte van de grootte van 40 procent had om 40 procent te geslagen om 40 procent te betrokken had geïnteresseerd is.
2025-05-30 00:43:32,609 - INFO - joeynmt.training - Example #1
2025-05-30 00:43:32,609 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:43:32,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:43:32,610 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'ck@@', 'ale', 'pro@@', 'ble@@', 'em', 'l@@', 'aat', 'zien', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 00:43:32,610 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:43:32,610 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:43:32,611 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van het speciale probleem dat het niet de dikke dickale probleem laat zien dat het niet de dicke van het ijs laat zien.
2025-05-30 00:43:32,611 - INFO - joeynmt.training - Example #2
2025-05-30 00:43:32,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:43:32,611 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:43:32,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'de', 'wer@@', 'el@@', 'd.', '</s>']
2025-05-30 00:43:32,612 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:43:32,613 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:43:32,613 - INFO - joeynmt.training - 	Hypothesis: In zekere zin de arctische ijskape ijs het slagende hart van onze wereldwijd van onze wereldwijd van de wereld.
2025-05-30 00:43:32,613 - INFO - joeynmt.training - Example #3
2025-05-30 00:43:32,613 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:43:32,613 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:43:32,614 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:43:32,614 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:43:32,615 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:43:32,615 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en schept in het zomers.
2025-05-30 00:43:32,615 - INFO - joeynmt.training - Example #4
2025-05-30 00:43:32,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:43:32,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:43:32,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'ff@@', 'er@@', 'a@@', '.', '</s>']
2025-05-30 00:43:32,616 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:43:32,616 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:43:32,617 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik jullie laten zien is een tijdraffera.
2025-05-30 00:43:41,484 - INFO - joeynmt.training - Epoch   4, Step:    33600, Batch Loss:     1.500009, Batch Acc: 0.550550, Tokens per Sec:     7868, Lr: 0.000300
2025-05-30 00:43:50,569 - INFO - joeynmt.training - Epoch   4, Step:    33700, Batch Loss:     1.419569, Batch Acc: 0.548183, Tokens per Sec:     8138, Lr: 0.000300
2025-05-30 00:43:59,345 - INFO - joeynmt.training - Epoch   4, Step:    33800, Batch Loss:     1.371696, Batch Acc: 0.544510, Tokens per Sec:     7983, Lr: 0.000300
2025-05-30 00:44:08,108 - INFO - joeynmt.training - Epoch   4, Step:    33900, Batch Loss:     1.437797, Batch Acc: 0.542437, Tokens per Sec:     8263, Lr: 0.000300
2025-05-30 00:44:16,560 - INFO - joeynmt.training - Epoch   4, Step:    34000, Batch Loss:     1.372005, Batch Acc: 0.550156, Tokens per Sec:     8356, Lr: 0.000300
2025-05-30 00:44:16,560 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:44:16,560 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:45:09,025 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.61, acc:   0.52, generation: 52.4108[sec], evaluation: 0.0000[sec]
2025-05-30 00:45:09,026 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:45:09,203 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/31500.ckpt
2025-05-30 00:45:09,218 - INFO - joeynmt.training - Example #0
2025-05-30 00:45:09,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:45:09,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:45:09,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'die', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's', 'de', 'gro@@', 'ot@@', 'ste', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'g', 'in', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'g', 'is.', '</s>']
2025-05-30 00:45:09,220 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:45:09,220 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:45:09,221 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik die twee dia toonde artische ijskape ijskape ijskape ijskape ijs de grootste van 48 staten had 40 procent had om 40 procent te geslag in de onderste 40 procent geslag is.
2025-05-30 00:45:09,221 - INFO - joeynmt.training - Example #1
2025-05-30 00:45:09,221 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:45:09,221 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:45:09,221 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ingen', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', 'dat', 'het', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', 'dat', 'het', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', '.', '</s>']
2025-05-30 00:45:09,222 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:45:09,222 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:45:09,223 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de eerste van dit specifiek probleem uit, omdat het niet de dikke dingen van het ijs laat zien dat het het ijs laat zien dat het het ijs laat zien van het ijs toon.
2025-05-30 00:45:09,223 - INFO - joeynmt.training - Example #2
2025-05-30 00:45:09,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:45:09,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:45:09,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:45:09,224 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:45:09,224 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:45:09,224 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape ijskape van ons wereldwijde klimaatsysteem.
2025-05-30 00:45:09,224 - INFO - joeynmt.training - Example #3
2025-05-30 00:45:09,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:45:09,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:45:09,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'oe@@', 'k', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:45:09,226 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:45:09,226 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:45:09,226 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zoek in de zomers.
2025-05-30 00:45:09,226 - INFO - joeynmt.training - Example #4
2025-05-30 00:45:09,227 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:45:09,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:45:09,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 't@@', 'ing', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:45:09,227 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:45:09,227 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:45:09,227 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrapporting in de laatste 25 jaar gebeurd is.
2025-05-30 00:45:18,245 - INFO - joeynmt.training - Epoch   4, Step:    34100, Batch Loss:     1.422503, Batch Acc: 0.540068, Tokens per Sec:     7754, Lr: 0.000300
2025-05-30 00:45:27,399 - INFO - joeynmt.training - Epoch   4, Step:    34200, Batch Loss:     1.409916, Batch Acc: 0.544391, Tokens per Sec:     8082, Lr: 0.000300
2025-05-30 00:45:36,441 - INFO - joeynmt.training - Epoch   4, Step:    34300, Batch Loss:     1.365034, Batch Acc: 0.548754, Tokens per Sec:     7866, Lr: 0.000300
2025-05-30 00:45:45,489 - INFO - joeynmt.training - Epoch   4, Step:    34400, Batch Loss:     1.565984, Batch Acc: 0.548437, Tokens per Sec:     8045, Lr: 0.000300
2025-05-30 00:45:54,430 - INFO - joeynmt.training - Epoch   4, Step:    34500, Batch Loss:     1.394519, Batch Acc: 0.542814, Tokens per Sec:     7899, Lr: 0.000300
2025-05-30 00:45:54,432 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:45:54,432 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:46:45,496 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.61, acc:   0.52, generation: 51.0202[sec], evaluation: 0.0000[sec]
2025-05-30 00:46:45,664 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/33000.ckpt
2025-05-30 00:46:45,681 - INFO - joeynmt.training - Example #0
2025-05-30 00:46:45,682 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:46:45,682 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:46:45,682 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'l@@', 'aat', 'zien', 'dat', 'de', 'ar@@', 'ct@@', 'ie@@', 'ke', 'ij@@', 'z@@', 'onder@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'et@@', 'e@@', 'ens', 'van', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'st@@', 'at@@', 'ies', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 'k@@', 'rij@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'g', 'is.', '</s>']
2025-05-30 00:46:45,683 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:46:45,683 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:46:45,684 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folië laat zien dat de arctieke ijzondere ijzondere ijzondere ijzondere ijzondere eteens van drie miljoen jaar de grootte van 40 procent staties had om 40 procent te had om 40 procent te verkrijgen om 40 procent te geslag is.
2025-05-30 00:46:45,684 - INFO - joeynmt.training - Example #1
2025-05-30 00:46:45,684 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:46:45,684 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:46:45,684 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'de', 'eer@@', 'ste', 'st@@', 'h@@', 'af@@', 'v@@', 'al', 'van', 'het', 'spe@@', 'ci@@', 'aal', 'van', 'het', 'spe@@', 'ci@@', 'aal', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 00:46:45,685 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:46:45,688 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:46:45,688 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van de eerste sthafval van het speciaal van het speciaal van het ijs laat zien.
2025-05-30 00:46:45,689 - INFO - joeynmt.training - Example #2
2025-05-30 00:46:45,689 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:46:45,689 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:46:45,689 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'man@@', 'ier', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:46:45,690 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:46:45,690 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:46:45,690 - INFO - joeynmt.training - 	Hypothesis: In zekere zin de artische ijskape ijzondere manier van ons wereldwijde klimaatsysteem.
2025-05-30 00:46:45,690 - INFO - joeynmt.training - Example #3
2025-05-30 00:46:45,691 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:46:45,691 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:46:45,691 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:46:45,692 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:46:45,692 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:46:45,692 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen in de winter en zich in de zomers.
2025-05-30 00:46:45,692 - INFO - joeynmt.training - Example #4
2025-05-30 00:46:45,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:46:45,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:46:45,693 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'op@@', 'n@@', 'am@@', 'e', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:46:45,693 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:46:45,694 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:46:45,694 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdrappopname wat er in de afgelopen 25 jaar gebeurd is.
2025-05-30 00:46:53,845 - INFO - joeynmt.training - Epoch   4, Step:    34600, Batch Loss:     1.332273, Batch Acc: 0.546180, Tokens per Sec:     8796, Lr: 0.000300
2025-05-30 00:47:01,866 - INFO - joeynmt.training - Epoch   4, Step:    34700, Batch Loss:     1.534876, Batch Acc: 0.547409, Tokens per Sec:     9094, Lr: 0.000300
2025-05-30 00:47:10,785 - INFO - joeynmt.training - Epoch   4, Step:    34800, Batch Loss:     1.462355, Batch Acc: 0.546991, Tokens per Sec:     8089, Lr: 0.000300
2025-05-30 00:47:19,706 - INFO - joeynmt.training - Epoch   4, Step:    34900, Batch Loss:     1.526278, Batch Acc: 0.544125, Tokens per Sec:     8285, Lr: 0.000300
2025-05-30 00:47:28,225 - INFO - joeynmt.training - Epoch   4, Step:    35000, Batch Loss:     1.466349, Batch Acc: 0.549515, Tokens per Sec:     8378, Lr: 0.000300
2025-05-30 00:47:28,226 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:47:28,226 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:48:13,940 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.58, acc:   0.52, generation: 45.6637[sec], evaluation: 0.0000[sec]
2025-05-30 00:48:13,941 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:48:14,115 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/32000.ckpt
2025-05-30 00:48:14,129 - INFO - joeynmt.training - Example #0
2025-05-30 00:48:14,130 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:48:14,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:48:14,130 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'voor', 'de', 'sch@@', 'aal', 'van', 'de', 'gro@@', 'ot@@', 'ste', 'p@@', 'un@@', 't', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'te', 'ge@@', 's@@', 'me@@', 'e@@', 'ste', 'ge@@', 's@@', 'm@@', 'p@@', 'er', 'is.', '</s>']
2025-05-30 00:48:14,131 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:48:14,132 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:48:14,132 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's toonde ik deze twee miljoen jaar de arctische ijskapen die voor de schaal van de grootste punt van de grootte van 48 staten had om 48 staten had 48 staten had om 48 staten had te gesmeeste gesmper is.
2025-05-30 00:48:14,132 - INFO - joeynmt.training - Example #1
2025-05-30 00:48:14,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:48:14,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:48:14,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 're@@', 's@@', 'ul@@', 't@@', 'aa@@', 't.', '</s>']
2025-05-30 00:48:14,133 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:48:14,133 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:48:14,134 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de resultaat.
2025-05-30 00:48:14,134 - INFO - joeynmt.training - Example #2
2025-05-30 00:48:14,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:48:14,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:48:14,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'c@@', 'l@@', 'i@@', 'p@@', 'p@@', 'el@@', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:48:14,135 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:48:14,135 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:48:14,135 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape ijskape clippelslagen van onze wereldwijde klimaatsysteem.
2025-05-30 00:48:14,135 - INFO - joeynmt.training - Example #3
2025-05-30 00:48:14,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:48:14,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:48:14,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:48:14,137 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:48:14,137 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:48:14,137 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppt in de zomers.
2025-05-30 00:48:14,137 - INFO - joeynmt.training - Example #4
2025-05-30 00:48:14,137 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:48:14,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:48:14,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'k@@', 'ra@@', 'cht@@', 'ige', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:48:14,139 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:48:14,140 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:48:14,140 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tijdskrachtige wat er in de laatste 25 jaar gebeurd is.
2025-05-30 00:48:23,066 - INFO - joeynmt.training - Epoch   4, Step:    35100, Batch Loss:     1.443998, Batch Acc: 0.545301, Tokens per Sec:     7921, Lr: 0.000300
2025-05-30 00:48:32,119 - INFO - joeynmt.training - Epoch   4, Step:    35200, Batch Loss:     1.420679, Batch Acc: 0.546038, Tokens per Sec:     7988, Lr: 0.000300
2025-05-30 00:48:41,272 - INFO - joeynmt.training - Epoch   4, Step:    35300, Batch Loss:     1.600110, Batch Acc: 0.546324, Tokens per Sec:     8113, Lr: 0.000300
2025-05-30 00:48:50,183 - INFO - joeynmt.training - Epoch   4, Step:    35400, Batch Loss:     1.399131, Batch Acc: 0.541640, Tokens per Sec:     7908, Lr: 0.000300
2025-05-30 00:48:59,712 - INFO - joeynmt.training - Epoch   4, Step:    35500, Batch Loss:     1.418487, Batch Acc: 0.544974, Tokens per Sec:     7526, Lr: 0.000300
2025-05-30 00:48:59,712 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:48:59,713 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:49:51,486 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.58, acc:   0.52, generation: 51.7275[sec], evaluation: 0.0000[sec]
2025-05-30 00:49:51,655 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/32500.ckpt
2025-05-30 00:49:51,673 - INFO - joeynmt.training - Example #0
2025-05-30 00:49:51,674 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:49:51,674 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:49:51,674 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'voor', 'de', 'onder@@', 'wij@@', 's', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8@@', '0', 'pro@@', 'c@@', 'ent', 'st@@', 'at@@', 'en,', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 's@@', 'n@@', 'ap@@', 't', 'te', 'k@@', 'rij@@', 'gen.', '</s>']
2025-05-30 00:49:51,675 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:49:51,675 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:49:51,675 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee miljoen jaar de artische ijskap, die voor de onderwijs miljoen jaar de grootte van de onderste 48 staten, om 480 procent staten, om 40 procent te snapt te krijgen.
2025-05-30 00:49:51,675 - INFO - joeynmt.training - Example #1
2025-05-30 00:49:51,676 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:49:51,676 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:49:51,676 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'de', 'eer@@', 'ste', 'st@@', 'h@@', 'af@@', 'gel@@', 'op@@', 'en', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 00:49:51,677 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:49:51,677 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:49:51,678 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste van de eerste sthafgelopen van dit specifieke probleem laat zien.
2025-05-30 00:49:51,678 - INFO - joeynmt.training - Example #2
2025-05-30 00:49:51,678 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:49:51,678 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:49:51,678 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:49:51,679 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:49:51,680 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:49:51,680 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape ijskape het slagende hart van onze wereldwijd klimaatsysteem.
2025-05-30 00:49:51,680 - INFO - joeynmt.training - Example #3
2025-05-30 00:49:51,680 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:49:51,680 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:49:51,680 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'g@@', ',', 'en', 'z@@', 'e@@', 'v@@', 'en@@', 'w@@', 'icht', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'g@@', 'aan@@', '.', '</s>']
2025-05-30 00:49:51,681 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:49:51,681 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:49:51,681 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorg, en zevenwicht in de winter en zorgaan.
2025-05-30 00:49:51,682 - INFO - joeynmt.training - Example #4
2025-05-30 00:49:51,682 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:49:51,682 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:49:51,682 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'p@@', 'er', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:49:51,683 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:49:51,683 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:49:51,683 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrappper 25 jaar gebeurd in de afgelopen 25 jaar gebeurd is.
2025-05-30 00:50:00,475 - INFO - joeynmt.training - Epoch   4, Step:    35600, Batch Loss:     1.378410, Batch Acc: 0.555607, Tokens per Sec:     8139, Lr: 0.000300
2025-05-30 00:50:09,265 - INFO - joeynmt.training - Epoch   4, Step:    35700, Batch Loss:     1.179251, Batch Acc: 0.546789, Tokens per Sec:     8228, Lr: 0.000300
2025-05-30 00:50:18,369 - INFO - joeynmt.training - Epoch   4, Step:    35800, Batch Loss:     1.582254, Batch Acc: 0.544643, Tokens per Sec:     8044, Lr: 0.000300
2025-05-30 00:50:27,440 - INFO - joeynmt.training - Epoch   4, Step:    35900, Batch Loss:     1.362314, Batch Acc: 0.539980, Tokens per Sec:     7559, Lr: 0.000300
2025-05-30 00:50:36,383 - INFO - joeynmt.training - Epoch   4, Step:    36000, Batch Loss:     1.418124, Batch Acc: 0.543939, Tokens per Sec:     7970, Lr: 0.000300
2025-05-30 00:50:36,386 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:50:36,386 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:51:23,151 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.57, acc:   0.52, generation: 46.7261[sec], evaluation: 0.0000[sec]
2025-05-30 00:51:23,153 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:51:23,320 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/33500.ckpt
2025-05-30 00:51:23,335 - INFO - joeynmt.training - Example #0
2025-05-30 00:51:23,336 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:51:23,337 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:51:23,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'l@@', 'aat', 'zien', 'zien', 'dat', 'de', 'ar@@', 'ct@@', 'ie@@', 've', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 's', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '%', 'st@@', 'at@@', 'en,', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'm@@', 'p@@', 'un@@', 't', 'voor', '4@@', '%', 'ge@@', 's@@', 'm@@', 'p@@', 'el@@', 'd.', '</s>']
2025-05-30 00:51:23,338 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:51:23,338 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:51:23,338 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laat zien zien dat de arctieve ijskappe ijskappe ijskappe ijskape ijskappels de grootte van 4% staten, om 40 procent te gesmpunt voor 4% gesmpeld.
2025-05-30 00:51:23,339 - INFO - joeynmt.training - Example #1
2025-05-30 00:51:23,339 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:51:23,339 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:51:23,339 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'aar', 'de', 'eer@@', 'ste', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'e', 'pro@@', 'ble@@', 'em', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 00:51:23,340 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:51:23,340 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:51:23,340 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste paar de eerste van dit specifieke probleem uit, omdat het niet de dike probleem laat zien.
2025-05-30 00:51:23,341 - INFO - joeynmt.training - Example #2
2025-05-30 00:51:23,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:51:23,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:51:23,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ct@@', 'ie@@', 've', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's', 'het', 'sl@@', 'ag@@', 'gen@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:51:23,342 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:51:23,342 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:51:23,342 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctieve ijskape ijs het slaggene hart van onze wereldwijde klimaatsysteem.
2025-05-30 00:51:23,342 - INFO - joeynmt.training - Example #3
2025-05-30 00:51:23,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:51:23,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:51:23,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'g@@', 'aan@@', '.', '</s>']
2025-05-30 00:51:23,344 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:51:23,344 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:51:23,344 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zorgaan.
2025-05-30 00:51:23,344 - INFO - joeynmt.training - Example #4
2025-05-30 00:51:23,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:51:23,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:51:23,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'op@@', 'n@@', 'am@@', 'e', 'ge@@', 'be@@', 'ur@@', 'd', 'is', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:51:23,345 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:51:23,346 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:51:23,346 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdrappopname gebeurd is in de laatste 25 jaar gebeurd.
2025-05-30 00:51:32,266 - INFO - joeynmt.training - Epoch   4, Step:    36100, Batch Loss:     1.211799, Batch Acc: 0.545787, Tokens per Sec:     7991, Lr: 0.000300
2025-05-30 00:51:40,442 - INFO - joeynmt.training - Epoch   4, Step:    36200, Batch Loss:     1.378556, Batch Acc: 0.547084, Tokens per Sec:     8968, Lr: 0.000300
2025-05-30 00:51:48,559 - INFO - joeynmt.training - Epoch   4, Step:    36300, Batch Loss:     1.495730, Batch Acc: 0.544356, Tokens per Sec:     8932, Lr: 0.000300
2025-05-30 00:51:56,869 - INFO - joeynmt.training - Epoch   4, Step:    36400, Batch Loss:     1.428911, Batch Acc: 0.551350, Tokens per Sec:     8978, Lr: 0.000300
2025-05-30 00:52:05,085 - INFO - joeynmt.training - Epoch   4, Step:    36500, Batch Loss:     1.571602, Batch Acc: 0.548885, Tokens per Sec:     8660, Lr: 0.000300
2025-05-30 00:52:05,086 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:52:05,086 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:52:49,265 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.56, acc:   0.52, generation: 44.1142[sec], evaluation: 0.0000[sec]
2025-05-30 00:52:49,266 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:52:49,440 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/34500.ckpt
2025-05-30 00:52:49,449 - INFO - joeynmt.training - Example #0
2025-05-30 00:52:49,450 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:52:49,450 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:52:49,450 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'dat', 'de', 'ar@@', 'ti@@', 'c@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'at@@', 'u@@', 'ur', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'st@@', 'at@@', 'en,', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'st@@', 'at@@', 'en,', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'te', 'ge@@', 'ven', 'in', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', 'jaar', 'van', 'de', 'onder@@', 'ste', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'v@@', 'is@@', 'u@@', 'el@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@']
2025-05-30 00:52:49,451 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:52:49,451 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:52:49,451 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee jaar heb getoond om te begrijpen dat de arctische ijskappen, dat de articappe ijskapparatuur van de grootte van de onderste 40 procent staten, om 40 procent staten, om 40 procent te geslagen om 40 procent te geslagen te geven in de grootte van de onderste jaar van de onderste jaar de grootte van de visuele ijskapp
2025-05-30 00:52:49,452 - INFO - joeynmt.training - Example #1
2025-05-30 00:52:49,452 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:52:49,452 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:52:49,452 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'd@@', 'ru@@', 'k@@', 'k@@', 'ig', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'de', 'n@@', 'st@@', 'o@@', 'ff@@', 'en', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'ij@@', 's@@', 'en.', '</s>']
2025-05-30 00:52:49,453 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:52:49,453 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:52:49,454 - INFO - joeynmt.training - 	Hypothesis: Maar dat drukkig genoeg de aarde de nstoffen van het ijskracht uit, omdat het niet de dicke van het ijsen.
2025-05-30 00:52:49,454 - INFO - joeynmt.training - Example #2
2025-05-30 00:52:49,454 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:52:49,454 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:52:49,454 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:52:49,455 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:52:49,455 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:52:49,455 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape ijskape hart van onze wereldwijde klimaatsysteem.
2025-05-30 00:52:49,456 - INFO - joeynmt.training - Example #3
2025-05-30 00:52:49,456 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:52:49,456 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:52:49,456 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'g', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:52:49,458 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:52:49,458 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:52:49,458 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorg in het zomers.
2025-05-30 00:52:49,458 - INFO - joeynmt.training - Example #4
2025-05-30 00:52:49,458 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:52:49,458 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:52:49,459 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ge@@', 'me@@', 'ensch@@', 'ap@@', 'p@@', 'el@@', 'ijk', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:52:49,459 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:52:49,460 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:52:49,460 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsgemeenschappelijk wat er in de laatste 25 jaar gebeurd is.
2025-05-30 00:52:58,030 - INFO - joeynmt.training - Epoch   4, Step:    36600, Batch Loss:     1.548315, Batch Acc: 0.544464, Tokens per Sec:     8275, Lr: 0.000300
2025-05-30 00:53:06,562 - INFO - joeynmt.training - Epoch   4, Step:    36700, Batch Loss:     1.495616, Batch Acc: 0.544123, Tokens per Sec:     8404, Lr: 0.000300
2025-05-30 00:53:15,317 - INFO - joeynmt.training - Epoch   4, Step:    36800, Batch Loss:     1.592777, Batch Acc: 0.541567, Tokens per Sec:     8166, Lr: 0.000300
2025-05-30 00:53:23,685 - INFO - joeynmt.training - Epoch   4, Step:    36900, Batch Loss:     1.446221, Batch Acc: 0.550206, Tokens per Sec:     8542, Lr: 0.000300
2025-05-30 00:53:32,001 - INFO - joeynmt.training - Epoch   4, Step:    37000, Batch Loss:     1.420319, Batch Acc: 0.541939, Tokens per Sec:     8675, Lr: 0.000300
2025-05-30 00:53:32,001 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:53:32,001 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:54:17,394 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.54, acc:   0.52, generation: 45.3466[sec], evaluation: 0.0000[sec]
2025-05-30 00:54:17,395 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:54:17,575 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/34000.ckpt
2025-05-30 00:54:17,585 - INFO - joeynmt.training - Example #0
2025-05-30 00:54:17,585 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:54:17,586 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:54:17,586 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'dit', 'jaar', 'gel@@', 'e@@', 'den', 'l@@', 'aten', 'zien', 'dat', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 't', 'om', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'i@@', 'z@@', 'en@@', 'den', 'j@@', 'aar@@', ',', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'm@@', 'p@@', 'er', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'm@@', 'p@@', 'er', 'is.', '</s>']
2025-05-30 00:54:17,587 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:54:17,588 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:54:17,588 - INFO - joeynmt.training - 	Hypothesis: Ik heb dit jaar geleden laten zien dat ik deze twee dia toont om te begrijpen dat de arctische ijizenden jaar, de grootte van 40 procent van 40 procent van 40 procent gesmper van 40 procent gesmper is.
2025-05-30 00:54:17,588 - INFO - joeynmt.training - Example #1
2025-05-30 00:54:17,588 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:54:17,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:54:17,589 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'be@@', 'ste', 'is', 'dat', 'het', 'ge@@', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'niet', 'de', 'di@@', 'k@@', 'er', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'er', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 00:54:17,590 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:54:17,590 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:54:17,590 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van het beste is dat het gespecifieke probleem niet de diker uit, omdat het niet de diker laat zien.
2025-05-30 00:54:17,590 - INFO - joeynmt.training - Example #2
2025-05-30 00:54:17,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:54:17,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:54:17,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'er@@', 's', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:54:17,592 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:54:17,592 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:54:17,592 - INFO - joeynmt.training - 	Hypothesis: In zezekere zin is de artische ijskape ijzers van onze wereldwijde klimaatsysteem.
2025-05-30 00:54:17,592 - INFO - joeynmt.training - Example #3
2025-05-30 00:54:17,593 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:54:17,593 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:54:17,593 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'we@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:54:17,594 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:54:17,594 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:54:17,594 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zwempt in de winter zomers.
2025-05-30 00:54:17,594 - INFO - joeynmt.training - Example #4
2025-05-30 00:54:17,594 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:54:17,594 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:54:17,595 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'en@@', 'st', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'te@@', 'ken@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:54:17,595 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:54:17,595 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:54:17,596 - INFO - joeynmt.training - 	Hypothesis: De volgende dienst die ik jullie laten zien, is een tekent in de laatste 25 jaar gebeurd.
2025-05-30 00:54:26,195 - INFO - joeynmt.training - Epoch   4, Step:    37100, Batch Loss:     1.265031, Batch Acc: 0.543561, Tokens per Sec:     8159, Lr: 0.000300
2025-05-30 00:54:34,964 - INFO - joeynmt.training - Epoch   4, Step:    37200, Batch Loss:     1.334223, Batch Acc: 0.550714, Tokens per Sec:     8176, Lr: 0.000300
2025-05-30 00:54:43,689 - INFO - joeynmt.training - Epoch   4, Step:    37300, Batch Loss:     1.325904, Batch Acc: 0.549489, Tokens per Sec:     8351, Lr: 0.000300
2025-05-30 00:54:52,105 - INFO - joeynmt.training - Epoch   4, Step:    37400, Batch Loss:     1.439766, Batch Acc: 0.549784, Tokens per Sec:     8714, Lr: 0.000300
2025-05-30 00:55:00,535 - INFO - joeynmt.training - Epoch   4, Step:    37500, Batch Loss:     1.529152, Batch Acc: 0.540792, Tokens per Sec:     8417, Lr: 0.000300
2025-05-30 00:55:00,536 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:55:00,536 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:55:48,983 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.55, acc:   0.52, generation: 48.3973[sec], evaluation: 0.0000[sec]
2025-05-30 00:55:49,146 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/35500.ckpt
2025-05-30 00:55:49,161 - INFO - joeynmt.training - Example #0
2025-05-30 00:55:49,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:55:49,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:55:49,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 's@@', 'n@@', 'el@@', 'heid', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'k@@', 'ijk@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'on@@', 'der', '4@@', '8', 'st@@', 'aten', 'van', '4@@', '8', 'st@@', 'aten', 'van', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'g', 'was', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'k@@', 'rij@@', 'gen.', '</s>']
2025-05-30 00:55:49,163 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:55:49,163 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:55:49,163 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee snelheid om te beginnen te kijken, dat de arctische ijskappen, die voor onder 48 staten van 48 staten van 48 staten, om 48 staten had 40 procent geslag was om 40 procent te krijgen.
2025-05-30 00:55:49,163 - INFO - joeynmt.training - Example #1
2025-05-30 00:55:49,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:55:49,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:55:49,164 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'e', 'van', 'het', 'ij@@', 's@@', 'b@@', 'o@@', 'el@@', '.', '</s>']
2025-05-30 00:55:49,164 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:55:49,164 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:55:49,164 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt genoeg de snelheid van dit speciale probleem van dit speciale probleem uit, want het is niet de dike van het ijsboel.
2025-05-30 00:55:49,164 - INFO - joeynmt.training - Example #2
2025-05-30 00:55:49,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:55:49,165 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:55:49,165 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'en', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 00:55:49,165 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:55:49,165 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:55:49,165 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijen het slagen van onze wereldwijde klimaatsysteem.
2025-05-30 00:55:49,165 - INFO - joeynmt.training - Example #3
2025-05-30 00:55:49,165 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:55:49,165 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:55:49,165 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:55:49,165 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:55:49,166 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:55:49,166 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomers.
2025-05-30 00:55:49,166 - INFO - joeynmt.training - Example #4
2025-05-30 00:55:49,166 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:55:49,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:55:49,166 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'k@@', 'ran@@', 'ten@@', 'z@@', 'ij', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 00:55:49,166 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:55:49,167 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:55:49,167 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een krantenzij wat er in de afgelopen 25 jaar gebeurd.
2025-05-30 00:55:57,390 - INFO - joeynmt.training - Epoch   4, Step:    37600, Batch Loss:     1.507845, Batch Acc: 0.542853, Tokens per Sec:     8730, Lr: 0.000300
2025-05-30 00:56:05,210 - INFO - joeynmt.training - Epoch   4, Step:    37700, Batch Loss:     1.856779, Batch Acc: 0.547273, Tokens per Sec:     9033, Lr: 0.000300
2025-05-30 00:56:13,839 - INFO - joeynmt.training - Epoch   4, Step:    37800, Batch Loss:     1.209882, Batch Acc: 0.547311, Tokens per Sec:     8369, Lr: 0.000300
2025-05-30 00:56:22,135 - INFO - joeynmt.training - Epoch   4, Step:    37900, Batch Loss:     1.398218, Batch Acc: 0.547764, Tokens per Sec:     8876, Lr: 0.000300
2025-05-30 00:56:30,803 - INFO - joeynmt.training - Epoch   4, Step:    38000, Batch Loss:     1.646380, Batch Acc: 0.547501, Tokens per Sec:     8220, Lr: 0.000300
2025-05-30 00:56:30,804 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:56:30,804 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:57:15,319 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.53, acc:   0.52, generation: 44.4678[sec], evaluation: 0.0000[sec]
2025-05-30 00:57:15,320 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 00:57:15,514 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/35000.ckpt
2025-05-30 00:57:15,529 - INFO - joeynmt.training - Example #0
2025-05-30 00:57:15,530 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:57:15,531 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:57:15,531 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'nen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'te@@', 'men@@', 't', 'voor', 'de', 'sch@@', 'aal@@', 'de', 'die', 'voor', 'on@@', 'der', '4@@', '8', 'st@@', 'aten', 'van', '4@@', '8', 'st@@', 'aten', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 's@@', 'la@@', 'g', 'te', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 00:57:15,532 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:57:15,532 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:57:15,532 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik dat de arctische ijnen dat de arctische ijskappartement voor de schaalde die voor onder 48 staten van 48 staten van 48 staten had om 48 staten had om 48 staten had geslag te gebeuren.
2025-05-30 00:57:15,533 - INFO - joeynmt.training - Example #1
2025-05-30 00:57:15,534 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:57:15,534 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:57:15,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'is', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'b@@', 'aar@@', '.', '</s>']
2025-05-30 00:57:15,535 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:57:15,535 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:57:15,536 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg genoeg de aarde is dat het speciale probleem uit, omdat het speciale probleem, omdat het niet de dikke van het ijsbaar.
2025-05-30 00:57:15,536 - INFO - joeynmt.training - Example #2
2025-05-30 00:57:15,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:57:15,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:57:15,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijk', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'st@@', 'el@@', '.', '</s>']
2025-05-30 00:57:15,538 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:57:15,538 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:57:15,538 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe ijskappelijk hart van onze wereldwijde klimaatstel.
2025-05-30 00:57:15,539 - INFO - joeynmt.training - Example #3
2025-05-30 00:57:15,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:57:15,539 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:57:15,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'het', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:57:15,540 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:57:15,540 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:57:15,540 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in het winter en zomers.
2025-05-30 00:57:15,540 - INFO - joeynmt.training - Example #4
2025-05-30 00:57:15,541 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:57:15,541 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:57:15,541 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'u@@', 'p@@', 'p@@', '-@@', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 00:57:15,542 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:57:15,542 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:57:15,542 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdrappupp-25 jaar gebeurt in de afgelopen 25 jaar gebeurd is.
2025-05-30 00:57:25,176 - INFO - joeynmt.training - Epoch   4, Step:    38100, Batch Loss:     1.862179, Batch Acc: 0.544977, Tokens per Sec:     7343, Lr: 0.000300
2025-05-30 00:57:34,163 - INFO - joeynmt.training - Epoch   4, Step:    38200, Batch Loss:     1.462858, Batch Acc: 0.547674, Tokens per Sec:     8280, Lr: 0.000300
2025-05-30 00:57:42,996 - INFO - joeynmt.training - Epoch   4, Step:    38300, Batch Loss:     1.501981, Batch Acc: 0.543598, Tokens per Sec:     8215, Lr: 0.000300
2025-05-30 00:57:51,806 - INFO - joeynmt.training - Epoch   4, Step:    38400, Batch Loss:     1.436844, Batch Acc: 0.545307, Tokens per Sec:     8249, Lr: 0.000300
2025-05-30 00:58:00,647 - INFO - joeynmt.training - Epoch   4, Step:    38500, Batch Loss:     1.319545, Batch Acc: 0.551002, Tokens per Sec:     8201, Lr: 0.000300
2025-05-30 00:58:00,647 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:58:00,647 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 00:58:48,951 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.55, acc:   0.53, generation: 48.2617[sec], evaluation: 0.0000[sec]
2025-05-30 00:58:49,122 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/36000.ckpt
2025-05-30 00:58:49,141 - INFO - joeynmt.training - Example #0
2025-05-30 00:58:49,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 00:58:49,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 00:58:49,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ken', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'nen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'nen', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '8', 'u@@', 'ur', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'st@@', 'op@@', 't', 'te', 'ge@@', 'z@@', 'et@@', '.', '</s>']
2025-05-30 00:58:49,143 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 00:58:49,143 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 00:58:49,143 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee politieken dat de artische ijnen die voor de artische ijnen die voor de onderste 40 procent van 48 uur had om 48 staten had 48 staten had om 40 procent gestopt te gezet.
2025-05-30 00:58:49,144 - INFO - joeynmt.training - Example #1
2025-05-30 00:58:49,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 00:58:49,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 00:58:49,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 're@@', 'c@@', 'ies', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'ck@@', 'e', 'di@@', 'ck@@', 'e', 'di@@', 'ck@@', 'e', 'pro@@', 'ble@@', 'em', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 00:58:49,145 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 00:58:49,145 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 00:58:49,145 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de precies van het specifieke probleem uit, want het is niet de dicke dicke dicke probleem laat zien.
2025-05-30 00:58:49,146 - INFO - joeynmt.training - Example #2
2025-05-30 00:58:49,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 00:58:49,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 00:58:49,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'nen', 'is', 'de', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'ste@@', '.', '</s>']
2025-05-30 00:58:49,147 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 00:58:49,147 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 00:58:49,147 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijnen is de slagende hart van onze wereldwijde klimaatste.
2025-05-30 00:58:49,147 - INFO - joeynmt.training - Example #3
2025-05-30 00:58:49,148 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 00:58:49,148 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 00:58:49,148 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'e@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 00:58:49,149 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 00:58:49,149 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 00:58:49,149 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zeer in de zomers.
2025-05-30 00:58:49,149 - INFO - joeynmt.training - Example #4
2025-05-30 00:58:49,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 00:58:49,149 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 00:58:49,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', '.', '</s>']
2025-05-30 00:58:49,150 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 00:58:49,151 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 00:58:49,151 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdperk in de afgelopen 25 jaar gebeurd in de afgelopen 25 jaar gebeur.
2025-05-30 00:58:58,255 - INFO - joeynmt.training - Epoch   4, Step:    38600, Batch Loss:     1.356524, Batch Acc: 0.546809, Tokens per Sec:     7699, Lr: 0.000300
2025-05-30 00:59:07,108 - INFO - joeynmt.training - Epoch   4, Step:    38700, Batch Loss:     1.493805, Batch Acc: 0.546503, Tokens per Sec:     7966, Lr: 0.000300
2025-05-30 00:59:16,128 - INFO - joeynmt.training - Epoch   4, Step:    38800, Batch Loss:     1.263330, Batch Acc: 0.555108, Tokens per Sec:     7981, Lr: 0.000300
2025-05-30 00:59:25,050 - INFO - joeynmt.training - Epoch   4, Step:    38900, Batch Loss:     1.429897, Batch Acc: 0.545309, Tokens per Sec:     8400, Lr: 0.000300
2025-05-30 00:59:33,767 - INFO - joeynmt.training - Epoch   4, Step:    39000, Batch Loss:     1.357423, Batch Acc: 0.546809, Tokens per Sec:     8464, Lr: 0.000300
2025-05-30 00:59:33,767 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 00:59:33,768 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:00:28,715 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.51, acc:   0.52, generation: 54.8960[sec], evaluation: 0.0000[sec]
2025-05-30 01:00:28,716 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:00:28,900 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/36500.ckpt
2025-05-30 01:00:28,923 - INFO - joeynmt.training - Example #0
2025-05-30 01:00:28,924 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:00:28,924 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:00:28,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'ies', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'nen', 'voor', 'de', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'die', 'voor', 'de', 'onder@@', 'ste', 'van', 'de', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'te', 'ge@@', 's@@', 'la@@', 'g', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'g', 'te', 'ver@@', 'ru@@', 'm@@', 'p@@', 't', 'is.', '</s>']
2025-05-30 01:00:28,925 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:00:28,926 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:00:28,926 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folies getoond om te kijken dat de arctische ijnen voor de miljoen die voor de onderste van de drie miljoen de grootte van 48 staten had om 48 staten had te geslag van 48 staten had om 40 procent te geslag te verrumpt is.
2025-05-30 01:00:28,926 - INFO - joeynmt.training - Example #1
2025-05-30 01:00:28,926 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:00:28,926 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:00:28,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'op@@', 'kom@@', 'ende', 'van', 'de', 'p@@', 'lan@@', 't@@', 'ig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'es', 'to@@', 'on@@', 't.', '</s>']
2025-05-30 01:00:28,927 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:00:28,927 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:00:28,928 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de opkomende van de plantigheid van dit speciale probleem uit, omdat het niet de dikke van het ijses toont.
2025-05-30 01:00:28,928 - INFO - joeynmt.training - Example #2
2025-05-30 01:00:28,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:00:28,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:00:28,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'onze', 'wer@@', 'k@@', 'ing@@', '.', '</s>']
2025-05-30 01:00:28,929 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:00:28,929 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:00:28,929 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe ijskape het slagen van onze wereldwijd van onze werking.
2025-05-30 01:00:28,930 - INFO - joeynmt.training - Example #3
2025-05-30 01:00:28,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:00:28,930 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:00:28,930 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ra@@', 'cht', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:00:28,931 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:00:28,931 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:00:28,931 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en kracht in de winter en zomers.
2025-05-30 01:00:28,931 - INFO - joeynmt.training - Example #4
2025-05-30 01:00:28,932 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:00:28,932 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:00:28,932 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'te@@', 'ken@@', 'is@@', ',', 'is', 'een', 'te@@', 'm@@', 'p@@', 'op@@', 'ul@@', 'a@@', 'ir@@', 'e', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:00:28,933 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:00:28,933 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:00:28,933 - INFO - joeynmt.training - 	Hypothesis: De volgende die ik jullie laten zien is een tekenis, is een tempopulaire wat er gebeurd in de afgelopen 25 jaar gebeurd.
2025-05-30 01:00:38,155 - INFO - joeynmt.training - Epoch   4, Step:    39100, Batch Loss:     1.382951, Batch Acc: 0.549685, Tokens per Sec:     7681, Lr: 0.000300
2025-05-30 01:00:46,384 - INFO - joeynmt.training - Epoch   4, Step:    39200, Batch Loss:     1.725040, Batch Acc: 0.550531, Tokens per Sec:     8844, Lr: 0.000300
2025-05-30 01:00:54,410 - INFO - joeynmt.training - Epoch   4, Step:    39300, Batch Loss:     1.371553, Batch Acc: 0.544580, Tokens per Sec:     8743, Lr: 0.000300
2025-05-30 01:01:02,351 - INFO - joeynmt.training - Epoch   4, Step:    39400, Batch Loss:     1.405358, Batch Acc: 0.551478, Tokens per Sec:     9309, Lr: 0.000300
2025-05-30 01:01:10,639 - INFO - joeynmt.training - Epoch   4, Step:    39500, Batch Loss:     1.243394, Batch Acc: 0.553196, Tokens per Sec:     8762, Lr: 0.000300
2025-05-30 01:01:10,641 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:01:10,642 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:01:55,035 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.50, ppl:   4.50, acc:   0.53, generation: 44.3500[sec], evaluation: 0.0000[sec]
2025-05-30 01:01:55,036 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:01:55,205 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/37500.ckpt
2025-05-30 01:01:55,222 - INFO - joeynmt.training - Example #0
2025-05-30 01:01:55,222 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:01:55,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:01:55,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'ies', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 'z@@', 'oe@@', 'ken', 'in', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 01:01:55,223 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:01:55,223 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:01:55,223 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folies getoond om te kijken dat de arctische ijskapen die voor de artische ijskape ijzondere miljoen jaar de grootte van 48 staten had om 480 procent te verzoeken in de onderste 40 procent van 40 procent van 40 procent geslagen is.
2025-05-30 01:01:55,224 - INFO - joeynmt.training - Example #1
2025-05-30 01:01:55,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:01:55,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:01:55,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'er@@', 'st@@', 'ie@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'er@@', 'v@@', 'ar@@', 'ing', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'de', 'ij@@', 'z@@', 'er@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:01:55,224 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:01:55,225 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:01:55,225 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de erstiek genoeg de ervaring van het ijs van het ijs van het ijs van de ijzers laat zien.
2025-05-30 01:01:55,225 - INFO - joeynmt.training - Example #2
2025-05-30 01:01:55,225 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:01:55,225 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:01:55,225 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'de', 'wer@@', 'k@@', 'ne@@', 'mer@@', 's', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'kl@@', 'im@@', 'aat@@', 'ver@@', 'kl@@', 'ar@@', 'en', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'l', 'kl@@', 'im@@', 'aat@@', 'ver@@', '.', '</s>']
2025-05-30 01:01:55,225 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:01:55,226 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:01:55,226 - INFO - joeynmt.training - 	Hypothesis: In zekere zin de werknemers is de artische ijskape ijzondere klimaatverklaren van onze wereldwijl klimaatver.
2025-05-30 01:01:55,226 - INFO - joeynmt.training - Example #3
2025-05-30 01:01:55,226 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:01:55,226 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:01:55,226 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:01:55,227 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:01:55,227 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:01:55,227 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich in de zomers.
2025-05-30 01:01:55,227 - INFO - joeynmt.training - Example #4
2025-05-30 01:01:55,227 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:01:55,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:01:55,228 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'te@@', 'ken@@', 'ing', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de.', '</s>']
2025-05-30 01:01:55,228 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:01:55,228 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:01:55,228 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tekening van de laatste 25 jaar gebeurt in de laatste 25 jaar gebeurde.
2025-05-30 01:02:04,201 - INFO - joeynmt.training - Epoch   4, Step:    39600, Batch Loss:     1.405461, Batch Acc: 0.545637, Tokens per Sec:     7609, Lr: 0.000300
2025-05-30 01:02:13,125 - INFO - joeynmt.training - Epoch   4, Step:    39700, Batch Loss:     1.432416, Batch Acc: 0.549013, Tokens per Sec:     7665, Lr: 0.000300
2025-05-30 01:02:21,950 - INFO - joeynmt.training - Epoch   4, Step:    39800, Batch Loss:     1.406557, Batch Acc: 0.547180, Tokens per Sec:     8291, Lr: 0.000300
2025-05-30 01:02:30,766 - INFO - joeynmt.training - Epoch   4, Step:    39900, Batch Loss:     1.492700, Batch Acc: 0.549321, Tokens per Sec:     7935, Lr: 0.000300
2025-05-30 01:02:39,564 - INFO - joeynmt.training - Epoch   4, Step:    40000, Batch Loss:     1.227208, Batch Acc: 0.546683, Tokens per Sec:     8213, Lr: 0.000300
2025-05-30 01:02:39,564 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:02:39,565 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:03:32,435 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.51, acc:   0.52, generation: 52.8007[sec], evaluation: 0.0000[sec]
2025-05-30 01:03:32,590 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/38500.ckpt
2025-05-30 01:03:32,606 - INFO - joeynmt.training - Example #0
2025-05-30 01:03:32,607 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:03:32,607 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:03:32,607 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'der', 'te', 'k@@', 'ijk@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'i@@', 'ë@@', 'r@@', 'en', 'die', 'voor', 'de', 'onder@@', 'ste', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'st@@', 'op@@', 'p@@', 'en.', '</s>']
2025-05-30 01:03:32,608 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:03:32,608 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:03:32,608 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folië getoond om te verander te kijken, dat de arctische ijiëren die voor de onderste van de onderste 48 staten, om 48 staten, om 48 staten, om 48 staten, om 48 staten, om 48 procent te gestoppen.
2025-05-30 01:03:32,608 - INFO - joeynmt.training - Example #1
2025-05-30 01:03:32,609 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:03:32,609 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:03:32,609 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'aar', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'er', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'e', 'van', 'de', 'ij@@', 's@@', 'ge@@', 'st@@', 'eld', 'zi@@', 'en.', '</s>']
2025-05-30 01:03:32,609 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:03:32,609 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:03:32,609 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet sterk genoeg de eerste paar probleem uit, want het is niet de diker uit, want het is niet de dike van de ijsgesteld zien.
2025-05-30 01:03:32,609 - INFO - joeynmt.training - Example #2
2025-05-30 01:03:32,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:03:32,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:03:32,610 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 't', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'st@@', '.', '</s>']
2025-05-30 01:03:32,610 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:03:32,610 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:03:32,610 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape ijt hart van onze wereldwijde klimaatst.
2025-05-30 01:03:32,610 - INFO - joeynmt.training - Example #3
2025-05-30 01:03:32,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:03:32,611 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:03:32,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:03:32,611 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:03:32,611 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:03:32,611 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppt in de zomers.
2025-05-30 01:03:32,611 - INFO - joeynmt.training - Example #4
2025-05-30 01:03:32,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:03:32,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:03:32,612 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 't@@', 'r@@', 'ein@@', ',', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:03:32,612 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:03:32,613 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:03:32,613 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrapportrein, wat er gebeurd in de laatste 25 jaar gebeurd.
2025-05-30 01:03:41,731 - INFO - joeynmt.training - Epoch   4, Step:    40100, Batch Loss:     1.289100, Batch Acc: 0.544021, Tokens per Sec:     7794, Lr: 0.000300
2025-05-30 01:03:50,638 - INFO - joeynmt.training - Epoch   4, Step:    40200, Batch Loss:     1.489069, Batch Acc: 0.548370, Tokens per Sec:     8074, Lr: 0.000300
2025-05-30 01:03:59,426 - INFO - joeynmt.training - Epoch   4, Step:    40300, Batch Loss:     1.346369, Batch Acc: 0.551467, Tokens per Sec:     8013, Lr: 0.000300
2025-05-30 01:04:08,315 - INFO - joeynmt.training - Epoch   4, Step:    40400, Batch Loss:     1.413047, Batch Acc: 0.551924, Tokens per Sec:     8098, Lr: 0.000300
2025-05-30 01:04:17,393 - INFO - joeynmt.training - Epoch   4, Step:    40500, Batch Loss:     1.377633, Batch Acc: 0.550710, Tokens per Sec:     8041, Lr: 0.000300
2025-05-30 01:04:17,394 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:04:17,394 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:05:04,672 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.50, ppl:   4.50, acc:   0.53, generation: 47.2353[sec], evaluation: 0.0000[sec]
2025-05-30 01:05:04,673 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:05:04,841 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/37000.ckpt
2025-05-30 01:05:04,856 - INFO - joeynmt.training - Example #0
2025-05-30 01:05:04,857 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:05:04,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:05:04,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', 'se', 'van', 'de', 'wer@@', 'k@@', ',', 'dat', 'de', 'ar@@', 'ti@@', 'c@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'aat', 'die', 'voor', 'on@@', 'der', '4@@', '8', 'st@@', 'at@@', 'en,', 'de', 'gro@@', 'ot@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'aten', 'in', 'de', 'st@@', 'aat', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 01:05:04,858 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:05:04,858 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:05:04,858 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee diase van de werk, dat de articappe ijskapparaat die voor onder 48 staten, de grootste 48 staten, 48 staten, om 48 staten, om 48 staten, om 48 staten, om 48 staten in de staat gebeuren.
2025-05-30 01:05:04,858 - INFO - joeynmt.training - Example #1
2025-05-30 01:05:04,859 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:05:04,859 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:05:04,859 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'is', 'het', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'heid', 'van', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'ge@@', 'st@@', 'el@@', 'd.', '</s>']
2025-05-30 01:05:04,860 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:05:04,860 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:05:04,860 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, is het niet sterk genoeg de snelheid van het speciale probleem uit, omdat het niet de dikke dikke dikke van de ijsgesteld.
2025-05-30 01:05:04,860 - INFO - joeynmt.training - Example #2
2025-05-30 01:05:04,861 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:05:04,861 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:05:04,861 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:05:04,862 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:05:04,862 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:05:04,862 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskape ijskape ijzondere klimaatsysteem.
2025-05-30 01:05:04,862 - INFO - joeynmt.training - Example #3
2025-05-30 01:05:04,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:05:04,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:05:04,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:05:04,863 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:05:04,863 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:05:04,863 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zrompt in de zomers.
2025-05-30 01:05:04,863 - INFO - joeynmt.training - Example #4
2025-05-30 01:05:04,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:05:04,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:05:04,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'te@@', 'ken@@', 't', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:05:04,864 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:05:04,864 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:05:04,864 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tekent van de laatste 25 jaar gebeurd in de laatste 25 jaar gebeurd is.
2025-05-30 01:05:13,551 - INFO - joeynmt.training - Epoch   4, Step:    40600, Batch Loss:     1.372915, Batch Acc: 0.548692, Tokens per Sec:     8091, Lr: 0.000300
2025-05-30 01:05:22,187 - INFO - joeynmt.training - Epoch   4, Step:    40700, Batch Loss:     1.452747, Batch Acc: 0.555018, Tokens per Sec:     8122, Lr: 0.000300
2025-05-30 01:05:30,719 - INFO - joeynmt.training - Epoch   4, Step:    40800, Batch Loss:     1.328977, Batch Acc: 0.550215, Tokens per Sec:     8450, Lr: 0.000300
2025-05-30 01:05:38,686 - INFO - joeynmt.training - Epoch   4, Step:    40900, Batch Loss:     1.371811, Batch Acc: 0.544999, Tokens per Sec:     8898, Lr: 0.000300
2025-05-30 01:05:46,709 - INFO - joeynmt.training - Epoch   4, Step:    41000, Batch Loss:     1.473037, Batch Acc: 0.552050, Tokens per Sec:     9292, Lr: 0.000300
2025-05-30 01:05:46,710 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:05:46,710 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:06:36,707 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.50, ppl:   4.49, acc:   0.52, generation: 49.9508[sec], evaluation: 0.0000[sec]
2025-05-30 01:06:36,708 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:06:36,889 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/38000.ckpt
2025-05-30 01:06:36,907 - INFO - joeynmt.training - Example #0
2025-05-30 01:06:36,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:06:36,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:06:36,908 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ë@@', 'n', 'die', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'ken', 'die', 'de', 'ar@@', 'ti@@', 'c@@', 'a', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'ste', 'de@@', 'el', 'van', 'de', 'gro@@', 'ot@@', 'ste', 'van', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 01:06:36,909 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:06:36,909 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:06:36,909 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee politieën die de artische ijken die de artica die voor de grootste deel van de grootste van 48 staten om 48 staten om 48 staten om 48 staten om 40 procent te gebeuren.
2025-05-30 01:06:36,909 - INFO - joeynmt.training - Example #1
2025-05-30 01:06:36,910 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:06:36,910 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:06:36,910 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'gen@@', 'oe@@', 'g', 'de', 're@@', 'st', 'van', 'de', 'p@@', 'ra@@', 'cht@@', 'ige', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ru@@', 'k', 'van', 'het', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:06:36,911 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:06:36,911 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:06:36,911 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt genoeg de rest van de prachtige probleem dat het niet de dikke druk van het ijs van de ijs van de ijss laat zien.
2025-05-30 01:06:36,911 - INFO - joeynmt.training - Example #2
2025-05-30 01:06:36,911 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:06:36,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:06:36,912 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's', 'de', 's@@', 'la@@', 'gen', 'van', 'ons', 'wer@@', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'm@@', 'en.', '</s>']
2025-05-30 01:06:36,913 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:06:36,913 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:06:36,913 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijs de slagen van ons werwereldwijde klimaatsystemen.
2025-05-30 01:06:36,914 - INFO - joeynmt.training - Example #3
2025-05-30 01:06:36,914 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:06:36,914 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:06:36,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 01:06:36,916 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:06:36,916 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:06:36,916 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schept in de zomer.
2025-05-30 01:06:36,916 - INFO - joeynmt.training - Example #4
2025-05-30 01:06:36,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:06:36,917 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:06:36,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'm@@', 'om@@', 'ent', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:06:36,918 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:06:36,918 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:06:36,918 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een moment van de laatste 25 jaar gebeurd.
2025-05-30 01:06:46,207 - INFO - joeynmt.training - Epoch   4, Step:    41100, Batch Loss:     1.525905, Batch Acc: 0.547719, Tokens per Sec:     7378, Lr: 0.000300
2025-05-30 01:06:55,013 - INFO - joeynmt.training - Epoch   4, Step:    41200, Batch Loss:     1.512181, Batch Acc: 0.550658, Tokens per Sec:     8061, Lr: 0.000300
2025-05-30 01:07:04,059 - INFO - joeynmt.training - Epoch   4, Step:    41300, Batch Loss:     1.529194, Batch Acc: 0.544939, Tokens per Sec:     7550, Lr: 0.000300
2025-05-30 01:07:13,195 - INFO - joeynmt.training - Epoch   4, Step:    41400, Batch Loss:     1.391179, Batch Acc: 0.552235, Tokens per Sec:     7963, Lr: 0.000300
2025-05-30 01:07:22,167 - INFO - joeynmt.training - Epoch   4, Step:    41500, Batch Loss:     1.343310, Batch Acc: 0.548331, Tokens per Sec:     8077, Lr: 0.000300
2025-05-30 01:07:22,167 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:07:22,168 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:08:08,603 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.50, ppl:   4.49, acc:   0.53, generation: 46.3808[sec], evaluation: 0.0000[sec]
2025-05-30 01:08:08,604 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:08:08,776 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/40000.ckpt
2025-05-30 01:08:08,791 - INFO - joeynmt.training - Example #0
2025-05-30 01:08:08,792 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:08:08,792 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:08:08,792 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'ies', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'ti@@', 'c@@', 'ul@@', 'a@@', 'ir@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', '3@@', '0', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'u@@', 'ur', 'te', 'ge@@', 'sl@@', 'ag@@', 'en.', '</s>']
2025-05-30 01:08:08,793 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:08:08,793 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:08:08,793 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folies getoond om te kijken dat de articulaire ijskappen die voor de onderste 30 miljoen jaar de grootte van 48 staten om 48 staten om 48 staten om 48 uur te geslagen.
2025-05-30 01:08:08,794 - INFO - joeynmt.training - Example #1
2025-05-30 01:08:08,794 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:08:08,794 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:08:08,794 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 're@@', 'c@@', 'ies', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'heid', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:08:08,795 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:08:08,795 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:08:08,795 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet sterk genoeg de precies van het ijs van het ijs niet de dikke dikke dikke van de ijsheid van het ijs laat zien.
2025-05-30 01:08:08,795 - INFO - joeynmt.training - Example #2
2025-05-30 01:08:08,795 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:08:08,795 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:08:08,795 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'c@@', 'ul@@', 'a@@', 'ir', 'ij@@', 's', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:08:08,797 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:08:08,798 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:08:08,798 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de articulair ijs het slagen van onze wereldwijde klimaatsysteem.
2025-05-30 01:08:08,798 - INFO - joeynmt.training - Example #3
2025-05-30 01:08:08,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:08:08,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:08:08,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'z@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'z@@', 'or@@', 'g@@', 'd', 'en', 'het', 'ver@@', 'z@@', 'am@@', 'el@@', 'ing@@', '.', '</s>']
2025-05-30 01:08:08,799 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:08:08,799 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:08:08,800 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schept in de zomer en zroept in de zomer en zorgd en het verzameling.
2025-05-30 01:08:08,800 - INFO - joeynmt.training - Example #4
2025-05-30 01:08:08,800 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:08:08,800 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:08:08,800 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'en@@', 'st', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'gen', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:08:08,801 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:08:08,802 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:08:08,802 - INFO - joeynmt.training - 	Hypothesis: De volgende dienst die ik jullie laat zien is een tijdragen van de laatste 25 jaar gebeurd.
2025-05-30 01:08:17,939 - INFO - joeynmt.training - Epoch   4, Step:    41600, Batch Loss:     1.438542, Batch Acc: 0.549840, Tokens per Sec:     7680, Lr: 0.000300
2025-05-30 01:08:27,145 - INFO - joeynmt.training - Epoch   4, Step:    41700, Batch Loss:     1.419600, Batch Acc: 0.551647, Tokens per Sec:     7806, Lr: 0.000300
2025-05-30 01:08:36,366 - INFO - joeynmt.training - Epoch   4, Step:    41800, Batch Loss:     1.427935, Batch Acc: 0.547034, Tokens per Sec:     7771, Lr: 0.000300
2025-05-30 01:08:45,234 - INFO - joeynmt.training - Epoch   4, Step:    41900, Batch Loss:     1.317188, Batch Acc: 0.550429, Tokens per Sec:     8049, Lr: 0.000300
2025-05-30 01:08:54,443 - INFO - joeynmt.training - Epoch   4, Step:    42000, Batch Loss:     1.490676, Batch Acc: 0.552887, Tokens per Sec:     7932, Lr: 0.000300
2025-05-30 01:08:54,444 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:08:54,444 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:09:43,103 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.50, ppl:   4.49, acc:   0.53, generation: 48.6076[sec], evaluation: 0.0000[sec]
2025-05-30 01:09:43,275 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/39000.ckpt
2025-05-30 01:09:43,291 - INFO - joeynmt.training - Example #0
2025-05-30 01:09:43,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:09:43,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:09:43,292 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'c@@', 'a', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'c@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'ge@@', 'sl@@', 'aa@@', 'g@@', 'd', 'is.', '</s>']
2025-05-30 01:09:43,293 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:09:43,293 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:09:43,293 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar getoond om te begrijpen dat de arctica te zien dat de arcticape ijskapen die voor de grootte van de onderste 48 staten, om 48 staten, om 48 staten, om 48 staten, om 40 procent gegeslaagd is.
2025-05-30 01:09:43,293 - INFO - joeynmt.training - Example #1
2025-05-30 01:09:43,294 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:09:43,294 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:09:43,294 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'heid', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k', 'l@@', 'aat', 'zien', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-30 01:09:43,295 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:09:43,295 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:09:43,295 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de snelheid van het ijs van het ijs is het niet de dikke probleem dat het niet de dik laat zien van het ijs toont.
2025-05-30 01:09:43,295 - INFO - joeynmt.training - Example #2
2025-05-30 01:09:43,296 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:09:43,296 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:09:43,296 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'c@@', 'ul@@', 'a@@', 'ir', 'ij@@', 's', 'het', 'sl@@', 'ag@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:09:43,298 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:09:43,298 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:09:43,298 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de articulair ijs het slage ijskape ijskape klimaatsysteem.
2025-05-30 01:09:43,298 - INFO - joeynmt.training - Example #3
2025-05-30 01:09:43,298 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:09:43,298 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:09:43,298 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:09:43,299 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:09:43,299 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:09:43,300 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schept in de zomers.
2025-05-30 01:09:43,300 - INFO - joeynmt.training - Example #4
2025-05-30 01:09:43,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:09:43,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:09:43,300 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'te@@', 'ken@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:09:43,301 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:09:43,301 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:09:43,301 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik jullie laten zien is een tekent in de laatste 25 jaar gebeurd is.
2025-05-30 01:09:52,111 - INFO - joeynmt.training - Epoch   4, Step:    42100, Batch Loss:     1.603730, Batch Acc: 0.546630, Tokens per Sec:     7803, Lr: 0.000300
2025-05-30 01:10:01,226 - INFO - joeynmt.training - Epoch   4, Step:    42200, Batch Loss:     1.472627, Batch Acc: 0.552017, Tokens per Sec:     8088, Lr: 0.000300
2025-05-30 01:10:10,338 - INFO - joeynmt.training - Epoch   4, Step:    42300, Batch Loss:     1.622315, Batch Acc: 0.552309, Tokens per Sec:     8204, Lr: 0.000300
2025-05-30 01:10:18,847 - INFO - joeynmt.training - Epoch   4, Step:    42400, Batch Loss:     1.243099, Batch Acc: 0.553608, Tokens per Sec:     8444, Lr: 0.000300
2025-05-30 01:10:21,646 - INFO - joeynmt.training - Epoch   4: total training loss 15170.85
2025-05-30 01:10:21,646 - INFO - joeynmt.training - EPOCH 5
2025-05-30 01:10:26,866 - INFO - joeynmt.training - Epoch   5, Step:    42500, Batch Loss:     1.534647, Batch Acc: 0.561908, Tokens per Sec:     9265, Lr: 0.000300
2025-05-30 01:10:26,868 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:10:26,868 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:11:11,589 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.50, ppl:   4.49, acc:   0.53, generation: 44.6784[sec], evaluation: 0.0000[sec]
2025-05-30 01:11:11,753 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/39500.ckpt
2025-05-30 01:11:11,770 - INFO - joeynmt.training - Example #0
2025-05-30 01:11:11,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:11:11,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:11:11,771 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'l@@', 'aat', 'deze', 'twe@@', 'e', 'ge@@', 'vol@@', 'g', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'vol@@', 'g', 'om', 'te', 'k@@', 'ijk@@', 'en,', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'st@@', 'aa@@', 't.', '</s>']
2025-05-30 01:11:11,772 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:11:11,772 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:11:11,772 - INFO - joeynmt.training - 	Hypothesis: Ik laat deze twee gevolg ik deze twee gevolg om te kijken, om te beginnen te zien dat de arctische ijskappen, die voor de grootte van de grootte van de onderste 48 staten had om 48 staten had gestaat.
2025-05-30 01:11:11,773 - INFO - joeynmt.training - Example #1
2025-05-30 01:11:11,773 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:11:11,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:11:11,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k', 'is', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'deze', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 'ti@@', 'g', 'ge@@', 'we@@', 'e@@', 'st@@', '.', '</s>']
2025-05-30 01:11:11,774 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:11:11,774 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:11:11,775 - INFO - joeynmt.training - 	Hypothesis: Maar dit druk is niet genoeg de eerste van deze specifieke probleem uit, omdat het niet de dikke van de ijskracht van de ijskracht van de ijskrachtig geweest.
2025-05-30 01:11:11,775 - INFO - joeynmt.training - Example #2
2025-05-30 01:11:11,775 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:11:11,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:11:11,775 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'c@@', 'ul@@', 'p', 'van', 'onze', 'wer@@', 'k@@', 'ing', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:11:11,776 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:11:11,776 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:11:11,776 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arcticulp van onze werking van onze wereldwijde klimaatsysteem.
2025-05-30 01:11:11,777 - INFO - joeynmt.training - Example #3
2025-05-30 01:11:11,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:11:11,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:11:11,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gt', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:11:11,778 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:11:11,778 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:11:11,778 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zorgt in de zomers.
2025-05-30 01:11:11,778 - INFO - joeynmt.training - Example #4
2025-05-30 01:11:11,779 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:11:11,779 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:11:11,779 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'te@@', 'ken@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:11:11,780 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:11:11,780 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:11:11,781 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tekent in de laatste 25 jaar gebeurd in de laatste 25 jaar gebeurd.
2025-05-30 01:11:20,810 - INFO - joeynmt.training - Epoch   5, Step:    42600, Batch Loss:     1.323347, Batch Acc: 0.556594, Tokens per Sec:     7834, Lr: 0.000300
2025-05-30 01:11:29,875 - INFO - joeynmt.training - Epoch   5, Step:    42700, Batch Loss:     1.384209, Batch Acc: 0.559800, Tokens per Sec:     7810, Lr: 0.000300
2025-05-30 01:11:38,782 - INFO - joeynmt.training - Epoch   5, Step:    42800, Batch Loss:     1.736766, Batch Acc: 0.558017, Tokens per Sec:     7915, Lr: 0.000300
2025-05-30 01:11:47,781 - INFO - joeynmt.training - Epoch   5, Step:    42900, Batch Loss:     1.401732, Batch Acc: 0.556555, Tokens per Sec:     7916, Lr: 0.000300
2025-05-30 01:11:56,740 - INFO - joeynmt.training - Epoch   5, Step:    43000, Batch Loss:     1.350510, Batch Acc: 0.563274, Tokens per Sec:     8098, Lr: 0.000300
2025-05-30 01:11:56,742 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:11:56,742 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:12:39,419 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.49, ppl:   4.45, acc:   0.53, generation: 42.6361[sec], evaluation: 0.0000[sec]
2025-05-30 01:12:39,420 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:12:39,581 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/40500.ckpt
2025-05-30 01:12:39,597 - INFO - joeynmt.training - Example #0
2025-05-30 01:12:39,598 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:12:39,598 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:12:39,598 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'om', 'te', 'ver@@', 'ander@@', 'en', 'dat', 'de', 'ar@@', 'ct@@', 'ie@@', 'k@@', 'ap@@', 'en', 'die', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'st@@', 'eld', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'st@@', 'eld', 'te', 'k@@', 'rij@@', 'gen', 'van', '4@@', '%', 'ge@@', 'st@@', 'am@@', 'p@@', 't', 'is.', '</s>']
2025-05-30 01:12:39,599 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:12:39,599 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:12:39,600 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee miljoen jaar om te veranderen dat de arctiekapen die de artische ijskapen die voor de grootte van de onderste 48 staten had gesteld om 48 staten had gesteld te krijgen van 4% gestampt is.
2025-05-30 01:12:39,600 - INFO - joeynmt.training - Example #1
2025-05-30 01:12:39,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:12:39,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:12:39,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 'lan@@', 'e@@', 'et', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:12:39,602 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:12:39,602 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:12:39,602 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de planeet van dit specifiek van dit speciale probleem uit, omdat het niet de dikke van het ijskracht van het ijs laat zien.
2025-05-30 01:12:39,602 - INFO - joeynmt.training - Example #2
2025-05-30 01:12:39,603 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:12:39,603 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:12:39,603 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's', 'van', 'de', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:12:39,604 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:12:39,604 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:12:39,604 - INFO - joeynmt.training - 	Hypothesis: In zekere ijskape ijskape ijskape ijs van de wereldwijde klimaatsysteem.
2025-05-30 01:12:39,604 - INFO - joeynmt.training - Example #3
2025-05-30 01:12:39,604 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:12:39,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:12:39,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'de', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-30 01:12:39,606 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:12:39,606 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:12:39,606 - INFO - joeynmt.training - 	Hypothesis: Ze groeide in de winter en zorgen in de zomer.
2025-05-30 01:12:39,606 - INFO - joeynmt.training - Example #4
2025-05-30 01:12:39,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:12:39,607 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:12:39,607 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'te@@', 'ken@@', 't', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 01:12:39,608 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:12:39,608 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:12:39,608 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een tekent in de afgelopen 25 jaar.
2025-05-30 01:12:48,704 - INFO - joeynmt.training - Epoch   5, Step:    43100, Batch Loss:     1.397282, Batch Acc: 0.559452, Tokens per Sec:     7626, Lr: 0.000300
2025-05-30 01:12:57,545 - INFO - joeynmt.training - Epoch   5, Step:    43200, Batch Loss:     1.415292, Batch Acc: 0.559572, Tokens per Sec:     8462, Lr: 0.000300
2025-05-30 01:13:06,170 - INFO - joeynmt.training - Epoch   5, Step:    43300, Batch Loss:     1.302285, Batch Acc: 0.554338, Tokens per Sec:     8329, Lr: 0.000300
2025-05-30 01:13:14,937 - INFO - joeynmt.training - Epoch   5, Step:    43400, Batch Loss:     1.240791, Batch Acc: 0.562830, Tokens per Sec:     8356, Lr: 0.000300
2025-05-30 01:13:23,631 - INFO - joeynmt.training - Epoch   5, Step:    43500, Batch Loss:     1.349610, Batch Acc: 0.558180, Tokens per Sec:     8297, Lr: 0.000300
2025-05-30 01:13:23,633 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:13:23,633 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:14:10,908 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.49, ppl:   4.46, acc:   0.53, generation: 47.2327[sec], evaluation: 0.0000[sec]
2025-05-30 01:14:11,080 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/41000.ckpt
2025-05-30 01:14:11,097 - INFO - joeynmt.training - Example #0
2025-05-30 01:14:11,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:14:11,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:14:11,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'stu@@', 'de@@', 'er@@', 't', 'te', 'be@@', 'stu@@', 'ur@@', 't', 'die', 'voor', 'on@@', 'ge@@', 've@@', 'er', '4@@', '8', 'st@@', 'aten', 'voor', 'on@@', 'der', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'aten', 'voor', '4@@', '8', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 01:14:11,098 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:14:11,098 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:14:11,098 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te beginnen te bestudeert te bestuurt die voor ongeveer 48 staten voor onder de grootte van de grootte van de onderste 48 staten, om 48 staten om 48 staten, om 48 staten voor 48 staten.
2025-05-30 01:14:11,098 - INFO - joeynmt.training - Example #1
2025-05-30 01:14:11,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:14:11,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:14:11,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'st@@', 'ar@@', 'k', 'is', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'is', 'het', 'ge@@', 'be@@', 'ur@@', 't', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zien', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'l@@', 'aat', 'zien', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'l@@', 'aat', 'zien', 'is.', '</s>']
2025-05-30 01:14:11,101 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:14:11,101 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:14:11,101 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de eerste stark is dat het speciale probleem is het gebeurt van het ijs laat zien dat het niet de dikke ijs laat zien dat het niet de dikke ijs laat zien is.
2025-05-30 01:14:11,101 - INFO - joeynmt.training - Example #2
2025-05-30 01:14:11,102 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:14:11,102 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:14:11,102 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:14:11,103 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:14:11,103 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:14:11,103 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-30 01:14:11,103 - INFO - joeynmt.training - Example #3
2025-05-30 01:14:11,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:14:11,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:14:11,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'en', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 01:14:11,104 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:14:11,104 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:14:11,105 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppt in de winter en zich in de winter en scheppt in de winter en de zomer in de winter en de zomer in de winter en de winter en de winter en de winter en de winter en de winter en de zomer in de winter en en de zomer.
2025-05-30 01:14:11,105 - INFO - joeynmt.training - Example #4
2025-05-30 01:14:11,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:14:11,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:14:11,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'te@@', 'ken@@', 't', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 01:14:11,106 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:14:11,106 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:14:11,106 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tekent gebeurde in de laatste 25 jaar.
2025-05-30 01:14:20,232 - INFO - joeynmt.training - Epoch   5, Step:    43600, Batch Loss:     1.301813, Batch Acc: 0.562323, Tokens per Sec:     7750, Lr: 0.000300
2025-05-30 01:14:29,390 - INFO - joeynmt.training - Epoch   5, Step:    43700, Batch Loss:     1.447076, Batch Acc: 0.559911, Tokens per Sec:     8003, Lr: 0.000300
2025-05-30 01:14:38,459 - INFO - joeynmt.training - Epoch   5, Step:    43800, Batch Loss:     1.464245, Batch Acc: 0.559955, Tokens per Sec:     7970, Lr: 0.000300
2025-05-30 01:14:47,467 - INFO - joeynmt.training - Epoch   5, Step:    43900, Batch Loss:     1.486352, Batch Acc: 0.555176, Tokens per Sec:     8085, Lr: 0.000300
2025-05-30 01:14:56,288 - INFO - joeynmt.training - Epoch   5, Step:    44000, Batch Loss:     1.511178, Batch Acc: 0.556868, Tokens per Sec:     8002, Lr: 0.000300
2025-05-30 01:14:56,288 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:14:56,290 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:15:39,503 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.49, ppl:   4.45, acc:   0.53, generation: 43.1703[sec], evaluation: 0.0000[sec]
2025-05-30 01:15:39,651 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/42500.ckpt
2025-05-30 01:15:39,671 - INFO - joeynmt.training - Example #0
2025-05-30 01:15:39,672 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:15:39,672 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:15:39,672 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'voor', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 01:15:39,673 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:15:39,673 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:15:39,673 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee dia om te verbeteren dat de artische ijskappen, die voor de grootte van de grootte van de grootte van de grootte van de grootte van de onderste 40 procent gebeurde voor 40 procent gegeslagen is.
2025-05-30 01:15:39,673 - INFO - joeynmt.training - Example #1
2025-05-30 01:15:39,674 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:15:39,674 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:15:39,674 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 're@@', 'st', 'van', 'het', 'ij@@', 's', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-30 01:15:39,675 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:15:39,675 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:15:39,675 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de rest van het ijs van het specifieke probleem, want het is niet de dikke dikke dikke van het ijs toont.
2025-05-30 01:15:39,675 - INFO - joeynmt.training - Example #2
2025-05-30 01:15:39,675 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:15:39,675 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:15:39,675 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'dat', 'het', 'sl@@', 'ag@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:15:39,676 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:15:39,676 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:15:39,676 - INFO - joeynmt.training - 	Hypothesis: In zekere zin de artische ijskappe dat het slage hart van onze wereldwijd klimaatsysteem.
2025-05-30 01:15:39,677 - INFO - joeynmt.training - Example #3
2025-05-30 01:15:39,677 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:15:39,677 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:15:39,677 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:15:39,677 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:15:39,678 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:15:39,679 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schrompt in de zomers.
2025-05-30 01:15:39,679 - INFO - joeynmt.training - Example #4
2025-05-30 01:15:39,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:15:39,680 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:15:39,680 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 't@@', 'ing', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'p@@', 'lan@@', 'e@@', 'et', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:15:39,681 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:15:39,681 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:15:39,681 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrapporting in de afgelopen 25 jaar gebeurde laatste 25 jaar gebeurde laatste 25 jaar gebeurde laatste 25 jaar gebeurde in de afgelopen 25 jaar gebeurde in de afgelopen 25 jaar gebeurde in de afgelopen 25 jaar gebeurde planeet in de afgelopen 25 jaar gebeurd.
2025-05-30 01:15:48,363 - INFO - joeynmt.training - Epoch   5, Step:    44100, Batch Loss:     1.314732, Batch Acc: 0.556207, Tokens per Sec:     8411, Lr: 0.000300
2025-05-30 01:15:57,079 - INFO - joeynmt.training - Epoch   5, Step:    44200, Batch Loss:     1.411133, Batch Acc: 0.553213, Tokens per Sec:     8031, Lr: 0.000300
2025-05-30 01:16:05,623 - INFO - joeynmt.training - Epoch   5, Step:    44300, Batch Loss:     1.366978, Batch Acc: 0.562103, Tokens per Sec:     8424, Lr: 0.000300
2025-05-30 01:16:14,591 - INFO - joeynmt.training - Epoch   5, Step:    44400, Batch Loss:     1.500004, Batch Acc: 0.554006, Tokens per Sec:     7985, Lr: 0.000300
2025-05-30 01:16:23,767 - INFO - joeynmt.training - Epoch   5, Step:    44500, Batch Loss:     1.563088, Batch Acc: 0.556548, Tokens per Sec:     7799, Lr: 0.000300
2025-05-30 01:16:23,767 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:16:23,768 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:17:11,188 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.49, ppl:   4.45, acc:   0.53, generation: 47.3760[sec], evaluation: 0.0000[sec]
2025-05-30 01:17:11,378 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/42000.ckpt
2025-05-30 01:17:11,392 - INFO - joeynmt.training - Example #0
2025-05-30 01:17:11,393 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:17:11,393 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:17:11,393 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'p@@', 'ol@@', 'it@@', 'ie@@', 'k', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'k@@', 'ijk@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'z@@', 'ro@@', 'm@@', 'p@@', 't', 'is.', '</s>']
2025-05-30 01:17:11,394 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:17:11,394 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:17:11,394 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee politiek getoond om te beginnen te kijken, dat de arctische ijskappen, de grootte van de grootte van de grootte van de grootte van 48 staten om 48 staten had 40 procent gezrompt is.
2025-05-30 01:17:11,395 - INFO - joeynmt.training - Example #1
2025-05-30 01:17:11,395 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:17:11,395 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:17:11,395 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 'lan@@', 't@@', 'ing@@', 's@@', 'ver@@', 'st@@', 'an@@', 'd,', 'is', 'het', 'p@@', 'ub@@', 'lie@@', 'k', 'van', 'dit', 'ij@@', 's', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's']
2025-05-30 01:17:11,396 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:17:11,396 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:17:11,397 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt genoeg de plantingsverstand, is het publiek van dit ijs niet de dikke van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs
2025-05-30 01:17:11,398 - INFO - joeynmt.training - Example #2
2025-05-30 01:17:11,398 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:17:11,398 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:17:11,398 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'igen', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'de', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'de', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'de', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'de', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'st@@', 'el@@', '.', '</s>']
2025-05-30 01:17:11,399 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:17:11,399 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:17:11,399 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigen is de arctische ijskape hart van onze wereldwijd van de wereldwijd van de wereldwijd van de wereldwijd van de wereldwijde klimaatstel.
2025-05-30 01:17:11,400 - INFO - joeynmt.training - Example #3
2025-05-30 01:17:11,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:17:11,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:17:11,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:17:11,401 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:17:11,401 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:17:11,401 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppt in de zomers.
2025-05-30 01:17:11,401 - INFO - joeynmt.training - Example #4
2025-05-30 01:17:11,402 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:17:11,402 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:17:11,402 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:17:11,403 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:17:11,403 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:17:11,403 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdperk van de laatste 25 jaar gebeurd.
2025-05-30 01:17:20,608 - INFO - joeynmt.training - Epoch   5, Step:    44600, Batch Loss:     1.381476, Batch Acc: 0.558520, Tokens per Sec:     7807, Lr: 0.000300
2025-05-30 01:17:30,047 - INFO - joeynmt.training - Epoch   5, Step:    44700, Batch Loss:     1.449488, Batch Acc: 0.560692, Tokens per Sec:     7681, Lr: 0.000300
2025-05-30 01:17:38,975 - INFO - joeynmt.training - Epoch   5, Step:    44800, Batch Loss:     1.495574, Batch Acc: 0.552427, Tokens per Sec:     7794, Lr: 0.000300
2025-05-30 01:17:47,856 - INFO - joeynmt.training - Epoch   5, Step:    44900, Batch Loss:     1.298173, Batch Acc: 0.559113, Tokens per Sec:     8227, Lr: 0.000300
2025-05-30 01:17:56,584 - INFO - joeynmt.training - Epoch   5, Step:    45000, Batch Loss:     1.391949, Batch Acc: 0.560809, Tokens per Sec:     8007, Lr: 0.000300
2025-05-30 01:17:56,585 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:17:56,585 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:18:43,696 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.49, ppl:   4.44, acc:   0.53, generation: 47.0660[sec], evaluation: 0.0000[sec]
2025-05-30 01:18:43,697 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:18:43,876 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/41500.ckpt
2025-05-30 01:18:43,895 - INFO - joeynmt.training - Example #0
2025-05-30 01:18:43,896 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:18:43,896 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:18:43,897 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'i@@', 'ë', 'om', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'k@@', 'el', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'at@@', 'en.', '</s>']
2025-05-30 01:18:43,897 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:18:43,898 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:18:43,898 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folië om te zien dat de artikel te zien dat de artische ijskappe ijskappe ijskappe ijskapparaten.
2025-05-30 01:18:43,898 - INFO - joeynmt.training - Example #1
2025-05-30 01:18:43,898 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:18:43,898 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:18:43,898 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'le@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:18:43,899 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:18:43,900 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:18:43,900 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet sterk genoeg de eerste plek van dit speciale probleem uit, omdat het niet de dikke van het ijs laat zien.
2025-05-30 01:18:43,900 - INFO - joeynmt.training - Example #2
2025-05-30 01:18:43,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:18:43,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:18:43,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'er@@', 's', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:18:43,901 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:18:43,901 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:18:43,901 - INFO - joeynmt.training - 	Hypothesis: In zekere zin de artische ijskape ijzers van onze wereldwijde klimaatsysteem.
2025-05-30 01:18:43,902 - INFO - joeynmt.training - Example #3
2025-05-30 01:18:43,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:18:43,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:18:43,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:18:43,903 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:18:43,903 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:18:43,903 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppt in de zomers.
2025-05-30 01:18:43,903 - INFO - joeynmt.training - Example #4
2025-05-30 01:18:43,904 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:18:43,904 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:18:43,904 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'dat', 'ik', 'je', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 't@@', 'ing', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:18:43,905 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:18:43,905 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:18:43,905 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien dat ik je een tijdrapporting van de laatste 25 jaar gebeurd.
2025-05-30 01:18:52,803 - INFO - joeynmt.training - Epoch   5, Step:    45100, Batch Loss:     1.325944, Batch Acc: 0.557283, Tokens per Sec:     8051, Lr: 0.000300
2025-05-30 01:19:01,695 - INFO - joeynmt.training - Epoch   5, Step:    45200, Batch Loss:     1.524827, Batch Acc: 0.559107, Tokens per Sec:     8202, Lr: 0.000300
2025-05-30 01:19:10,594 - INFO - joeynmt.training - Epoch   5, Step:    45300, Batch Loss:     1.533804, Batch Acc: 0.563375, Tokens per Sec:     8069, Lr: 0.000300
2025-05-30 01:19:19,627 - INFO - joeynmt.training - Epoch   5, Step:    45400, Batch Loss:     1.255797, Batch Acc: 0.556561, Tokens per Sec:     7865, Lr: 0.000300
2025-05-30 01:19:28,539 - INFO - joeynmt.training - Epoch   5, Step:    45500, Batch Loss:     1.120042, Batch Acc: 0.557392, Tokens per Sec:     8320, Lr: 0.000300
2025-05-30 01:19:28,539 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:19:28,539 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:20:09,115 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.49, ppl:   4.43, acc:   0.53, generation: 40.5291[sec], evaluation: 0.0000[sec]
2025-05-30 01:20:09,116 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:20:09,287 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/43500.ckpt
2025-05-30 01:20:09,302 - INFO - joeynmt.training - Example #0
2025-05-30 01:20:09,303 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:20:09,303 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:20:09,303 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'ies', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 't', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'ste', '4@@', '0', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 01:20:09,304 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:20:09,304 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:20:09,304 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folies getoond om te veranden dat de arctische ijskappe ijskappe ijskappt die voor de grootste 40 staten.
2025-05-30 01:20:09,305 - INFO - joeynmt.training - Example #1
2025-05-30 01:20:09,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:20:09,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:20:09,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'is', 'dat', 'het', 'spe@@', 'ci@@', 'el@@', 'e', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:20:09,306 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:20:09,306 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:20:09,307 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de aarde is dat het speciele probleem uit, omdat het niet de dikke van het ijs laat zien.
2025-05-30 01:20:09,307 - INFO - joeynmt.training - Example #2
2025-05-30 01:20:09,307 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:20:09,307 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:20:09,307 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'k@@', 'ing@@', 'ste@@', 'm@@', '.', '</s>']
2025-05-30 01:20:09,308 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:20:09,308 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:20:09,308 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe hart van onze werkingstem.
2025-05-30 01:20:09,308 - INFO - joeynmt.training - Example #3
2025-05-30 01:20:09,308 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:20:09,308 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:20:09,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'en', 'z@@', 'ich', 'in', 'het', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:20:09,309 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:20:09,309 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:20:09,309 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen en zich in het zomers.
2025-05-30 01:20:09,309 - INFO - joeynmt.training - Example #4
2025-05-30 01:20:09,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:20:09,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:20:09,309 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'dat', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:20:09,310 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:20:09,310 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:20:09,310 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen dat is een tijdsgebeurde in de laatste 25 jaar gebeurd.
2025-05-30 01:20:17,794 - INFO - joeynmt.training - Epoch   5, Step:    45600, Batch Loss:     1.216045, Batch Acc: 0.563663, Tokens per Sec:     8217, Lr: 0.000300
2025-05-30 01:20:25,950 - INFO - joeynmt.training - Epoch   5, Step:    45700, Batch Loss:     1.393950, Batch Acc: 0.553536, Tokens per Sec:     8547, Lr: 0.000300
2025-05-30 01:20:34,071 - INFO - joeynmt.training - Epoch   5, Step:    45800, Batch Loss:     1.461061, Batch Acc: 0.563510, Tokens per Sec:     8685, Lr: 0.000300
2025-05-30 01:20:42,090 - INFO - joeynmt.training - Epoch   5, Step:    45900, Batch Loss:     1.362551, Batch Acc: 0.561979, Tokens per Sec:     8804, Lr: 0.000300
2025-05-30 01:20:50,895 - INFO - joeynmt.training - Epoch   5, Step:    46000, Batch Loss:     1.544295, Batch Acc: 0.554845, Tokens per Sec:     8150, Lr: 0.000300
2025-05-30 01:20:50,895 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:20:50,895 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:21:36,868 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.41, acc:   0.53, generation: 45.9255[sec], evaluation: 0.0000[sec]
2025-05-30 01:21:36,869 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:21:37,039 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/44500.ckpt
2025-05-30 01:21:37,052 - INFO - joeynmt.training - Example #0
2025-05-30 01:21:37,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:21:37,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:21:37,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'heb', 'deze', 'twe@@', 'e', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'om', 'te', 'ver@@', 'ander@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'i@@', 'z@@', 'en@@', 'den', 'die', 'voor', 'de', 'k@@', 'n@@', 'i@@', 'p@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'k@@', 'rij@@', 'gen', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'onder@@', 'ste', 'p@@', 'aar', 'jaar', 'de', 'gro@@', 'ot@@', 'ste', 'p@@', 'aar', 'is.', '</s>']
2025-05-30 01:21:37,054 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:21:37,054 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:21:37,054 - INFO - joeynmt.training - 	Hypothesis: Ik heb deze twee jaar heb ik deze twee dia toonde om te veranderen dat de artische ijizenden die voor de knippen die voor de onderste 40 procent van de onderste 40 procent van 48 staten had om 40 procent te krijgen van 40 procent van de onderste paar jaar de grootste paar is.
2025-05-30 01:21:37,054 - INFO - joeynmt.training - Example #1
2025-05-30 01:21:37,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:21:37,055 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:21:37,055 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:21:37,055 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:21:37,055 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:21:37,056 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de snelheid van dit speciale probleem is dat het niet de dikke van het ijs van het ijs laat zien.
2025-05-30 01:21:37,056 - INFO - joeynmt.training - Example #2
2025-05-30 01:21:37,056 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:21:37,056 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:21:37,057 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'k@@', 'ing', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:21:37,057 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:21:37,057 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:21:37,057 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe hart van onze werking van onze wereldwijde klimaatsysteem.
2025-05-30 01:21:37,057 - INFO - joeynmt.training - Example #3
2025-05-30 01:21:37,058 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:21:37,058 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:21:37,058 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er', 'is.', '</s>']
2025-05-30 01:21:37,059 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:21:37,059 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:21:37,059 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomer in de zomer in de zomer is.
2025-05-30 01:21:37,059 - INFO - joeynmt.training - Example #4
2025-05-30 01:21:37,059 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:21:37,059 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:21:37,059 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:21:37,060 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:21:37,060 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:21:37,060 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdperk van de laatste 25 jaar gebeurd is.
2025-05-30 01:21:45,773 - INFO - joeynmt.training - Epoch   5, Step:    46100, Batch Loss:     1.425196, Batch Acc: 0.554004, Tokens per Sec:     8148, Lr: 0.000300
2025-05-30 01:21:55,229 - INFO - joeynmt.training - Epoch   5, Step:    46200, Batch Loss:     1.391011, Batch Acc: 0.554547, Tokens per Sec:     7715, Lr: 0.000300
2025-05-30 01:22:04,359 - INFO - joeynmt.training - Epoch   5, Step:    46300, Batch Loss:     1.288662, Batch Acc: 0.562515, Tokens per Sec:     7775, Lr: 0.000300
2025-05-30 01:22:13,331 - INFO - joeynmt.training - Epoch   5, Step:    46400, Batch Loss:     1.246324, Batch Acc: 0.558288, Tokens per Sec:     8332, Lr: 0.000300
2025-05-30 01:22:22,380 - INFO - joeynmt.training - Epoch   5, Step:    46500, Batch Loss:     1.359485, Batch Acc: 0.558749, Tokens per Sec:     7817, Lr: 0.000300
2025-05-30 01:22:22,381 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:22:22,381 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:23:11,393 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.49, ppl:   4.43, acc:   0.53, generation: 48.9655[sec], evaluation: 0.0000[sec]
2025-05-30 01:23:11,561 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/44000.ckpt
2025-05-30 01:23:11,576 - INFO - joeynmt.training - Example #0
2025-05-30 01:23:11,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:23:11,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:23:11,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'lan@@', 'g', 'om', 'te', 'beg@@', 're@@', 'pen', 'dat', 'de', 'ar@@', 'ti@@', 'c@@', 'a', 'te', 'et@@', 'en,', 'die', 'voor', 'de', 'onder@@', 'ste', 'p@@', 'aar', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 01:23:11,578 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:23:11,578 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:23:11,578 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee miljoen jaar lang om te begrepen dat de artica te eten, die voor de onderste paar jaar de grootte van de onderste 40 procent van 40 procent te gebeuren.
2025-05-30 01:23:11,579 - INFO - joeynmt.training - Example #1
2025-05-30 01:23:11,579 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:23:11,579 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:23:11,579 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 're@@', 's@@', 'ul@@', 't@@', 'aat', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:23:11,581 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:23:11,581 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:23:11,581 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet sterk genoeg de resultaat van dit specifieke probleem uit, omdat het niet de dikke ijs van het ijs laat zien.
2025-05-30 01:23:11,581 - INFO - joeynmt.training - Example #2
2025-05-30 01:23:11,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:23:11,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:23:11,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'c@@', 'a', 'van', 'onze', 'wer@@', 'k@@', 'ing', 'van', 'onze', 'wer@@', 'k@@', 'ing', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:23:11,583 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:23:11,583 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:23:11,583 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctica van onze werking van onze werking van onze wereldwijde klimaatsysteem.
2025-05-30 01:23:11,584 - INFO - joeynmt.training - Example #3
2025-05-30 01:23:11,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:23:11,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:23:11,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:23:11,585 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:23:11,585 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:23:11,586 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomers.
2025-05-30 01:23:11,586 - INFO - joeynmt.training - Example #4
2025-05-30 01:23:11,586 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:23:11,586 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:23:11,586 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'er@@', 'ende', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:23:11,587 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:23:11,587 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:23:11,587 - INFO - joeynmt.training - 	Hypothesis: De volgende die ik jullie laten zien is een tijdrapperende 25 jaar gebeurde laatste 25 jaar gebeurd.
2025-05-30 01:23:20,615 - INFO - joeynmt.training - Epoch   5, Step:    46600, Batch Loss:     1.447847, Batch Acc: 0.559116, Tokens per Sec:     7787, Lr: 0.000300
2025-05-30 01:23:29,704 - INFO - joeynmt.training - Epoch   5, Step:    46700, Batch Loss:     1.267263, Batch Acc: 0.557355, Tokens per Sec:     7930, Lr: 0.000300
2025-05-30 01:23:38,832 - INFO - joeynmt.training - Epoch   5, Step:    46800, Batch Loss:     1.553605, Batch Acc: 0.560382, Tokens per Sec:     8003, Lr: 0.000300
2025-05-30 01:23:47,615 - INFO - joeynmt.training - Epoch   5, Step:    46900, Batch Loss:     1.306914, Batch Acc: 0.562182, Tokens per Sec:     8368, Lr: 0.000300
2025-05-30 01:23:56,475 - INFO - joeynmt.training - Epoch   5, Step:    47000, Batch Loss:     1.312961, Batch Acc: 0.558847, Tokens per Sec:     8060, Lr: 0.000300
2025-05-30 01:23:56,476 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:23:56,476 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:24:45,058 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.39, acc:   0.53, generation: 48.5346[sec], evaluation: 0.0000[sec]
2025-05-30 01:24:45,059 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:24:45,225 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/43000.ckpt
2025-05-30 01:24:45,241 - INFO - joeynmt.training - Example #0
2025-05-30 01:24:45,241 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:24:45,242 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:24:45,242 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'di@@', 'a@@', "'s", 'to@@', 'on@@', 'de', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'wer@@', 'eld', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'van', '4@@', '8', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'g', 'is.', '</s>']
2025-05-30 01:24:45,243 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:24:45,243 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:24:45,243 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde dia's toonde de arctische ijskappen die voor de wereld voor de grootte van de grootte van 48 staten had om 48 staten had 48 staten had om 48 staten had om 48 procent geslagen van 48 procent geslag is.
2025-05-30 01:24:45,243 - INFO - joeynmt.training - Example #1
2025-05-30 01:24:45,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:24:45,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:24:45,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'un@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-30 01:24:45,245 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:24:45,245 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:24:45,245 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de eerste punt van dit speciale probleem uit, omdat het niet de dikke van het ijs toont.
2025-05-30 01:24:45,245 - INFO - joeynmt.training - Example #2
2025-05-30 01:24:45,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:24:45,246 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:24:45,246 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:24:45,247 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:24:45,247 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:24:45,247 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe hart van onze wereldwijde klimaatsysteem.
2025-05-30 01:24:45,247 - INFO - joeynmt.training - Example #3
2025-05-30 01:24:45,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:24:45,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:24:45,247 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:24:45,248 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:24:45,248 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:24:45,249 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen in de zomers.
2025-05-30 01:24:45,249 - INFO - joeynmt.training - Example #4
2025-05-30 01:24:45,249 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:24:45,249 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:24:45,249 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'to@@', 'on@@', ',', 'is', 'een', 'tij@@', 'd@@', 's@@', 'me@@', 'e@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 01:24:45,250 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:24:45,250 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:24:45,250 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je toon, is een tijdsmeeste 25 jaar.
2025-05-30 01:24:54,857 - INFO - joeynmt.training - Epoch   5, Step:    47100, Batch Loss:     1.348189, Batch Acc: 0.552805, Tokens per Sec:     7438, Lr: 0.000300
2025-05-30 01:25:03,959 - INFO - joeynmt.training - Epoch   5, Step:    47200, Batch Loss:     1.278077, Batch Acc: 0.558680, Tokens per Sec:     7823, Lr: 0.000300
2025-05-30 01:25:12,258 - INFO - joeynmt.training - Epoch   5, Step:    47300, Batch Loss:     1.247076, Batch Acc: 0.559953, Tokens per Sec:     8670, Lr: 0.000300
2025-05-30 01:25:20,355 - INFO - joeynmt.training - Epoch   5, Step:    47400, Batch Loss:     1.627802, Batch Acc: 0.556009, Tokens per Sec:     9133, Lr: 0.000300
2025-05-30 01:25:28,283 - INFO - joeynmt.training - Epoch   5, Step:    47500, Batch Loss:     1.395238, Batch Acc: 0.555593, Tokens per Sec:     8996, Lr: 0.000300
2025-05-30 01:25:28,284 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:25:28,284 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:26:05,672 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.39, acc:   0.54, generation: 37.3437[sec], evaluation: 0.0000[sec]
2025-05-30 01:26:05,843 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/45000.ckpt
2025-05-30 01:26:05,859 - INFO - joeynmt.training - Example #0
2025-05-30 01:26:05,860 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:26:05,860 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:26:05,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'jaar', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'der', 'te', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'c@@', 'ti@@', 'c@@', 'a', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'voor', '4@@', '8', 'st@@', 'aten', 'is.', '</s>']
2025-05-30 01:26:05,861 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:26:05,861 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:26:05,862 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee jaar getoond om te verander te kijken dat de arctische ijskappen die voor de arctica van de onderste 48 staten om 48 staten om 48 staten om 48 staten om 48 staten om 48 staten voor 48 staten is.
2025-05-30 01:26:05,862 - INFO - joeynmt.training - Example #1
2025-05-30 01:26:05,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:26:05,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:26:05,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'er@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'k@@', 'ra@@', 'ch@@', 'ten', 'de', 'p@@', 'un@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'el@@', 'e', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:26:05,863 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:26:05,863 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:26:05,864 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg de krachten de punt van dit speciele probleem uit, omdat het niet de dikke dik laat zien.
2025-05-30 01:26:05,864 - INFO - joeynmt.training - Example #2
2025-05-30 01:26:05,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:26:05,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:26:05,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:26:05,865 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:26:05,865 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:26:05,866 - INFO - joeynmt.training - 	Hypothesis: In zekere ijskappe ijskappe ijskappe ijskappe klimaatsysteem.
2025-05-30 01:26:05,866 - INFO - joeynmt.training - Example #3
2025-05-30 01:26:05,866 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:26:05,866 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:26:05,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-30 01:26:05,867 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:26:05,868 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:26:05,868 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen en zorgen in de zomer.
2025-05-30 01:26:05,868 - INFO - joeynmt.training - Example #4
2025-05-30 01:26:05,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:26:05,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:26:05,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'c@@', 'ij@@', 'f@@', 'er@@', 's', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 01:26:05,869 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:26:05,870 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:26:05,870 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een cijfers wat er in de laatste 25 jaar.
2025-05-30 01:26:14,920 - INFO - joeynmt.training - Epoch   5, Step:    47600, Batch Loss:     1.366577, Batch Acc: 0.558771, Tokens per Sec:     7979, Lr: 0.000300
2025-05-30 01:26:24,112 - INFO - joeynmt.training - Epoch   5, Step:    47700, Batch Loss:     1.536272, Batch Acc: 0.556039, Tokens per Sec:     7680, Lr: 0.000300
2025-05-30 01:26:33,116 - INFO - joeynmt.training - Epoch   5, Step:    47800, Batch Loss:     1.252711, Batch Acc: 0.556484, Tokens per Sec:     8078, Lr: 0.000300
2025-05-30 01:26:42,157 - INFO - joeynmt.training - Epoch   5, Step:    47900, Batch Loss:     1.487346, Batch Acc: 0.561250, Tokens per Sec:     8153, Lr: 0.000300
2025-05-30 01:26:50,754 - INFO - joeynmt.training - Epoch   5, Step:    48000, Batch Loss:     1.404709, Batch Acc: 0.562946, Tokens per Sec:     8246, Lr: 0.000300
2025-05-30 01:26:50,754 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:26:50,754 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:27:32,148 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.41, acc:   0.53, generation: 41.3540[sec], evaluation: 0.0000[sec]
2025-05-30 01:27:32,315 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/45500.ckpt
2025-05-30 01:27:32,332 - INFO - joeynmt.training - Example #0
2025-05-30 01:27:32,333 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:27:32,333 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:27:32,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'jaar', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'der', 'te', 'k@@', 'ijk@@', 'en,', 'dat', 'de', 'ar@@', 'ct@@', 'ie@@', 've', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'g', 'te', 'ge@@', 'ven', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'k@@', 'rij@@', 'gen.', '</s>']
2025-05-30 01:27:32,334 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:27:32,334 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:27:32,335 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee jaar getoond om te verander te kijken, dat de arctieve ijskapen die voor de onderste 48 staten die voor de onderste 48 staten had 48 staten had 48 staten had om 48 staten om 40 procent te geslag te geven om 40 procent te krijgen.
2025-05-30 01:27:32,335 - INFO - joeynmt.training - Example #1
2025-05-30 01:27:32,335 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:27:32,335 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:27:32,335 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'k@@', 'ra@@', 'cht', 'van', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'pro@@', 'ble@@', 'em', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:27:32,336 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:27:32,337 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:27:32,337 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de kracht van het speciale probleem dat het niet de dikke probleem laat zien.
2025-05-30 01:27:32,337 - INFO - joeynmt.training - Example #2
2025-05-30 01:27:32,337 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:27:32,337 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:27:32,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijk', 'is.', '</s>']
2025-05-30 01:27:32,338 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:27:32,338 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:27:32,339 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappelijke ijskappelijk is.
2025-05-30 01:27:32,339 - INFO - joeynmt.training - Example #3
2025-05-30 01:27:32,339 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:27:32,339 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:27:32,339 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:27:32,340 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:27:32,340 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:27:32,340 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomers.
2025-05-30 01:27:32,341 - INFO - joeynmt.training - Example #4
2025-05-30 01:27:32,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:27:32,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:27:32,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'te@@', 'ken@@', 's', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:27:32,342 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:27:32,342 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:27:32,342 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tekens wat er gebeurd in de laatste 25 jaar gebeurd is.
2025-05-30 01:27:41,233 - INFO - joeynmt.training - Epoch   5, Step:    48100, Batch Loss:     1.645481, Batch Acc: 0.548474, Tokens per Sec:     7733, Lr: 0.000300
2025-05-30 01:27:50,276 - INFO - joeynmt.training - Epoch   5, Step:    48200, Batch Loss:     1.384600, Batch Acc: 0.557256, Tokens per Sec:     8088, Lr: 0.000300
2025-05-30 01:27:59,693 - INFO - joeynmt.training - Epoch   5, Step:    48300, Batch Loss:     1.258466, Batch Acc: 0.557954, Tokens per Sec:     7631, Lr: 0.000300
2025-05-30 01:28:08,738 - INFO - joeynmt.training - Epoch   5, Step:    48400, Batch Loss:     1.409055, Batch Acc: 0.550806, Tokens per Sec:     7781, Lr: 0.000300
2025-05-30 01:28:17,712 - INFO - joeynmt.training - Epoch   5, Step:    48500, Batch Loss:     1.316499, Batch Acc: 0.560707, Tokens per Sec:     7953, Lr: 0.000300
2025-05-30 01:28:17,713 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:28:17,713 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:29:00,850 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.39, acc:   0.53, generation: 43.0923[sec], evaluation: 0.0000[sec]
2025-05-30 01:29:01,028 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/46500.ckpt
2025-05-30 01:29:01,044 - INFO - joeynmt.training - Example #0
2025-05-30 01:29:01,045 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:29:01,045 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:29:01,045 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'l@@', 'aten', 'zien', 'dat', 'de', 'ar@@', 'ct@@', 'ie@@', 've', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'p@@', 'en,', '4@@', '8', 'st@@', 'aten', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'st@@', 'el@@', 'd.', '</s>']
2025-05-30 01:29:01,047 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:29:01,047 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:29:01,047 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee dia's laten zien dat de arctieve ijskappe ijskappe ijskapppe ijskapppen, 48 staten van 48 staten had 48 staten om 40 procent gesteld.
2025-05-30 01:29:01,047 - INFO - joeynmt.training - Example #1
2025-05-30 01:29:01,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:29:01,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:29:01,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'd@@', 'ru@@', 'k@@', 't', 'het', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'k@@', 'e', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:29:01,049 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:29:01,049 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:29:01,049 - INFO - joeynmt.training - 	Hypothesis: Maar dat drukt het niet genoeg de eerste van dit specifieke probleem is dat het niet de dikke van het ijs laat zien.
2025-05-30 01:29:01,049 - INFO - joeynmt.training - Example #2
2025-05-30 01:29:01,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:29:01,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:29:01,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:29:01,050 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:29:01,051 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:29:01,051 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 01:29:01,051 - INFO - joeynmt.training - Example #3
2025-05-30 01:29:01,051 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:29:01,051 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:29:01,051 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'sch@@', 'ro@@', 'e@@', 'p@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'or@@', 'gen.', '</s>']
2025-05-30 01:29:01,052 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:29:01,052 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:29:01,053 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroept in de zomer in de zomer in de winter en zomer in de winter en zomer in de winter en zich zomer in de winter en zich zomer in de winter en schroepppt in de winter en zich zomer in de winter en schrompt in de winter en zich schroepppt in de winter en zich zorgen.
2025-05-30 01:29:01,053 - INFO - joeynmt.training - Example #4
2025-05-30 01:29:01,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:29:01,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:29:01,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 't@@', 'ran@@', 's@@', 'for@@', 'm@@', 'atie', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:29:01,054 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:29:01,054 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:29:01,054 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een transformatie in de laatste 25 jaar gebeurd.
2025-05-30 01:29:10,022 - INFO - joeynmt.training - Epoch   5, Step:    48600, Batch Loss:     1.265345, Batch Acc: 0.566033, Tokens per Sec:     7856, Lr: 0.000300
2025-05-30 01:29:19,055 - INFO - joeynmt.training - Epoch   5, Step:    48700, Batch Loss:     1.468975, Batch Acc: 0.554295, Tokens per Sec:     8109, Lr: 0.000300
2025-05-30 01:29:27,850 - INFO - joeynmt.training - Epoch   5, Step:    48800, Batch Loss:     1.493866, Batch Acc: 0.558181, Tokens per Sec:     8416, Lr: 0.000300
2025-05-30 01:29:36,689 - INFO - joeynmt.training - Epoch   5, Step:    48900, Batch Loss:     1.383634, Batch Acc: 0.562097, Tokens per Sec:     8257, Lr: 0.000300
2025-05-30 01:29:45,373 - INFO - joeynmt.training - Epoch   5, Step:    49000, Batch Loss:     1.294702, Batch Acc: 0.565479, Tokens per Sec:     8389, Lr: 0.000300
2025-05-30 01:29:45,374 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:29:45,374 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:30:26,320 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.37, acc:   0.54, generation: 40.9039[sec], evaluation: 0.0000[sec]
2025-05-30 01:30:26,321 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:30:26,491 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/46000.ckpt
2025-05-30 01:30:26,506 - INFO - joeynmt.training - Example #0
2025-05-30 01:30:26,507 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:30:26,507 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:30:26,507 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'c@@', 'ul@@', 'a@@', 'ir', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'k@@', 'el', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'd@@', 'ra@@', 'gen', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'd@@', 'ra@@', 'gen', 'om', '4@@', '8', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'da@@', 'ch@@', 't.', '</s>']
2025-05-30 01:30:26,508 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:30:26,509 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:30:26,509 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen dat de arcticulair ijskappen die voor de artikel voor de onderste 48 staten had om 48 staten had om 48 staten had gedragen om 48 staten had gedragen om 48 procent te gedacht.
2025-05-30 01:30:26,509 - INFO - joeynmt.training - Example #1
2025-05-30 01:30:26,509 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:30:26,509 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:30:26,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'ij@@', 's@@', 'ge@@', 'st@@', 'el@@', 'd.', '</s>']
2025-05-30 01:30:26,510 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:30:26,511 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:30:26,511 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de eerste van dit specifieke probleem van dit specifieke probleem dat het niet de dikke dikke van ijsgesteld.
2025-05-30 01:30:26,511 - INFO - joeynmt.training - Example #2
2025-05-30 01:30:26,511 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:30:26,511 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:30:26,511 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:30:26,512 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:30:26,512 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:30:26,512 - INFO - joeynmt.training - 	Hypothesis: In zekere zin de arctische ijskapen het slagen van onze wereldwijde klimaatsysteem.
2025-05-30 01:30:26,512 - INFO - joeynmt.training - Example #3
2025-05-30 01:30:26,512 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:30:26,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:30:26,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-30 01:30:26,514 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:30:26,515 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:30:26,515 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zorgen in de zomer.
2025-05-30 01:30:26,515 - INFO - joeynmt.training - Example #4
2025-05-30 01:30:26,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:30:26,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:30:26,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'te@@', 'm@@', 'p@@', 'o@@', 'st@@', '-@@', 'in@@', 'st@@', 'ru@@', 'men@@', 'ten', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:30:26,516 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:30:26,517 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:30:26,517 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tempost-instrumenten wat er in de afgelopen 25 jaar gebeurd is.
2025-05-30 01:30:34,547 - INFO - joeynmt.training - Epoch   5, Step:    49100, Batch Loss:     1.281306, Batch Acc: 0.561267, Tokens per Sec:     8730, Lr: 0.000300
2025-05-30 01:30:43,000 - INFO - joeynmt.training - Epoch   5, Step:    49200, Batch Loss:     1.472016, Batch Acc: 0.558388, Tokens per Sec:     8767, Lr: 0.000300
2025-05-30 01:30:51,932 - INFO - joeynmt.training - Epoch   5, Step:    49300, Batch Loss:     1.428516, Batch Acc: 0.557490, Tokens per Sec:     7987, Lr: 0.000300
2025-05-30 01:31:00,869 - INFO - joeynmt.training - Epoch   5, Step:    49400, Batch Loss:     1.474050, Batch Acc: 0.560166, Tokens per Sec:     8256, Lr: 0.000300
2025-05-30 01:31:09,874 - INFO - joeynmt.training - Epoch   5, Step:    49500, Batch Loss:     1.403201, Batch Acc: 0.560814, Tokens per Sec:     7905, Lr: 0.000300
2025-05-30 01:31:09,875 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:31:09,875 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:31:58,911 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.38, acc:   0.53, generation: 48.9901[sec], evaluation: 0.0000[sec]
2025-05-30 01:31:59,078 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/48000.ckpt
2025-05-30 01:31:59,095 - INFO - joeynmt.training - Example #0
2025-05-30 01:31:59,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:31:59,096 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:31:59,096 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'der', 'te', 'k@@', 'ij@@', 'ken', 'naar', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'op', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'op', '4@@', '8', 'st@@', 'aten', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 01:31:59,097 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:31:59,098 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:31:59,098 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verander te kijken naar de arctische ijskappe ijskappe ijskappen, de grootte van de onderste 48 staten had om 48 staten op 48 staten had om 48 staten op 48 staten gebeuren.
2025-05-30 01:31:59,098 - INFO - joeynmt.training - Example #1
2025-05-30 01:31:59,098 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:31:59,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:31:59,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'op@@', 'n@@', 'am@@', 'e', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:31:59,099 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:31:59,099 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:31:59,099 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de opname probleem van dit speciale probleem laat zien.
2025-05-30 01:31:59,100 - INFO - joeynmt.training - Example #2
2025-05-30 01:31:59,100 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:31:59,100 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:31:59,100 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:31:59,101 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:31:59,101 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:31:59,101 - INFO - joeynmt.training - 	Hypothesis: In zekere ijskape ijskape ijskape ijskape klimaatsysteem.
2025-05-30 01:31:59,101 - INFO - joeynmt.training - Example #3
2025-05-30 01:31:59,101 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:31:59,102 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:31:59,102 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'en', 'z@@', 'or@@', 'gen.', '</s>']
2025-05-30 01:31:59,102 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:31:59,102 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:31:59,103 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen en zorgen.
2025-05-30 01:31:59,103 - INFO - joeynmt.training - Example #4
2025-05-30 01:31:59,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:31:59,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:31:59,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'te@@', 'm@@', 'p@@', 'el', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:31:59,104 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:31:59,104 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:31:59,104 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tempel wat er gebeurd in de afgelopen 25 jaar gebeurd.
2025-05-30 01:32:07,979 - INFO - joeynmt.training - Epoch   5, Step:    49600, Batch Loss:     1.482094, Batch Acc: 0.566336, Tokens per Sec:     7736, Lr: 0.000300
2025-05-30 01:32:16,874 - INFO - joeynmt.training - Epoch   5, Step:    49700, Batch Loss:     1.353251, Batch Acc: 0.561681, Tokens per Sec:     8084, Lr: 0.000300
2025-05-30 01:32:25,635 - INFO - joeynmt.training - Epoch   5, Step:    49800, Batch Loss:     1.370958, Batch Acc: 0.562616, Tokens per Sec:     8117, Lr: 0.000300
2025-05-30 01:32:34,197 - INFO - joeynmt.training - Epoch   5, Step:    49900, Batch Loss:     1.484160, Batch Acc: 0.554297, Tokens per Sec:     8293, Lr: 0.000300
2025-05-30 01:32:43,066 - INFO - joeynmt.training - Epoch   5, Step:    50000, Batch Loss:     1.478618, Batch Acc: 0.555303, Tokens per Sec:     7980, Lr: 0.000300
2025-05-30 01:32:43,066 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:32:43,066 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:33:29,308 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.38, acc:   0.53, generation: 46.1937[sec], evaluation: 0.0000[sec]
2025-05-30 01:33:29,464 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/47500.ckpt
2025-05-30 01:33:29,480 - INFO - joeynmt.training - Example #0
2025-05-30 01:33:29,481 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:33:29,481 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:33:29,482 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'de', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'k@@', 'ap@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'i@@', 'ë@@', 'l@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:33:29,482 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:33:29,483 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:33:29,483 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik de twee getoond om te kappen dat de arctische ijiële ijskappen die voor de onderste 40 procent van de onderste 40 procent staten had om 40 procent te gebeurd.
2025-05-30 01:33:29,483 - INFO - joeynmt.training - Example #1
2025-05-30 01:33:29,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:33:29,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:33:29,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 'un@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:33:29,484 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:33:29,485 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:33:29,485 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de punt van dit specifieke probleem van dit specifieke probleem uit, want het is niet de dikke laat zien.
2025-05-30 01:33:29,485 - INFO - joeynmt.training - Example #2
2025-05-30 01:33:29,485 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:33:29,485 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:33:29,485 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'i@@', 'ë@@', 'l@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:33:29,486 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:33:29,486 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:33:29,486 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijiële ijskape hart van onze wereldwijde klimaatsysteem.
2025-05-30 01:33:29,487 - INFO - joeynmt.training - Example #3
2025-05-30 01:33:29,487 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:33:29,487 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:33:29,487 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'g@@', 'd', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 01:33:29,488 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:33:29,488 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:33:29,488 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgd in de zomer.
2025-05-30 01:33:29,488 - INFO - joeynmt.training - Example #4
2025-05-30 01:33:29,488 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:33:29,488 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:33:29,488 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'te@@', 'ken@@', 'de', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:33:29,489 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:33:29,490 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:33:29,490 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik jullie laat zien is een tekende 25 jaar gebeurd in de laatste 25 jaar gebeurd.
2025-05-30 01:33:38,532 - INFO - joeynmt.training - Epoch   5, Step:    50100, Batch Loss:     1.535493, Batch Acc: 0.559742, Tokens per Sec:     7752, Lr: 0.000300
2025-05-30 01:33:47,801 - INFO - joeynmt.training - Epoch   5, Step:    50200, Batch Loss:     1.461892, Batch Acc: 0.559815, Tokens per Sec:     7873, Lr: 0.000300
2025-05-30 01:33:56,915 - INFO - joeynmt.training - Epoch   5, Step:    50300, Batch Loss:     1.273340, Batch Acc: 0.561796, Tokens per Sec:     7942, Lr: 0.000300
2025-05-30 01:34:06,447 - INFO - joeynmt.training - Epoch   5, Step:    50400, Batch Loss:     1.341021, Batch Acc: 0.563305, Tokens per Sec:     7685, Lr: 0.000300
2025-05-30 01:34:15,796 - INFO - joeynmt.training - Epoch   5, Step:    50500, Batch Loss:     1.242694, Batch Acc: 0.558950, Tokens per Sec:     7438, Lr: 0.000300
2025-05-30 01:34:15,798 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:34:15,798 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:35:12,175 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.38, acc:   0.53, generation: 56.3359[sec], evaluation: 0.0000[sec]
2025-05-30 01:35:12,345 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/48500.ckpt
2025-05-30 01:35:12,360 - INFO - joeynmt.training - Example #0
2025-05-30 01:35:12,361 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:35:12,361 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:35:12,361 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'e@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 's', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 01:35:12,362 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:35:12,362 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:35:12,362 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te verbeelden dat de arctische ijeskappe ijskappe ijskappe ijskappels van de onderste 48 staten had om 48 staten had gegeslagen is.
2025-05-30 01:35:12,363 - INFO - joeynmt.training - Example #1
2025-05-30 01:35:12,363 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:35:12,363 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:35:12,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 're@@', 's@@', 'ent@@', 'atie', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:35:12,363 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:35:12,363 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:35:12,364 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de presentatie van dit specifieke probleem uit, want het is niet de dikke van de ijskracht laat zien.
2025-05-30 01:35:12,364 - INFO - joeynmt.training - Example #2
2025-05-30 01:35:12,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:35:12,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:35:12,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'de', 'ze@@', 'ker@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:35:12,364 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:35:12,365 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:35:12,365 - INFO - joeynmt.training - 	Hypothesis: In zezekere zin de zekere ijskappe ijskappe hart van onze wereldwijde klimaatsysteem.
2025-05-30 01:35:12,365 - INFO - joeynmt.training - Example #3
2025-05-30 01:35:12,365 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:35:12,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:35:12,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:35:12,365 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:35:12,366 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:35:12,366 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen in de winter en zomers.
2025-05-30 01:35:12,366 - INFO - joeynmt.training - Example #4
2025-05-30 01:35:12,366 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:35:12,366 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:35:12,366 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'k@@', 'ran@@', 't', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:35:12,366 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:35:12,367 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:35:12,367 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een krant van wat er gebeurd in de laatste 25 jaar gebeurd is.
2025-05-30 01:35:20,515 - INFO - joeynmt.training - Epoch   5, Step:    50600, Batch Loss:     1.365987, Batch Acc: 0.555572, Tokens per Sec:     8722, Lr: 0.000300
2025-05-30 01:35:28,345 - INFO - joeynmt.training - Epoch   5, Step:    50700, Batch Loss:     1.518036, Batch Acc: 0.560905, Tokens per Sec:     9211, Lr: 0.000300
2025-05-30 01:35:35,706 - INFO - joeynmt.training - Epoch   5, Step:    50800, Batch Loss:     1.465353, Batch Acc: 0.557560, Tokens per Sec:    10272, Lr: 0.000300
2025-05-30 01:35:42,939 - INFO - joeynmt.training - Epoch   5, Step:    50900, Batch Loss:     1.376193, Batch Acc: 0.562415, Tokens per Sec:     9675, Lr: 0.000300
2025-05-30 01:35:50,939 - INFO - joeynmt.training - Epoch   5, Step:    51000, Batch Loss:     1.424617, Batch Acc: 0.558117, Tokens per Sec:     8997, Lr: 0.000300
2025-05-30 01:35:50,940 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:35:50,940 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:36:39,955 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.36, acc:   0.53, generation: 48.9671[sec], evaluation: 0.0000[sec]
2025-05-30 01:36:39,956 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:36:40,139 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/47000.ckpt
2025-05-30 01:36:40,159 - INFO - joeynmt.training - Example #0
2025-05-30 01:36:40,160 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:36:40,160 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:36:40,160 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'de', 'gro@@', 'ot@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'de', 'gro@@', 'ot@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 01:36:40,161 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:36:40,161 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:36:40,161 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te begrijpen dat de arctische ijskappen, die voor de artische ijskappen, de grootste 48 staten, de grootste 48 staten, om 48 staten, om 48 staten, om 48 staten.
2025-05-30 01:36:40,161 - INFO - joeynmt.training - Example #1
2025-05-30 01:36:40,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:36:40,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:36:40,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:36:40,163 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:36:40,163 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:36:40,163 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van het specifiek van dit specifieke probleem uit, omdat het niet de dicks van het ijs laat zien.
2025-05-30 01:36:40,164 - INFO - joeynmt.training - Example #2
2025-05-30 01:36:40,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:36:40,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:36:40,164 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'ig@@', 'en@@', 'lijk', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:36:40,165 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:36:40,165 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:36:40,165 - INFO - joeynmt.training - 	Hypothesis: In zezekere zintuigenlijk is de arctische ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-30 01:36:40,165 - INFO - joeynmt.training - Example #3
2025-05-30 01:36:40,166 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:36:40,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:36:40,166 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'aa@@', 'k', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:36:40,167 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:36:40,167 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:36:40,167 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zich zaak in de winter en zomers.
2025-05-30 01:36:40,167 - INFO - joeynmt.training - Example #4
2025-05-30 01:36:40,167 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:36:40,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:36:40,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ver@@', 'z@@', 'am@@', 'el@@', 'ing', 'van', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:36:40,169 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:36:40,169 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:36:40,169 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdsverzameling van wat er in de laatste 25 jaar gebeurd.
2025-05-30 01:36:49,223 - INFO - joeynmt.training - Epoch   5, Step:    51100, Batch Loss:     1.229048, Batch Acc: 0.560876, Tokens per Sec:     7831, Lr: 0.000300
2025-05-30 01:36:58,423 - INFO - joeynmt.training - Epoch   5, Step:    51200, Batch Loss:     1.345280, Batch Acc: 0.559664, Tokens per Sec:     7758, Lr: 0.000300
2025-05-30 01:37:07,902 - INFO - joeynmt.training - Epoch   5, Step:    51300, Batch Loss:     1.157156, Batch Acc: 0.563884, Tokens per Sec:     7640, Lr: 0.000300
2025-05-30 01:37:16,838 - INFO - joeynmt.training - Epoch   5, Step:    51400, Batch Loss:     1.550978, Batch Acc: 0.564843, Tokens per Sec:     7955, Lr: 0.000300
2025-05-30 01:37:25,677 - INFO - joeynmt.training - Epoch   5, Step:    51500, Batch Loss:     1.554508, Batch Acc: 0.555029, Tokens per Sec:     8118, Lr: 0.000300
2025-05-30 01:37:25,678 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:37:25,678 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:38:08,598 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.37, acc:   0.53, generation: 42.8746[sec], evaluation: 0.0000[sec]
2025-05-30 01:38:08,775 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/50000.ckpt
2025-05-30 01:38:08,789 - INFO - joeynmt.training - Example #0
2025-05-30 01:38:08,790 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:38:08,790 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:38:08,790 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'onder@@', 'e', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'stu@@', 'de@@', 'er@@', 'd', 'te', 'ver@@', 'k@@', 'rij@@', 'gen.', '</s>']
2025-05-30 01:38:08,791 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:38:08,791 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:38:08,791 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee dia toonde arctische ijskape ijskape ijskape ijskape ijzondere 48 staten had om 48 staten had om 48 staten had gestudeerd te verkrijgen.
2025-05-30 01:38:08,791 - INFO - joeynmt.training - Example #1
2025-05-30 01:38:08,791 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:38:08,791 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:38:08,792 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:38:08,792 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:38:08,792 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:38:08,793 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van dit specifieke probleem uit, omdat het niet de dicks van het ijs laat zien.
2025-05-30 01:38:08,793 - INFO - joeynmt.training - Example #2
2025-05-30 01:38:08,793 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:38:08,793 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:38:08,793 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:38:08,794 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:38:08,794 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:38:08,794 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijskape van ons wereldwijde klimaatsysteem.
2025-05-30 01:38:08,794 - INFO - joeynmt.training - Example #3
2025-05-30 01:38:08,794 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:38:08,795 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:38:08,795 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:38:08,795 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:38:08,796 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:38:08,796 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppt in de zomers.
2025-05-30 01:38:08,796 - INFO - joeynmt.training - Example #4
2025-05-30 01:38:08,796 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:38:08,796 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:38:08,796 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'te@@', 'ken@@', 'ing', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:38:08,797 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:38:08,797 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:38:08,797 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik jullie laten zien is een tekening van de laatste 25 jaar gebeurt in de laatste 25 jaar gebeurd.
2025-05-30 01:38:17,492 - INFO - joeynmt.training - Epoch   5, Step:    51600, Batch Loss:     1.304938, Batch Acc: 0.560916, Tokens per Sec:     8232, Lr: 0.000300
2025-05-30 01:38:26,005 - INFO - joeynmt.training - Epoch   5, Step:    51700, Batch Loss:     1.541455, Batch Acc: 0.558523, Tokens per Sec:     8576, Lr: 0.000300
2025-05-30 01:38:34,675 - INFO - joeynmt.training - Epoch   5, Step:    51800, Batch Loss:     1.418226, Batch Acc: 0.559875, Tokens per Sec:     8370, Lr: 0.000300
2025-05-30 01:38:42,945 - INFO - joeynmt.training - Epoch   5, Step:    51900, Batch Loss:     1.432434, Batch Acc: 0.554566, Tokens per Sec:     8789, Lr: 0.000300
2025-05-30 01:38:50,995 - INFO - joeynmt.training - Epoch   5, Step:    52000, Batch Loss:     1.477131, Batch Acc: 0.555150, Tokens per Sec:     9225, Lr: 0.000300
2025-05-30 01:38:50,995 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:38:50,996 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:39:40,379 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.34, acc:   0.54, generation: 49.3407[sec], evaluation: 0.0000[sec]
2025-05-30 01:39:40,380 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:39:40,545 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/49500.ckpt
2025-05-30 01:39:40,566 - INFO - joeynmt.training - Example #0
2025-05-30 01:39:40,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:39:40,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:39:40,567 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'in', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 01:39:40,567 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:39:40,568 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:39:40,568 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te begrijpen dat de arctische ijskape ijskape ijskape ijskape ijskape in de onderste 48 staten om 40 procent te gebeuren.
2025-05-30 01:39:40,568 - INFO - joeynmt.training - Example #1
2025-05-30 01:39:40,568 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:39:40,568 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:39:40,568 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 're@@', 'c@@', 'ies', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ru@@', 'k', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:39:40,570 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:39:40,570 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:39:40,570 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de precies van dit specifiek genoeg de druk van het ijs van het ijs laat zien.
2025-05-30 01:39:40,570 - INFO - joeynmt.training - Example #2
2025-05-30 01:39:40,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:39:40,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:39:40,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:39:40,571 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:39:40,571 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:39:40,572 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe het slagen van onze wereldwijde klimaatsysteem.
2025-05-30 01:39:40,572 - INFO - joeynmt.training - Example #3
2025-05-30 01:39:40,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:39:40,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:39:40,572 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'en', 'z@@', 'or@@', 'g@@', 'aan@@', '.', '</s>']
2025-05-30 01:39:40,573 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:39:40,573 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:39:40,573 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen en zorgaan.
2025-05-30 01:39:40,573 - INFO - joeynmt.training - Example #4
2025-05-30 01:39:40,574 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:39:40,574 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:39:40,574 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'te@@', 'ken@@', 'de', 't@@', 'al@@', 'k', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't.', '</s>']
2025-05-30 01:39:40,575 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:39:40,575 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:39:40,575 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tekende talk van wat er gebeurd in de laatste 25 jaar gebeurt.
2025-05-30 01:39:49,635 - INFO - joeynmt.training - Epoch   5, Step:    52100, Batch Loss:     1.317402, Batch Acc: 0.557173, Tokens per Sec:     7972, Lr: 0.000300
2025-05-30 01:39:58,480 - INFO - joeynmt.training - Epoch   5, Step:    52200, Batch Loss:     1.180773, Batch Acc: 0.558843, Tokens per Sec:     7997, Lr: 0.000300
2025-05-30 01:40:09,021 - INFO - joeynmt.training - Epoch   5, Step:    52300, Batch Loss:     1.442217, Batch Acc: 0.562211, Tokens per Sec:     6897, Lr: 0.000300
2025-05-30 01:40:18,563 - INFO - joeynmt.training - Epoch   5, Step:    52400, Batch Loss:     1.389644, Batch Acc: 0.561907, Tokens per Sec:     7375, Lr: 0.000300
2025-05-30 01:40:26,820 - INFO - joeynmt.training - Epoch   5, Step:    52500, Batch Loss:     1.327577, Batch Acc: 0.559884, Tokens per Sec:     8753, Lr: 0.000300
2025-05-30 01:40:26,820 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:40:26,820 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:41:11,103 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.35, acc:   0.54, generation: 44.2368[sec], evaluation: 0.0000[sec]
2025-05-30 01:41:11,277 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/50500.ckpt
2025-05-30 01:41:11,294 - INFO - joeynmt.training - Example #0
2025-05-30 01:41:11,295 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:41:11,295 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:41:11,295 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'p@@', 'er', 'jaar', 'om', 'te', 'ver@@', 't@@', 'ro@@', 'u@@', 'w@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'er@@', 's', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 'st@@', 'ro@@', 'm@@', 'p@@', 't', 'te', 'ver@@', 'st@@', 'op@@', 't', 'is.', '</s>']
2025-05-30 01:41:11,296 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:41:11,296 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:41:11,296 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee per jaar om te vertrouwen dat de arctische ijskape ijskape ijzers die voor de onderste 40 procent van de grootte van de onderste 40 procent had om 40 procent te verstrompt te verstopt is.
2025-05-30 01:41:11,296 - INFO - joeynmt.training - Example #1
2025-05-30 01:41:11,297 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:41:11,297 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:41:11,297 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'de', 'ij@@', 's@@', 'je@@', '.', '</s>']
2025-05-30 01:41:11,298 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:41:11,298 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:41:11,298 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van het ijskracht van dit speciale probleem dat het niet de dikke van het ijs van het ijs van het ijs van de ijsje.
2025-05-30 01:41:11,298 - INFO - joeynmt.training - Example #2
2025-05-30 01:41:11,298 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:41:11,298 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:41:11,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:41:11,299 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:41:11,299 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:41:11,299 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe hart van onze wereldwijde klimaatsysteem.
2025-05-30 01:41:11,299 - INFO - joeynmt.training - Example #3
2025-05-30 01:41:11,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:41:11,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:41:11,300 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ru@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:41:11,300 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:41:11,301 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:41:11,301 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en krumpt in de zomers.
2025-05-30 01:41:11,301 - INFO - joeynmt.training - Example #4
2025-05-30 01:41:11,301 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:41:11,301 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:41:11,301 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'ff@@', 'er@@', 'a@@', 'ge@@', 's', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:41:11,302 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:41:11,302 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:41:11,302 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrafferages wat er in de afgelopen 25 jaar gebeurd is.
2025-05-30 01:41:20,178 - INFO - joeynmt.training - Epoch   5, Step:    52600, Batch Loss:     1.227937, Batch Acc: 0.563297, Tokens per Sec:     8052, Lr: 0.000300
2025-05-30 01:41:28,785 - INFO - joeynmt.training - Epoch   5, Step:    52700, Batch Loss:     1.514709, Batch Acc: 0.556701, Tokens per Sec:     8161, Lr: 0.000300
2025-05-30 01:41:37,358 - INFO - joeynmt.training - Epoch   5, Step:    52800, Batch Loss:     1.374286, Batch Acc: 0.557838, Tokens per Sec:     8484, Lr: 0.000300
2025-05-30 01:41:45,329 - INFO - joeynmt.training - Epoch   5, Step:    52900, Batch Loss:     1.274746, Batch Acc: 0.559659, Tokens per Sec:     8803, Lr: 0.000300
2025-05-30 01:41:53,287 - INFO - joeynmt.training - Epoch   5, Step:    53000, Batch Loss:     1.406748, Batch Acc: 0.561994, Tokens per Sec:     9008, Lr: 0.000300
2025-05-30 01:41:53,287 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:41:53,288 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:42:45,337 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.35, acc:   0.54, generation: 51.9979[sec], evaluation: 0.0000[sec]
2025-05-30 01:42:45,504 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/51500.ckpt
2025-05-30 01:42:45,522 - INFO - joeynmt.training - Example #0
2025-05-30 01:42:45,522 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:42:45,523 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:42:45,523 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'die', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'ven', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'ven', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 's@@', 'la@@', 'gen', 'van', '4@@', '8', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 's@@', 'la@@', 'g', 'is.', '</s>']
2025-05-30 01:42:45,524 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:42:45,524 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:42:45,524 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen te bekijken dat de arctische ijskape ijskape ijskape die de grootte van de onderste 48 staten, om 48 staten om 48 procent te geven om 40 procent te geven om 40 procent te verslagen van 48 procent te verslag is.
2025-05-30 01:42:45,524 - INFO - joeynmt.training - Example #1
2025-05-30 01:42:45,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:42:45,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:42:45,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 're@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:42:45,526 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:42:45,526 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:42:45,526 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de rest van dit specifieke probleem van dit specifieke probleem uit, omdat het niet de dik van het ijskracht van het ijskracht laat zien.
2025-05-30 01:42:45,526 - INFO - joeynmt.training - Example #2
2025-05-30 01:42:45,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:42:45,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:42:45,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 's@@', 'la@@', 'p@@', 'p@@', 'ige', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:42:45,528 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:42:45,528 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:42:45,528 - INFO - joeynmt.training - 	Hypothesis: In zezekere zin is de artische ijskape het slappige hart van onze wereldwijde klimaatsysteem.
2025-05-30 01:42:45,528 - INFO - joeynmt.training - Example #3
2025-05-30 01:42:45,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:42:45,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:42:45,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 'en.', '</s>']
2025-05-30 01:42:45,529 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:42:45,530 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:42:45,530 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schept in de winter en scheppt in de winter en scheppen.
2025-05-30 01:42:45,530 - INFO - joeynmt.training - Example #4
2025-05-30 01:42:45,531 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:42:45,531 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:42:45,531 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'te@@', 'ken@@', 't', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:42:45,532 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:42:45,532 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:42:45,532 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tekent wat er in de laatste 25 jaar gebeurd.
2025-05-30 01:42:49,476 - INFO - joeynmt.training - Epoch   5: total training loss 14742.16
2025-05-30 01:42:49,476 - INFO - joeynmt.training - EPOCH 6
2025-05-30 01:42:54,548 - INFO - joeynmt.training - Epoch   6, Step:    53100, Batch Loss:     1.323552, Batch Acc: 0.564635, Tokens per Sec:     7680, Lr: 0.000300
2025-05-30 01:43:03,629 - INFO - joeynmt.training - Epoch   6, Step:    53200, Batch Loss:     1.192500, Batch Acc: 0.571716, Tokens per Sec:     8041, Lr: 0.000300
2025-05-30 01:43:12,430 - INFO - joeynmt.training - Epoch   6, Step:    53300, Batch Loss:     1.558830, Batch Acc: 0.567856, Tokens per Sec:     8152, Lr: 0.000300
2025-05-30 01:43:21,418 - INFO - joeynmt.training - Epoch   6, Step:    53400, Batch Loss:     1.299659, Batch Acc: 0.570281, Tokens per Sec:     7969, Lr: 0.000300
2025-05-30 01:43:30,323 - INFO - joeynmt.training - Epoch   6, Step:    53500, Batch Loss:     1.501730, Batch Acc: 0.568921, Tokens per Sec:     8095, Lr: 0.000300
2025-05-30 01:43:30,324 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:43:30,324 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:44:19,931 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.35, acc:   0.54, generation: 49.5594[sec], evaluation: 0.0000[sec]
2025-05-30 01:44:20,119 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/49000.ckpt
2025-05-30 01:44:20,138 - INFO - joeynmt.training - Example #0
2025-05-30 01:44:20,138 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:44:20,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:44:20,138 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'k@@', 'ijk@@', 'en,', 'om', 'te', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'u@@', 'ur', 'te', 'ver@@', 'z@@', 'et@@', 'ten', 'om', '4@@', '0@@', '%', 'ge@@', 'sl@@', 'ag@@', 'en.', '</s>']
2025-05-30 01:44:20,139 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:44:20,140 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:44:20,140 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te kijken, om te kijken dat de arctische ijskappe ijskappe ijskappen, de grootte van de onderste 48 staten had om 48 uur te verzetten om 40% geslagen.
2025-05-30 01:44:20,140 - INFO - joeynmt.training - Example #1
2025-05-30 01:44:20,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:44:20,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:44:20,141 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 're@@', 's@@', 'ul@@', 't@@', 'aat', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'k@@', 'e', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht@@', 'ige', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht@@', 'ige', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht@@', 'ige', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht@@', 'ige', 'pro@@', 'ble@@', 'em@@', '.', '</s>']
2025-05-30 01:44:20,142 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:44:20,142 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:44:20,142 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de resultaat van dit specifieke probleem dat het niet de dikke van het ijskrachtige ijskrachtige van het ijskrachtige ijskrachtige probleem.
2025-05-30 01:44:20,142 - INFO - joeynmt.training - Example #2
2025-05-30 01:44:20,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:44:20,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:44:20,143 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 'sl@@', 'aa@@', 'p@@', 'ende', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:44:20,143 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:44:20,144 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:44:20,144 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slaapende hart van ons wereldwijde klimaatsysteem.
2025-05-30 01:44:20,144 - INFO - joeynmt.training - Example #3
2025-05-30 01:44:20,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:44:20,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:44:20,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ru@@', 'm@@', 'p@@', 'el@@', '.', '</s>']
2025-05-30 01:44:20,145 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:44:20,145 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:44:20,145 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppt in de winter en krumpel.
2025-05-30 01:44:20,146 - INFO - joeynmt.training - Example #4
2025-05-30 01:44:20,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:44:20,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:44:20,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'te@@', 'ken@@', 'is@@', ',', 'is', 'een', 'te@@', 'ken@@', 'ing', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:44:20,147 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:44:20,147 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:44:20,147 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tekenis, is een tekening van de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurd is.
2025-05-30 01:44:29,185 - INFO - joeynmt.training - Epoch   6, Step:    53600, Batch Loss:     1.473941, Batch Acc: 0.572940, Tokens per Sec:     7713, Lr: 0.000300
2025-05-30 01:44:37,979 - INFO - joeynmt.training - Epoch   6, Step:    53700, Batch Loss:     1.410600, Batch Acc: 0.567574, Tokens per Sec:     8084, Lr: 0.000300
2025-05-30 01:44:46,805 - INFO - joeynmt.training - Epoch   6, Step:    53800, Batch Loss:     1.604114, Batch Acc: 0.563225, Tokens per Sec:     8263, Lr: 0.000300
2025-05-30 01:44:54,785 - INFO - joeynmt.training - Epoch   6, Step:    53900, Batch Loss:     1.291821, Batch Acc: 0.565310, Tokens per Sec:     8952, Lr: 0.000300
2025-05-30 01:45:02,741 - INFO - joeynmt.training - Epoch   6, Step:    54000, Batch Loss:     1.209645, Batch Acc: 0.571349, Tokens per Sec:     8804, Lr: 0.000300
2025-05-30 01:45:02,741 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:45:02,742 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:45:42,273 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.35, acc:   0.54, generation: 39.4849[sec], evaluation: 0.0000[sec]
2025-05-30 01:45:42,450 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/51000.ckpt
2025-05-30 01:45:42,467 - INFO - joeynmt.training - Example #0
2025-05-30 01:45:42,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:45:42,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:45:42,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'er@@', 's', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', 'p@@', 'un@@', 't', 'van', 'de', 'onder@@', 'ste', 'p@@', 'un@@', 't', 'van', 'de', 'onder@@', 'ste', 'p@@', 'un@@', 't', 'is.', '</s>']
2025-05-30 01:45:42,469 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:45:42,469 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:45:42,469 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen te begrijpen dat de arctische ijskape ijskape ijskape ijzers van de grootte van de onderste 48 staten van de onderste punt van de onderste punt van de onderste punt is.
2025-05-30 01:45:42,469 - INFO - joeynmt.training - Example #1
2025-05-30 01:45:42,470 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:45:42,470 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:45:42,470 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 're@@', 'c@@', 'ies', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 'ti@@', 'g', 'te', 'l@@', 'aten', 'zi@@', 'en.', '</s>']
2025-05-30 01:45:42,471 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:45:42,471 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:45:42,471 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de precies van dit speciale probleem dat het speciale probleem uit, omdat het niet de dikke van de ijskrachtig te laten zien.
2025-05-30 01:45:42,471 - INFO - joeynmt.training - Example #2
2025-05-30 01:45:42,471 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:45:42,472 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:45:42,472 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'ig@@', ',', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:45:42,473 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:45:42,473 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:45:42,473 - INFO - joeynmt.training - 	Hypothesis: In zezekere zintuig, de arctische ijskape ijskape van onze wereldwijde klimaatsysteem.
2025-05-30 01:45:42,473 - INFO - joeynmt.training - Example #3
2025-05-30 01:45:42,473 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:45:42,473 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:45:42,473 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 01:45:42,474 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:45:42,474 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:45:42,475 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schept in de zomer.
2025-05-30 01:45:42,475 - INFO - joeynmt.training - Example #4
2025-05-30 01:45:42,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:45:42,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:45:42,475 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'p@@', 'aar', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:45:42,476 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:45:42,476 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:45:42,476 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een paar gebeurt in de laatste 25 jaar gebeurd is.
2025-05-30 01:45:51,714 - INFO - joeynmt.training - Epoch   6, Step:    54100, Batch Loss:     1.384405, Batch Acc: 0.570143, Tokens per Sec:     7652, Lr: 0.000300
2025-05-30 01:46:00,862 - INFO - joeynmt.training - Epoch   6, Step:    54200, Batch Loss:     1.576317, Batch Acc: 0.566456, Tokens per Sec:     7889, Lr: 0.000300
2025-05-30 01:46:09,912 - INFO - joeynmt.training - Epoch   6, Step:    54300, Batch Loss:     1.349124, Batch Acc: 0.573185, Tokens per Sec:     7982, Lr: 0.000300
2025-05-30 01:46:19,509 - INFO - joeynmt.training - Epoch   6, Step:    54400, Batch Loss:     1.359951, Batch Acc: 0.570029, Tokens per Sec:     7446, Lr: 0.000300
2025-05-30 01:46:28,563 - INFO - joeynmt.training - Epoch   6, Step:    54500, Batch Loss:     1.345563, Batch Acc: 0.567066, Tokens per Sec:     7922, Lr: 0.000300
2025-05-30 01:46:28,564 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:46:28,564 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:47:21,904 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.35, acc:   0.54, generation: 53.2987[sec], evaluation: 0.0000[sec]
2025-05-30 01:47:22,064 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/54000.ckpt
2025-05-30 01:47:22,074 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit_bpe_smallvoc/54000.ckpt
2025-05-30 01:47:22,075 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe_smallvoc\54000.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit_bpe_smallvoc\\54000.ckpt')
2025-05-30 01:47:22,081 - INFO - joeynmt.training - Example #0
2025-05-30 01:47:22,082 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:47:22,082 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:47:22,082 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'gr@@', 'ij@@', 'p@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'die', 'voor', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'e', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'te', 'ge@@', 'da@@', 'ch@@', 'ten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 01:47:22,083 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:47:22,083 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:47:22,084 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te beginnen te begrijpen, dat de arctische ijskape ijskape ijskape die voor de onderkant van de ondere 48 staten had om 48 staten had te gedachten om 40 procent te gebeuren.
2025-05-30 01:47:22,084 - INFO - joeynmt.training - Example #1
2025-05-30 01:47:22,084 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:47:22,084 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:47:22,084 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 'ra@@', 'kt@@', 'ijk@@', ',', 'dat', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 't.', '</s>']
2025-05-30 01:47:22,085 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:47:22,085 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:47:22,086 - INFO - joeynmt.training - 	Hypothesis: Maar dit druk niet sterk genoeg de praktijk, dat het specifieke probleem uit, omdat het niet de dikke van de ijskracht.
2025-05-30 01:47:22,086 - INFO - joeynmt.training - Example #2
2025-05-30 01:47:22,086 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:47:22,086 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:47:22,086 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'en', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:47:22,087 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:47:22,087 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:47:22,088 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is het arctische ijskape ijskape ijskape en klimaatsysteem.
2025-05-30 01:47:22,088 - INFO - joeynmt.training - Example #3
2025-05-30 01:47:22,088 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:47:22,088 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:47:22,088 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'g@@', 'aan@@', '.', '</s>']
2025-05-30 01:47:22,089 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:47:22,089 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:47:22,089 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen en zorgen in de winter en zorgaan.
2025-05-30 01:47:22,089 - INFO - joeynmt.training - Example #4
2025-05-30 01:47:22,090 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:47:22,090 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:47:22,090 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'p@@', 'aar', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:47:22,091 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:47:22,091 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:47:22,091 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik jullie laten zien is een paar gebeurt in de laatste 25 jaar gebeurd is.
2025-05-30 01:47:31,116 - INFO - joeynmt.training - Epoch   6, Step:    54600, Batch Loss:     1.652736, Batch Acc: 0.567327, Tokens per Sec:     7635, Lr: 0.000300
2025-05-30 01:47:39,814 - INFO - joeynmt.training - Epoch   6, Step:    54700, Batch Loss:     1.250681, Batch Acc: 0.566430, Tokens per Sec:     8318, Lr: 0.000300
2025-05-30 01:47:48,342 - INFO - joeynmt.training - Epoch   6, Step:    54800, Batch Loss:     1.104667, Batch Acc: 0.564479, Tokens per Sec:     8501, Lr: 0.000300
2025-05-30 01:47:56,513 - INFO - joeynmt.training - Epoch   6, Step:    54900, Batch Loss:     1.340942, Batch Acc: 0.563340, Tokens per Sec:     9000, Lr: 0.000300
2025-05-30 01:48:04,548 - INFO - joeynmt.training - Epoch   6, Step:    55000, Batch Loss:     1.310420, Batch Acc: 0.567212, Tokens per Sec:     9100, Lr: 0.000300
2025-05-30 01:48:04,549 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:48:04,549 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:48:56,377 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.34, acc:   0.54, generation: 51.7822[sec], evaluation: 0.0000[sec]
2025-05-30 01:48:56,378 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:48:56,535 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/54500.ckpt
2025-05-30 01:48:56,549 - INFO - joeynmt.training - Example #0
2025-05-30 01:48:56,550 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:48:56,550 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:48:56,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'ken@@', 'nen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'voor', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'da@@', 'an@@', '.', '</s>']
2025-05-30 01:48:56,551 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:48:56,552 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:48:56,552 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te verkennen dat de arctische ijskapen die voor de arctische ijskapen die voor de grootste 40 procent had om 40 procent geslagen van 40 procent gedaan.
2025-05-30 01:48:56,552 - INFO - joeynmt.training - Example #1
2025-05-30 01:48:56,552 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:48:56,552 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:48:56,552 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'un@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'gen@@', 'oe@@', 'g', 'de', 'st@@', 'a@@', 'k@@', 'k@@', 'er', 'van']
2025-05-30 01:48:56,553 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:48:56,554 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:48:56,554 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet genoeg genoeg de eerste punt van dit specifieke probleem dat het specifieke probleem is dat het niet de dikke van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijskracht genoeg de stakker van
2025-05-30 01:48:56,554 - INFO - joeynmt.training - Example #2
2025-05-30 01:48:56,554 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:48:56,554 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:48:56,554 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:48:56,555 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:48:56,555 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:48:56,555 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapen het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 01:48:56,556 - INFO - joeynmt.training - Example #3
2025-05-30 01:48:56,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:48:56,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:48:56,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:48:56,557 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:48:56,557 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:48:56,557 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schept in de winter en zomers.
2025-05-30 01:48:56,557 - INFO - joeynmt.training - Example #4
2025-05-30 01:48:56,558 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:48:56,558 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:48:56,558 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'dat', 'er', 'een', 'tij@@', 'd@@', 'per@@', 'i@@', 'o@@', 'de', 'dat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 01:48:56,558 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:48:56,558 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:48:56,559 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdperk dat er een tijdperiode dat er in de laatste 25 jaar.
2025-05-30 01:49:05,584 - INFO - joeynmt.training - Epoch   6, Step:    55100, Batch Loss:     1.433605, Batch Acc: 0.569761, Tokens per Sec:     7891, Lr: 0.000300
2025-05-30 01:49:14,640 - INFO - joeynmt.training - Epoch   6, Step:    55200, Batch Loss:     1.468959, Batch Acc: 0.563099, Tokens per Sec:     7946, Lr: 0.000300
2025-05-30 01:49:23,652 - INFO - joeynmt.training - Epoch   6, Step:    55300, Batch Loss:     1.409177, Batch Acc: 0.564928, Tokens per Sec:     7804, Lr: 0.000300
2025-05-30 01:49:32,576 - INFO - joeynmt.training - Epoch   6, Step:    55400, Batch Loss:     1.414060, Batch Acc: 0.566377, Tokens per Sec:     8208, Lr: 0.000300
2025-05-30 01:49:41,460 - INFO - joeynmt.training - Epoch   6, Step:    55500, Batch Loss:     1.277079, Batch Acc: 0.565454, Tokens per Sec:     8394, Lr: 0.000300
2025-05-30 01:49:41,460 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:49:41,460 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:50:24,939 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.33, acc:   0.54, generation: 43.4360[sec], evaluation: 0.0000[sec]
2025-05-30 01:50:24,940 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:50:25,125 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/53000.ckpt
2025-05-30 01:50:25,142 - INFO - joeynmt.training - Example #0
2025-05-30 01:50:25,143 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:50:25,143 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:50:25,143 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'ol@@', 'ies', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'onder@@', 'ste', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'd@@', 'ra@@', 'gen', 'voor', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de.', '</s>']
2025-05-30 01:50:25,144 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:50:25,144 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:50:25,144 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee folies getoond om te verbeelden dat de arctische ijskappen, die voor de onderste van de onderste 48 staten had drie miljoen jaar de grootte van 48 staten had om 40 procent te gedragen voor 40 procent gebeurde.
2025-05-30 01:50:25,144 - INFO - joeynmt.training - Example #1
2025-05-30 01:50:25,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:50:25,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:50:25,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'k@@', 'ra@@', 'cht', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 'ub@@', 'lie@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'el@@', 't', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het']
2025-05-30 01:50:25,146 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:50:25,146 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:50:25,146 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de kracht genoeg de publiek van dit specielt van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het
2025-05-30 01:50:25,146 - INFO - joeynmt.training - Example #2
2025-05-30 01:50:25,147 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:50:25,147 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:50:25,147 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'ig@@', 'en@@', 'lijk', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:50:25,148 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:50:25,148 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:50:25,148 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigenlijk is de arctische ijskapp het slagen van ons wereldwijde klimaatsysteem.
2025-05-30 01:50:25,148 - INFO - joeynmt.training - Example #3
2025-05-30 01:50:25,148 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:50:25,148 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:50:25,149 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'het', 'gro@@', 'ei@@', '.', '</s>']
2025-05-30 01:50:25,149 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:50:25,149 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:50:25,149 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppt in de winter en scheppt in de winter en het groei.
2025-05-30 01:50:25,149 - INFO - joeynmt.training - Example #4
2025-05-30 01:50:25,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:50:25,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:50:25,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'en@@', 'st', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'te@@', 'ken@@', 'is@@', ',', 'een', 'te@@', 'ken@@', 'de', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:50:25,150 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:50:25,150 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:50:25,151 - INFO - joeynmt.training - 	Hypothesis: De volgende dienst die ik jullie laten zien is een tekenis, een tekende 25 jaar gebeurd is.
2025-05-30 01:50:33,210 - INFO - joeynmt.training - Epoch   6, Step:    55600, Batch Loss:     1.271077, Batch Acc: 0.572168, Tokens per Sec:     8687, Lr: 0.000300
2025-05-30 01:50:40,996 - INFO - joeynmt.training - Epoch   6, Step:    55700, Batch Loss:     1.219143, Batch Acc: 0.566956, Tokens per Sec:     9098, Lr: 0.000300
2025-05-30 01:50:49,252 - INFO - joeynmt.training - Epoch   6, Step:    55800, Batch Loss:     1.268788, Batch Acc: 0.560430, Tokens per Sec:     8793, Lr: 0.000300
2025-05-30 01:50:58,088 - INFO - joeynmt.training - Epoch   6, Step:    55900, Batch Loss:     1.351784, Batch Acc: 0.569827, Tokens per Sec:     8035, Lr: 0.000300
2025-05-30 01:51:07,545 - INFO - joeynmt.training - Epoch   6, Step:    56000, Batch Loss:     1.515875, Batch Acc: 0.573130, Tokens per Sec:     7404, Lr: 0.000300
2025-05-30 01:51:07,547 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:51:07,547 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:51:53,456 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.36, acc:   0.54, generation: 45.8664[sec], evaluation: 0.0000[sec]
2025-05-30 01:51:53,467 - INFO - joeynmt.training - Example #0
2025-05-30 01:51:53,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:51:53,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:51:53,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'twe@@', 'e', 'p@@', 'ol@@', 'it@@', 'ie@@', 'ë@@', 'n', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'se@@', 'ff@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 01:51:53,469 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:51:53,469 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:51:53,470 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde twee politieën getoond om te beseffen dat de arctische ijskappe ijskappen die de grootte van de onderste 48 staten.
2025-05-30 01:51:53,470 - INFO - joeynmt.training - Example #1
2025-05-30 01:51:53,470 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:51:53,470 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:51:53,470 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:51:53,471 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:51:53,472 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:51:53,472 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de snelheid van dit speciale probleem uit, omdat het speciale probleem laat zien.
2025-05-30 01:51:53,472 - INFO - joeynmt.training - Example #2
2025-05-30 01:51:53,472 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:51:53,472 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:51:53,472 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'igen', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:51:53,473 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:51:53,474 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:51:53,474 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigen is de arctische ijskappe hart van onze wereldwijde klimaatsysteem.
2025-05-30 01:51:53,474 - INFO - joeynmt.training - Example #3
2025-05-30 01:51:53,474 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:51:53,474 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:51:53,474 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 01:51:53,475 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:51:53,475 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:51:53,475 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppt in de winter en zomers.
2025-05-30 01:51:53,476 - INFO - joeynmt.training - Example #4
2025-05-30 01:51:53,476 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:51:53,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:51:53,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'te@@', 'gen@@', 'over', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:51:53,477 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:51:53,477 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:51:53,477 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tegenover de afgelopen 25 jaar gebeurd in de afgelopen 25 jaar gebeurd.
2025-05-30 01:52:02,554 - INFO - joeynmt.training - Epoch   6, Step:    56100, Batch Loss:     1.379645, Batch Acc: 0.562772, Tokens per Sec:     7787, Lr: 0.000300
2025-05-30 01:52:11,382 - INFO - joeynmt.training - Epoch   6, Step:    56200, Batch Loss:     1.232554, Batch Acc: 0.567261, Tokens per Sec:     8135, Lr: 0.000300
2025-05-30 01:52:20,273 - INFO - joeynmt.training - Epoch   6, Step:    56300, Batch Loss:     1.526156, Batch Acc: 0.567920, Tokens per Sec:     8202, Lr: 0.000300
2025-05-30 01:52:29,839 - INFO - joeynmt.training - Epoch   6, Step:    56400, Batch Loss:     1.286593, Batch Acc: 0.564476, Tokens per Sec:     7304, Lr: 0.000300
2025-05-30 01:52:38,747 - INFO - joeynmt.training - Epoch   6, Step:    56500, Batch Loss:     1.408084, Batch Acc: 0.568274, Tokens per Sec:     7880, Lr: 0.000300
2025-05-30 01:52:38,748 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:52:38,748 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:53:26,563 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.34, acc:   0.54, generation: 47.7631[sec], evaluation: 0.0000[sec]
2025-05-30 01:53:26,729 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/53500.ckpt
2025-05-30 01:53:26,745 - INFO - joeynmt.training - Example #0
2025-05-30 01:53:26,745 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:53:26,746 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:53:26,746 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'l@@', 'aten', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'k@@', 'el', 'ge@@', 'be@@', 'ur@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 'm@@', 'inder@@', 'en', 'van', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 'm@@', 'inder@@', 'en.', '</s>']
2025-05-30 01:53:26,746 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:53:26,747 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:53:26,747 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee dia's laten zien dat de arctische ijskappen die voor de artikel gebeurd om 40 procent te verminderen van 48 staten om 40 procent te verminderen.
2025-05-30 01:53:26,747 - INFO - joeynmt.training - Example #1
2025-05-30 01:53:26,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:53:26,747 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:53:26,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 'ra@@', 'cht@@', 'ige', 'p@@', 'ar@@', 'tij@@', 'd@@', 'je', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:53:26,748 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:53:26,748 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:53:26,748 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de prachtige partijdje van dit specifieke probleem uit, omdat het niet de dicks van het ijs van het ijs van het ijs van het ijs laat zien.
2025-05-30 01:53:26,748 - INFO - joeynmt.training - Example #2
2025-05-30 01:53:26,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:53:26,749 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:53:26,749 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:53:26,750 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:53:26,750 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:53:26,750 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappen het slagende hart van onze wereldwijd van onze wereldwijd klimaatsysteem.
2025-05-30 01:53:26,750 - INFO - joeynmt.training - Example #3
2025-05-30 01:53:26,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:53:26,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:53:26,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'k@@', 'ken', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'op@@', 'p@@', 'en.', '</s>']
2025-05-30 01:53:26,751 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:53:26,751 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:53:26,752 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroept in de winter en schrokken in de winter en schroeppt in de winter en stoppen.
2025-05-30 01:53:26,752 - INFO - joeynmt.training - Example #4
2025-05-30 01:53:26,752 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:53:26,752 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:53:26,752 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ge@@', 'be@@', 'ur@@', 'd', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:53:26,753 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:53:26,753 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:53:26,753 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsgebeurd wat er in de laatste 25 jaar gebeurd is.
2025-05-30 01:53:35,542 - INFO - joeynmt.training - Epoch   6, Step:    56600, Batch Loss:     1.372673, Batch Acc: 0.572231, Tokens per Sec:     8471, Lr: 0.000300
2025-05-30 01:53:44,792 - INFO - joeynmt.training - Epoch   6, Step:    56700, Batch Loss:     1.434590, Batch Acc: 0.565622, Tokens per Sec:     7806, Lr: 0.000300
2025-05-30 01:53:53,705 - INFO - joeynmt.training - Epoch   6, Step:    56800, Batch Loss:     1.375632, Batch Acc: 0.563923, Tokens per Sec:     8009, Lr: 0.000300
2025-05-30 01:54:02,699 - INFO - joeynmt.training - Epoch   6, Step:    56900, Batch Loss:     1.163983, Batch Acc: 0.567478, Tokens per Sec:     8308, Lr: 0.000300
2025-05-30 01:54:11,643 - INFO - joeynmt.training - Epoch   6, Step:    57000, Batch Loss:     1.378349, Batch Acc: 0.559523, Tokens per Sec:     7846, Lr: 0.000300
2025-05-30 01:54:11,644 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:54:11,644 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:54:52,602 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.32, acc:   0.54, generation: 40.9126[sec], evaluation: 0.0000[sec]
2025-05-30 01:54:52,603 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 01:54:52,763 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/52500.ckpt
2025-05-30 01:54:52,778 - INFO - joeynmt.training - Example #0
2025-05-30 01:54:52,779 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:54:52,779 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:54:52,779 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'ander@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'i@@', 'ë@@', 'r@@', 's', 'die', 'voor', 'de', 'be@@', 'dr@@', 'ij@@', 'ven', 'voor', 'de', 'onder@@', 'ste', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 01:54:52,780 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:54:52,780 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:54:52,780 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde getoond om te veranderen dat de arctische ijiërs die voor de bedrijven voor de onderste van de grootte van de onderste 40 procent van 40 procent staten.
2025-05-30 01:54:52,780 - INFO - joeynmt.training - Example #1
2025-05-30 01:54:52,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:54:52,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:54:52,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'st@@', 'a@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'ck@@', 'u@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:54:52,782 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:54:52,782 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:54:52,782 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet sterk genoeg de stak van dit specifieke probleem uit, omdat het niet de dikke dickus van het ijs laat zien.
2025-05-30 01:54:52,782 - INFO - joeynmt.training - Example #2
2025-05-30 01:54:52,782 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:54:52,783 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:54:52,783 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:54:52,784 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:54:52,784 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:54:52,784 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijs van ons wereldwijd ons wereldwijde klimaatsysteem.
2025-05-30 01:54:52,784 - INFO - joeynmt.training - Example #3
2025-05-30 01:54:52,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:54:52,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:54:52,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'r@@', 'ik@@', 'k@@', 'ing', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-30 01:54:52,785 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:54:52,786 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:54:52,786 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrikking in de zomer.
2025-05-30 01:54:52,786 - INFO - joeynmt.training - Example #4
2025-05-30 01:54:52,786 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:54:52,786 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:54:52,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ver@@', 'st@@', 're@@', 'k@@', 'ken', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:54:52,787 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:54:52,787 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:54:52,787 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een tijdsverstrekken wat er in de laatste 25 jaar gebeurd is.
2025-05-30 01:55:01,790 - INFO - joeynmt.training - Epoch   6, Step:    57100, Batch Loss:     1.443361, Batch Acc: 0.568281, Tokens per Sec:     7959, Lr: 0.000300
2025-05-30 01:55:10,662 - INFO - joeynmt.training - Epoch   6, Step:    57200, Batch Loss:     1.424783, Batch Acc: 0.566197, Tokens per Sec:     8086, Lr: 0.000300
2025-05-30 01:55:19,747 - INFO - joeynmt.training - Epoch   6, Step:    57300, Batch Loss:     1.301868, Batch Acc: 0.566769, Tokens per Sec:     7798, Lr: 0.000300
2025-05-30 01:55:28,977 - INFO - joeynmt.training - Epoch   6, Step:    57400, Batch Loss:     1.250960, Batch Acc: 0.570544, Tokens per Sec:     7755, Lr: 0.000300
2025-05-30 01:55:36,811 - INFO - joeynmt.training - Epoch   6, Step:    57500, Batch Loss:     1.265849, Batch Acc: 0.567920, Tokens per Sec:     9353, Lr: 0.000300
2025-05-30 01:55:36,812 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:55:36,812 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:56:22,146 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.32, acc:   0.54, generation: 45.2867[sec], evaluation: 0.0000[sec]
2025-05-30 01:56:22,303 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/52000.ckpt
2025-05-30 01:56:22,320 - INFO - joeynmt.training - Example #0
2025-05-30 01:56:22,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:56:22,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:56:22,321 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'ken@@', 'nen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'de', 'ar@@', 'ti@@', 'c@@', 'ul@@', 'eren', 'van', 'de', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'ste', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '8', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 01:56:22,322 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:56:22,322 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:56:22,322 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verkennen dat de arctische ijskappen die de articuleren van de drie miljoen jaar de grootste van de onderste 40 procent van 48 staten.
2025-05-30 01:56:22,322 - INFO - joeynmt.training - Example #1
2025-05-30 01:56:22,323 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:56:22,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:56:22,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:56:22,324 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:56:22,324 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:56:22,324 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de snelheid van dit specifieke probleem uit, omdat het niet de dikke dikkke dikke van het ijs laat zien.
2025-05-30 01:56:22,324 - INFO - joeynmt.training - Example #2
2025-05-30 01:56:22,325 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:56:22,325 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:56:22,325 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'igen', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:56:22,326 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:56:22,326 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:56:22,326 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigen is de arctische ijskapen het slagende hart van onze wereldwijd klimaatsysteem.
2025-05-30 01:56:22,326 - INFO - joeynmt.training - Example #3
2025-05-30 01:56:22,327 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:56:22,327 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:56:22,327 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@']
2025-05-30 01:56:22,327 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:56:22,328 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:56:22,328 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroept in de winter en schroept in de winter en schroept in de winter en schroept in de winter en schroept in de winter en schroept in de winter en schroept in de winter en schroept in de winter en schroept in de winter en schroept in de winter en schroept in de winter en schroe
2025-05-30 01:56:22,328 - INFO - joeynmt.training - Example #4
2025-05-30 01:56:22,328 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:56:22,328 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:56:22,329 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'gen', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:56:22,329 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:56:22,330 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:56:22,330 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolgen die ik jullie laten zien is een tijdperk van wat er gebeurd in de afgelopen 25 jaar gebeurd is.
2025-05-30 01:56:31,386 - INFO - joeynmt.training - Epoch   6, Step:    57600, Batch Loss:     1.399575, Batch Acc: 0.569602, Tokens per Sec:     8059, Lr: 0.000300
2025-05-30 01:56:40,388 - INFO - joeynmt.training - Epoch   6, Step:    57700, Batch Loss:     1.457966, Batch Acc: 0.571482, Tokens per Sec:     7980, Lr: 0.000300
2025-05-30 01:56:49,562 - INFO - joeynmt.training - Epoch   6, Step:    57800, Batch Loss:     1.311554, Batch Acc: 0.574614, Tokens per Sec:     7896, Lr: 0.000300
2025-05-30 01:56:58,812 - INFO - joeynmt.training - Epoch   6, Step:    57900, Batch Loss:     1.403330, Batch Acc: 0.571759, Tokens per Sec:     7805, Lr: 0.000300
2025-05-30 01:57:07,897 - INFO - joeynmt.training - Epoch   6, Step:    58000, Batch Loss:     1.544665, Batch Acc: 0.568003, Tokens per Sec:     7956, Lr: 0.000300
2025-05-30 01:57:07,897 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:57:07,897 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:57:54,368 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.33, acc:   0.54, generation: 46.4271[sec], evaluation: 0.0000[sec]
2025-05-30 01:57:54,560 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/55000.ckpt
2025-05-30 01:57:54,580 - INFO - joeynmt.training - Example #0
2025-05-30 01:57:54,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:57:54,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:57:54,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 01:57:54,582 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:57:54,582 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:57:54,582 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee dia's getoond om te verbeteren dat de arctische ijskappen, die voor de onderste 48 staten.
2025-05-30 01:57:54,582 - INFO - joeynmt.training - Example #1
2025-05-30 01:57:54,583 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:57:54,583 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:57:54,583 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'st@@', 'a@@', 'di@@', 'c@@', 'ij@@', 'f@@', 'er@@', 's', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's@@', 'n@@', 'el@@', 'heid', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 't.', '</s>']
2025-05-30 01:57:54,583 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:57:54,583 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:57:54,584 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de stadicijfers uit, omdat het niet de dikkke van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijsnelheid van het ijs van het ijskracht.
2025-05-30 01:57:54,584 - INFO - joeynmt.training - Example #2
2025-05-30 01:57:54,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:57:54,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:57:54,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:57:54,585 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:57:54,585 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:57:54,585 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 01:57:54,585 - INFO - joeynmt.training - Example #3
2025-05-30 01:57:54,585 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:57:54,585 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:57:54,585 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'r@@', 'ik@@', 't', 'in', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 01:57:54,586 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:57:54,586 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:57:54,586 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrikt in zomer.
2025-05-30 01:57:54,586 - INFO - joeynmt.training - Example #4
2025-05-30 01:57:54,586 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:57:54,586 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:57:54,586 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 01:57:54,588 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:57:54,588 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:57:54,588 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdperk van de laatste 25 jaar gebeurd is.
2025-05-30 01:58:03,716 - INFO - joeynmt.training - Epoch   6, Step:    58100, Batch Loss:     1.317220, Batch Acc: 0.560846, Tokens per Sec:     7890, Lr: 0.000300
2025-05-30 01:58:12,781 - INFO - joeynmt.training - Epoch   6, Step:    58200, Batch Loss:     1.294852, Batch Acc: 0.567073, Tokens per Sec:     7881, Lr: 0.000300
2025-05-30 01:58:21,717 - INFO - joeynmt.training - Epoch   6, Step:    58300, Batch Loss:     1.340192, Batch Acc: 0.567249, Tokens per Sec:     7957, Lr: 0.000300
2025-05-30 01:58:30,505 - INFO - joeynmt.training - Epoch   6, Step:    58400, Batch Loss:     1.303336, Batch Acc: 0.570050, Tokens per Sec:     8176, Lr: 0.000300
2025-05-30 01:58:39,164 - INFO - joeynmt.training - Epoch   6, Step:    58500, Batch Loss:     1.420345, Batch Acc: 0.567393, Tokens per Sec:     8204, Lr: 0.000300
2025-05-30 01:58:39,165 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 01:58:39,165 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 01:59:23,537 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.32, acc:   0.54, generation: 44.3285[sec], evaluation: 0.0000[sec]
2025-05-30 01:59:23,696 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/56500.ckpt
2025-05-30 01:59:23,709 - INFO - joeynmt.training - Example #0
2025-05-30 01:59:23,710 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 01:59:23,710 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 01:59:23,710 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'jaar', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'an@@', 'c@@', 'eer@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'st@@', 'op@@', 'p@@', 'en.', '</s>']
2025-05-30 01:59:23,711 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 01:59:23,712 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 01:59:23,712 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee jaar getoond om te veranceerden dat de arctische ijskappen, die voor de arctische ijskappen, die voor de onderste 40 procent geslagen van 40 procent gestoppen.
2025-05-30 01:59:23,712 - INFO - joeynmt.training - Example #1
2025-05-30 01:59:23,712 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 01:59:23,712 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 01:59:23,712 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 01:59:23,713 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 01:59:23,713 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 01:59:23,714 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de snelheid van dit speciale probleem uit, omdat het het niet de dicke van het ijs van het ijs laat zien.
2025-05-30 01:59:23,714 - INFO - joeynmt.training - Example #2
2025-05-30 01:59:23,714 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 01:59:23,714 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 01:59:23,714 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 01:59:23,715 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 01:59:23,715 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 01:59:23,716 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-30 01:59:23,716 - INFO - joeynmt.training - Example #3
2025-05-30 01:59:23,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 01:59:23,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 01:59:23,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 01:59:23,717 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 01:59:23,717 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 01:59:23,717 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppt in de winter en zomer.
2025-05-30 01:59:23,717 - INFO - joeynmt.training - Example #4
2025-05-30 01:59:23,718 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 01:59:23,718 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 01:59:23,718 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 01:59:23,719 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 01:59:23,719 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 01:59:23,719 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdperk van wat er in de laatste 25 jaar gebeurd.
2025-05-30 01:59:32,727 - INFO - joeynmt.training - Epoch   6, Step:    58600, Batch Loss:     1.357758, Batch Acc: 0.566887, Tokens per Sec:     7857, Lr: 0.000300
2025-05-30 01:59:41,771 - INFO - joeynmt.training - Epoch   6, Step:    58700, Batch Loss:     1.468498, Batch Acc: 0.567749, Tokens per Sec:     8020, Lr: 0.000300
2025-05-30 01:59:50,692 - INFO - joeynmt.training - Epoch   6, Step:    58800, Batch Loss:     1.264676, Batch Acc: 0.568848, Tokens per Sec:     8223, Lr: 0.000300
2025-05-30 01:59:59,508 - INFO - joeynmt.training - Epoch   6, Step:    58900, Batch Loss:     1.379425, Batch Acc: 0.571437, Tokens per Sec:     8100, Lr: 0.000300
2025-05-30 02:00:08,434 - INFO - joeynmt.training - Epoch   6, Step:    59000, Batch Loss:     1.383792, Batch Acc: 0.567877, Tokens per Sec:     8197, Lr: 0.000300
2025-05-30 02:00:08,435 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:00:08,435 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:00:49,474 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.29, acc:   0.54, generation: 41.0005[sec], evaluation: 0.0000[sec]
2025-05-30 02:00:49,475 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:00:49,629 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/55500.ckpt
2025-05-30 02:00:49,644 - INFO - joeynmt.training - Example #0
2025-05-30 02:00:49,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:00:49,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:00:49,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'jaar', 'lan@@', 'g', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'er@@', 's', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'ven', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'z@@', 'et@@', '.', '</s>']
2025-05-30 02:00:49,647 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:00:49,647 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:00:49,647 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee jaar lang getoond om te verbeteren dat de arctische ijskape ijskape ijzers de grootte van de onderste 48 staten had om 40 procent te geven om 40 procent te gezet.
2025-05-30 02:00:49,647 - INFO - joeynmt.training - Example #1
2025-05-30 02:00:49,648 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:00:49,648 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:00:49,648 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'b@@', 'u@@', 'ur@@', 't', 'de', 'n@@', 'st@@', 'o@@', 'ff@@', 'en@@', 'd@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'je@@', '.', '</s>']
2025-05-30 02:00:49,648 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:00:49,649 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:00:49,649 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de buurt de nstoffendheid van dit specifieke probleem dat het niet de dikke dikke van de ijsje.
2025-05-30 02:00:49,649 - INFO - joeynmt.training - Example #2
2025-05-30 02:00:49,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:00:49,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:00:49,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:00:49,650 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:00:49,651 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:00:49,651 - INFO - joeynmt.training - 	Hypothesis: In zezekere zin is de arctische ijskape hart van onze wereldwijde klimaatsysteem.
2025-05-30 02:00:49,651 - INFO - joeynmt.training - Example #3
2025-05-30 02:00:49,651 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:00:49,651 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:00:49,652 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 02:00:49,652 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:00:49,652 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:00:49,653 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schept in de zomers.
2025-05-30 02:00:49,653 - INFO - joeynmt.training - Example #4
2025-05-30 02:00:49,653 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:00:49,653 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:00:49,653 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:00:49,654 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:00:49,654 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:00:49,654 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tijdperk van de laatste 25 jaar gebeurd is.
2025-05-30 02:00:57,580 - INFO - joeynmt.training - Epoch   6, Step:    59100, Batch Loss:     1.358457, Batch Acc: 0.563979, Tokens per Sec:     8915, Lr: 0.000300
2025-05-30 02:01:06,370 - INFO - joeynmt.training - Epoch   6, Step:    59200, Batch Loss:     1.438731, Batch Acc: 0.565656, Tokens per Sec:     8117, Lr: 0.000300
2025-05-30 02:01:15,187 - INFO - joeynmt.training - Epoch   6, Step:    59300, Batch Loss:     1.406913, Batch Acc: 0.568857, Tokens per Sec:     8282, Lr: 0.000300
2025-05-30 02:01:23,941 - INFO - joeynmt.training - Epoch   6, Step:    59400, Batch Loss:     1.220005, Batch Acc: 0.567482, Tokens per Sec:     8310, Lr: 0.000300
2025-05-30 02:01:32,727 - INFO - joeynmt.training - Epoch   6, Step:    59500, Batch Loss:     1.446956, Batch Acc: 0.568238, Tokens per Sec:     8242, Lr: 0.000300
2025-05-30 02:01:32,728 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:01:32,728 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:02:19,260 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.45, ppl:   4.28, acc:   0.54, generation: 46.4836[sec], evaluation: 0.0000[sec]
2025-05-30 02:02:19,261 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:02:19,431 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/58000.ckpt
2025-05-30 02:02:19,447 - INFO - joeynmt.training - Example #0
2025-05-30 02:02:19,448 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:02:19,448 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:02:19,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'ver@@', 'be@@', 'el@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'i@@', 'z@@', 'en@@', 'den', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8@@', ',', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'en@@', 't.', '</s>']
2025-05-30 02:02:19,450 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:02:19,450 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:02:19,451 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen te verbeelden dat de arctische ijizenden die voor de onderste 48, de grootte van de onderste 40 procent.
2025-05-30 02:02:19,451 - INFO - joeynmt.training - Example #1
2025-05-30 02:02:19,451 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:02:19,451 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:02:19,451 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'aar', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:02:19,452 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:02:19,453 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:02:19,453 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet sterk genoeg de eerste paar probleem uit, omdat het niet de dikke dikke van het ijs laat zien.
2025-05-30 02:02:19,453 - INFO - joeynmt.training - Example #2
2025-05-30 02:02:19,454 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:02:19,454 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:02:19,454 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:02:19,455 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:02:19,455 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:02:19,455 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-30 02:02:19,455 - INFO - joeynmt.training - Example #3
2025-05-30 02:02:19,456 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:02:19,456 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:02:19,456 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'we@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:02:19,457 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:02:19,457 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:02:19,457 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zwempt in de zomer.
2025-05-30 02:02:19,457 - INFO - joeynmt.training - Example #4
2025-05-30 02:02:19,458 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:02:19,458 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:02:19,458 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'te@@', 'ken@@', 't', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'is.', '</s>']
2025-05-30 02:02:19,459 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:02:19,459 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:02:19,459 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tekent wat er in de laatste 25 jaar gebeurde laatste 25 jaar gebeurde is.
2025-05-30 02:02:28,491 - INFO - joeynmt.training - Epoch   6, Step:    59600, Batch Loss:     1.390271, Batch Acc: 0.566268, Tokens per Sec:     7493, Lr: 0.000300
2025-05-30 02:02:37,501 - INFO - joeynmt.training - Epoch   6, Step:    59700, Batch Loss:     1.316844, Batch Acc: 0.561333, Tokens per Sec:     7931, Lr: 0.000300
2025-05-30 02:02:46,780 - INFO - joeynmt.training - Epoch   6, Step:    59800, Batch Loss:     1.417436, Batch Acc: 0.560299, Tokens per Sec:     7797, Lr: 0.000300
2025-05-30 02:02:56,111 - INFO - joeynmt.training - Epoch   6, Step:    59900, Batch Loss:     1.509557, Batch Acc: 0.566623, Tokens per Sec:     7567, Lr: 0.000300
2025-05-30 02:03:05,064 - INFO - joeynmt.training - Epoch   6, Step:    60000, Batch Loss:     1.290574, Batch Acc: 0.565100, Tokens per Sec:     8181, Lr: 0.000300
2025-05-30 02:03:05,064 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:03:05,065 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:03:50,256 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.45, ppl:   4.27, acc:   0.54, generation: 45.1465[sec], evaluation: 0.0000[sec]
2025-05-30 02:03:50,257 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:03:50,427 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/58500.ckpt
2025-05-30 02:03:50,441 - INFO - joeynmt.training - Example #0
2025-05-30 02:03:50,442 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:03:50,442 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:03:50,442 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'v@@', 'ier@@', 'kan@@', 't', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'st@@', 'aten', 'ha@@', 'd', '4@@', '0', 'pro@@', 'c@@', 'ent', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'm@@', 'id@@', 'del@@', 'en', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 02:03:50,443 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:03:50,443 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:03:50,443 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te beginnen te bekijken dat de arctische ijskape ijskape ijskape ijskape vierkant om 40 procent staten had 40 procent staten had om 40 procent te gesmiddelen van 40 procent geslagen is.
2025-05-30 02:03:50,444 - INFO - joeynmt.training - Example #1
2025-05-30 02:03:50,444 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:03:50,444 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:03:50,444 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'er@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'un@@', 't', 'van', 'deze', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'd@@', 'is@@', 'c@@', 'u@@', 'ss@@', 'ie', 'l@@', 'aten', 'zi@@', 'en.', '</s>']
2025-05-30 02:03:50,445 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:03:50,445 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:03:50,446 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg de eerste punt van deze speciale probleem uit, omdat het niet de dikke dikke discussie laten zien.
2025-05-30 02:03:50,446 - INFO - joeynmt.training - Example #2
2025-05-30 02:03:50,446 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:03:50,446 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:03:50,446 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:03:50,447 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:03:50,447 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:03:50,447 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijskape hart van ons wereldwijde klimaatsysteem.
2025-05-30 02:03:50,448 - INFO - joeynmt.training - Example #3
2025-05-30 02:03:50,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:03:50,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:03:50,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'en', 'z@@', 'ich', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:03:50,450 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:03:50,450 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:03:50,450 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zich in en zich zomer.
2025-05-30 02:03:50,450 - INFO - joeynmt.training - Example #4
2025-05-30 02:03:50,450 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:03:50,451 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:03:50,451 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'te@@', 'ken@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:03:50,452 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:03:50,452 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:03:50,452 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tekent in de laatste 25 jaar gebeurd in de laatste 25 jaar gebeurd is.
2025-05-30 02:03:59,252 - INFO - joeynmt.training - Epoch   6, Step:    60100, Batch Loss:     1.431925, Batch Acc: 0.570277, Tokens per Sec:     8056, Lr: 0.000300
2025-05-30 02:04:07,958 - INFO - joeynmt.training - Epoch   6, Step:    60200, Batch Loss:     1.319533, Batch Acc: 0.565817, Tokens per Sec:     8226, Lr: 0.000300
2025-05-30 02:04:16,562 - INFO - joeynmt.training - Epoch   6, Step:    60300, Batch Loss:     1.556913, Batch Acc: 0.568971, Tokens per Sec:     8667, Lr: 0.000300
2025-05-30 02:04:25,094 - INFO - joeynmt.training - Epoch   6, Step:    60400, Batch Loss:     1.474726, Batch Acc: 0.564879, Tokens per Sec:     8486, Lr: 0.000300
2025-05-30 02:04:34,148 - INFO - joeynmt.training - Epoch   6, Step:    60500, Batch Loss:     1.313455, Batch Acc: 0.566296, Tokens per Sec:     7998, Lr: 0.000300
2025-05-30 02:04:34,150 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:04:34,150 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:05:26,972 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.45, ppl:   4.25, acc:   0.54, generation: 52.7813[sec], evaluation: 0.0000[sec]
2025-05-30 02:05:26,973 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:05:27,135 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/57500.ckpt
2025-05-30 02:05:27,152 - INFO - joeynmt.training - Example #0
2025-05-30 02:05:27,153 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:05:27,153 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:05:27,153 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'z@@', 'ro@@', 'm@@', 'p@@', 't', 'is.', '</s>']
2025-05-30 02:05:27,154 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:05:27,155 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:05:27,155 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verbeteren dat de arctische ijskappe ijskappe ijskape ijskappen die de grootte van de onderste 40 procent gezrompt is.
2025-05-30 02:05:27,155 - INFO - joeynmt.training - Example #1
2025-05-30 02:05:27,155 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:05:27,155 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:05:27,155 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'st@@', 'on@@', 'd', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's@@', 'k@@', 'er', 'zi@@', 'en.', '</s>']
2025-05-30 02:05:27,156 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:05:27,156 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:05:27,157 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste stond van dit speciale probleem uit, want het is niet de dik van de ijs van de ijs van de ijsker zien.
2025-05-30 02:05:27,157 - INFO - joeynmt.training - Example #2
2025-05-30 02:05:27,157 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:05:27,157 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:05:27,157 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:05:27,158 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:05:27,158 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:05:27,158 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe klimaatsysteem.
2025-05-30 02:05:27,158 - INFO - joeynmt.training - Example #3
2025-05-30 02:05:27,159 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:05:27,159 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:05:27,159 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 02:05:27,160 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:05:27,160 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:05:27,160 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich in de zomers.
2025-05-30 02:05:27,160 - INFO - joeynmt.training - Example #4
2025-05-30 02:05:27,160 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:05:27,160 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:05:27,161 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'je', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 't', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:05:27,161 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:05:27,162 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:05:27,162 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdje laatste 25 jaar gebeurt in de laatste 25 jaar gebeurd is.
2025-05-30 02:05:36,080 - INFO - joeynmt.training - Epoch   6, Step:    60600, Batch Loss:     1.331445, Batch Acc: 0.560464, Tokens per Sec:     7902, Lr: 0.000300
2025-05-30 02:05:44,528 - INFO - joeynmt.training - Epoch   6, Step:    60700, Batch Loss:     1.335907, Batch Acc: 0.559742, Tokens per Sec:     8725, Lr: 0.000300
2025-05-30 02:05:52,382 - INFO - joeynmt.training - Epoch   6, Step:    60800, Batch Loss:     1.313957, Batch Acc: 0.569439, Tokens per Sec:     9293, Lr: 0.000300
2025-05-30 02:06:00,416 - INFO - joeynmt.training - Epoch   6, Step:    60900, Batch Loss:     1.269873, Batch Acc: 0.568035, Tokens per Sec:     8815, Lr: 0.000300
2025-05-30 02:06:08,332 - INFO - joeynmt.training - Epoch   6, Step:    61000, Batch Loss:     1.259905, Batch Acc: 0.563417, Tokens per Sec:     9135, Lr: 0.000300
2025-05-30 02:06:08,332 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:06:08,333 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:06:56,571 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.45, ppl:   4.28, acc:   0.54, generation: 48.1945[sec], evaluation: 0.0000[sec]
2025-05-30 02:06:56,744 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/57000.ckpt
2025-05-30 02:06:56,760 - INFO - joeynmt.training - Example #0
2025-05-30 02:06:56,761 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:06:56,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:06:56,762 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'se@@', 'ff@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'z@@', 'ro@@', 'm@@', 'p@@', 't', 'te', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 02:06:56,763 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:06:56,763 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:06:56,763 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te beginnen te beseffen dat de arctische ijskappen, die voor de grootte van de onderste 48 staten had om 40 procent te gezrompt te gebeuren.
2025-05-30 02:06:56,763 - INFO - joeynmt.training - Example #1
2025-05-30 02:06:56,763 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:06:56,764 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:06:56,764 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 'un@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:06:56,765 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:06:56,765 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:06:56,765 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de punt van dit specifieke probleem uit, want het niet de dikke van het ijs laat zien.
2025-05-30 02:06:56,766 - INFO - joeynmt.training - Example #2
2025-05-30 02:06:56,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:06:56,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:06:56,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:06:56,767 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:06:56,767 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:06:56,767 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-30 02:06:56,768 - INFO - joeynmt.training - Example #3
2025-05-30 02:06:56,768 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:06:56,768 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:06:56,768 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 02:06:56,769 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:06:56,769 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:06:56,769 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomers.
2025-05-30 02:06:56,769 - INFO - joeynmt.training - Example #4
2025-05-30 02:06:56,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:06:56,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:06:56,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:06:56,770 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:06:56,770 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:06:56,771 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdperk van wat er in de laatste 25 jaar gebeurd is.
2025-05-30 02:07:05,505 - INFO - joeynmt.training - Epoch   6, Step:    61100, Batch Loss:     1.202335, Batch Acc: 0.577085, Tokens per Sec:     8061, Lr: 0.000300
2025-05-30 02:07:14,288 - INFO - joeynmt.training - Epoch   6, Step:    61200, Batch Loss:     1.613402, Batch Acc: 0.569282, Tokens per Sec:     8258, Lr: 0.000300
2025-05-30 02:07:23,205 - INFO - joeynmt.training - Epoch   6, Step:    61300, Batch Loss:     1.266049, Batch Acc: 0.560081, Tokens per Sec:     7817, Lr: 0.000300
2025-05-30 02:07:32,286 - INFO - joeynmt.training - Epoch   6, Step:    61400, Batch Loss:     1.204224, Batch Acc: 0.568404, Tokens per Sec:     8009, Lr: 0.000300
2025-05-30 02:07:41,778 - INFO - joeynmt.training - Epoch   6, Step:    61500, Batch Loss:     1.322594, Batch Acc: 0.567368, Tokens per Sec:     7707, Lr: 0.000300
2025-05-30 02:07:41,780 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:07:41,780 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:08:24,587 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.45, ppl:   4.26, acc:   0.54, generation: 42.7583[sec], evaluation: 0.0000[sec]
2025-05-30 02:08:24,749 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/59000.ckpt
2025-05-30 02:08:24,766 - INFO - joeynmt.training - Example #0
2025-05-30 02:08:24,767 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:08:24,767 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:08:24,767 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'ken@@', 'nen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'te', 'ver@@', 'z@@', 'oe@@', 'ken', 'is.', '</s>']
2025-05-30 02:08:24,768 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:08:24,768 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:08:24,769 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkennen dat de arctische ijskappen die voor de grootte van de onderste 40 procent van 40 procent geslagen van 40 procent gehad om 40 procent geslagen te verzoeken is.
2025-05-30 02:08:24,769 - INFO - joeynmt.training - Example #1
2025-05-30 02:08:24,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:08:24,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:08:24,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ru@@', 'k@@', 'k@@', 'ing', 'van', 'de', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:08:24,770 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:08:24,770 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:08:24,771 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet genoeg de eerste van dit speciale probleem uit, omdat het niet de dikke drukking van de ijs laat zien.
2025-05-30 02:08:24,771 - INFO - joeynmt.training - Example #2
2025-05-30 02:08:24,771 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:08:24,771 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:08:24,772 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'dat', 's@@', 'la@@', 'p@@', 'ende', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'k@@', 'ing@@', 's@@', 'st@@', 'a@@', 'p', 'van', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:08:24,773 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:08:24,773 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:08:24,773 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape dat slapende hart van onze werkingsstap van klimaatsysteem.
2025-05-30 02:08:24,773 - INFO - joeynmt.training - Example #3
2025-05-30 02:08:24,774 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:08:24,774 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:08:24,774 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'den', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ro@@', 'l@@', '.', '</s>']
2025-05-30 02:08:24,775 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:08:24,775 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:08:24,775 - INFO - joeynmt.training - 	Hypothesis: Ze groeiden in de winter en zrompt in de winter en zrol.
2025-05-30 02:08:24,775 - INFO - joeynmt.training - Example #4
2025-05-30 02:08:24,775 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:08:24,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:08:24,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:08:24,776 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:08:24,777 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:08:24,777 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsgebeurde in de afgelopen 25 jaar gebeurd is.
2025-05-30 02:08:33,777 - INFO - joeynmt.training - Epoch   6, Step:    61600, Batch Loss:     1.425564, Batch Acc: 0.569300, Tokens per Sec:     7887, Lr: 0.000300
2025-05-30 02:08:42,817 - INFO - joeynmt.training - Epoch   6, Step:    61700, Batch Loss:     1.217352, Batch Acc: 0.564911, Tokens per Sec:     7990, Lr: 0.000300
2025-05-30 02:08:51,844 - INFO - joeynmt.training - Epoch   6, Step:    61800, Batch Loss:     1.381487, Batch Acc: 0.566325, Tokens per Sec:     7772, Lr: 0.000300
2025-05-30 02:09:00,864 - INFO - joeynmt.training - Epoch   6, Step:    61900, Batch Loss:     1.413878, Batch Acc: 0.566766, Tokens per Sec:     7933, Lr: 0.000300
2025-05-30 02:09:09,881 - INFO - joeynmt.training - Epoch   6, Step:    62000, Batch Loss:     1.306329, Batch Acc: 0.565715, Tokens per Sec:     8099, Lr: 0.000300
2025-05-30 02:09:09,885 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:09:09,886 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:09:58,210 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.45, ppl:   4.24, acc:   0.54, generation: 48.2765[sec], evaluation: 0.0000[sec]
2025-05-30 02:09:58,211 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:09:58,373 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/61000.ckpt
2025-05-30 02:09:58,387 - INFO - joeynmt.training - Example #0
2025-05-30 02:09:58,388 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:09:58,388 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:09:58,388 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 'z@@', 'oe@@', 'ken', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 's@@', 'la@@', 'v@@', 'ing@@', '.', '</s>']
2025-05-30 02:09:58,389 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:09:58,389 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:09:58,389 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te beginnen te begrijpen dat de arctische ijskappen die voor de grootte van de onderste 48 staten, om 48 staten, om 48 staten, om 40 procent te verzoeken om 40 procent te verslaving.
2025-05-30 02:09:58,389 - INFO - joeynmt.training - Example #1
2025-05-30 02:09:58,389 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:09:58,389 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:09:58,389 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'un@@', 't', 'van', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:09:58,390 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:09:58,390 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:09:58,390 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste punt van het speciale probleem uit, omdat het speciale probleem uit, omdat het niet de dikke van het ijskracht laat zien.
2025-05-30 02:09:58,390 - INFO - joeynmt.training - Example #2
2025-05-30 02:09:58,390 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:09:58,391 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:09:58,391 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'ig@@', 'en@@', 'lijk', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 'sl@@', 'aa@@', 'g@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:09:58,391 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:09:58,392 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:09:58,392 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigenlijk is de arctische ijskape het slaagde hart van onze wereldwijde klimaatsysteem.
2025-05-30 02:09:58,392 - INFO - joeynmt.training - Example #3
2025-05-30 02:09:58,392 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:09:58,392 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:09:58,392 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'g@@', 'v@@', 'en.', '</s>']
2025-05-30 02:09:58,393 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:09:58,393 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:09:58,393 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen in de winter en zich in de winter en zich in de winter en zich in de winter en zorgven.
2025-05-30 02:09:58,393 - INFO - joeynmt.training - Example #4
2025-05-30 02:09:58,393 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:09:58,393 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:09:58,393 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'de', 'vol@@', 'gen@@', 'de', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'vol@@', 'gen@@', 'de', 'di@@', 'a', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:09:58,394 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:09:58,394 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:09:58,394 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdperk van de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde de volgende 25 jaar gebeurde volgende dia 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurd.
2025-05-30 02:10:07,499 - INFO - joeynmt.training - Epoch   6, Step:    62100, Batch Loss:     1.340480, Batch Acc: 0.568708, Tokens per Sec:     7599, Lr: 0.000300
2025-05-30 02:10:16,711 - INFO - joeynmt.training - Epoch   6, Step:    62200, Batch Loss:     1.389523, Batch Acc: 0.561862, Tokens per Sec:     7844, Lr: 0.000300
2025-05-30 02:10:25,729 - INFO - joeynmt.training - Epoch   6, Step:    62300, Batch Loss:     1.430553, Batch Acc: 0.573335, Tokens per Sec:     8210, Lr: 0.000300
2025-05-30 02:10:34,634 - INFO - joeynmt.training - Epoch   6, Step:    62400, Batch Loss:     1.329193, Batch Acc: 0.569371, Tokens per Sec:     8054, Lr: 0.000300
2025-05-30 02:10:43,625 - INFO - joeynmt.training - Epoch   6, Step:    62500, Batch Loss:     1.290937, Batch Acc: 0.567178, Tokens per Sec:     7836, Lr: 0.000300
2025-05-30 02:10:43,626 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:10:43,626 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:11:20,469 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.45, ppl:   4.25, acc:   0.54, generation: 36.8017[sec], evaluation: 0.0000[sec]
2025-05-30 02:11:20,620 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/59500.ckpt
2025-05-30 02:11:20,633 - INFO - joeynmt.training - Example #0
2025-05-30 02:11:20,634 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:11:20,634 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:11:20,634 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'ste', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'ste', 'van', 'de', 'gro@@', 'ot@@', 'ste', 'van', 'de', 'gro@@', 'ot@@', 'ste', 'is', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'm@@', 'p@@', 'oo@@', 'l@@', '.', '</s>']
2025-05-30 02:11:20,635 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:11:20,635 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:11:20,635 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen te begrijpen dat de arctische ijskappen die voor de grootste drie miljoen jaar de grootste van de grootste van de grootste is van 40 procent gesmpool.
2025-05-30 02:11:20,635 - INFO - joeynmt.training - Example #1
2025-05-30 02:11:20,636 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:11:20,636 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:11:20,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'st@@', 'a@@', 'p', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em@@', ',', 'om@@', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em@@', '.', '</s>']
2025-05-30 02:11:20,637 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:11:20,637 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:11:20,637 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet sterk genoeg de eerste stap van dit speciale probleem, omdat het speciale probleem.
2025-05-30 02:11:20,637 - INFO - joeynmt.training - Example #2
2025-05-30 02:11:20,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:11:20,638 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:11:20,638 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:11:20,638 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:11:20,638 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:11:20,638 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 02:11:20,639 - INFO - joeynmt.training - Example #3
2025-05-30 02:11:20,639 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:11:20,639 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:11:20,639 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ru@@', 'p@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-30 02:11:20,640 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:11:20,640 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:11:20,640 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zruppt in de zomer.
2025-05-30 02:11:20,640 - INFO - joeynmt.training - Example #4
2025-05-30 02:11:20,640 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:11:20,640 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:11:20,640 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ge@@', 'ven', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:11:20,641 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:11:20,641 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:11:20,642 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsgeven in de laatste 25 jaar gebeurd.
2025-05-30 02:11:29,447 - INFO - joeynmt.training - Epoch   6, Step:    62600, Batch Loss:     1.292358, Batch Acc: 0.567267, Tokens per Sec:     8345, Lr: 0.000300
2025-05-30 02:11:38,290 - INFO - joeynmt.training - Epoch   6, Step:    62700, Batch Loss:     1.353067, Batch Acc: 0.575573, Tokens per Sec:     8108, Lr: 0.000300
2025-05-30 02:11:47,312 - INFO - joeynmt.training - Epoch   6, Step:    62800, Batch Loss:     1.285257, Batch Acc: 0.565653, Tokens per Sec:     8087, Lr: 0.000300
2025-05-30 02:11:56,196 - INFO - joeynmt.training - Epoch   6, Step:    62900, Batch Loss:     1.426419, Batch Acc: 0.573606, Tokens per Sec:     8291, Lr: 0.000300
2025-05-30 02:12:05,749 - INFO - joeynmt.training - Epoch   6, Step:    63000, Batch Loss:     1.238654, Batch Acc: 0.570078, Tokens per Sec:     7654, Lr: 0.000300
2025-05-30 02:12:05,749 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:12:05,750 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:12:54,807 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.45, ppl:   4.24, acc:   0.54, generation: 49.0154[sec], evaluation: 0.0000[sec]
2025-05-30 02:12:54,808 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:12:54,974 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/60000.ckpt
2025-05-30 02:12:54,988 - INFO - joeynmt.training - Example #0
2025-05-30 02:12:54,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:12:54,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:12:54,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijk', 'in', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'st@@', 'el@@', 'd.', '</s>']
2025-05-30 02:12:54,990 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:12:54,990 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:12:54,990 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee dia's getoond dat de arctische ijskappe ijskappelijke ijskappelijk in de onderste 48 staten had om 48 staten om 40 procent te gesteld.
2025-05-30 02:12:54,990 - INFO - joeynmt.training - Example #1
2025-05-30 02:12:54,991 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:12:54,991 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:12:54,991 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 'u@@', 'z@@', 'z@@', 'el', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k', 'van', 'de', 'ij@@', 's@@', 'k@@', 'er', 'van', 'de', 'ij@@', 's@@', 'k@@', 'er', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's@@', 'k@@', 'er', 'van', 'de', 'ij@@', 's@@', 'k@@', 'er', 'van', 'het', 'ij@@', 's@@', 'k@@', 'er', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'gen@@', 'oe@@', 'g', 'die', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's@@', 'k@@', 'er', 'van', 'het', 'ij@@', 's@@', 'k@@', 'er', 'van', 'het', 'ij@@', 's', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 'u@@', 'bl@@', 'ic@@', 'eer@@', '.', '</s>']
2025-05-30 02:12:54,992 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:12:54,992 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:12:54,992 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg genoeg de puzzel probleem uit, want het is niet de dik van de ijsker van de ijsker van de ijs van de ijsker van de ijsker van het ijsker van het ijskracht genoeg die de dik van het ijsker van het ijsker van het ijs van de ijskracht genoeg de publiceer.
2025-05-30 02:12:54,992 - INFO - joeynmt.training - Example #2
2025-05-30 02:12:54,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:12:54,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:12:54,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:12:54,994 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:12:54,994 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:12:54,994 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 02:12:54,994 - INFO - joeynmt.training - Example #3
2025-05-30 02:12:54,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:12:54,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:12:54,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er', 'z@@', 'om@@', 'er', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:12:54,996 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:12:54,996 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:12:54,996 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomer in de zomer zomer en zomer.
2025-05-30 02:12:54,996 - INFO - joeynmt.training - Example #4
2025-05-30 02:12:54,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:12:54,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:12:54,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'p@@', 'or@@', 't@@', 'ing', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:12:54,998 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:12:54,998 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:12:54,998 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrappporting in de laatste 25 jaar gebeurd.
2025-05-30 02:13:03,948 - INFO - joeynmt.training - Epoch   6, Step:    63100, Batch Loss:     1.273143, Batch Acc: 0.567781, Tokens per Sec:     7833, Lr: 0.000300
2025-05-30 02:13:13,064 - INFO - joeynmt.training - Epoch   6, Step:    63200, Batch Loss:     1.114300, Batch Acc: 0.567122, Tokens per Sec:     7843, Lr: 0.000300
2025-05-30 02:13:21,918 - INFO - joeynmt.training - Epoch   6, Step:    63300, Batch Loss:     1.356276, Batch Acc: 0.564814, Tokens per Sec:     8182, Lr: 0.000300
2025-05-30 02:13:30,985 - INFO - joeynmt.training - Epoch   6, Step:    63400, Batch Loss:     1.389542, Batch Acc: 0.568453, Tokens per Sec:     7844, Lr: 0.000300
2025-05-30 02:13:39,908 - INFO - joeynmt.training - Epoch   6, Step:    63500, Batch Loss:     1.201852, Batch Acc: 0.566128, Tokens per Sec:     8254, Lr: 0.000300
2025-05-30 02:13:39,908 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:13:39,909 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:14:26,139 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.45, ppl:   4.25, acc:   0.54, generation: 46.1873[sec], evaluation: 0.0000[sec]
2025-05-30 02:14:26,305 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/61500.ckpt
2025-05-30 02:14:26,321 - INFO - joeynmt.training - Example #0
2025-05-30 02:14:26,322 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:14:26,322 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:14:26,322 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'be@@', 'v@@', 'at@@', 'ten', 'van', 'de', 'onder@@', 'ste', 'p@@', 'le@@', 'k', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 02:14:26,323 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:14:26,323 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:14:26,324 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te kijken dat de arctische ijskappen die voor de bevatten van de onderste plek van de onderste 48 staten.
2025-05-30 02:14:26,324 - INFO - joeynmt.training - Example #1
2025-05-30 02:14:26,324 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:14:26,324 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:14:26,324 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'd@@', 'ingen', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'j@@', 'es', 'van', 'de', 'ij@@', 's@@', 'en.', '</s>']
2025-05-30 02:14:26,325 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:14:26,325 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:14:26,326 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg genoeg de eerste dingen van dit specifieke probleem uit, omdat het niet de dikke van de ijsjes van de ijsen.
2025-05-30 02:14:26,326 - INFO - joeynmt.training - Example #2
2025-05-30 02:14:26,326 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:14:26,327 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:14:26,327 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'ig@@', 'l@@', 'ijke', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:14:26,327 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:14:26,327 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:14:26,327 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuiglijke ijskape ijskape van onze wereldwijde klimaatsysteem.
2025-05-30 02:14:26,328 - INFO - joeynmt.training - Example #3
2025-05-30 02:14:26,328 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:14:26,328 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:14:26,328 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'r@@', 'am@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'el@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'el@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'el@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'el@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'r@@', 'on@@', 'd', 'in', 'de', 'w@@', 'in@@', 'ter', 'en']
2025-05-30 02:14:26,329 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:14:26,329 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:14:26,329 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en strampt in de winter en strompt in de winter en stelt in de winter en strompt in de winter en stelt in de winter en stelt in de winter en stelt in de winter en strompt in de winter en strompt in de winter en strompt in de winter en strompt in de winter en strond in de winter en
2025-05-30 02:14:26,329 - INFO - joeynmt.training - Example #4
2025-05-30 02:14:26,329 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:14:26,330 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:14:26,330 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:14:26,331 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:14:26,332 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:14:26,332 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdperk van de laatste 25 jaar gebeurd in de afgelopen 25 jaar gebeurd.
2025-05-30 02:14:35,378 - INFO - joeynmt.training - Epoch   6, Step:    63600, Batch Loss:     1.437672, Batch Acc: 0.566829, Tokens per Sec:     7778, Lr: 0.000300
2025-05-30 02:14:39,915 - INFO - joeynmt.training - Epoch   6: total training loss 14412.37
2025-05-30 02:14:39,916 - INFO - joeynmt.training - EPOCH 7
2025-05-30 02:14:44,329 - INFO - joeynmt.training - Epoch   7, Step:    63700, Batch Loss:     1.334812, Batch Acc: 0.585426, Tokens per Sec:     8403, Lr: 0.000300
2025-05-30 02:14:53,118 - INFO - joeynmt.training - Epoch   7, Step:    63800, Batch Loss:     1.273248, Batch Acc: 0.575610, Tokens per Sec:     8245, Lr: 0.000300
2025-05-30 02:15:01,783 - INFO - joeynmt.training - Epoch   7, Step:    63900, Batch Loss:     1.223519, Batch Acc: 0.581397, Tokens per Sec:     8220, Lr: 0.000300
2025-05-30 02:15:10,533 - INFO - joeynmt.training - Epoch   7, Step:    64000, Batch Loss:     1.376795, Batch Acc: 0.581767, Tokens per Sec:     8347, Lr: 0.000300
2025-05-30 02:15:10,534 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:15:10,535 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:15:54,332 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.24, acc:   0.54, generation: 43.7506[sec], evaluation: 0.0000[sec]
2025-05-30 02:15:54,333 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:15:54,501 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/60500.ckpt
2025-05-30 02:15:54,520 - INFO - joeynmt.training - Example #0
2025-05-30 02:15:54,521 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:15:54,521 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:15:54,521 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 't', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'zien', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 02:15:54,522 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:15:54,522 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:15:54,522 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toont om te beginnen te zien dat de artische ijskape ijskape ijskapen die voor de grootte van de grootte van de onderste staten.
2025-05-30 02:15:54,522 - INFO - joeynmt.training - Example #1
2025-05-30 02:15:54,523 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:15:54,523 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:15:54,523 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'le@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'de', 'ij@@', 's@@', 'en.', '</s>']
2025-05-30 02:15:54,524 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:15:54,524 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:15:54,524 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet sterk genoeg de eerste plek van dit specifieke probleem uit, omdat het niet de dik van de ijsen.
2025-05-30 02:15:54,524 - INFO - joeynmt.training - Example #2
2025-05-30 02:15:54,524 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:15:54,525 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:15:54,525 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:15:54,526 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:15:54,526 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:15:54,526 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskapen het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 02:15:54,526 - INFO - joeynmt.training - Example #3
2025-05-30 02:15:54,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:15:54,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:15:54,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 02:15:54,527 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:15:54,528 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:15:54,528 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zrompt in de zomers.
2025-05-30 02:15:54,528 - INFO - joeynmt.training - Example #4
2025-05-30 02:15:54,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:15:54,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:15:54,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'p@@', 'aar', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 02:15:54,529 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:15:54,529 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:15:54,529 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een paar laatste 25 jaar.
2025-05-30 02:16:03,413 - INFO - joeynmt.training - Epoch   7, Step:    64100, Batch Loss:     1.396572, Batch Acc: 0.578828, Tokens per Sec:     7939, Lr: 0.000300
2025-05-30 02:16:11,749 - INFO - joeynmt.training - Epoch   7, Step:    64200, Batch Loss:     1.192497, Batch Acc: 0.570740, Tokens per Sec:     8585, Lr: 0.000300
2025-05-30 02:16:20,156 - INFO - joeynmt.training - Epoch   7, Step:    64300, Batch Loss:     1.426508, Batch Acc: 0.576185, Tokens per Sec:     8621, Lr: 0.000300
2025-05-30 02:16:28,142 - INFO - joeynmt.training - Epoch   7, Step:    64400, Batch Loss:     1.209653, Batch Acc: 0.571993, Tokens per Sec:     9043, Lr: 0.000300
2025-05-30 02:16:36,461 - INFO - joeynmt.training - Epoch   7, Step:    64500, Batch Loss:     1.379102, Batch Acc: 0.577783, Tokens per Sec:     8585, Lr: 0.000300
2025-05-30 02:16:36,462 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:16:36,462 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:17:23,813 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.24, acc:   0.54, generation: 47.3004[sec], evaluation: 0.0000[sec]
2025-05-30 02:17:23,814 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:17:23,999 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/62500.ckpt
2025-05-30 02:17:24,012 - INFO - joeynmt.training - Example #0
2025-05-30 02:17:24,013 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:17:24,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:17:24,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'gr@@', 'ij@@', 'p@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', 'van', 'de', 'onder@@', 'ste', 'onder@@', 'ste', 'st@@', 'aten', 'van', '4@@', '8', 'st@@', 'aten', 'onder@@', 'ste@@', 'un@@', 'ing', 'van', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ver@@', 'z@@', 'et@@', 'ten', 'te', 'ver@@', 'z@@', 'et@@', 'ten', 'te', 'ver@@', 'z@@', 'or@@', 'g@@', 'd', 'is.', '</s>']
2025-05-30 02:17:24,014 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:17:24,015 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:17:24,015 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen te begrijpen, dat de arctische ijskappen die voor de onderste van de onderste onderste staten van 48 staten ondersteuning van 48 staten om 48 staten te verzetten te verzetten te verzorgd is.
2025-05-30 02:17:24,015 - INFO - joeynmt.training - Example #1
2025-05-30 02:17:24,015 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:17:24,015 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:17:24,015 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:17:24,016 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:17:24,017 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:17:24,017 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de eerste van dit specifieke probleem is dat het niet de dik van het ijskracht laat zien.
2025-05-30 02:17:24,017 - INFO - joeynmt.training - Example #2
2025-05-30 02:17:24,017 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:17:24,017 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:17:24,017 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's', 'het', 's@@', 'la@@', 'gen', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'm@@', 'en.', '</s>']
2025-05-30 02:17:24,019 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:17:24,019 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:17:24,019 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijs het slagen van ons wereldwijde klimaatsystemen.
2025-05-30 02:17:24,020 - INFO - joeynmt.training - Example #3
2025-05-30 02:17:24,020 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:17:24,020 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:17:24,020 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 02:17:24,021 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:17:24,021 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:17:24,021 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich zich in de zomers.
2025-05-30 02:17:24,022 - INFO - joeynmt.training - Example #4
2025-05-30 02:17:24,022 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:17:24,022 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:17:24,022 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 02:17:24,023 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:17:24,023 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:17:24,024 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdperk van wat er in de laatste 25 jaar.
2025-05-30 02:17:33,100 - INFO - joeynmt.training - Epoch   7, Step:    64600, Batch Loss:     1.249929, Batch Acc: 0.578995, Tokens per Sec:     7729, Lr: 0.000300
2025-05-30 02:17:41,802 - INFO - joeynmt.training - Epoch   7, Step:    64700, Batch Loss:     1.288186, Batch Acc: 0.577213, Tokens per Sec:     8497, Lr: 0.000300
2025-05-30 02:17:50,435 - INFO - joeynmt.training - Epoch   7, Step:    64800, Batch Loss:     1.317332, Batch Acc: 0.581368, Tokens per Sec:     8270, Lr: 0.000300
2025-05-30 02:17:58,930 - INFO - joeynmt.training - Epoch   7, Step:    64900, Batch Loss:     1.348229, Batch Acc: 0.576396, Tokens per Sec:     8481, Lr: 0.000300
2025-05-30 02:18:07,738 - INFO - joeynmt.training - Epoch   7, Step:    65000, Batch Loss:     1.547930, Batch Acc: 0.577063, Tokens per Sec:     8374, Lr: 0.000300
2025-05-30 02:18:07,738 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:18:07,739 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:18:55,133 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.23, acc:   0.54, generation: 47.3459[sec], evaluation: 0.0000[sec]
2025-05-30 02:18:55,134 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:18:55,308 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/63500.ckpt
2025-05-30 02:18:55,324 - INFO - joeynmt.training - Example #0
2025-05-30 02:18:55,325 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:18:55,325 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:18:55,325 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:18:55,326 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:18:55,326 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:18:55,327 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te begrijpen dat de arctische ijskape ijskape ijskape ijskappen die voor de onderste 48 staten had om 48 staten had om 48 staten gebeurd.
2025-05-30 02:18:55,327 - INFO - joeynmt.training - Example #1
2025-05-30 02:18:55,327 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:18:55,327 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:18:55,327 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'un@@', 't', 'van', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'ij@@', 's@@', 'e@@', 'er', 'is', 'het', 'niet', 'de', 'di@@', 'ck@@', 'e', 'van', 'het', 'ij@@', 's@@', 'en.', '</s>']
2025-05-30 02:18:55,328 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:18:55,328 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:18:55,328 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de eerste punt van het speciale probleem uit, omdat het niet de dicke van het ijseer is het niet de dicke van het ijsen.
2025-05-30 02:18:55,329 - INFO - joeynmt.training - Example #2
2025-05-30 02:18:55,329 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:18:55,329 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:18:55,329 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:18:55,330 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:18:55,330 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:18:55,330 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijs het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 02:18:55,330 - INFO - joeynmt.training - Example #3
2025-05-30 02:18:55,330 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:18:55,330 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:18:55,331 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'or@@', 'gen.', '</s>']
2025-05-30 02:18:55,331 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:18:55,332 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:18:55,332 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zich zorgen.
2025-05-30 02:18:55,332 - INFO - joeynmt.training - Example #4
2025-05-30 02:18:55,332 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:18:55,332 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:18:55,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a@@', "'s", 'die', 'ik', 'jullie', 't@@', 'on@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:18:55,333 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:18:55,334 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:18:55,334 - INFO - joeynmt.training - 	Hypothesis: De volgende dia's die ik jullie tonen, is een tijdperk van wat er in de afgelopen 25 jaar gebeurd is.
2025-05-30 02:19:04,258 - INFO - joeynmt.training - Epoch   7, Step:    65100, Batch Loss:     1.216213, Batch Acc: 0.583461, Tokens per Sec:     7964, Lr: 0.000300
2025-05-30 02:19:13,249 - INFO - joeynmt.training - Epoch   7, Step:    65200, Batch Loss:     1.197389, Batch Acc: 0.582223, Tokens per Sec:     8168, Lr: 0.000300
2025-05-30 02:19:22,116 - INFO - joeynmt.training - Epoch   7, Step:    65300, Batch Loss:     1.654359, Batch Acc: 0.569739, Tokens per Sec:     7866, Lr: 0.000300
2025-05-30 02:19:31,177 - INFO - joeynmt.training - Epoch   7, Step:    65400, Batch Loss:     1.184044, Batch Acc: 0.576811, Tokens per Sec:     7970, Lr: 0.000300
2025-05-30 02:19:40,154 - INFO - joeynmt.training - Epoch   7, Step:    65500, Batch Loss:     1.351928, Batch Acc: 0.575388, Tokens per Sec:     8112, Lr: 0.000300
2025-05-30 02:19:40,154 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:19:40,155 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:20:32,210 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.24, acc:   0.54, generation: 52.0137[sec], evaluation: 0.0000[sec]
2025-05-30 02:20:32,390 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/62000.ckpt
2025-05-30 02:20:32,408 - INFO - joeynmt.training - Example #0
2025-05-30 02:20:32,408 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:20:32,409 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:20:32,409 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'k@@', 'el', 'ge@@', 'to@@', 'on@@', 'd', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'i@@', 'ë@@', 'l@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'on@@', 'der', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'te', 'ge@@', 's@@', 'la@@', 'cht', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 02:20:32,410 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:20:32,410 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:20:32,410 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik dat de arctikel getoond dat de arctische ijiële ijskappen, die voor onder 48 staten had om 48 staten had te geslacht van de grootte van de grootte van de staten.
2025-05-30 02:20:32,410 - INFO - joeynmt.training - Example #1
2025-05-30 02:20:32,410 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:20:32,411 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:20:32,411 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'un@@', 't', 'van', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'pro@@', 'ble@@', 'em', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:20:32,411 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:20:32,412 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:20:32,412 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet sterk genoeg de eerste punt van het speciale probleem dat het niet de dikke probleem laat zien.
2025-05-30 02:20:32,412 - INFO - joeynmt.training - Example #2
2025-05-30 02:20:32,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:20:32,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:20:32,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'ig@@', 'en@@', 'lijk', 'is', 'de', 'ar@@', 'ti@@', 'k@@', 'el', 'dat', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:20:32,413 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:20:32,413 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:20:32,413 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigenlijk is de artikel dat het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 02:20:32,414 - INFO - joeynmt.training - Example #3
2025-05-30 02:20:32,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:20:32,414 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:20:32,414 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'g@@', 'd', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 02:20:32,415 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:20:32,415 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:20:32,415 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zorgd in de zomers.
2025-05-30 02:20:32,415 - INFO - joeynmt.training - Example #4
2025-05-30 02:20:32,415 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:20:32,416 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:20:32,416 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'tij@@', 'd@@', 'per@@', 'k', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:20:32,417 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:20:32,417 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:20:32,417 - INFO - joeynmt.training - 	Hypothesis: De volgende die ik jullie laten zien, is een tijdperk van de tijdperk in de afgelopen 25 jaar gebeurd is.
2025-05-30 02:20:41,355 - INFO - joeynmt.training - Epoch   7, Step:    65600, Batch Loss:     1.273575, Batch Acc: 0.565055, Tokens per Sec:     7893, Lr: 0.000300
2025-05-30 02:20:50,058 - INFO - joeynmt.training - Epoch   7, Step:    65700, Batch Loss:     1.377750, Batch Acc: 0.577095, Tokens per Sec:     8270, Lr: 0.000300
2025-05-30 02:20:58,272 - INFO - joeynmt.training - Epoch   7, Step:    65800, Batch Loss:     1.645077, Batch Acc: 0.577983, Tokens per Sec:     8780, Lr: 0.000300
2025-05-30 02:21:06,186 - INFO - joeynmt.training - Epoch   7, Step:    65900, Batch Loss:     1.348877, Batch Acc: 0.574583, Tokens per Sec:     9101, Lr: 0.000300
2025-05-30 02:21:14,015 - INFO - joeynmt.training - Epoch   7, Step:    66000, Batch Loss:     1.360874, Batch Acc: 0.574137, Tokens per Sec:     9270, Lr: 0.000300
2025-05-30 02:21:14,016 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:21:14,016 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:21:55,064 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.23, acc:   0.54, generation: 40.9978[sec], evaluation: 0.0000[sec]
2025-05-30 02:21:55,066 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:21:55,251 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/63000.ckpt
2025-05-30 02:21:55,266 - INFO - joeynmt.training - Example #0
2025-05-30 02:21:55,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:21:55,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:21:55,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'kel@@', 'en', 'die', 'voor', 'de', 'sch@@', 'aal', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'voor', '4@@', '8', 'st@@', 'aten', 'is.', '</s>']
2025-05-30 02:21:55,268 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:21:55,268 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:21:55,268 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te beginnen te begrijpen dat de arctikelen die voor de schaal ijskappen die voor de onderste 48 staten had drie miljoen jaar de grootte van de onderste 48 staten had om 48 staten voor 48 staten is.
2025-05-30 02:21:55,268 - INFO - joeynmt.training - Example #1
2025-05-30 02:21:55,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:21:55,269 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:21:55,269 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'st@@', 'ar@@', 'k', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'd@@', 'ru@@', 'k@@', 'ken', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 'ten', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 'ten', 'van', 'de', 'ij@@', 's@@', 'n@@', 'el@@', 'heid', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'dat', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:21:55,269 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:21:55,270 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:21:55,270 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de stark van het specifieke probleem van dit speciale probleem uit, omdat het niet de dikke dikke drukken van de ijskrachten van de ijskrachten van de ijsnelheid van het ijskracht van het ijskracht van het ijskracht van het ijskracht van het ijskracht dat het specifieke probleem laat zien.
2025-05-30 02:21:55,270 - INFO - joeynmt.training - Example #2
2025-05-30 02:21:55,270 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:21:55,270 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:21:55,270 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'igen', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en.', '</s>']
2025-05-30 02:21:55,271 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:21:55,271 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:21:55,271 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigen is de arctische ijskape ijskappe ijskappen.
2025-05-30 02:21:55,272 - INFO - joeynmt.training - Example #3
2025-05-30 02:21:55,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:21:55,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:21:55,272 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'r@@', 'on@@', 'd', 'en', 'z@@', 'r@@', 'on@@', 'd', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 02:21:55,273 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:21:55,273 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:21:55,273 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zrond en zrond de zomers.
2025-05-30 02:21:55,273 - INFO - joeynmt.training - Example #4
2025-05-30 02:21:55,274 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:21:55,274 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:21:55,274 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'p@@', 'ar@@', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 02:21:55,274 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:21:55,274 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:21:55,274 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een partijdperk van de laatste 25 jaar.
2025-05-30 02:22:04,099 - INFO - joeynmt.training - Epoch   7, Step:    66100, Batch Loss:     1.483820, Batch Acc: 0.578027, Tokens per Sec:     7966, Lr: 0.000300
2025-05-30 02:22:13,074 - INFO - joeynmt.training - Epoch   7, Step:    66200, Batch Loss:     1.303014, Batch Acc: 0.569394, Tokens per Sec:     8262, Lr: 0.000300
2025-05-30 02:22:21,982 - INFO - joeynmt.training - Epoch   7, Step:    66300, Batch Loss:     1.355004, Batch Acc: 0.565526, Tokens per Sec:     7926, Lr: 0.000300
2025-05-30 02:22:30,946 - INFO - joeynmt.training - Epoch   7, Step:    66400, Batch Loss:     1.296258, Batch Acc: 0.571258, Tokens per Sec:     8253, Lr: 0.000300
2025-05-30 02:22:39,952 - INFO - joeynmt.training - Epoch   7, Step:    66500, Batch Loss:     1.293154, Batch Acc: 0.575748, Tokens per Sec:     8010, Lr: 0.000300
2025-05-30 02:22:39,952 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:22:39,952 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:23:23,059 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.23, acc:   0.54, generation: 43.0668[sec], evaluation: 0.0000[sec]
2025-05-30 02:23:23,224 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/64000.ckpt
2025-05-30 02:23:23,248 - INFO - joeynmt.training - Example #0
2025-05-30 02:23:23,249 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:23:23,249 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:23:23,250 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 't', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'd@@', 'ing', 'te', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'er@@', 's', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'an@@', '.', '</s>']
2025-05-30 02:23:23,250 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:23:23,251 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:23:23,251 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toont om te verbeelding te kijken dat de arctische ijskape ijzers die voor de onderste 48 staten had drie miljoen jaar de grootte van de onderste 40 procent geslaan.
2025-05-30 02:23:23,251 - INFO - joeynmt.training - Example #1
2025-05-30 02:23:23,251 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:23:23,252 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:23:23,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'st@@', 'o@@', 'ff@@', 'en@@', 'd@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'to@@', 'on@@', 't.', '</s>']
2025-05-30 02:23:23,254 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:23:23,254 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:23:23,255 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet sterk genoeg de stoffendheid van dit specifieke probleem uit, omdat het niet de dikke dikke van het ijs toont.
2025-05-30 02:23:23,255 - INFO - joeynmt.training - Example #2
2025-05-30 02:23:23,255 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:23:23,255 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:23:23,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'ig@@', 'l@@', 'ijke', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'het', 's@@', 'la@@', 'gen@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:23:23,256 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:23:23,257 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:23:23,257 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuiglijke ijskape ijskape ijskape het slagende klimaatsysteem.
2025-05-30 02:23:23,257 - INFO - joeynmt.training - Example #3
2025-05-30 02:23:23,257 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:23:23,257 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:23:23,257 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 02:23:23,258 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:23:23,259 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:23:23,259 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en scheppt in de zomers.
2025-05-30 02:23:23,259 - INFO - joeynmt.training - Example #4
2025-05-30 02:23:23,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:23:23,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:23:23,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'je', 'dat', 'er', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:23:23,260 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:23:23,260 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:23:23,260 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdje dat er in de afgelopen 25 jaar gebeurd is.
2025-05-30 02:23:32,085 - INFO - joeynmt.training - Epoch   7, Step:    66600, Batch Loss:     1.214832, Batch Acc: 0.571886, Tokens per Sec:     7965, Lr: 0.000300
2025-05-30 02:23:40,683 - INFO - joeynmt.training - Epoch   7, Step:    66700, Batch Loss:     1.276584, Batch Acc: 0.573158, Tokens per Sec:     8166, Lr: 0.000300
2025-05-30 02:23:49,548 - INFO - joeynmt.training - Epoch   7, Step:    66800, Batch Loss:     1.202100, Batch Acc: 0.574591, Tokens per Sec:     8290, Lr: 0.000300
2025-05-30 02:23:58,032 - INFO - joeynmt.training - Epoch   7, Step:    66900, Batch Loss:     1.209052, Batch Acc: 0.572834, Tokens per Sec:     8432, Lr: 0.000300
2025-05-30 02:24:06,339 - INFO - joeynmt.training - Epoch   7, Step:    67000, Batch Loss:     1.376695, Batch Acc: 0.571379, Tokens per Sec:     8680, Lr: 0.000300
2025-05-30 02:24:06,339 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:24:06,340 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:24:51,925 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.23, acc:   0.54, generation: 45.5399[sec], evaluation: 0.0000[sec]
2025-05-30 02:24:52,102 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/65500.ckpt
2025-05-30 02:24:52,117 - INFO - joeynmt.training - Example #0
2025-05-30 02:24:52,118 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:24:52,118 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:24:52,118 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'k@@', 'ijk@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'n@@', 'am@@', 'e', 'ij@@', 'z@@', 'er@@', 's', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ver@@', 'st@@', 'op@@', 'p@@', 'en.', '</s>']
2025-05-30 02:24:52,119 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:24:52,119 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:24:52,122 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te kijken, dat de arctische ijskappen die voor de name ijzers die voor de onderste 48 staten van de onderste 48 staten om 48 staten te verstoppen.
2025-05-30 02:24:52,122 - INFO - joeynmt.training - Example #1
2025-05-30 02:24:52,122 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:24:52,123 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:24:52,123 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 'ken', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 'ra@@', 'cht@@', 'ig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:24:52,124 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:24:52,124 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:24:52,124 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukken niet sterk genoeg de prachtigheid van dit specifieke probleem uit, omdat het niet de dikke dikke van de ijs van de ijs van de ijs laat zien.
2025-05-30 02:24:52,124 - INFO - joeynmt.training - Example #2
2025-05-30 02:24:52,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:24:52,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:24:52,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'igen', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'st@@', 'aan@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:24:52,126 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:24:52,126 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:24:52,126 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigen is de arctische ijskape ijstaande hart van onze wereldwijd klimaatsysteem.
2025-05-30 02:24:52,127 - INFO - joeynmt.training - Example #3
2025-05-30 02:24:52,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:24:52,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:24:52,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 02:24:52,128 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:24:52,128 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:24:52,128 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en strompt in de zomers.
2025-05-30 02:24:52,129 - INFO - joeynmt.training - Example #4
2025-05-30 02:24:52,129 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:24:52,129 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:24:52,129 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'p@@', 'ar@@', 'tij@@', 'en', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 02:24:52,130 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:24:52,130 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:24:52,130 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een partijen wat er gebeurd in de afgelopen 25 jaar.
2025-05-30 02:25:01,506 - INFO - joeynmt.training - Epoch   7, Step:    67100, Batch Loss:     1.404894, Batch Acc: 0.570790, Tokens per Sec:     7361, Lr: 0.000300
2025-05-30 02:25:10,514 - INFO - joeynmt.training - Epoch   7, Step:    67200, Batch Loss:     1.385454, Batch Acc: 0.571049, Tokens per Sec:     8070, Lr: 0.000300
2025-05-30 02:25:19,708 - INFO - joeynmt.training - Epoch   7, Step:    67300, Batch Loss:     1.393968, Batch Acc: 0.570898, Tokens per Sec:     7552, Lr: 0.000300
2025-05-30 02:25:28,679 - INFO - joeynmt.training - Epoch   7, Step:    67400, Batch Loss:     1.269422, Batch Acc: 0.571737, Tokens per Sec:     8207, Lr: 0.000300
2025-05-30 02:25:37,640 - INFO - joeynmt.training - Epoch   7, Step:    67500, Batch Loss:     1.243548, Batch Acc: 0.573627, Tokens per Sec:     8110, Lr: 0.000300
2025-05-30 02:25:37,641 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:25:37,641 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:26:26,441 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.22, acc:   0.54, generation: 48.7577[sec], evaluation: 0.0000[sec]
2025-05-30 02:26:26,442 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:26:26,620 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/64500.ckpt
2025-05-30 02:26:26,636 - INFO - joeynmt.training - Example #0
2025-05-30 02:26:26,637 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:26:26,637 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:26:26,637 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'ti@@', 'k@@', 'el', 'ge@@', 'be@@', 'ur@@', 'de', 'voor', 'de', 'sch@@', 'aal', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd@@', 'den', '4@@', '8', 'st@@', 'aten', 'ge@@', 's@@', 'm@@', 'p@@', 'el@@', 'd.', '</s>']
2025-05-30 02:26:26,638 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:26:26,638 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:26:26,639 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee miljoen jaar getoond om te bekijken dat de artikel gebeurde voor de schaal van de onderste 48 staten voor de onderste 48 staten hadden 48 staten gesmpeld.
2025-05-30 02:26:26,639 - INFO - joeynmt.training - Example #1
2025-05-30 02:26:26,639 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:26:26,639 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:26:26,639 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'k@@', 'ra@@', 'cht', 'gen@@', 'oe@@', 'g', 'de', 'st@@', 'a@@', 'p', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:26:26,640 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:26:26,640 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:26:26,640 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de kracht genoeg de stap van dit specifieke probleem uit, omdat het niet de dikke dikke van het ijs van het ijs laat zien.
2025-05-30 02:26:26,641 - INFO - joeynmt.training - Example #2
2025-05-30 02:26:26,641 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:26:26,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:26:26,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'at@@', 'u@@', 'ur', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:26:26,642 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:26:26,642 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:26:26,642 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de artische ijskappe ijskappe ijskapparatuur van onze wereldwijde klimaatsysteem.
2025-05-30 02:26:26,642 - INFO - joeynmt.training - Example #3
2025-05-30 02:26:26,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:26:26,643 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:26:26,643 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 02:26:26,644 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:26:26,644 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:26:26,644 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomers.
2025-05-30 02:26:26,644 - INFO - joeynmt.training - Example #4
2025-05-30 02:26:26,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:26:26,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:26:26,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'p@@', 'le@@', 'k', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:26:26,646 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:26:26,646 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:26:26,646 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een plek van de laatste 25 jaar gebeurd.
2025-05-30 02:26:35,598 - INFO - joeynmt.training - Epoch   7, Step:    67600, Batch Loss:     1.421928, Batch Acc: 0.578283, Tokens per Sec:     7988, Lr: 0.000300
2025-05-30 02:26:43,979 - INFO - joeynmt.training - Epoch   7, Step:    67700, Batch Loss:     1.404553, Batch Acc: 0.577230, Tokens per Sec:     8598, Lr: 0.000300
2025-05-30 02:26:51,692 - INFO - joeynmt.training - Epoch   7, Step:    67800, Batch Loss:     1.351723, Batch Acc: 0.566266, Tokens per Sec:     9196, Lr: 0.000300
2025-05-30 02:26:59,571 - INFO - joeynmt.training - Epoch   7, Step:    67900, Batch Loss:     1.284560, Batch Acc: 0.577281, Tokens per Sec:     8962, Lr: 0.000300
2025-05-30 02:27:07,485 - INFO - joeynmt.training - Epoch   7, Step:    68000, Batch Loss:     1.289937, Batch Acc: 0.577933, Tokens per Sec:     8975, Lr: 0.000300
2025-05-30 02:27:07,486 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:27:07,486 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:27:50,358 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.24, acc:   0.54, generation: 42.8224[sec], evaluation: 0.0000[sec]
2025-05-30 02:27:50,373 - INFO - joeynmt.training - Example #0
2025-05-30 02:27:50,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:27:50,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:27:50,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'vol@@', 'g', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'vol@@', 'g', 'om', 'te', 'k@@', 'ijk@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'i@@', 'z@@', 'en,', 'voor', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'm@@', 'p@@', 'e@@', 'e@@', 'st@@', '.', '</s>']
2025-05-30 02:27:50,375 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:27:50,375 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:27:50,375 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee gevolg ik deze twee gevolg om te kijken, dat de arctische ijizen, voor de arctische miljoen jaar de grootte van de grootte van 48 staten had geslagen om 40 procent gesmpeest.
2025-05-30 02:27:50,376 - INFO - joeynmt.training - Example #1
2025-05-30 02:27:50,376 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:27:50,376 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:27:50,376 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'aar@@', 'de', 'is', 'dat', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'k@@', 'ke', 'di@@', 'k@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:27:50,377 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:27:50,377 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:27:50,377 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de aarde is dat het specifieke probleem uit, want het is niet de dikkke dikkke van het ijs van het ijs laat zien.
2025-05-30 02:27:50,377 - INFO - joeynmt.training - Example #2
2025-05-30 02:27:50,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:27:50,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:27:50,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'p@@', 'ende', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:27:50,379 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:27:50,380 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:27:50,380 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slapende hart van ons wereldwijde klimaatsysteem.
2025-05-30 02:27:50,380 - INFO - joeynmt.training - Example #3
2025-05-30 02:27:50,380 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:27:50,380 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:27:50,380 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ru@@', 'i@@', 'p@@', 'en.', '</s>']
2025-05-30 02:27:50,381 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:27:50,382 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:27:50,382 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen in de winter en zomer in de winter en zomer in de winter en kruipen.
2025-05-30 02:27:50,382 - INFO - joeynmt.training - Example #4
2025-05-30 02:27:50,383 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:27:50,383 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:27:50,383 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'b@@', 'oe@@', 'k', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:27:50,384 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:27:50,384 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:27:50,384 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een boek van de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurd.
2025-05-30 02:27:59,474 - INFO - joeynmt.training - Epoch   7, Step:    68100, Batch Loss:     1.367420, Batch Acc: 0.570650, Tokens per Sec:     7892, Lr: 0.000300
2025-05-30 02:28:08,506 - INFO - joeynmt.training - Epoch   7, Step:    68200, Batch Loss:     1.274507, Batch Acc: 0.582200, Tokens per Sec:     8183, Lr: 0.000300
2025-05-30 02:28:17,687 - INFO - joeynmt.training - Epoch   7, Step:    68300, Batch Loss:     1.260008, Batch Acc: 0.574228, Tokens per Sec:     7922, Lr: 0.000300
2025-05-30 02:28:26,655 - INFO - joeynmt.training - Epoch   7, Step:    68400, Batch Loss:     1.409239, Batch Acc: 0.570946, Tokens per Sec:     8020, Lr: 0.000300
2025-05-30 02:28:35,644 - INFO - joeynmt.training - Epoch   7, Step:    68500, Batch Loss:     1.319937, Batch Acc: 0.573653, Tokens per Sec:     8002, Lr: 0.000300
2025-05-30 02:28:35,645 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:28:35,645 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:29:23,667 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.22, acc:   0.54, generation: 47.9791[sec], evaluation: 0.0000[sec]
2025-05-30 02:29:23,668 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:29:23,838 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/65000.ckpt
2025-05-30 02:29:23,853 - INFO - joeynmt.training - Example #0
2025-05-30 02:29:23,854 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:29:23,854 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:29:23,854 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'f@@', 'l@@', 'at@@', 'er', 'ge@@', 'to@@', 'on@@', 'd', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'lan@@', 'den', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'n@@', 'ap@@', 't', 'is.', '</s>']
2025-05-30 02:29:23,855 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:29:23,855 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:29:23,855 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee flater getoond dat de arctische ijskappe ijskappen, drie miljoen jaar de grootte van de onderste 48 landen van de onderste 40 procent gesnapt is.
2025-05-30 02:29:23,855 - INFO - joeynmt.training - Example #1
2025-05-30 02:29:23,856 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:29:23,856 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:29:23,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'op@@', 'kom@@', 'st', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'et@@', '.', '</s>']
2025-05-30 02:29:23,857 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:29:23,857 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:29:23,857 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de opkomst van het specifieke probleem uit, omdat het specifieke probleem uit, omdat het niet de dicket.
2025-05-30 02:29:23,857 - INFO - joeynmt.training - Example #2
2025-05-30 02:29:23,858 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:29:23,858 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:29:23,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'p@@', 'ende', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:29:23,859 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:29:23,859 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:29:23,859 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slapende hart van ons wereldwijde klimaatsysteem.
2025-05-30 02:29:23,859 - INFO - joeynmt.training - Example #3
2025-05-30 02:29:23,860 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:29:23,860 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:29:23,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'en', 'z@@', 'or@@', 'gen.', '</s>']
2025-05-30 02:29:23,861 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:29:23,861 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:29:23,861 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen en zorgen.
2025-05-30 02:29:23,861 - INFO - joeynmt.training - Example #4
2025-05-30 02:29:23,861 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:29:23,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:29:23,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'b@@', 'la@@', 'd@@', 'z@@', 'aa@@', 'k', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de']
2025-05-30 02:29:23,863 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:29:23,863 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:29:23,863 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een bladzaak gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde
2025-05-30 02:29:32,713 - INFO - joeynmt.training - Epoch   7, Step:    68600, Batch Loss:     1.232062, Batch Acc: 0.576244, Tokens per Sec:     8038, Lr: 0.000300
2025-05-30 02:29:41,840 - INFO - joeynmt.training - Epoch   7, Step:    68700, Batch Loss:     1.442400, Batch Acc: 0.577703, Tokens per Sec:     7706, Lr: 0.000300
2025-05-30 02:29:50,715 - INFO - joeynmt.training - Epoch   7, Step:    68800, Batch Loss:     1.294851, Batch Acc: 0.571509, Tokens per Sec:     8235, Lr: 0.000300
2025-05-30 02:29:59,645 - INFO - joeynmt.training - Epoch   7, Step:    68900, Batch Loss:     1.440613, Batch Acc: 0.572317, Tokens per Sec:     7710, Lr: 0.000300
2025-05-30 02:30:08,760 - INFO - joeynmt.training - Epoch   7, Step:    69000, Batch Loss:     1.234134, Batch Acc: 0.573957, Tokens per Sec:     7987, Lr: 0.000300
2025-05-30 02:30:08,760 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:30:08,761 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:30:58,668 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.22, acc:   0.54, generation: 49.8638[sec], evaluation: 0.0000[sec]
2025-05-30 02:30:58,669 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:30:58,825 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/67000.ckpt
2025-05-30 02:30:58,846 - INFO - joeynmt.training - Example #0
2025-05-30 02:30:58,847 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:30:58,847 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:30:58,847 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 're@@', 'e@@', 'p', 'te', 'k@@', 'ij@@', 'ken', 'naar', 'de', 'ar@@', 'ct@@', 'ie@@', 've', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'die', 'voor', 'de', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 02:30:58,848 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:30:58,848 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:30:58,848 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te begreep te kijken naar de arctieve ijskapp die voor de drie miljoen jaar de grootte van de onderste 40 procent van de onderste 40 procent van 40 procent geslagen is.
2025-05-30 02:30:58,849 - INFO - joeynmt.training - Example #1
2025-05-30 02:30:58,849 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:30:58,849 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:30:58,849 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'op@@', 'er@@', 'st@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'pro@@', 'ble@@', 'em', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:30:58,850 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:30:58,850 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:30:58,851 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de operst, want het is niet de dikke probleem van het specifieke probleem laat zien.
2025-05-30 02:30:58,851 - INFO - joeynmt.training - Example #2
2025-05-30 02:30:58,851 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:30:58,851 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:30:58,851 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:30:58,852 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:30:58,852 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:30:58,852 - INFO - joeynmt.training - 	Hypothesis: In zekere ijskapp is de arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 02:30:58,853 - INFO - joeynmt.training - Example #3
2025-05-30 02:30:58,853 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:30:58,853 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:30:58,853 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:30:58,854 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:30:58,854 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:30:58,854 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen in de zomer.
2025-05-30 02:30:58,854 - INFO - joeynmt.training - Example #4
2025-05-30 02:30:58,855 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:30:58,855 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:30:58,855 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ver@@', 'ander@@', 'ing', 'van', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:30:58,856 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:30:58,856 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:30:58,856 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdsverandering van wat er in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurd is.
2025-05-30 02:31:07,874 - INFO - joeynmt.training - Epoch   7, Step:    69100, Batch Loss:     1.533733, Batch Acc: 0.573025, Tokens per Sec:     7643, Lr: 0.000300
2025-05-30 02:31:16,796 - INFO - joeynmt.training - Epoch   7, Step:    69200, Batch Loss:     1.238235, Batch Acc: 0.574779, Tokens per Sec:     8170, Lr: 0.000300
2025-05-30 02:31:25,751 - INFO - joeynmt.training - Epoch   7, Step:    69300, Batch Loss:     1.279136, Batch Acc: 0.574355, Tokens per Sec:     7784, Lr: 0.000300
2025-05-30 02:31:34,819 - INFO - joeynmt.training - Epoch   7, Step:    69400, Batch Loss:     1.251375, Batch Acc: 0.569727, Tokens per Sec:     8114, Lr: 0.000300
2025-05-30 02:31:43,768 - INFO - joeynmt.training - Epoch   7, Step:    69500, Batch Loss:     1.329099, Batch Acc: 0.570154, Tokens per Sec:     8115, Lr: 0.000300
2025-05-30 02:31:43,768 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:31:43,768 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:32:26,557 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.21, acc:   0.55, generation: 42.7499[sec], evaluation: 0.0000[sec]
2025-05-30 02:32:26,558 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:32:26,725 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/66500.ckpt
2025-05-30 02:32:26,739 - INFO - joeynmt.training - Example #0
2025-05-30 02:32:26,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:32:26,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:32:26,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 't', 'om', 'te', 'be@@', 'k@@', 'ijk@@', 'en,', 'om', 'te', 'be@@', 'se@@', 'ff@@', 'en', 'dat', 'de', 'ar@@', 'ct@@', 'ie@@', 've', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 't', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '8', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'ru@@', 'im@@', 'p@@', 't.', '</s>']
2025-05-30 02:32:26,743 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:32:26,743 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:32:26,744 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toont om te bekijken, om te beseffen dat de arctieve ijskappe ijskappe ijskappt die voor de grootte van de onderste 48 staten had 48 procent gesruimpt.
2025-05-30 02:32:26,744 - INFO - joeynmt.training - Example #1
2025-05-30 02:32:26,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:32:26,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:32:26,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'kan@@', 's', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'd@@', 'ie@@', 'p@@', 'g@@', 'aan@@', '.', '</s>']
2025-05-30 02:32:26,745 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:32:26,746 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:32:26,746 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste kans van dit specifieke probleem uit, omdat het specifieke probleem uit, omdat het niet de diepgaan.
2025-05-30 02:32:26,746 - INFO - joeynmt.training - Example #2
2025-05-30 02:32:26,746 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:32:26,746 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:32:26,746 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'ge@@', 'me@@', 'ensch@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:32:26,747 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:32:26,748 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:32:26,748 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de wereldwijde gemeenschappelijke ijskapp van ons wereldwijde klimaatsysteem.
2025-05-30 02:32:26,748 - INFO - joeynmt.training - Example #3
2025-05-30 02:32:26,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:32:26,749 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:32:26,749 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'z@@', 'ich', 'z@@', 'or@@', 'gen', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:32:26,749 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:32:26,750 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:32:26,750 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen in de zomer en zich zorgen in de zomer.
2025-05-30 02:32:26,750 - INFO - joeynmt.training - Example #4
2025-05-30 02:32:26,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:32:26,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:32:26,751 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'l@@', 'aat', 'zien', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:32:26,751 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:32:26,752 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:32:26,752 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdje laat zien wat er in de afgelopen 25 jaar gebeurd is.
2025-05-30 02:32:35,322 - INFO - joeynmt.training - Epoch   7, Step:    69600, Batch Loss:     1.123427, Batch Acc: 0.571238, Tokens per Sec:     8029, Lr: 0.000300
2025-05-30 02:32:44,155 - INFO - joeynmt.training - Epoch   7, Step:    69700, Batch Loss:     1.402309, Batch Acc: 0.579992, Tokens per Sec:     8157, Lr: 0.000300
2025-05-30 02:32:52,959 - INFO - joeynmt.training - Epoch   7, Step:    69800, Batch Loss:     1.413177, Batch Acc: 0.578303, Tokens per Sec:     8316, Lr: 0.000300
2025-05-30 02:33:01,778 - INFO - joeynmt.training - Epoch   7, Step:    69900, Batch Loss:     1.491510, Batch Acc: 0.573075, Tokens per Sec:     8069, Lr: 0.000300
2025-05-30 02:33:10,517 - INFO - joeynmt.training - Epoch   7, Step:    70000, Batch Loss:     1.420735, Batch Acc: 0.573469, Tokens per Sec:     8219, Lr: 0.000300
2025-05-30 02:33:10,518 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:33:10,518 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:33:53,322 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.22, acc:   0.55, generation: 42.7628[sec], evaluation: 0.0000[sec]
2025-05-30 02:33:53,500 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/66000.ckpt
2025-05-30 02:33:53,517 - INFO - joeynmt.training - Example #0
2025-05-30 02:33:53,518 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:33:53,518 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:33:53,518 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'p@@', 't', 'is.', '</s>']
2025-05-30 02:33:53,519 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:33:53,519 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:33:53,519 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen, om te beginnen, dat de arctische ijskappen, die voor de grootte van de grootte van de grootte van de grootte van 48 staten had om 40 procent te gedrapppt is.
2025-05-30 02:33:53,519 - INFO - joeynmt.training - Example #1
2025-05-30 02:33:53,520 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:33:53,520 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:33:53,520 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:33:53,521 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:33:53,521 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:33:53,521 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg genoeg de snelheid van dit specifieke probleem van het ijs van het ijs van het ijs laat zien.
2025-05-30 02:33:53,521 - INFO - joeynmt.training - Example #2
2025-05-30 02:33:53,522 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:33:53,522 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:33:53,522 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en.', '</s>']
2025-05-30 02:33:53,523 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:33:53,523 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:33:53,523 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe ijskappe ijskappen.
2025-05-30 02:33:53,523 - INFO - joeynmt.training - Example #3
2025-05-30 02:33:53,524 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:33:53,524 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:33:53,524 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:33:53,525 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:33:53,525 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:33:53,525 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich in de zomer in de zomer.
2025-05-30 02:33:53,525 - INFO - joeynmt.training - Example #4
2025-05-30 02:33:53,525 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:33:53,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:33:53,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'b@@', 'o@@', 'ei@@', 'ende', 'tij@@', 'd@@', 'per@@', 'k', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 02:33:53,526 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:33:53,527 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:33:53,527 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een boeiende tijdperk in de afgelopen 25 jaar is.
2025-05-30 02:34:02,633 - INFO - joeynmt.training - Epoch   7, Step:    70100, Batch Loss:     1.362652, Batch Acc: 0.575664, Tokens per Sec:     7724, Lr: 0.000300
2025-05-30 02:34:11,424 - INFO - joeynmt.training - Epoch   7, Step:    70200, Batch Loss:     1.189022, Batch Acc: 0.576026, Tokens per Sec:     8074, Lr: 0.000300
2025-05-30 02:34:20,236 - INFO - joeynmt.training - Epoch   7, Step:    70300, Batch Loss:     1.269927, Batch Acc: 0.570959, Tokens per Sec:     8122, Lr: 0.000300
2025-05-30 02:34:28,659 - INFO - joeynmt.training - Epoch   7, Step:    70400, Batch Loss:     1.325655, Batch Acc: 0.574062, Tokens per Sec:     8659, Lr: 0.000300
2025-05-30 02:34:37,386 - INFO - joeynmt.training - Epoch   7, Step:    70500, Batch Loss:     1.250087, Batch Acc: 0.576569, Tokens per Sec:     8162, Lr: 0.000300
2025-05-30 02:34:37,387 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:34:37,387 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:35:26,118 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.22, acc:   0.55, generation: 48.6841[sec], evaluation: 0.0000[sec]
2025-05-30 02:35:26,293 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/67500.ckpt
2025-05-30 02:35:26,318 - INFO - joeynmt.training - Example #0
2025-05-30 02:35:26,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:35:26,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:35:26,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'sch@@', 'aal', 'van', 'de', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'k@@', 'rij@@', 'gen.', '</s>']
2025-05-30 02:35:26,320 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:35:26,320 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:35:26,320 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te beginnen te bekijken dat de arctische ijskappen die voor de schaal van de drie miljoen jaar de grootte van de onderste 40 procent staten om 40 procent te geslagen om 40 procent te krijgen.
2025-05-30 02:35:26,320 - INFO - joeynmt.training - Example #1
2025-05-30 02:35:26,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:35:26,321 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:35:26,321 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 're@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ingen', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'er', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 't.', '</s>']
2025-05-30 02:35:26,322 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:35:26,322 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:35:26,322 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de rest van dit specifieke probleem uit, want het is niet de dikke dingen van het ijskracht van het ijsker van het ijskracht.
2025-05-30 02:35:26,322 - INFO - joeynmt.training - Example #2
2025-05-30 02:35:26,322 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:35:26,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:35:26,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'k@@', 'ne@@', 'mer@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:35:26,323 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:35:26,324 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:35:26,324 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe hart van ons werknemersysteem.
2025-05-30 02:35:26,324 - INFO - joeynmt.training - Example #3
2025-05-30 02:35:26,324 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:35:26,324 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:35:26,324 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:35:26,324 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:35:26,325 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:35:26,325 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen in de zomer.
2025-05-30 02:35:26,325 - INFO - joeynmt.training - Example #4
2025-05-30 02:35:26,325 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:35:26,325 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:35:26,325 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ver@@', 'b@@', 'and', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:35:26,325 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:35:26,326 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:35:26,326 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een tijdsverband wat er in de laatste 25 jaar gebeurd is.
2025-05-30 02:35:35,048 - INFO - joeynmt.training - Epoch   7, Step:    70600, Batch Loss:     1.286682, Batch Acc: 0.575157, Tokens per Sec:     8186, Lr: 0.000300
2025-05-30 02:35:43,782 - INFO - joeynmt.training - Epoch   7, Step:    70700, Batch Loss:     1.184009, Batch Acc: 0.575494, Tokens per Sec:     8273, Lr: 0.000300
2025-05-30 02:35:52,518 - INFO - joeynmt.training - Epoch   7, Step:    70800, Batch Loss:     1.245759, Batch Acc: 0.572492, Tokens per Sec:     8287, Lr: 0.000300
2025-05-30 02:36:01,287 - INFO - joeynmt.training - Epoch   7, Step:    70900, Batch Loss:     1.422511, Batch Acc: 0.574678, Tokens per Sec:     8484, Lr: 0.000300
2025-05-30 02:36:10,022 - INFO - joeynmt.training - Epoch   7, Step:    71000, Batch Loss:     1.178248, Batch Acc: 0.572065, Tokens per Sec:     8278, Lr: 0.000300
2025-05-30 02:36:10,023 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:36:10,023 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:36:50,964 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.21, acc:   0.54, generation: 40.9027[sec], evaluation: 0.0000[sec]
2025-05-30 02:36:50,965 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:36:51,133 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/68500.ckpt
2025-05-30 02:36:51,149 - INFO - joeynmt.training - Example #0
2025-05-30 02:36:51,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:36:51,150 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:36:51,150 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'to@@', 'on@@', 'de', 'dit', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'sch@@', 'aal', 'ge@@', 'zi@@', 'en,', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'be@@', 'ste@@', 'm@@', 'm@@', 'ing', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'st@@', 'aten', 'ha@@', 'd@@', 'den', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'ru@@', 'p@@', 'p@@', 'el@@', 'd.', '</s>']
2025-05-30 02:36:51,151 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:36:51,151 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:36:51,151 - INFO - joeynmt.training - 	Hypothesis: Ik toonde dit jaar heb ik deze twee dia getoond om te beginnen, dat de arctische ijskappen die voor de schaal gezien, om 40 procent te bestemming van de onderste 40 procent staten hadden om 40 procent te gesruppeld.
2025-05-30 02:36:51,152 - INFO - joeynmt.training - Example #1
2025-05-30 02:36:51,152 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:36:51,152 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:36:51,152 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'un@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ingen', 'van', 'het', 'ij@@', 's@@', 'en.', '</s>']
2025-05-30 02:36:51,153 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:36:51,153 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:36:51,153 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de eerste punt van dit specifieke probleem uit, omdat het niet de dikke dingen van het ijsen.
2025-05-30 02:36:51,154 - INFO - joeynmt.training - Example #2
2025-05-30 02:36:51,154 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:36:51,154 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:36:51,154 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', ',', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:36:51,155 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:36:51,155 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:36:51,155 - INFO - joeynmt.training - 	Hypothesis: In zekere zin, is de arctische ijskappen het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 02:36:51,155 - INFO - joeynmt.training - Example #3
2025-05-30 02:36:51,156 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:36:51,156 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:36:51,156 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'or@@', 'g@@', 'aan@@', '.', '</s>']
2025-05-30 02:36:51,158 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:36:51,158 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:36:51,158 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich zorgaan.
2025-05-30 02:36:51,158 - INFO - joeynmt.training - Example #4
2025-05-30 02:36:51,158 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:36:51,158 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:36:51,158 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 'te@@', 'er@@', 'de', 'dat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 02:36:51,159 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:36:51,159 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:36:51,160 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrapporteerde dat er in de laatste 25 jaar is.
2025-05-30 02:36:59,878 - INFO - joeynmt.training - Epoch   7, Step:    71100, Batch Loss:     1.366029, Batch Acc: 0.575000, Tokens per Sec:     8095, Lr: 0.000300
2025-05-30 02:37:08,215 - INFO - joeynmt.training - Epoch   7, Step:    71200, Batch Loss:     1.138764, Batch Acc: 0.572782, Tokens per Sec:     8535, Lr: 0.000300
2025-05-30 02:37:16,401 - INFO - joeynmt.training - Epoch   7, Step:    71300, Batch Loss:     1.238431, Batch Acc: 0.572508, Tokens per Sec:     8977, Lr: 0.000300
2025-05-30 02:37:24,076 - INFO - joeynmt.training - Epoch   7, Step:    71400, Batch Loss:     1.161527, Batch Acc: 0.572164, Tokens per Sec:     9392, Lr: 0.000300
2025-05-30 02:37:31,548 - INFO - joeynmt.training - Epoch   7, Step:    71500, Batch Loss:     1.257632, Batch Acc: 0.572037, Tokens per Sec:     9616, Lr: 0.000300
2025-05-30 02:37:31,548 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:37:31,549 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:38:18,085 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.20, acc:   0.54, generation: 46.4915[sec], evaluation: 0.0000[sec]
2025-05-30 02:38:18,086 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:38:18,248 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/69000.ckpt
2025-05-30 02:38:18,260 - INFO - joeynmt.training - Example #0
2025-05-30 02:38:18,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:38:18,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:38:18,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'z@@', 'or@@', 'gen', 'voor', '4@@', '8', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'lo@@', 'ten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'ven', 'is.', '</s>']
2025-05-30 02:38:18,262 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:38:18,262 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:38:18,262 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen, dat de arctische ijskappen die voor de onderkant van de onderkant van de onderkant van de onderkant van 48 staten om 48 staten om 48 procent te gezorgen voor 48 procent te geslagen van 40 procent gesloten om 40 procent te geven is.
2025-05-30 02:38:18,262 - INFO - joeynmt.training - Example #1
2025-05-30 02:38:18,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:38:18,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:38:18,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'er@@', 'g', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:38:18,263 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:38:18,263 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:38:18,263 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet erg genoeg genoeg de eerste van dit specifieke probleem uit, want het is niet de dik van het ijs van het ijs van het ijs van het ijs van het ijs laat zien.
2025-05-30 02:38:18,264 - INFO - joeynmt.training - Example #2
2025-05-30 02:38:18,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:38:18,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:38:18,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:38:18,264 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:38:18,264 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:38:18,265 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijs het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 02:38:18,265 - INFO - joeynmt.training - Example #3
2025-05-30 02:38:18,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:38:18,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:38:18,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:38:18,266 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:38:18,266 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:38:18,266 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schept in de zomer.
2025-05-30 02:38:18,266 - INFO - joeynmt.training - Example #4
2025-05-30 02:38:18,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:38:18,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:38:18,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ge@@', 'ven', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:38:18,269 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:38:18,269 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:38:18,269 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsgeven wat er in de laatste 25 jaar gebeurd.
2025-05-30 02:38:27,178 - INFO - joeynmt.training - Epoch   7, Step:    71600, Batch Loss:     1.349039, Batch Acc: 0.568779, Tokens per Sec:     8022, Lr: 0.000300
2025-05-30 02:38:35,905 - INFO - joeynmt.training - Epoch   7, Step:    71700, Batch Loss:     1.507207, Batch Acc: 0.574118, Tokens per Sec:     8153, Lr: 0.000300
2025-05-30 02:38:44,738 - INFO - joeynmt.training - Epoch   7, Step:    71800, Batch Loss:     1.334412, Batch Acc: 0.573617, Tokens per Sec:     8245, Lr: 0.000300
2025-05-30 02:38:53,413 - INFO - joeynmt.training - Epoch   7, Step:    71900, Batch Loss:     1.137376, Batch Acc: 0.579130, Tokens per Sec:     8134, Lr: 0.000300
2025-05-30 02:39:02,239 - INFO - joeynmt.training - Epoch   7, Step:    72000, Batch Loss:     1.179534, Batch Acc: 0.570221, Tokens per Sec:     8179, Lr: 0.000300
2025-05-30 02:39:02,241 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:39:02,241 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:39:43,912 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.20, acc:   0.55, generation: 41.6318[sec], evaluation: 0.0000[sec]
2025-05-30 02:39:44,069 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/70000.ckpt
2025-05-30 02:39:44,084 - INFO - joeynmt.training - Example #0
2025-05-30 02:39:44,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:39:44,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:39:44,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'die', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'at@@', 'u@@', 'ur', 'die', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 02:39:44,086 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:39:44,086 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:39:44,086 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee dia's die arctische ijskappe ijskappe ijskapparatuur die de grootte van de onderste 40 procent van de onderste 40 procent geslagen om 40 procent te geslagen is.
2025-05-30 02:39:44,087 - INFO - joeynmt.training - Example #1
2025-05-30 02:39:44,087 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:39:44,087 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:39:44,087 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'z@@', 'er@@', 's.', '</s>']
2025-05-30 02:39:44,088 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:39:44,088 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:39:44,088 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van het specifieke probleem uit, omdat het niet de dikke dikke van het ijzers.
2025-05-30 02:39:44,088 - INFO - joeynmt.training - Example #2
2025-05-30 02:39:44,089 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:39:44,089 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:39:44,089 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:39:44,090 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:39:44,090 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:39:44,090 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijt van ons wereldwijde klimaatsysteem.
2025-05-30 02:39:44,090 - INFO - joeynmt.training - Example #3
2025-05-30 02:39:44,090 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:39:44,090 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:39:44,091 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 02:39:44,091 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:39:44,091 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:39:44,092 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich in de zomers.
2025-05-30 02:39:44,092 - INFO - joeynmt.training - Example #4
2025-05-30 02:39:44,092 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:39:44,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:39:44,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ver@@', 'b@@', 'on@@', 'den', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:39:44,093 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:39:44,093 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:39:44,093 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laten zien, is een tijdsverbonden wat er in de afgelopen 25 jaar is gebeurd.
2025-05-30 02:39:52,826 - INFO - joeynmt.training - Epoch   7, Step:    72100, Batch Loss:     1.181742, Batch Acc: 0.571350, Tokens per Sec:     8173, Lr: 0.000300
2025-05-30 02:40:01,470 - INFO - joeynmt.training - Epoch   7, Step:    72200, Batch Loss:     1.365603, Batch Acc: 0.573423, Tokens per Sec:     8270, Lr: 0.000300
2025-05-30 02:40:10,740 - INFO - joeynmt.training - Epoch   7, Step:    72300, Batch Loss:     1.221940, Batch Acc: 0.572372, Tokens per Sec:     7963, Lr: 0.000300
2025-05-30 02:40:19,692 - INFO - joeynmt.training - Epoch   7, Step:    72400, Batch Loss:     1.428224, Batch Acc: 0.573252, Tokens per Sec:     8358, Lr: 0.000300
2025-05-30 02:40:28,752 - INFO - joeynmt.training - Epoch   7, Step:    72500, Batch Loss:     1.306976, Batch Acc: 0.568156, Tokens per Sec:     7947, Lr: 0.000300
2025-05-30 02:40:28,752 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:40:28,753 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:41:10,135 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.18, acc:   0.55, generation: 41.3452[sec], evaluation: 0.0000[sec]
2025-05-30 02:41:10,136 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:41:10,299 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/70500.ckpt
2025-05-30 02:41:10,318 - INFO - joeynmt.training - Example #0
2025-05-30 02:41:10,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:41:10,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:41:10,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'jaar', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'd@@', 'ing', 'te', 'l@@', 'aten', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'st@@', 'el@@', 'd.', '</s>']
2025-05-30 02:41:10,320 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:41:10,320 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:41:10,321 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee jaar getoond om te verbeelding te laten zien dat de arctische ijskappen, die voor de grootte van de onderste 48 staten had om 40 procent staten had gesteld.
2025-05-30 02:41:10,321 - INFO - joeynmt.training - Example #1
2025-05-30 02:41:10,321 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:41:10,321 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:41:10,321 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'is', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:41:10,322 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:41:10,322 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:41:10,322 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet sterk genoeg de eerste van het specifieke probleem uit, want het is niet de dikke ijsis van het ijs laat zien.
2025-05-30 02:41:10,323 - INFO - joeynmt.training - Example #2
2025-05-30 02:41:10,323 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:41:10,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:41:10,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ij', 'is', 'het', 's@@', 'la@@', 'gen', 'van', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:41:10,324 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:41:10,324 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:41:10,324 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe ijskappij is het slagen van klimaatsysteem.
2025-05-30 02:41:10,324 - INFO - joeynmt.training - Example #3
2025-05-30 02:41:10,325 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:41:10,325 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:41:10,325 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 02:41:10,326 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:41:10,326 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:41:10,326 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomers.
2025-05-30 02:41:10,326 - INFO - joeynmt.training - Example #4
2025-05-30 02:41:10,326 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:41:10,327 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:41:10,327 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ver@@', 'b@@', 'and', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:41:10,328 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:41:10,328 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:41:10,328 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdsverband wat er gebeurd in de laatste 25 jaar gebeurd is.
2025-05-30 02:41:19,209 - INFO - joeynmt.training - Epoch   7, Step:    72600, Batch Loss:     1.363751, Batch Acc: 0.571142, Tokens per Sec:     7806, Lr: 0.000300
2025-05-30 02:41:28,123 - INFO - joeynmt.training - Epoch   7, Step:    72700, Batch Loss:     1.331643, Batch Acc: 0.570431, Tokens per Sec:     8033, Lr: 0.000300
2025-05-30 02:41:36,804 - INFO - joeynmt.training - Epoch   7, Step:    72800, Batch Loss:     1.353855, Batch Acc: 0.574656, Tokens per Sec:     8256, Lr: 0.000300
2025-05-30 02:41:45,498 - INFO - joeynmt.training - Epoch   7, Step:    72900, Batch Loss:     1.231833, Batch Acc: 0.570171, Tokens per Sec:     8505, Lr: 0.000300
2025-05-30 02:41:54,144 - INFO - joeynmt.training - Epoch   7, Step:    73000, Batch Loss:     1.211815, Batch Acc: 0.576710, Tokens per Sec:     8339, Lr: 0.000300
2025-05-30 02:41:54,144 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:41:54,145 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:42:38,084 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.18, acc:   0.55, generation: 43.9069[sec], evaluation: 0.0000[sec]
2025-05-30 02:42:38,085 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:42:38,240 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/69500.ckpt
2025-05-30 02:42:38,257 - INFO - joeynmt.training - Example #0
2025-05-30 02:42:38,257 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:42:38,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:42:38,258 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 're@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'm@@', 'p@@', 't', 'te', 'ge@@', 's@@', 'lo@@', 'ten', 'in', 'de', 'b@@', 'as@@', 'is', 'van', 'de', 'v@@', 'ier@@', 'en.', '</s>']
2025-05-30 02:42:38,258 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:42:38,259 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:42:38,259 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te begrepen dat de arctische ijskappe ijskappe ijskappe drie miljoen jaar de grootte van de onderste 40 procent geslagen om 40 procent geslagen om 40 procent gesmpt te gesloten in de basis van de vieren.
2025-05-30 02:42:38,259 - INFO - joeynmt.training - Example #1
2025-05-30 02:42:38,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:42:38,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:42:38,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'deze', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em@@', ',', 'om@@', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em@@', '.', '</s>']
2025-05-30 02:42:38,260 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:42:38,260 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:42:38,261 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van deze specifieke probleem, omdat het speciale probleem.
2025-05-30 02:42:38,261 - INFO - joeynmt.training - Example #2
2025-05-30 02:42:38,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:42:38,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:42:38,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'm@@', 'on@@', 'di@@', 'ale', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:42:38,262 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:42:38,262 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:42:38,262 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijskape ijskape hart van onze mondiale klimaatsysteem.
2025-05-30 02:42:38,262 - INFO - joeynmt.training - Example #3
2025-05-30 02:42:38,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:42:38,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:42:38,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:42:38,263 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:42:38,263 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:42:38,263 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schrompt in de zomer.
2025-05-30 02:42:38,265 - INFO - joeynmt.training - Example #4
2025-05-30 02:42:38,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:42:38,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:42:38,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'at@@', 'h@@', 'ie@@', 'f', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:42:38,266 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:42:38,266 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:42:38,266 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een tijdrappathief wat er in de laatste 25 jaar gebeurd is.
2025-05-30 02:42:46,053 - INFO - joeynmt.training - Epoch   7, Step:    73100, Batch Loss:     1.184288, Batch Acc: 0.573754, Tokens per Sec:     9335, Lr: 0.000300
2025-05-30 02:42:54,066 - INFO - joeynmt.training - Epoch   7, Step:    73200, Batch Loss:     1.467036, Batch Acc: 0.574007, Tokens per Sec:     9171, Lr: 0.000300
2025-05-30 02:43:02,574 - INFO - joeynmt.training - Epoch   7, Step:    73300, Batch Loss:     1.413471, Batch Acc: 0.575319, Tokens per Sec:     8655, Lr: 0.000300
2025-05-30 02:43:11,850 - INFO - joeynmt.training - Epoch   7, Step:    73400, Batch Loss:     1.338474, Batch Acc: 0.565911, Tokens per Sec:     7742, Lr: 0.000300
2025-05-30 02:43:21,272 - INFO - joeynmt.training - Epoch   7, Step:    73500, Batch Loss:     1.286744, Batch Acc: 0.572759, Tokens per Sec:     7522, Lr: 0.000300
2025-05-30 02:43:21,273 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:43:21,273 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:44:18,431 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.19, acc:   0.55, generation: 57.1064[sec], evaluation: 0.0000[sec]
2025-05-30 02:44:18,624 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/71000.ckpt
2025-05-30 02:44:18,642 - INFO - joeynmt.training - Example #0
2025-05-30 02:44:18,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:44:18,643 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:44:18,643 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 're@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'ge@@', 'st@@', 'eld', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 02:44:18,644 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:44:18,645 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:44:18,645 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te begrepen dat de arctische ijskappen die voor de arctische ijskappen die voor de onderste 48 staten had om 48 staten had gegesteld om 40 procent te gebeuren.
2025-05-30 02:44:18,645 - INFO - joeynmt.training - Example #1
2025-05-30 02:44:18,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:44:18,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:44:18,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 're@@', 's@@', 'ul@@', 't@@', 'aat', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's@@', 'en.', '</s>']
2025-05-30 02:44:18,646 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:44:18,647 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:44:18,647 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de resultaat van dit specifieke probleem uit, want het is niet de dikke dik van het ijs van het ijs van het ijs van het ijsen.
2025-05-30 02:44:18,647 - INFO - joeynmt.training - Example #2
2025-05-30 02:44:18,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:44:18,647 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:44:18,649 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:44:18,649 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:44:18,649 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:44:18,649 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappen het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 02:44:18,649 - INFO - joeynmt.training - Example #3
2025-05-30 02:44:18,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:44:18,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:44:18,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'g@@', ',', 'en', 'z@@', 'or@@', 'g@@', ',', 'en', 'z@@', 'or@@', 'g@@', 'aan@@', '.', '</s>']
2025-05-30 02:44:18,651 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:44:18,651 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:44:18,651 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in winter en zorg, en zorg, en zorgaan.
2025-05-30 02:44:18,652 - INFO - joeynmt.training - Example #4
2025-05-30 02:44:18,652 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:44:18,652 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:44:18,652 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ge@@', 'ven', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 02:44:18,653 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:44:18,653 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:44:18,654 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsgeven in de laatste 25 jaar.
2025-05-30 02:44:28,714 - INFO - joeynmt.training - Epoch   7, Step:    73600, Batch Loss:     1.344572, Batch Acc: 0.570968, Tokens per Sec:     7036, Lr: 0.000300
2025-05-30 02:44:38,198 - INFO - joeynmt.training - Epoch   7, Step:    73700, Batch Loss:     1.472996, Batch Acc: 0.569783, Tokens per Sec:     7733, Lr: 0.000300
2025-05-30 02:44:47,706 - INFO - joeynmt.training - Epoch   7, Step:    73800, Batch Loss:     1.340758, Batch Acc: 0.576078, Tokens per Sec:     7754, Lr: 0.000300
2025-05-30 02:44:56,996 - INFO - joeynmt.training - Epoch   7, Step:    73900, Batch Loss:     1.259557, Batch Acc: 0.574854, Tokens per Sec:     7647, Lr: 0.000300
2025-05-30 02:45:06,203 - INFO - joeynmt.training - Epoch   7, Step:    74000, Batch Loss:     1.314431, Batch Acc: 0.576665, Tokens per Sec:     7882, Lr: 0.000300
2025-05-30 02:45:06,205 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:45:06,205 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:45:55,716 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.18, acc:   0.55, generation: 49.4675[sec], evaluation: 0.0000[sec]
2025-05-30 02:45:55,891 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/72000.ckpt
2025-05-30 02:45:55,908 - INFO - joeynmt.training - Example #0
2025-05-30 02:45:55,909 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:45:55,909 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:45:55,909 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ijk@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'ste', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ge@@', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:45:55,910 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:45:55,910 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:45:55,910 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te bekijken, dat de arctische ijskappen die voor de onderste drie miljoen jaar de grootste van de onderste 48 staten gegebeurd.
2025-05-30 02:45:55,910 - INFO - joeynmt.training - Example #1
2025-05-30 02:45:55,911 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:45:55,911 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:45:55,911 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em@@', '.', '</s>']
2025-05-30 02:45:55,912 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:45:55,912 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:45:55,912 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet genoeg genoeg de eerste van dit specifieke probleem dat het speciale probleem.
2025-05-30 02:45:55,912 - INFO - joeynmt.training - Example #2
2025-05-30 02:45:55,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:45:55,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:45:55,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:45:55,914 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:45:55,914 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:45:55,914 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijskape hart van ons wereldwijd klimaatsysteem.
2025-05-30 02:45:55,914 - INFO - joeynmt.training - Example #3
2025-05-30 02:45:55,915 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:45:55,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:45:55,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:45:55,917 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:45:55,917 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:45:55,917 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zrompt in de zomer.
2025-05-30 02:45:55,917 - INFO - joeynmt.training - Example #4
2025-05-30 02:45:55,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:45:55,918 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:45:55,918 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'ar@@', 'tij@@', 'en', 'is', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:45:55,919 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:45:55,919 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:45:55,919 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrappartijen is gebeurd in de afgelopen 25 jaar gebeurd.
2025-05-30 02:46:05,286 - INFO - joeynmt.training - Epoch   7, Step:    74100, Batch Loss:     1.376950, Batch Acc: 0.575828, Tokens per Sec:     7466, Lr: 0.000300
2025-05-30 02:46:14,634 - INFO - joeynmt.training - Epoch   7, Step:    74200, Batch Loss:     1.270861, Batch Acc: 0.568343, Tokens per Sec:     7798, Lr: 0.000300
2025-05-30 02:46:19,051 - INFO - joeynmt.training - Epoch   7: total training loss 14157.55
2025-05-30 02:46:19,052 - INFO - joeynmt.training - EPOCH 8
2025-05-30 02:46:24,076 - INFO - joeynmt.training - Epoch   8, Step:    74300, Batch Loss:     1.244573, Batch Acc: 0.583953, Tokens per Sec:     7501, Lr: 0.000300
2025-05-30 02:46:33,559 - INFO - joeynmt.training - Epoch   8, Step:    74400, Batch Loss:     1.360644, Batch Acc: 0.585088, Tokens per Sec:     7625, Lr: 0.000300
2025-05-30 02:46:42,928 - INFO - joeynmt.training - Epoch   8, Step:    74500, Batch Loss:     1.311795, Batch Acc: 0.578366, Tokens per Sec:     7632, Lr: 0.000300
2025-05-30 02:46:42,928 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:46:42,929 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:47:38,561 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.19, acc:   0.55, generation: 55.5843[sec], evaluation: 0.0000[sec]
2025-05-30 02:47:38,737 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/71500.ckpt
2025-05-30 02:47:38,751 - INFO - joeynmt.training - Example #0
2025-05-30 02:47:38,752 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:47:38,752 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:47:38,752 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e,', 'die', 'voor', 'de', 'sch@@', 'aal@@', ',', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 02:47:38,753 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:47:38,754 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:47:38,754 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde om te bekijken dat de arctische ijskape, die voor de schaal, die voor de grootte van de onderste 48 staten had om 48 staten gebeuren.
2025-05-30 02:47:38,754 - INFO - joeynmt.training - Example #1
2025-05-30 02:47:38,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:47:38,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:47:38,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'h@@', 'aa@@', 'k@@', ',', 'dat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's@@', 'le@@', 'ch@@', 'ts', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 't.', '</s>']
2025-05-30 02:47:38,755 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:47:38,756 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:47:38,756 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de eerste haak, dat het niet de dik van het ijslechts van de ijskracht van de ijskracht van de ijskracht van de ijskracht van de ijskracht van de ijskracht.
2025-05-30 02:47:38,756 - INFO - joeynmt.training - Example #2
2025-05-30 02:47:38,756 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:47:38,756 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:47:38,756 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:47:38,757 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:47:38,757 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:47:38,757 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijskape ijskape hart van onze wereldwijd klimaatsysteem.
2025-05-30 02:47:38,758 - INFO - joeynmt.training - Example #3
2025-05-30 02:47:38,758 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:47:38,758 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:47:38,758 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'en', 'z@@', 'or@@', 'gen.', '</s>']
2025-05-30 02:47:38,760 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:47:38,760 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:47:38,760 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen en zorgen.
2025-05-30 02:47:38,760 - INFO - joeynmt.training - Example #4
2025-05-30 02:47:38,760 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:47:38,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:47:38,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'er', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:47:38,762 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:47:38,762 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:47:38,762 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrapper 25 jaar gebeurd in de laatste 25 jaar gebeurd.
2025-05-30 02:47:48,136 - INFO - joeynmt.training - Epoch   8, Step:    74600, Batch Loss:     1.235446, Batch Acc: 0.586490, Tokens per Sec:     7683, Lr: 0.000300
2025-05-30 02:47:57,433 - INFO - joeynmt.training - Epoch   8, Step:    74700, Batch Loss:     1.207363, Batch Acc: 0.579071, Tokens per Sec:     7758, Lr: 0.000300
2025-05-30 02:48:06,724 - INFO - joeynmt.training - Epoch   8, Step:    74800, Batch Loss:     1.240895, Batch Acc: 0.582238, Tokens per Sec:     7476, Lr: 0.000300
2025-05-30 02:48:15,292 - INFO - joeynmt.training - Epoch   8, Step:    74900, Batch Loss:     1.494524, Batch Acc: 0.582710, Tokens per Sec:     8096, Lr: 0.000300
2025-05-30 02:48:23,490 - INFO - joeynmt.training - Epoch   8, Step:    75000, Batch Loss:     1.211314, Batch Acc: 0.585743, Tokens per Sec:     8712, Lr: 0.000300
2025-05-30 02:48:23,491 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:48:23,491 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:49:02,079 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.19, acc:   0.55, generation: 38.5449[sec], evaluation: 0.0000[sec]
2025-05-30 02:49:02,271 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/74500.ckpt
2025-05-30 02:49:02,282 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit_bpe_smallvoc/74500.ckpt
2025-05-30 02:49:02,283 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe_smallvoc\74500.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit_bpe_smallvoc\\74500.ckpt')
2025-05-30 02:49:02,288 - INFO - joeynmt.training - Example #0
2025-05-30 02:49:02,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:49:02,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:49:02,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'l@@', 'aat', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'sch@@', 'aal', 'van', 'de', 'onder@@', 'z@@', 'oe@@', 'k', 'die', 'voor', 'de', 'onder@@', 'ste', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'st@@', 'ar@@', 't', 'was', 'om', '4@@', '8', 'st@@', 'aten', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 02:49:02,290 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:49:02,291 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:49:02,291 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's laat zien dat de arctische ijskappen die voor de schaal van de onderzoek die voor de onderste van de onderste 48 staten had gestart was om 48 staten gebeuren.
2025-05-30 02:49:02,291 - INFO - joeynmt.training - Example #1
2025-05-30 02:49:02,291 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:49:02,291 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:49:02,291 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'gen@@', 'oe@@', 'g', 'de', 're@@', 's@@', 'ul@@', 't@@', 'aat', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ie@@', 'p@@', 'e', 'pro@@', 'ble@@', 'em@@', '.', '</s>']
2025-05-30 02:49:02,292 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:49:02,293 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:49:02,293 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet genoeg de resultaat van dit specifieke probleem dat het niet de dikke diepe probleem.
2025-05-30 02:49:02,293 - INFO - joeynmt.training - Example #2
2025-05-30 02:49:02,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:49:02,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:49:02,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'ig@@', 'l@@', 'ijke', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:49:02,294 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:49:02,295 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:49:02,295 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuiglijke ijskape ijskape ijskappe hart van onze wereldwijde klimaatsysteem.
2025-05-30 02:49:02,295 - INFO - joeynmt.training - Example #3
2025-05-30 02:49:02,295 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:49:02,295 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:49:02,295 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:49:02,296 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:49:02,296 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:49:02,296 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen in de zomer.
2025-05-30 02:49:02,297 - INFO - joeynmt.training - Example #4
2025-05-30 02:49:02,297 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:49:02,297 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:49:02,297 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:49:02,298 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:49:02,298 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:49:02,298 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdperk van wat er in de laatste 25 jaar gebeurd.
2025-05-30 02:49:11,730 - INFO - joeynmt.training - Epoch   8, Step:    75100, Batch Loss:     1.417126, Batch Acc: 0.579972, Tokens per Sec:     7464, Lr: 0.000300
2025-05-30 02:49:21,071 - INFO - joeynmt.training - Epoch   8, Step:    75200, Batch Loss:     1.225333, Batch Acc: 0.586878, Tokens per Sec:     7782, Lr: 0.000300
2025-05-30 02:49:30,510 - INFO - joeynmt.training - Epoch   8, Step:    75300, Batch Loss:     1.389070, Batch Acc: 0.578466, Tokens per Sec:     7716, Lr: 0.000300
2025-05-30 02:49:39,745 - INFO - joeynmt.training - Epoch   8, Step:    75400, Batch Loss:     1.263872, Batch Acc: 0.586370, Tokens per Sec:     7479, Lr: 0.000300
2025-05-30 02:49:49,151 - INFO - joeynmt.training - Epoch   8, Step:    75500, Batch Loss:     1.194005, Batch Acc: 0.578250, Tokens per Sec:     7628, Lr: 0.000300
2025-05-30 02:49:49,151 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:49:49,151 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:50:39,033 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.21, acc:   0.55, generation: 49.8389[sec], evaluation: 0.0000[sec]
2025-05-30 02:50:39,040 - INFO - joeynmt.training - Example #0
2025-05-30 02:50:39,041 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:50:39,041 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:50:39,041 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'to@@', 'on@@', 'de', 'ik', 'to@@', 'on@@', 'de', 'om', 'te', 'be@@', 'se@@', 'ff@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'ge@@', 'ven', 'te', 'ge@@', 'ven', 'is.', '</s>']
2025-05-30 02:50:39,042 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:50:39,045 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:50:39,045 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's toonde ik toonde om te beseffen dat de arctische ijskappen die voor de onderste 48 staten had drie miljoen jaar de grootte van 48 staten om 48 staten geven te geven is.
2025-05-30 02:50:39,045 - INFO - joeynmt.training - Example #1
2025-05-30 02:50:39,046 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:50:39,046 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:50:39,046 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:50:39,047 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:50:39,047 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:50:39,047 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de snelheid van dit specifieke probleem dat het specifieke probleem laat zien.
2025-05-30 02:50:39,047 - INFO - joeynmt.training - Example #2
2025-05-30 02:50:39,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:50:39,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:50:39,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en.', '</s>']
2025-05-30 02:50:39,049 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:50:39,049 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:50:39,049 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe ijskappe ijskappen.
2025-05-30 02:50:39,049 - INFO - joeynmt.training - Example #3
2025-05-30 02:50:39,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:50:39,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:50:39,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:50:39,053 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:50:39,053 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:50:39,053 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen in de winter en zomer.
2025-05-30 02:50:39,053 - INFO - joeynmt.training - Example #4
2025-05-30 02:50:39,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:50:39,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:50:39,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 't@@', 'ige', 'dat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 02:50:39,055 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:50:39,055 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:50:39,055 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tijdrapportige dat er in de laatste 25 jaar.
2025-05-30 02:50:48,434 - INFO - joeynmt.training - Epoch   8, Step:    75600, Batch Loss:     1.165210, Batch Acc: 0.580304, Tokens per Sec:     7570, Lr: 0.000300
2025-05-30 02:50:57,635 - INFO - joeynmt.training - Epoch   8, Step:    75700, Batch Loss:     1.324659, Batch Acc: 0.582657, Tokens per Sec:     7798, Lr: 0.000300
2025-05-30 02:51:06,720 - INFO - joeynmt.training - Epoch   8, Step:    75800, Batch Loss:     1.322434, Batch Acc: 0.579359, Tokens per Sec:     7650, Lr: 0.000300
2025-05-30 02:51:15,912 - INFO - joeynmt.training - Epoch   8, Step:    75900, Batch Loss:     1.362515, Batch Acc: 0.579126, Tokens per Sec:     7739, Lr: 0.000300
2025-05-30 02:51:24,960 - INFO - joeynmt.training - Epoch   8, Step:    76000, Batch Loss:     1.254163, Batch Acc: 0.578247, Tokens per Sec:     8062, Lr: 0.000300
2025-05-30 02:51:24,961 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:51:24,961 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:52:12,997 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.18, acc:   0.55, generation: 47.9900[sec], evaluation: 0.0000[sec]
2025-05-30 02:52:13,168 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/75000.ckpt
2025-05-30 02:52:13,180 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit_bpe_smallvoc/75000.ckpt
2025-05-30 02:52:13,181 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe_smallvoc\75000.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit_bpe_smallvoc\\75000.ckpt')
2025-05-30 02:52:13,186 - INFO - joeynmt.training - Example #0
2025-05-30 02:52:13,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:52:13,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:52:13,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'zien', 'dat', 'de', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'om', 'te', 'be@@', 'se@@', 'ff@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 02:52:13,188 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:52:13,188 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:52:13,188 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's gezien dat de wereldwijd om te beseffen dat de arctische ijskappen, die voor de grootte van de onderste 48 staten, om 48 staten, om 48 staten, om 48 staten.
2025-05-30 02:52:13,189 - INFO - joeynmt.training - Example #1
2025-05-30 02:52:13,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:52:13,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:52:13,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'st@@', 'o@@', 'ff@@', 'en@@', 'd@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 'ti@@', 'g', 'gen@@', 'oe@@', 'g', 'om', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'te', 'ver@@', 'ander@@', 'en.', '</s>']
2025-05-30 02:52:13,190 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:52:13,190 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:52:13,190 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste stoffendheid van dit specifieke probleem dat het niet de dik van het ijs van het ijskracht van het ijskracht van het ijskracht van het ijskracht van het ijskracht van het ijskracht van het ijskracht van het ijskracht van het ijskrachtig genoeg om dit specifieke probleem te veranderen.
2025-05-30 02:52:13,191 - INFO - joeynmt.training - Example #2
2025-05-30 02:52:13,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:52:13,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:52:13,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'd', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:52:13,191 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:52:13,192 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:52:13,192 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slagende hart van onze wereldwijd klimaatsysteem.
2025-05-30 02:52:13,192 - INFO - joeynmt.training - Example #3
2025-05-30 02:52:13,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:52:13,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:52:13,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'or@@', 'gen', 'en', 'de', 'w@@', 'in@@', 'ter', 'en', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@']
2025-05-30 02:52:13,192 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:52:13,193 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:52:13,193 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de winter en zich in de winter en zich in de winter en zich in de winter en zich in de winter en de winter en de winter en de winter en de winter en de winter en de winter en de winter en de winter en zich in de winter en zich zorgen en de winter en en schrompt in de winter en zorgen en zich in de win
2025-05-30 02:52:13,193 - INFO - joeynmt.training - Example #4
2025-05-30 02:52:13,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:52:13,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:52:13,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:52:13,193 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:52:13,194 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:52:13,194 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdperk van wat er gebeurde in de afgelopen 25 jaar gebeurd is.
2025-05-30 02:52:22,490 - INFO - joeynmt.training - Epoch   8, Step:    76100, Batch Loss:     1.253329, Batch Acc: 0.581753, Tokens per Sec:     7510, Lr: 0.000300
2025-05-30 02:52:31,732 - INFO - joeynmt.training - Epoch   8, Step:    76200, Batch Loss:     1.330414, Batch Acc: 0.578974, Tokens per Sec:     8066, Lr: 0.000300
2025-05-30 02:52:41,062 - INFO - joeynmt.training - Epoch   8, Step:    76300, Batch Loss:     1.329711, Batch Acc: 0.578895, Tokens per Sec:     7704, Lr: 0.000300
2025-05-30 02:52:50,430 - INFO - joeynmt.training - Epoch   8, Step:    76400, Batch Loss:     1.254227, Batch Acc: 0.586220, Tokens per Sec:     7714, Lr: 0.000300
2025-05-30 02:52:59,691 - INFO - joeynmt.training - Epoch   8, Step:    76500, Batch Loss:     1.343606, Batch Acc: 0.579267, Tokens per Sec:     7745, Lr: 0.000300
2025-05-30 02:52:59,691 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:52:59,692 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:53:50,123 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.19, acc:   0.55, generation: 50.3835[sec], evaluation: 0.0000[sec]
2025-05-30 02:53:50,130 - INFO - joeynmt.training - Example #0
2025-05-30 02:53:50,131 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:53:50,131 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:53:50,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'zi@@', 'en,', 'om', 'te', 'ver@@', 't@@', 'ellen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'ge@@', 'be@@', 'ur@@', 'de', 'dr@@', 'ij@@', 'ven', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', '4@@', '8', 'st@@', 'at@@', 'en,', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'lo@@', 'ten', 'te', 'ge@@', 'ven', 'is.', '</s>']
2025-05-30 02:53:50,132 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:53:50,133 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:53:50,133 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's gezien, om te vertellen dat de arctische ijskappen, die voor de gebeurde drijven van de grootte van de grootte van de 48 staten, om 48 staten, 48 staten, 40 procent gesloten te geven is.
2025-05-30 02:53:50,133 - INFO - joeynmt.training - Example #1
2025-05-30 02:53:50,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:53:50,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:53:50,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ingen', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:53:50,135 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:53:50,135 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:53:50,135 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de snelheid van dit specifieke probleem uit, omdat het niet de dikke dingen van het ijs laat zien.
2025-05-30 02:53:50,135 - INFO - joeynmt.training - Example #2
2025-05-30 02:53:50,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:53:50,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:53:50,136 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'k@@', 't.', '</s>']
2025-05-30 02:53:50,137 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:53:50,137 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:53:50,137 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is het arctische ijskape ijskappe hart van ons werkt.
2025-05-30 02:53:50,137 - INFO - joeynmt.training - Example #3
2025-05-30 02:53:50,137 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:53:50,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:53:50,138 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'gro@@', 'ei@@', 't.', '</s>']
2025-05-30 02:53:50,139 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:53:50,139 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:53:50,139 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zich in de zomer in de winter en zomer in de winter en zich in de winter en zich in de winter en zich in de winter en zorgen in de winter en zomer in de winter en zomer in de winter en zomer in de winter en zomer in de winter en zomer in de winter en zomer groeit.
2025-05-30 02:53:50,139 - INFO - joeynmt.training - Example #4
2025-05-30 02:53:50,139 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:53:50,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:53:50,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 'ter@@', 'en', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:53:50,140 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:53:50,141 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:53:50,141 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrapporteren in de laatste 25 jaar gebeurd is.
2025-05-30 02:53:58,400 - INFO - joeynmt.training - Epoch   8, Step:    76600, Batch Loss:     1.242982, Batch Acc: 0.584218, Tokens per Sec:     8992, Lr: 0.000300
2025-05-30 02:54:06,630 - INFO - joeynmt.training - Epoch   8, Step:    76700, Batch Loss:     1.259570, Batch Acc: 0.582851, Tokens per Sec:     9141, Lr: 0.000300
2025-05-30 02:54:14,723 - INFO - joeynmt.training - Epoch   8, Step:    76800, Batch Loss:     1.268352, Batch Acc: 0.580729, Tokens per Sec:     8980, Lr: 0.000300
2025-05-30 02:54:23,301 - INFO - joeynmt.training - Epoch   8, Step:    76900, Batch Loss:     1.394212, Batch Acc: 0.580858, Tokens per Sec:     8609, Lr: 0.000300
2025-05-30 02:54:32,767 - INFO - joeynmt.training - Epoch   8, Step:    77000, Batch Loss:     1.262835, Batch Acc: 0.577148, Tokens per Sec:     7687, Lr: 0.000300
2025-05-30 02:54:32,768 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:54:32,768 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:55:22,021 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.16, acc:   0.55, generation: 49.2004[sec], evaluation: 0.0000[sec]
2025-05-30 02:55:22,022 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 02:55:22,212 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/73500.ckpt
2025-05-30 02:55:22,231 - INFO - joeynmt.training - Example #0
2025-05-30 02:55:22,232 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:55:22,232 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:55:22,232 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 're@@', 'st', 'van', 'de', 'ge@@', 'me@@', 'ensch@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 02:55:22,233 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:55:22,233 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:55:22,233 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee miljoen jaar de rest van de gemeenschappelijke ijskappen, die voor de grootte van de onderste staten.
2025-05-30 02:55:22,233 - INFO - joeynmt.training - Example #1
2025-05-30 02:55:22,234 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:55:22,234 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:55:22,234 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van']
2025-05-30 02:55:22,235 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:55:22,235 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:55:22,235 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg genoeg de eerste van dit specifieke probleem dat het niet de dikke van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van het ijs van
2025-05-30 02:55:22,235 - INFO - joeynmt.training - Example #2
2025-05-30 02:55:22,236 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:55:22,236 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:55:22,236 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 02:55:22,237 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:55:22,237 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:55:22,237 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijskappe ijskappelijke klimaatsysteem.
2025-05-30 02:55:22,237 - INFO - joeynmt.training - Example #3
2025-05-30 02:55:22,237 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:55:22,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:55:22,238 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 'en.', '</s>']
2025-05-30 02:55:22,238 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:55:22,239 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:55:22,239 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de winter en schrompen.
2025-05-30 02:55:22,239 - INFO - joeynmt.training - Example #4
2025-05-30 02:55:22,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:55:22,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:55:22,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:55:22,240 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:55:22,241 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:55:22,241 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdje van wat er gebeurd in de laatste 25 jaar gebeurd.
2025-05-30 02:55:31,669 - INFO - joeynmt.training - Epoch   8, Step:    77100, Batch Loss:     1.169902, Batch Acc: 0.583999, Tokens per Sec:     7552, Lr: 0.000300
2025-05-30 02:55:41,181 - INFO - joeynmt.training - Epoch   8, Step:    77200, Batch Loss:     1.197662, Batch Acc: 0.583499, Tokens per Sec:     7412, Lr: 0.000300
2025-05-30 02:55:50,431 - INFO - joeynmt.training - Epoch   8, Step:    77300, Batch Loss:     1.333670, Batch Acc: 0.576055, Tokens per Sec:     7875, Lr: 0.000300
2025-05-30 02:55:59,699 - INFO - joeynmt.training - Epoch   8, Step:    77400, Batch Loss:     1.206550, Batch Acc: 0.578110, Tokens per Sec:     7599, Lr: 0.000300
2025-05-30 02:56:09,903 - INFO - joeynmt.training - Epoch   8, Step:    77500, Batch Loss:     1.471774, Batch Acc: 0.578985, Tokens per Sec:     7311, Lr: 0.000300
2025-05-30 02:56:09,904 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:56:09,904 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:56:58,915 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.16, acc:   0.55, generation: 48.9709[sec], evaluation: 0.0000[sec]
2025-05-30 02:56:59,083 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/72500.ckpt
2025-05-30 02:56:59,093 - INFO - joeynmt.training - Example #0
2025-05-30 02:56:59,094 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:56:59,094 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:56:59,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'd@@', 'ing', 'te', 'ver@@', 'be@@', 'el@@', 'd@@', 'ing', 'te', 'ver@@', 'ander@@', 'en', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 02:56:59,095 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:56:59,095 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:56:59,095 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee dia om te verbeelding te verbeelding te veranderen voor de grootte van de grootte van de grootte van de onderste 48 staten.
2025-05-30 02:56:59,095 - INFO - joeynmt.training - Example #1
2025-05-30 02:56:59,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:56:59,096 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:56:59,096 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'st@@', 'o@@', 'el@@', 't@@', 'je', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'van', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:56:59,097 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:56:59,097 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:56:59,097 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de stoeltje van dit specifieke probleem uit, omdat het niet de dikke ijs van ijs laat zien.
2025-05-30 02:56:59,097 - INFO - joeynmt.training - Example #2
2025-05-30 02:56:59,098 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:56:59,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:56:59,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd.', '</s>']
2025-05-30 02:56:59,099 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:56:59,099 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:56:59,099 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijskapp het slagende hart van ons wereld.
2025-05-30 02:56:59,099 - INFO - joeynmt.training - Example #3
2025-05-30 02:56:59,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:56:59,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:56:59,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'ver@@', 'b@@', 'on@@', 'den', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'ver@@', 'b@@', 'on@@', 'den', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:56:59,100 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:56:59,100 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:56:59,101 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich in de winter en zich in de winter en zich in de winter en zich in de winter en zich verbonden in de winter en zich in de winter en zich verbonden en zich in de winter en zich in de winter en zomer in de winter en zomer.
2025-05-30 02:56:59,101 - INFO - joeynmt.training - Example #4
2025-05-30 02:56:59,101 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:56:59,101 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:56:59,101 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 02:56:59,102 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:56:59,102 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:56:59,102 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een tijdje laatste 25 jaar gebeurd in de laatste 25 jaar gebeurd is.
2025-05-30 02:57:07,869 - INFO - joeynmt.training - Epoch   8, Step:    77600, Batch Loss:     1.303064, Batch Acc: 0.580398, Tokens per Sec:     8346, Lr: 0.000300
2025-05-30 02:57:15,972 - INFO - joeynmt.training - Epoch   8, Step:    77700, Batch Loss:     1.353994, Batch Acc: 0.578851, Tokens per Sec:     8552, Lr: 0.000300
2025-05-30 02:57:23,875 - INFO - joeynmt.training - Epoch   8, Step:    77800, Batch Loss:     1.288141, Batch Acc: 0.576639, Tokens per Sec:     9313, Lr: 0.000300
2025-05-30 02:57:31,703 - INFO - joeynmt.training - Epoch   8, Step:    77900, Batch Loss:     1.218970, Batch Acc: 0.577616, Tokens per Sec:     9277, Lr: 0.000300
2025-05-30 02:57:39,561 - INFO - joeynmt.training - Epoch   8, Step:    78000, Batch Loss:     1.301964, Batch Acc: 0.576289, Tokens per Sec:     9157, Lr: 0.000300
2025-05-30 02:57:39,562 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:57:39,562 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:58:25,735 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.18, acc:   0.55, generation: 46.1304[sec], evaluation: 0.0000[sec]
2025-05-30 02:58:25,893 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/76000.ckpt
2025-05-30 02:58:25,909 - INFO - joeynmt.training - Example #0
2025-05-30 02:58:25,910 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:58:25,910 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:58:25,911 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'ï@@', 'n@@', 'ter@@', 'ess@@', 'eer@@', 'd', 'in', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'maa@@', 'kt', 'is.', '</s>']
2025-05-30 02:58:25,911 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:58:25,912 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:58:25,912 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te verbeelden dat de arctische ijskape, die voor de grootte van de onderste 48 staten had geïnteresseerd in de grootte van de onderste 48 staten had gemaakt is.
2025-05-30 02:58:25,912 - INFO - joeynmt.training - Example #1
2025-05-30 02:58:25,912 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:58:25,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:58:25,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'ge@@', 'wel@@', 'dig', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 'lan@@', 'e@@', 'et', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:58:25,913 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:58:25,914 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:58:25,914 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo geweldig genoeg de planeet van dit specifieke probleem, omdat het niet de dikke van het ijs van het ijs van het ijs laat zien.
2025-05-30 02:58:25,914 - INFO - joeynmt.training - Example #2
2025-05-30 02:58:25,914 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:58:25,914 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:58:25,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', '.', '</s>']
2025-05-30 02:58:25,916 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:58:25,916 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:58:25,916 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijskape ijskape ijskap.
2025-05-30 02:58:25,916 - INFO - joeynmt.training - Example #3
2025-05-30 02:58:25,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:58:25,917 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:58:25,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:58:25,918 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:58:25,918 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:58:25,918 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen en zomer.
2025-05-30 02:58:25,918 - INFO - joeynmt.training - Example #4
2025-05-30 02:58:25,918 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:58:25,918 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:58:25,918 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'p@@', 'aar', 'ver@@', 'z@@', 'am@@', 'el@@', 'en', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 02:58:25,919 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:58:25,919 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:58:25,919 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een paar verzamelen wat er gebeurd in de laatste 25 jaar gebeurd.
2025-05-30 02:58:34,845 - INFO - joeynmt.training - Epoch   8, Step:    78100, Batch Loss:     1.275051, Batch Acc: 0.574873, Tokens per Sec:     7840, Lr: 0.000300
2025-05-30 02:58:43,685 - INFO - joeynmt.training - Epoch   8, Step:    78200, Batch Loss:     1.424814, Batch Acc: 0.579184, Tokens per Sec:     8192, Lr: 0.000300
2025-05-30 02:58:52,853 - INFO - joeynmt.training - Epoch   8, Step:    78300, Batch Loss:     1.606023, Batch Acc: 0.578228, Tokens per Sec:     7907, Lr: 0.000300
2025-05-30 02:59:01,839 - INFO - joeynmt.training - Epoch   8, Step:    78400, Batch Loss:     1.430595, Batch Acc: 0.579997, Tokens per Sec:     8058, Lr: 0.000300
2025-05-30 02:59:10,730 - INFO - joeynmt.training - Epoch   8, Step:    78500, Batch Loss:     1.273869, Batch Acc: 0.575005, Tokens per Sec:     7968, Lr: 0.000300
2025-05-30 02:59:10,731 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 02:59:10,731 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 02:59:54,068 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.18, acc:   0.55, generation: 43.2925[sec], evaluation: 0.0000[sec]
2025-05-30 02:59:54,237 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/74000.ckpt
2025-05-30 02:59:54,253 - INFO - joeynmt.training - Example #0
2025-05-30 02:59:54,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 02:59:54,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 02:59:54,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'l@@', 'aat', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'aan@@', 'del@@', 'en', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ver@@', 'ander@@', 'en', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ver@@', 'ru@@', 'im@@', 'te', 'is', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 'ru@@', 'im@@', 'te', 'in', 'de', 'wer@@', 'eld', 'te', 'ver@@', 'ander@@', 'en', 'in', 'de', 'l@@', 'aat@@', 'ste', 'p@@', 'aar', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'twe@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@']
2025-05-30 02:59:54,256 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 02:59:54,256 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 02:59:54,256 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's laat zien dat de arctische ijskappen die voor de aandelen voor de grootte van de drie miljoen jaar de grootte van de onderste 48 staten om 48 staten om 48 staten te veranderen om 48 staten te verruimte is geslagen om 40 procent te verruimte in de wereld te veranderen in de laatste paar jaar de grootte van de twee miljoen jaar de groot
2025-05-30 02:59:54,256 - INFO - joeynmt.training - Example #1
2025-05-30 02:59:54,257 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 02:59:54,257 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 02:59:54,257 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'goe@@', 'd', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 02:59:54,258 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 02:59:54,259 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 02:59:54,259 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo goed genoeg de snelheid van dit specifiek probleem uit, omdat het niet de dikke van het ijs laat zien.
2025-05-30 02:59:54,259 - INFO - joeynmt.training - Example #2
2025-05-30 02:59:54,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 02:59:54,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 02:59:54,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en.', '</s>']
2025-05-30 02:59:54,260 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 02:59:54,260 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 02:59:54,261 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe ijskappen.
2025-05-30 02:59:54,261 - INFO - joeynmt.training - Example #3
2025-05-30 02:59:54,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 02:59:54,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 02:59:54,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 02:59:54,262 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 02:59:54,262 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 02:59:54,262 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich zomer.
2025-05-30 02:59:54,262 - INFO - joeynmt.training - Example #4
2025-05-30 02:59:54,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 02:59:54,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 02:59:54,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'gen', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 02:59:54,263 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 02:59:54,264 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 02:59:54,264 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdragen van de laatste 25 jaar.
2025-05-30 03:00:03,060 - INFO - joeynmt.training - Epoch   8, Step:    78600, Batch Loss:     1.350584, Batch Acc: 0.580928, Tokens per Sec:     7982, Lr: 0.000300
2025-05-30 03:00:11,796 - INFO - joeynmt.training - Epoch   8, Step:    78700, Batch Loss:     1.438363, Batch Acc: 0.579167, Tokens per Sec:     8335, Lr: 0.000300
2025-05-30 03:00:20,616 - INFO - joeynmt.training - Epoch   8, Step:    78800, Batch Loss:     1.430396, Batch Acc: 0.577180, Tokens per Sec:     8138, Lr: 0.000300
2025-05-30 03:00:28,702 - INFO - joeynmt.training - Epoch   8, Step:    78900, Batch Loss:     1.301708, Batch Acc: 0.579429, Tokens per Sec:     8925, Lr: 0.000300
2025-05-30 03:00:36,564 - INFO - joeynmt.training - Epoch   8, Step:    79000, Batch Loss:     1.340106, Batch Acc: 0.575045, Tokens per Sec:     8848, Lr: 0.000300
2025-05-30 03:00:36,564 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:00:36,565 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:01:18,809 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.18, acc:   0.55, generation: 42.1997[sec], evaluation: 0.0000[sec]
2025-05-30 03:01:18,967 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/73000.ckpt
2025-05-30 03:01:18,982 - INFO - joeynmt.training - Example #0
2025-05-30 03:01:18,983 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:01:18,983 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:01:18,983 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'jaar', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'aan@@', 't@@', 'al', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 03:01:18,983 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:01:18,984 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:01:18,984 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee jaar getoond om te bekijken dat de arctische ijskappen, die voor de aantal drie miljoen jaar de grootte van de onderste 48 staten.
2025-05-30 03:01:18,984 - INFO - joeynmt.training - Example #1
2025-05-30 03:01:18,984 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:01:18,984 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:01:18,984 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'zo', 'goe@@', 'd', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'we@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'aal', 'pro@@', 'ble@@', 'em', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ie@@', 'p@@', 'e', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:01:18,985 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:01:18,985 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:01:18,985 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet zo goed genoeg de snelweg de snelheid van dit speciaal probleem is dat het niet de dikke diepe ijs van het ijs van het ijs van het ijs laat zien.
2025-05-30 03:01:18,985 - INFO - joeynmt.training - Example #2
2025-05-30 03:01:18,985 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:01:18,985 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:01:18,985 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'h@@', 'oe@@', 've@@', 'el@@', 'heid', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'ver@@', '.', '</s>']
2025-05-30 03:01:18,986 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:01:18,986 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:01:18,986 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappelijke hoeveelheid van ons wereldwijde klimaatver.
2025-05-30 03:01:18,986 - INFO - joeynmt.training - Example #3
2025-05-30 03:01:18,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:01:18,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:01:18,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'den', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:01:18,987 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:01:18,987 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:01:18,987 - INFO - joeynmt.training - 	Hypothesis: Ze groeiden in de winter en schrompt in de zomer.
2025-05-30 03:01:18,987 - INFO - joeynmt.training - Example #4
2025-05-30 03:01:18,987 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:01:18,987 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:01:18,987 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 't@@', 'ing', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de.', '</s>']
2025-05-30 03:01:18,988 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:01:18,988 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:01:18,988 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tijdrapporting van wat er gebeurde in de laatste 25 jaar gebeurde.
2025-05-30 03:01:27,929 - INFO - joeynmt.training - Epoch   8, Step:    79100, Batch Loss:     1.277451, Batch Acc: 0.581953, Tokens per Sec:     7889, Lr: 0.000300
2025-05-30 03:01:36,831 - INFO - joeynmt.training - Epoch   8, Step:    79200, Batch Loss:     1.342811, Batch Acc: 0.579519, Tokens per Sec:     8128, Lr: 0.000300
2025-05-30 03:01:45,873 - INFO - joeynmt.training - Epoch   8, Step:    79300, Batch Loss:     1.133379, Batch Acc: 0.574174, Tokens per Sec:     7989, Lr: 0.000300
2025-05-30 03:01:55,119 - INFO - joeynmt.training - Epoch   8, Step:    79400, Batch Loss:     1.121576, Batch Acc: 0.578392, Tokens per Sec:     7693, Lr: 0.000300
2025-05-30 03:02:04,190 - INFO - joeynmt.training - Epoch   8, Step:    79500, Batch Loss:     1.255612, Batch Acc: 0.575851, Tokens per Sec:     7885, Lr: 0.000300
2025-05-30 03:02:04,190 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:02:04,191 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:02:55,411 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.17, acc:   0.55, generation: 51.1768[sec], evaluation: 0.0000[sec]
2025-05-30 03:02:55,571 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/78500.ckpt
2025-05-30 03:02:55,586 - INFO - joeynmt.training - Example #0
2025-05-30 03:02:55,587 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:02:55,587 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:02:55,587 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ik', 'to@@', 'on@@', 'de', 'dit', 'jaar', 'was', 'ik', 'deze', 'twe@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'om', 'te', 'beg@@', 're@@', 'e@@', 'p', 'te', 'beg@@', 'in@@', 'nen', 'met', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'ge@@', 'p@@', 're@@', 'st@@', 'at@@', 'ies', 'te', 'k@@', 're@@', 'gen', 'om', '4@@', '8', 'st@@', 'aten', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 03:02:55,588 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:02:55,588 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:02:55,588 - INFO - joeynmt.training - 	Hypothesis: Ik toonde dit jaar was ik deze twee miljoen om te begreep te beginnen met de arctische ijskappen die voor de grootte van de onderste 48 staten om 48 staten geprestaties te kregen om 48 staten gebeuren.
2025-05-30 03:02:55,589 - INFO - joeynmt.training - Example #1
2025-05-30 03:02:55,589 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:02:55,589 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:02:55,589 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ingen', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:02:55,590 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:02:55,590 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:02:55,590 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de snelheid van dit speciale probleem uit, omdat het niet de dikke dingen van het ijs laat zien.
2025-05-30 03:02:55,590 - INFO - joeynmt.training - Example #2
2025-05-30 03:02:55,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:02:55,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:02:55,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'er', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:02:55,592 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:02:55,592 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:02:55,592 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijskape ijzer van ons wereldwijde klimaatsysteem.
2025-05-30 03:02:55,593 - INFO - joeynmt.training - Example #3
2025-05-30 03:02:55,593 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:02:55,593 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:02:55,593 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:02:55,594 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:02:55,594 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:02:55,594 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomer.
2025-05-30 03:02:55,594 - INFO - joeynmt.training - Example #4
2025-05-30 03:02:55,595 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:02:55,595 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:02:55,595 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:02:55,596 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:02:55,596 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:02:55,596 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tijdje laatste 25 jaar gebeurd in de laatste 25 jaar gebeurd is.
2025-05-30 03:03:04,240 - INFO - joeynmt.training - Epoch   8, Step:    79600, Batch Loss:     1.326349, Batch Acc: 0.584159, Tokens per Sec:     8046, Lr: 0.000300
2025-05-30 03:03:12,846 - INFO - joeynmt.training - Epoch   8, Step:    79700, Batch Loss:     1.389258, Batch Acc: 0.578842, Tokens per Sec:     8534, Lr: 0.000300
2025-05-30 03:03:21,123 - INFO - joeynmt.training - Epoch   8, Step:    79800, Batch Loss:     1.229156, Batch Acc: 0.579273, Tokens per Sec:     8541, Lr: 0.000300
2025-05-30 03:03:29,013 - INFO - joeynmt.training - Epoch   8, Step:    79900, Batch Loss:     1.275806, Batch Acc: 0.574143, Tokens per Sec:     8779, Lr: 0.000300
2025-05-30 03:03:36,877 - INFO - joeynmt.training - Epoch   8, Step:    80000, Batch Loss:     1.431411, Batch Acc: 0.576676, Tokens per Sec:     9210, Lr: 0.000300
2025-05-30 03:03:36,878 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:03:36,878 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:04:17,916 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.16, acc:   0.55, generation: 40.9952[sec], evaluation: 0.0000[sec]
2025-05-30 03:04:17,917 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:04:18,081 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/79000.ckpt
2025-05-30 03:04:18,095 - INFO - joeynmt.training - Example #0
2025-05-30 03:04:18,095 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:04:18,095 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:04:18,096 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 't', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'naar', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijk', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'ge@@', 'st@@', 'ar@@', 't', 'te', 'ver@@', 'ander@@', 'en.', '</s>']
2025-05-30 03:04:18,096 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:04:18,097 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:04:18,097 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toont om te bekijken naar de arctische ijskappen die voor de artische ijskappelijk voor de onderste 48 staten, de grootte van 48 staten om 48 staten gestart te veranderen.
2025-05-30 03:04:18,098 - INFO - joeynmt.training - Example #1
2025-05-30 03:04:18,098 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:04:18,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:04:18,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 'ra@@', 'cht@@', 'ig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'zi@@', 'en.', '</s>']
2025-05-30 03:04:18,099 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:04:18,099 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:04:18,099 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet sterk genoeg de prachtigheid van dit specifieke probleem uit, omdat het niet de dikke dikke van het ijs zien.
2025-05-30 03:04:18,099 - INFO - joeynmt.training - Example #2
2025-05-30 03:04:18,100 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:04:18,100 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:04:18,100 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'e', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:04:18,101 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:04:18,101 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:04:18,101 - INFO - joeynmt.training - 	Hypothesis: In zekere zine is de arctische ijskappe ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-30 03:04:18,101 - INFO - joeynmt.training - Example #3
2025-05-30 03:04:18,101 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:04:18,102 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:04:18,102 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:04:18,103 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:04:18,103 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:04:18,103 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de winter en zomer.
2025-05-30 03:04:18,103 - INFO - joeynmt.training - Example #4
2025-05-30 03:04:18,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:04:18,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:04:18,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'er@@', 's@@', 'ver@@', 'na@@', 'm', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 03:04:18,104 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:04:18,105 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:04:18,105 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdrappersvernam wat er in de laatste 25 jaar gebeurd.
2025-05-30 03:04:26,883 - INFO - joeynmt.training - Epoch   8, Step:    80100, Batch Loss:     1.463021, Batch Acc: 0.574416, Tokens per Sec:     8233, Lr: 0.000300
2025-05-30 03:04:36,038 - INFO - joeynmt.training - Epoch   8, Step:    80200, Batch Loss:     1.372566, Batch Acc: 0.579136, Tokens per Sec:     7663, Lr: 0.000300
2025-05-30 03:04:44,952 - INFO - joeynmt.training - Epoch   8, Step:    80300, Batch Loss:     1.267277, Batch Acc: 0.580314, Tokens per Sec:     8189, Lr: 0.000300
2025-05-30 03:04:52,950 - INFO - joeynmt.training - Epoch   8, Step:    80400, Batch Loss:     1.341987, Batch Acc: 0.579516, Tokens per Sec:     9060, Lr: 0.000300
2025-05-30 03:05:00,848 - INFO - joeynmt.training - Epoch   8, Step:    80500, Batch Loss:     1.509513, Batch Acc: 0.568715, Tokens per Sec:     9125, Lr: 0.000300
2025-05-30 03:05:00,848 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:05:00,848 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:05:49,900 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.17, acc:   0.55, generation: 49.0059[sec], evaluation: 0.0000[sec]
2025-05-30 03:05:50,050 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/78000.ckpt
2025-05-30 03:05:50,067 - INFO - joeynmt.training - Example #0
2025-05-30 03:05:50,067 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:05:50,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:05:50,068 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'naar', 'de', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'sch@@', 'aal@@', 't@@', 'je', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ge@@', 'st@@', 'or@@', 'ven', 'te', 'k@@', 'rij@@', 'gen', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ver@@', 'z@@', 'et@@', '.', '</s>']
2025-05-30 03:05:50,069 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:05:50,069 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:05:50,069 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen te bekijken naar de wereldwijde ijskappen die voor de schaaltje van 48 staten had om 48 staten gestorven te krijgen om 48 staten te verzet.
2025-05-30 03:05:50,069 - INFO - joeynmt.training - Example #1
2025-05-30 03:05:50,070 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:05:50,070 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:05:50,070 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'het', 'p@@', 'un@@', 't', 'gen@@', 'oe@@', 'g', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'ck@@', 's', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 't.', '</s>']
2025-05-30 03:05:50,075 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:05:50,075 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:05:50,075 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg het punt genoeg van dit speciale probleem uit, omdat het niet de dikke dicks van het ijskracht.
2025-05-30 03:05:50,076 - INFO - joeynmt.training - Example #2
2025-05-30 03:05:50,077 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:05:50,077 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:05:50,077 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:05:50,078 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:05:50,078 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:05:50,078 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slagende ijskappe klimaatsysteem.
2025-05-30 03:05:50,078 - INFO - joeynmt.training - Example #3
2025-05-30 03:05:50,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:05:50,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:05:50,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:05:50,080 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:05:50,080 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:05:50,080 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomer.
2025-05-30 03:05:50,080 - INFO - joeynmt.training - Example #4
2025-05-30 03:05:50,081 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:05:50,081 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:05:50,081 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'gen', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:05:50,082 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:05:50,082 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:05:50,082 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik laat zien is een tijdragen van de laatste 25 jaar gebeurd is.
2025-05-30 03:05:58,647 - INFO - joeynmt.training - Epoch   8, Step:    80600, Batch Loss:     1.278403, Batch Acc: 0.578448, Tokens per Sec:     8259, Lr: 0.000300
2025-05-30 03:06:07,184 - INFO - joeynmt.training - Epoch   8, Step:    80700, Batch Loss:     1.362417, Batch Acc: 0.581332, Tokens per Sec:     8484, Lr: 0.000300
2025-05-30 03:06:16,074 - INFO - joeynmt.training - Epoch   8, Step:    80800, Batch Loss:     1.426173, Batch Acc: 0.580181, Tokens per Sec:     8095, Lr: 0.000300
2025-05-30 03:06:24,623 - INFO - joeynmt.training - Epoch   8, Step:    80900, Batch Loss:     1.345791, Batch Acc: 0.574602, Tokens per Sec:     8357, Lr: 0.000300
2025-05-30 03:06:33,396 - INFO - joeynmt.training - Epoch   8, Step:    81000, Batch Loss:     1.437987, Batch Acc: 0.582385, Tokens per Sec:     8046, Lr: 0.000300
2025-05-30 03:06:33,401 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:06:33,402 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:07:19,289 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.16, acc:   0.55, generation: 45.8458[sec], evaluation: 0.0000[sec]
2025-05-30 03:07:19,291 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:07:19,479 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/79500.ckpt
2025-05-30 03:07:19,495 - INFO - joeynmt.training - Example #0
2025-05-30 03:07:19,496 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:07:19,496 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:07:19,496 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 't', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'l@@', 'aten', 'zien', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'at@@', 'u@@', 'ur@@', ',', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'te', 'ge@@', 'st@@', 'op@@', 'p@@', 'en.', '</s>']
2025-05-30 03:07:19,497 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:07:19,497 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:07:19,498 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toont om te beginnen te laten zien dat de arctische ijskappe ijskappe ijskapparatuur, om 48 staten had om 48 staten had om 48 staten had te gestoppen.
2025-05-30 03:07:19,498 - INFO - joeynmt.training - Example #1
2025-05-30 03:07:19,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:07:19,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:07:19,498 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'ge@@', 'wel@@', 'dig', 'pro@@', 'ble@@', 'em@@', ',', 'het', 'spe@@', 'ci@@', 'aal', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'in@@', 's', 'van', 'het', 'ij@@', 's@@', 't.', '</s>']
2025-05-30 03:07:19,499 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:07:19,499 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:07:19,499 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de eerste van het geweldig probleem, het speciaal van dit specifieke probleem, omdat het niet de dickins van het ijst.
2025-05-30 03:07:19,500 - INFO - joeynmt.training - Example #2
2025-05-30 03:07:19,500 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:07:19,500 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:07:19,500 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'aat', 'van', 'ons', 'wer@@', 'el@@', 'd.', '</s>']
2025-05-30 03:07:19,501 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:07:19,501 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:07:19,501 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe ijskapparaat van ons wereld.
2025-05-30 03:07:19,502 - INFO - joeynmt.training - Example #3
2025-05-30 03:07:19,502 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:07:19,502 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:07:19,502 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:07:19,503 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:07:19,503 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:07:19,503 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen in de zomer.
2025-05-30 03:07:19,503 - INFO - joeynmt.training - Example #4
2025-05-30 03:07:19,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:07:19,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:07:19,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'te@@', 'ken@@', 's', 'die', 'ik', 'l@@', 'aat', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 03:07:19,505 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:07:19,505 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:07:19,505 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tekens die ik laat gebeurd in de laatste 25 jaar gebeurd.
2025-05-30 03:07:28,398 - INFO - joeynmt.training - Epoch   8, Step:    81100, Batch Loss:     1.404150, Batch Acc: 0.574998, Tokens per Sec:     7920, Lr: 0.000300
2025-05-30 03:07:37,450 - INFO - joeynmt.training - Epoch   8, Step:    81200, Batch Loss:     1.353699, Batch Acc: 0.581022, Tokens per Sec:     8063, Lr: 0.000300
2025-05-30 03:07:46,701 - INFO - joeynmt.training - Epoch   8, Step:    81300, Batch Loss:     1.333457, Batch Acc: 0.576282, Tokens per Sec:     8004, Lr: 0.000300
2025-05-30 03:07:55,885 - INFO - joeynmt.training - Epoch   8, Step:    81400, Batch Loss:     1.327605, Batch Acc: 0.579863, Tokens per Sec:     7764, Lr: 0.000300
2025-05-30 03:08:04,911 - INFO - joeynmt.training - Epoch   8, Step:    81500, Batch Loss:     1.190320, Batch Acc: 0.581519, Tokens per Sec:     7970, Lr: 0.000300
2025-05-30 03:08:04,912 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:08:04,912 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:08:58,571 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.16, acc:   0.55, generation: 53.6249[sec], evaluation: 0.0000[sec]
2025-05-30 03:08:58,727 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/80500.ckpt
2025-05-30 03:08:58,744 - INFO - joeynmt.training - Example #0
2025-05-30 03:08:58,745 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:08:58,745 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:08:58,745 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 're@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'c@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de', 'te', 'st@@', 'op@@', 'p@@', 'en.', '</s>']
2025-05-30 03:08:58,746 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:08:58,746 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:08:58,746 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te begrepen dat de arcticape ijskape ijskape ijskappen die voor de grootte van de 48 staten had om 48 staten had om 48 staten om 40 procent gebeurde te stoppen.
2025-05-30 03:08:58,747 - INFO - joeynmt.training - Example #1
2025-05-30 03:08:58,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:08:58,747 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:08:58,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'oo@@', 'g@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'aal', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'k@@', 'k@@', 'er', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 't.', '</s>']
2025-05-30 03:08:58,748 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:08:58,748 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:08:58,749 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de eerste van het oogst van dit speciaal probleem uit, omdat het niet de dikkker van het ijskracht.
2025-05-30 03:08:58,749 - INFO - joeynmt.training - Example #2
2025-05-30 03:08:58,749 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:08:58,749 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:08:58,749 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:08:58,750 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:08:58,750 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:08:58,751 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slagen van ons wereldwijde klimaatsysteem.
2025-05-30 03:08:58,751 - INFO - joeynmt.training - Example #3
2025-05-30 03:08:58,751 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:08:58,751 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:08:58,751 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'or@@', 'gen', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'or@@', 'gen', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'or@@', 'gen', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'gro@@', 'ei@@', '.', '</s>']
2025-05-30 03:08:58,752 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:08:58,752 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:08:58,752 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich in de winter en zich zorgen in de winter en zich in de winter en zich in de winter en zich in de winter en zich in de winter en zich zorgen in de winter en zich in de winter en zich in de winter en zich in de winter en zich zorgen in de winter en zich in de winter en zorgen in de winter en zorgen groei.
2025-05-30 03:08:58,753 - INFO - joeynmt.training - Example #4
2025-05-30 03:08:58,753 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:08:58,753 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:08:58,753 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:08:58,754 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:08:58,754 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:08:58,754 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik jullie laten zien, is een tijdperk van wat er gebeurd in de afgelopen 25 jaar gebeurd is.
2025-05-30 03:09:07,458 - INFO - joeynmt.training - Epoch   8, Step:    81600, Batch Loss:     1.404414, Batch Acc: 0.572135, Tokens per Sec:     8036, Lr: 0.000300
2025-05-30 03:09:16,367 - INFO - joeynmt.training - Epoch   8, Step:    81700, Batch Loss:     1.464959, Batch Acc: 0.581090, Tokens per Sec:     7946, Lr: 0.000300
2025-05-30 03:09:24,663 - INFO - joeynmt.training - Epoch   8, Step:    81800, Batch Loss:     1.282210, Batch Acc: 0.581579, Tokens per Sec:     8604, Lr: 0.000300
2025-05-30 03:09:33,126 - INFO - joeynmt.training - Epoch   8, Step:    81900, Batch Loss:     1.323998, Batch Acc: 0.582970, Tokens per Sec:     8704, Lr: 0.000300
2025-05-30 03:09:41,487 - INFO - joeynmt.training - Epoch   8, Step:    82000, Batch Loss:     1.232301, Batch Acc: 0.585541, Tokens per Sec:     8474, Lr: 0.000300
2025-05-30 03:09:41,488 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:09:41,488 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:10:26,846 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.43, ppl:   4.16, acc:   0.55, generation: 45.3198[sec], evaluation: 0.0000[sec]
2025-05-30 03:10:26,998 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/77500.ckpt
2025-05-30 03:10:27,009 - INFO - joeynmt.training - Example #0
2025-05-30 03:10:27,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:10:27,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:10:27,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'en', 'to@@', 'on@@', 'de', 'ik', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 't@@', 'ellen', 'dat', 'de', 'ar@@', 'ct@@', 'ie@@', 've', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'vo@@', 'el@@', 'd.', '</s>']
2025-05-30 03:10:27,011 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:10:27,011 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:10:27,011 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dien toonde ik toond om te vertellen dat de arctieve ijskappen die voor de arctische ijskappen die 48 staten had om 48 staten te verzamelen van 40 procent gevoeld.
2025-05-30 03:10:27,011 - INFO - joeynmt.training - Example #1
2025-05-30 03:10:27,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:10:27,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:10:27,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'de', 'eer@@', 'ste', 'k@@', 'ra@@', 'ch@@', 't,', 'om@@', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'ck@@', 'te', 'l@@', 'aten', 'zi@@', 'en.', '</s>']
2025-05-30 03:10:27,013 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:10:27,013 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:10:27,013 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de eerste van de eerste kracht, omdat het speciale probleem uit, omdat het niet de dikke dickte laten zien.
2025-05-30 03:10:27,014 - INFO - joeynmt.training - Example #2
2025-05-30 03:10:27,014 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:10:27,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:10:27,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:10:27,015 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:10:27,015 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:10:27,015 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijskape ijskape klimaatsysteem.
2025-05-30 03:10:27,016 - INFO - joeynmt.training - Example #3
2025-05-30 03:10:27,016 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:10:27,016 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:10:27,016 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'r@@', 'on@@', 'd', 'en', 'z@@', 'r@@', 'on@@', 'd', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:10:27,017 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:10:27,017 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:10:27,017 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zrond en zrond de zomer.
2025-05-30 03:10:27,017 - INFO - joeynmt.training - Example #4
2025-05-30 03:10:27,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:10:27,018 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:10:27,018 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:10:27,019 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:10:27,019 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:10:27,019 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdperk van de laatste 25 jaar gebeurd is.
2025-05-30 03:10:35,704 - INFO - joeynmt.training - Epoch   8, Step:    82100, Batch Loss:     1.537866, Batch Acc: 0.583079, Tokens per Sec:     8075, Lr: 0.000300
2025-05-30 03:10:43,940 - INFO - joeynmt.training - Epoch   8, Step:    82200, Batch Loss:     1.394777, Batch Acc: 0.582068, Tokens per Sec:     8833, Lr: 0.000300
2025-05-30 03:10:51,959 - INFO - joeynmt.training - Epoch   8, Step:    82300, Batch Loss:     1.194676, Batch Acc: 0.575933, Tokens per Sec:     9060, Lr: 0.000300
2025-05-30 03:11:00,861 - INFO - joeynmt.training - Epoch   8, Step:    82400, Batch Loss:     1.341345, Batch Acc: 0.576955, Tokens per Sec:     8067, Lr: 0.000300
2025-05-30 03:11:09,361 - INFO - joeynmt.training - Epoch   8, Step:    82500, Batch Loss:     1.317094, Batch Acc: 0.577613, Tokens per Sec:     8727, Lr: 0.000300
2025-05-30 03:11:09,361 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:11:09,361 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:11:54,523 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.15, acc:   0.55, generation: 45.1150[sec], evaluation: 0.0000[sec]
2025-05-30 03:11:54,524 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:11:54,696 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/77000.ckpt
2025-05-30 03:11:54,712 - INFO - joeynmt.training - Example #0
2025-05-30 03:11:54,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:11:54,713 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:11:54,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'p@@', 'er', 'jaar', 'aan', 'om', 'te', 'ver@@', 'be@@', 'ter@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 'be@@', 'ur@@', 'de.', '</s>']
2025-05-30 03:11:54,714 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:11:54,714 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:11:54,715 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee per jaar aan om te verbeteren dat de arctische ijskappe ijskappen, die voor de grootte van 48 staten had om 48 staten had 40 procent gebeurde.
2025-05-30 03:11:54,715 - INFO - joeynmt.training - Example #1
2025-05-30 03:11:54,715 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:11:54,715 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:11:54,715 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:11:54,717 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:11:54,717 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:11:54,717 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg genoeg de eerste probleem van dit specifieke probleem uit, omdat het niet de dicks van het ijs laat zien.
2025-05-30 03:11:54,717 - INFO - joeynmt.training - Example #2
2025-05-30 03:11:54,718 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:11:54,718 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:11:54,718 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:11:54,718 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:11:54,719 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:11:54,719 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijskape ijskappe klimaatsysteem.
2025-05-30 03:11:54,719 - INFO - joeynmt.training - Example #3
2025-05-30 03:11:54,719 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:11:54,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:11:54,720 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:11:54,720 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:11:54,720 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:11:54,720 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich in de winter en zomer.
2025-05-30 03:11:54,720 - INFO - joeynmt.training - Example #4
2025-05-30 03:11:54,720 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:11:54,720 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:11:54,721 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:11:54,721 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:11:54,721 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:11:54,721 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdperk van de laatste 25 jaar gebeurd in de laatste 25 jaar gebeurd is.
2025-05-30 03:12:03,261 - INFO - joeynmt.training - Epoch   8, Step:    82600, Batch Loss:     1.252443, Batch Acc: 0.580971, Tokens per Sec:     8236, Lr: 0.000300
2025-05-30 03:12:11,791 - INFO - joeynmt.training - Epoch   8, Step:    82700, Batch Loss:     1.505866, Batch Acc: 0.579911, Tokens per Sec:     8449, Lr: 0.000300
2025-05-30 03:12:20,283 - INFO - joeynmt.training - Epoch   8, Step:    82800, Batch Loss:     1.494067, Batch Acc: 0.578831, Tokens per Sec:     8812, Lr: 0.000300
2025-05-30 03:12:28,884 - INFO - joeynmt.training - Epoch   8, Step:    82900, Batch Loss:     1.325552, Batch Acc: 0.578807, Tokens per Sec:     8180, Lr: 0.000300
2025-05-30 03:12:38,277 - INFO - joeynmt.training - Epoch   8, Step:    83000, Batch Loss:     1.290040, Batch Acc: 0.579318, Tokens per Sec:     7841, Lr: 0.000300
2025-05-30 03:12:38,278 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:12:38,278 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:13:22,981 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.14, acc:   0.55, generation: 44.6614[sec], evaluation: 0.0000[sec]
2025-05-30 03:13:22,982 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:13:23,180 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/81500.ckpt
2025-05-30 03:13:23,204 - INFO - joeynmt.training - Example #0
2025-05-30 03:13:23,205 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:13:23,205 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:13:23,206 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'p@@', 'un@@', 't', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'p@@', 'ar@@', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ver@@', 'z@@', 'et@@', 'ten.', '</s>']
2025-05-30 03:13:23,207 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:13:23,207 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:13:23,207 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee punt om te verbeelden dat de arctische ijskappe ijskappelijke partijdperk van de grootte van de onderste 48 staten had om 40 procent te verzetten.
2025-05-30 03:13:23,207 - INFO - joeynmt.training - Example #1
2025-05-30 03:13:23,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:13:23,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:13:23,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'st@@', 'a@@', 'p', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's@@', 'ei@@', 'zo@@', 'en.', '</s>']
2025-05-30 03:13:23,208 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:13:23,209 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:13:23,209 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg genoeg de stap van dit specifieke probleem uit, omdat het niet de dikke van het ijseizoen.
2025-05-30 03:13:23,209 - INFO - joeynmt.training - Example #2
2025-05-30 03:13:23,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:13:23,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:13:23,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'ig@@', 'en@@', 'l@@', 'ijke', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:13:23,210 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:13:23,211 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:13:23,211 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigenlijke ijskape ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-30 03:13:23,211 - INFO - joeynmt.training - Example #3
2025-05-30 03:13:23,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:13:23,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:13:23,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'op', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'op', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'en', 'z@@', 'ich', 'op', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'en', 'z@@', 'ich']
2025-05-30 03:13:23,212 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:13:23,212 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:13:23,213 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zorgen en zorgen in de zomer in de winter en zomer in de winter en zomer in de winter en zich op de winter en zich op de winter en zomer in de winter en zomer in de winter en en zich op de winter en zomer in de winter en zomer in de winter en zich zomer in de winter en zomer in de winter en zomer en zich
2025-05-30 03:13:23,213 - INFO - joeynmt.training - Example #4
2025-05-30 03:13:23,213 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:13:23,213 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:13:23,213 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 't@@', 'ing', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 03:13:23,214 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:13:23,214 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:13:23,215 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdrapporting wat er gebeurd in de laatste 25 jaar gebeurd.
2025-05-30 03:13:32,110 - INFO - joeynmt.training - Epoch   8, Step:    83100, Batch Loss:     1.384638, Batch Acc: 0.578248, Tokens per Sec:     7821, Lr: 0.000300
2025-05-30 03:13:41,204 - INFO - joeynmt.training - Epoch   8, Step:    83200, Batch Loss:     1.234366, Batch Acc: 0.585237, Tokens per Sec:     7751, Lr: 0.000300
2025-05-30 03:13:50,076 - INFO - joeynmt.training - Epoch   8, Step:    83300, Batch Loss:     1.416919, Batch Acc: 0.579816, Tokens per Sec:     8228, Lr: 0.000300
2025-05-30 03:13:58,412 - INFO - joeynmt.training - Epoch   8, Step:    83400, Batch Loss:     1.479756, Batch Acc: 0.570789, Tokens per Sec:     8169, Lr: 0.000300
2025-05-30 03:14:06,879 - INFO - joeynmt.training - Epoch   8, Step:    83500, Batch Loss:     1.391500, Batch Acc: 0.575446, Tokens per Sec:     8513, Lr: 0.000300
2025-05-30 03:14:06,880 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:14:06,880 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:14:53,267 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.15, acc:   0.55, generation: 46.3394[sec], evaluation: 0.0000[sec]
2025-05-30 03:14:53,432 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/80000.ckpt
2025-05-30 03:14:53,440 - INFO - joeynmt.training - Example #0
2025-05-30 03:14:53,441 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:14:53,441 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:14:53,441 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'ct@@', 'ie@@', 've', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'z@@', 'in@@', '.', '</s>']
2025-05-30 03:14:53,442 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:14:53,442 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:14:53,443 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toond om te bekijken dat de arctieve ijskappen, die voor de drie miljoen jaar de grootte van de grootte van de onderste 48 staten had om 48 staten om 40 procent te gezin.
2025-05-30 03:14:53,443 - INFO - joeynmt.training - Example #1
2025-05-30 03:14:53,443 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:14:53,443 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:14:53,443 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'un@@', 't', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'i@@', 'o@@', '-@@', 'in@@', '-@@', 'di@@', 'ck@@', 'e', 'van', 'de', 'ij@@', 's@@', 'i@@', 'o@@', 'en@@', 's.', '</s>']
2025-05-30 03:14:53,444 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:14:53,444 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:14:53,444 - INFO - joeynmt.training - 	Hypothesis: Maar dit specifieke genoeg de eerste punt van dit specifieke probleem uit, want het is niet de dikke van de ijsio-in-dicke van de ijsioens.
2025-05-30 03:14:53,445 - INFO - joeynmt.training - Example #2
2025-05-30 03:14:53,445 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:14:53,445 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:14:53,445 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:14:53,445 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:14:53,445 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:14:53,446 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe ijskappe klimaatsysteem.
2025-05-30 03:14:53,446 - INFO - joeynmt.training - Example #3
2025-05-30 03:14:53,446 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:14:53,446 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:14:53,446 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'or@@', 'g@@', ',', 'en', 'z@@', 'or@@', 'g@@', ',', 'en', 'z@@', 'r@@', 'on@@', 'd', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:14:53,446 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:14:53,447 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:14:53,447 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zich zorg, en zorg, en zrond in de zomer.
2025-05-30 03:14:53,447 - INFO - joeynmt.training - Example #4
2025-05-30 03:14:53,447 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:14:53,447 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:14:53,447 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 't@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:14:53,448 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:14:53,448 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:14:53,448 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrapportste 25 jaar gebeurd is.
2025-05-30 03:15:02,249 - INFO - joeynmt.training - Epoch   8, Step:    83600, Batch Loss:     1.347244, Batch Acc: 0.579498, Tokens per Sec:     8108, Lr: 0.000300
2025-05-30 03:15:11,112 - INFO - joeynmt.training - Epoch   8, Step:    83700, Batch Loss:     1.368233, Batch Acc: 0.574963, Tokens per Sec:     8128, Lr: 0.000300
2025-05-30 03:15:20,008 - INFO - joeynmt.training - Epoch   8, Step:    83800, Batch Loss:     1.275793, Batch Acc: 0.575589, Tokens per Sec:     7993, Lr: 0.000300
2025-05-30 03:15:29,113 - INFO - joeynmt.training - Epoch   8, Step:    83900, Batch Loss:     1.264026, Batch Acc: 0.578770, Tokens per Sec:     7982, Lr: 0.000300
2025-05-30 03:15:37,885 - INFO - joeynmt.training - Epoch   8, Step:    84000, Batch Loss:     1.210577, Batch Acc: 0.583765, Tokens per Sec:     8276, Lr: 0.000300
2025-05-30 03:15:37,886 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:15:37,886 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:16:18,565 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.12, acc:   0.55, generation: 40.6391[sec], evaluation: 0.0000[sec]
2025-05-30 03:16:18,566 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:16:18,738 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/82000.ckpt
2025-05-30 03:16:18,754 - INFO - joeynmt.training - Example #0
2025-05-30 03:16:18,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:16:18,755 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:16:18,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'sch@@', 'aal', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'te', 'ver@@', 'ander@@', 'en', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 03:16:18,756 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:16:18,756 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:16:18,756 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen te bekijken dat de arctische ijskappen, die voor de schaal van de onderste 48 staten te veranderen 48 staten om 48 staten te geslagen om 40 procent te geslagen om 40 procent te geslagen is.
2025-05-30 03:16:18,756 - INFO - joeynmt.training - Example #1
2025-05-30 03:16:18,757 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:16:18,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:16:18,757 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'zo', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'o@@', 'sit@@', 'ie@@', 've', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'di@@', 'k', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:16:18,758 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:16:18,759 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:16:18,759 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet zo sterk genoeg de eerste positieve probleem uit, want het is niet de dikke dikke dik van het ijs laat zien.
2025-05-30 03:16:18,759 - INFO - joeynmt.training - Example #2
2025-05-30 03:16:18,759 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:16:18,759 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:16:18,759 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'ig@@', 'l@@', 'ijke', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:16:18,760 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:16:18,760 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:16:18,761 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuiglijke ijskappe ijskappe ijskappe klimaatsysteem.
2025-05-30 03:16:18,761 - INFO - joeynmt.training - Example #3
2025-05-30 03:16:18,761 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:16:18,761 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:16:18,761 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:16:18,762 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:16:18,762 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:16:18,762 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen en zomer in de zomer.
2025-05-30 03:16:18,762 - INFO - joeynmt.training - Example #4
2025-05-30 03:16:18,763 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:16:18,763 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:16:18,763 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ge@@', 'gev@@', 'en@@', 's,', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:16:18,764 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:16:18,764 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:16:18,764 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsgegevens, wat er in de laatste 25 jaar gebeurd is.
2025-05-30 03:16:26,827 - INFO - joeynmt.training - Epoch   8, Step:    84100, Batch Loss:     1.330503, Batch Acc: 0.578053, Tokens per Sec:     8563, Lr: 0.000300
2025-05-30 03:16:35,778 - INFO - joeynmt.training - Epoch   8, Step:    84200, Batch Loss:     1.482543, Batch Acc: 0.572249, Tokens per Sec:     8012, Lr: 0.000300
2025-05-30 03:16:44,652 - INFO - joeynmt.training - Epoch   8, Step:    84300, Batch Loss:     1.173581, Batch Acc: 0.583648, Tokens per Sec:     8149, Lr: 0.000300
2025-05-30 03:16:53,611 - INFO - joeynmt.training - Epoch   8, Step:    84400, Batch Loss:     1.302254, Batch Acc: 0.572199, Tokens per Sec:     8069, Lr: 0.000300
2025-05-30 03:17:02,421 - INFO - joeynmt.training - Epoch   8, Step:    84500, Batch Loss:     1.307753, Batch Acc: 0.583597, Tokens per Sec:     8278, Lr: 0.000300
2025-05-30 03:17:02,422 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:17:02,423 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:17:48,143 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.13, acc:   0.55, generation: 45.6739[sec], evaluation: 0.0000[sec]
2025-05-30 03:17:48,305 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/81000.ckpt
2025-05-30 03:17:48,321 - INFO - joeynmt.training - Example #0
2025-05-30 03:17:48,322 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:17:48,322 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:17:48,322 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'nen', 'die', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 03:17:48,323 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:17:48,324 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:17:48,324 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te verkijken dat de arctische ijnen die de arctische miljoen jaar de grootte van de onderste 48 staten om 48 staten te geslagen om 40 procent te geslagen om 40 procent te geslagen is.
2025-05-30 03:17:48,324 - INFO - joeynmt.training - Example #1
2025-05-30 03:17:48,324 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:17:48,325 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:17:48,325 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'o@@', 'sit@@', 'ie', 'van', 'het', 'ij@@', 'z@@', 'onder@@', 'e', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 'z@@', 'onder@@', 'e', 'pro@@', 'ble@@', 'em@@', '.', '</s>']
2025-05-30 03:17:48,326 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:17:48,326 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:17:48,326 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de eerste positie van het ijzondere probleem uit, omdat het niet de dikkke van het ijzondere probleem.
2025-05-30 03:17:48,326 - INFO - joeynmt.training - Example #2
2025-05-30 03:17:48,326 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:17:48,327 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:17:48,327 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'nen', 'is', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:17:48,328 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:17:48,328 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:17:48,328 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijnen is het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 03:17:48,328 - INFO - joeynmt.training - Example #3
2025-05-30 03:17:48,328 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:17:48,328 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:17:48,328 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'g@@', 'aan@@', '.', '</s>']
2025-05-30 03:17:48,329 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:17:48,329 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:17:48,329 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zrompt in de winter en zrompt in de winter en zich in de winter en zich in de winter en zich in de winter en zorgaan.
2025-05-30 03:17:48,329 - INFO - joeynmt.training - Example #4
2025-05-30 03:17:48,330 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:17:48,330 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:17:48,330 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'gen', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 03:17:48,331 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:17:48,331 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:17:48,331 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdragen van de laatste 25 jaar.
2025-05-30 03:17:57,532 - INFO - joeynmt.training - Epoch   8, Step:    84600, Batch Loss:     1.408024, Batch Acc: 0.579714, Tokens per Sec:     7713, Lr: 0.000300
2025-05-30 03:18:06,642 - INFO - joeynmt.training - Epoch   8, Step:    84700, Batch Loss:     1.351143, Batch Acc: 0.581910, Tokens per Sec:     7923, Lr: 0.000300
2025-05-30 03:18:15,479 - INFO - joeynmt.training - Epoch   8, Step:    84800, Batch Loss:     1.304977, Batch Acc: 0.574673, Tokens per Sec:     7922, Lr: 0.000300
2025-05-30 03:18:21,498 - INFO - joeynmt.training - Epoch   8: total training loss 13993.84
2025-05-30 03:18:21,498 - INFO - joeynmt.training - EPOCH 9
2025-05-30 03:18:24,262 - INFO - joeynmt.training - Epoch   9, Step:    84900, Batch Loss:     1.240774, Batch Acc: 0.591840, Tokens per Sec:     8178, Lr: 0.000300
2025-05-30 03:18:33,104 - INFO - joeynmt.training - Epoch   9, Step:    85000, Batch Loss:     1.283735, Batch Acc: 0.586762, Tokens per Sec:     8299, Lr: 0.000300
2025-05-30 03:18:33,104 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:18:33,105 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:19:24,607 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.15, acc:   0.55, generation: 51.4550[sec], evaluation: 0.0000[sec]
2025-05-30 03:19:24,778 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/82500.ckpt
2025-05-30 03:19:24,793 - INFO - joeynmt.training - Example #0
2025-05-30 03:19:24,794 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:19:24,794 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:19:24,794 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'te@@', 'men@@', 't', 'in', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 's@@', 'm@@', 'p@@', 'el@@', 'd.', '</s>']
2025-05-30 03:19:24,795 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:19:24,795 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:19:24,796 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te begrijpen dat de arctische ijskappe ijskappe ijskappelijke ijskappartement in de onderste 48 staten had gesmpeld.
2025-05-30 03:19:24,796 - INFO - joeynmt.training - Example #1
2025-05-30 03:19:24,796 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:19:24,796 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:19:24,796 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'de', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'un@@', 't', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:19:24,797 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:19:24,797 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:19:24,797 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet de genoeg de eerste punt van het ijs van het ijs van het ijs omdat het niet de dik van het ijs laat zien.
2025-05-30 03:19:24,798 - INFO - joeynmt.training - Example #2
2025-05-30 03:19:24,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:19:24,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:19:24,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en.', '</s>']
2025-05-30 03:19:24,799 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:19:24,799 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:19:24,799 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe ijskappe ijskappen.
2025-05-30 03:19:24,799 - INFO - joeynmt.training - Example #3
2025-05-30 03:19:24,799 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:19:24,800 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:19:24,800 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'gro@@', 'ei@@', 'en.', '</s>']
2025-05-30 03:19:24,800 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:19:24,801 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:19:24,801 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomer en zomer in de winter en zomer in de winter en krompt in de winter en zomer in de winter en zomer in de winter en zomer in de winter en zomer in de winter en zomer in de winter en zomer groeien.
2025-05-30 03:19:24,801 - INFO - joeynmt.training - Example #4
2025-05-30 03:19:24,801 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:19:24,801 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:19:24,802 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:19:24,803 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:19:24,803 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:19:24,803 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdslag van de laatste 25 jaar gebeurd is.
2025-05-30 03:19:33,673 - INFO - joeynmt.training - Epoch   9, Step:    85100, Batch Loss:     1.155399, Batch Acc: 0.589735, Tokens per Sec:     7885, Lr: 0.000300
2025-05-30 03:19:42,894 - INFO - joeynmt.training - Epoch   9, Step:    85200, Batch Loss:     1.235161, Batch Acc: 0.583539, Tokens per Sec:     8004, Lr: 0.000300
2025-05-30 03:19:51,778 - INFO - joeynmt.training - Epoch   9, Step:    85300, Batch Loss:     1.250933, Batch Acc: 0.585903, Tokens per Sec:     7959, Lr: 0.000300
2025-05-30 03:20:00,752 - INFO - joeynmt.training - Epoch   9, Step:    85400, Batch Loss:     1.459094, Batch Acc: 0.592391, Tokens per Sec:     7841, Lr: 0.000300
2025-05-30 03:20:09,639 - INFO - joeynmt.training - Epoch   9, Step:    85500, Batch Loss:     1.173905, Batch Acc: 0.584226, Tokens per Sec:     8147, Lr: 0.000300
2025-05-30 03:20:09,639 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:20:09,640 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:20:55,139 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.13, acc:   0.55, generation: 45.4592[sec], evaluation: 0.0000[sec]
2025-05-30 03:20:55,317 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/83500.ckpt
2025-05-30 03:20:55,344 - INFO - joeynmt.training - Example #0
2025-05-30 03:20:55,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:20:55,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:20:55,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'ge@@', 's@@', 'la@@', 'gen', 'ha@@', 'd', 'ge@@', 's@@', 'la@@', 'gen', 'ha@@', 'd', 'ge@@', 'ha@@', 'd', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'voor', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'voor', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'voor', 'de', 'onder@@', 'ste', 'p@@', 'aar', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'deze', 'twe@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@']
2025-05-30 03:20:55,346 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:20:55,347 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:20:55,347 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te bekijken dat de arctische ijskappe ijskappe ijskappen, die voor de onderste 48 staten had gegeslagen had geslagen had gehad geslagen om 40 procent te geslagen voor 40 procent geslagen voor 40 procent geslagen voor de onderste paar jaar de grootte van deze twee miljoen jaar de groot
2025-05-30 03:20:55,347 - INFO - joeynmt.training - Example #1
2025-05-30 03:20:55,347 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:20:55,347 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:20:55,348 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'zo', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 're@@', 'c@@', 'en@@', 't,', 'om@@', 'dat', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'k@@', 'er', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:20:55,348 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:20:55,348 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:20:55,348 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet zo sterk genoeg de recent, omdat het specifieke probleem uit, omdat het niet de dikker van het ijs van het ijs van het ijs van het ijs laat zien.
2025-05-30 03:20:55,349 - INFO - joeynmt.training - Example #2
2025-05-30 03:20:55,349 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:20:55,349 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:20:55,349 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:20:55,350 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:20:55,350 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:20:55,350 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-30 03:20:55,350 - INFO - joeynmt.training - Example #3
2025-05-30 03:20:55,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:20:55,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:20:55,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-30 03:20:55,352 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:20:55,352 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:20:55,352 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomer in de zomer.
2025-05-30 03:20:55,352 - INFO - joeynmt.training - Example #4
2025-05-30 03:20:55,352 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:20:55,353 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:20:55,353 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'p@@', 'or@@', 't@@', 'a@@', 'k', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 03:20:55,354 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:20:55,354 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:20:55,354 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrappportak wat er gebeurd in de laatste 25 jaar.
2025-05-30 03:21:04,979 - INFO - joeynmt.training - Epoch   9, Step:    85600, Batch Loss:     1.193531, Batch Acc: 0.589792, Tokens per Sec:     7180, Lr: 0.000300
2025-05-30 03:21:13,911 - INFO - joeynmt.training - Epoch   9, Step:    85700, Batch Loss:     1.275421, Batch Acc: 0.590804, Tokens per Sec:     8160, Lr: 0.000300
2025-05-30 03:21:22,479 - INFO - joeynmt.training - Epoch   9, Step:    85800, Batch Loss:     1.105473, Batch Acc: 0.587414, Tokens per Sec:     8219, Lr: 0.000300
2025-05-30 03:21:31,061 - INFO - joeynmt.training - Epoch   9, Step:    85900, Batch Loss:     1.166730, Batch Acc: 0.593098, Tokens per Sec:     8559, Lr: 0.000300
2025-05-30 03:21:39,862 - INFO - joeynmt.training - Epoch   9, Step:    86000, Batch Loss:     1.374394, Batch Acc: 0.591617, Tokens per Sec:     8377, Lr: 0.000300
2025-05-30 03:21:39,862 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:21:39,863 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:22:21,042 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.15, acc:   0.55, generation: 41.1376[sec], evaluation: 0.0000[sec]
2025-05-30 03:22:21,062 - INFO - joeynmt.training - Example #0
2025-05-30 03:22:21,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:22:21,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:22:21,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'm@@', 'p@@', 't', 'te', 'be@@', 'ste@@', 'm@@', 'd', 'is.', '</s>']
2025-05-30 03:22:21,064 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:22:21,064 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:22:21,064 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verbeelden dat de arctische ijskappe ijskappen, die voor de onderste 48 staten, om 48 staten, om 48 staten, om 40 procent te gesmpt te bestemd is.
2025-05-30 03:22:21,064 - INFO - joeynmt.training - Example #1
2025-05-30 03:22:21,065 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:22:21,065 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:22:21,065 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'er', 'gen@@', 'oe@@', 'g', 'de', 'st@@', 'a@@', 'p', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'ge@@', 'd@@', 'ra@@', 'gen', 'van', 'de', 'ij@@', 's@@', 'ge@@', 'd@@', 'ra@@', 'gen', 'van', 'de', 'ij@@', 's@@', 'ge@@', 'z@@', 'et@@', '.', '</s>']
2025-05-30 03:22:21,066 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:22:21,066 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:22:21,066 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de dieper genoeg de stap van dit specifieke probleem uit, omdat het niet de dikke ijsgedragen van de ijsgedragen van de ijsgezet.
2025-05-30 03:22:21,066 - INFO - joeynmt.training - Example #2
2025-05-30 03:22:21,067 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:22:21,067 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:22:21,067 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'nen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:22:21,068 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:22:21,068 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:22:21,068 - INFO - joeynmt.training - 	Hypothesis: In zezekere zin is het arctische ijnen van onze wereldwijde klimaatsysteem.
2025-05-30 03:22:21,068 - INFO - joeynmt.training - Example #3
2025-05-30 03:22:21,069 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:22:21,069 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:22:21,069 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'r@@', 'on@@', 'd', 'en', 'z@@', 'r@@', 'on@@', 'd', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:22:21,070 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:22:21,070 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:22:21,070 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zrond en zrond de zomer.
2025-05-30 03:22:21,070 - INFO - joeynmt.training - Example #4
2025-05-30 03:22:21,070 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:22:21,070 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:22:21,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'be@@', 'eld', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:22:21,072 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:22:21,072 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:22:21,072 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsbeeld wat er gebeurd in de laatste 25 jaar gebeurd is.
2025-05-30 03:22:29,796 - INFO - joeynmt.training - Epoch   9, Step:    86100, Batch Loss:     1.376216, Batch Acc: 0.584262, Tokens per Sec:     8221, Lr: 0.000300
2025-05-30 03:22:38,547 - INFO - joeynmt.training - Epoch   9, Step:    86200, Batch Loss:     1.314465, Batch Acc: 0.589574, Tokens per Sec:     8104, Lr: 0.000300
2025-05-30 03:22:47,366 - INFO - joeynmt.training - Epoch   9, Step:    86300, Batch Loss:     1.412034, Batch Acc: 0.584376, Tokens per Sec:     8411, Lr: 0.000300
2025-05-30 03:22:56,240 - INFO - joeynmt.training - Epoch   9, Step:    86400, Batch Loss:     1.317753, Batch Acc: 0.593162, Tokens per Sec:     8043, Lr: 0.000300
2025-05-30 03:23:05,296 - INFO - joeynmt.training - Epoch   9, Step:    86500, Batch Loss:     1.409133, Batch Acc: 0.589734, Tokens per Sec:     7892, Lr: 0.000300
2025-05-30 03:23:05,296 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:23:05,297 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:23:49,512 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.16, acc:   0.55, generation: 44.1754[sec], evaluation: 0.0000[sec]
2025-05-30 03:23:49,520 - INFO - joeynmt.training - Example #0
2025-05-30 03:23:49,520 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:23:49,521 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:23:49,521 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'ste', 'st@@', 'at@@', 'en,', 'de', 'gro@@', 'ot@@', 'ste', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 03:23:49,522 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:23:49,522 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:23:49,522 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee getoond om te verkijken dat de arctische ijskappe ijskappe ijskappen, die voor de grootste staten, de grootste staten.
2025-05-30 03:23:49,522 - INFO - joeynmt.training - Example #1
2025-05-30 03:23:49,522 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:23:49,522 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:23:49,523 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'k@@', 't,', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'de', 'd@@', 'ie@@', 'p@@', 'e', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'ck@@', 's@@', '-@@', 'pro@@', 'ble@@', 'em', 'van', 'de', 'ij@@', 's@@', 'je@@', '.', '</s>']
2025-05-30 03:23:49,524 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:23:49,524 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:23:49,524 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt, niet genoeg de eerste van de diepe probleem uit, want het is niet de dicks-probleem van de ijsje.
2025-05-30 03:23:49,524 - INFO - joeynmt.training - Example #2
2025-05-30 03:23:49,524 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:23:49,524 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:23:49,524 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:23:49,526 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:23:49,528 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:23:49,528 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe klimaatsysteem.
2025-05-30 03:23:49,529 - INFO - joeynmt.training - Example #3
2025-05-30 03:23:49,529 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:23:49,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:23:49,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:23:49,530 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:23:49,530 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:23:49,530 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zroept in de zomer.
2025-05-30 03:23:49,530 - INFO - joeynmt.training - Example #4
2025-05-30 03:23:49,531 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:23:49,531 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:23:49,531 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'ge@@', 'vol@@', 'g', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'ort', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 03:23:49,532 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:23:49,532 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:23:49,532 - INFO - joeynmt.training - 	Hypothesis: De volgende gevolg die ik je laat zien is een tijdrapport van de laatste 25 jaar.
2025-05-30 03:23:58,299 - INFO - joeynmt.training - Epoch   9, Step:    86600, Batch Loss:     0.990088, Batch Acc: 0.589088, Tokens per Sec:     8446, Lr: 0.000300
2025-05-30 03:24:07,007 - INFO - joeynmt.training - Epoch   9, Step:    86700, Batch Loss:     1.324731, Batch Acc: 0.585816, Tokens per Sec:     8002, Lr: 0.000300
2025-05-30 03:24:15,597 - INFO - joeynmt.training - Epoch   9, Step:    86800, Batch Loss:     1.395904, Batch Acc: 0.580545, Tokens per Sec:     8111, Lr: 0.000300
2025-05-30 03:24:24,162 - INFO - joeynmt.training - Epoch   9, Step:    86900, Batch Loss:     1.383542, Batch Acc: 0.586718, Tokens per Sec:     8270, Lr: 0.000300
2025-05-30 03:24:32,990 - INFO - joeynmt.training - Epoch   9, Step:    87000, Batch Loss:     1.304208, Batch Acc: 0.584447, Tokens per Sec:     8031, Lr: 0.000300
2025-05-30 03:24:32,990 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:24:32,990 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:25:23,110 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.15, acc:   0.55, generation: 50.0760[sec], evaluation: 0.0000[sec]
2025-05-30 03:25:23,274 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/85000.ckpt
2025-05-30 03:25:23,289 - INFO - joeynmt.training - Example #0
2025-05-30 03:25:23,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:25:23,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:25:23,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'te@@', 'men@@', 't', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 03:25:23,291 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:25:23,292 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:25:23,292 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te bekijken dat de arctische ijskappe ijskappe ijskappartement van 48 staten had geslagen om 48 staten te geslagen om 40 procent te geslagen is.
2025-05-30 03:25:23,292 - INFO - joeynmt.training - Example #1
2025-05-30 03:25:23,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:25:23,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:25:23,292 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'e', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:25:23,293 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:25:23,293 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:25:23,294 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg genoeg de diepe probleem van dit speciale probleem uit, want het is niet de dik van de ijs van de ijskracht van de ijskracht van de ijskracht van de ijskracht van de ijskracht van het ijs laat zien.
2025-05-30 03:25:23,294 - INFO - joeynmt.training - Example #2
2025-05-30 03:25:23,294 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:25:23,294 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:25:23,294 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:25:23,295 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:25:23,295 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:25:23,295 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe ijskappelijke klimaatsysteem.
2025-05-30 03:25:23,295 - INFO - joeynmt.training - Example #3
2025-05-30 03:25:23,296 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:25:23,296 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:25:23,296 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:25:23,297 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:25:23,297 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:25:23,297 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich zomer in de zomer.
2025-05-30 03:25:23,297 - INFO - joeynmt.training - Example #4
2025-05-30 03:25:23,298 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:25:23,298 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:25:23,298 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'p@@', 'or@@', 'te@@', 'er@@', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:25:23,298 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:25:23,301 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:25:23,301 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdrappporteerde laatste 25 jaar gebeurd is.
2025-05-30 03:25:32,200 - INFO - joeynmt.training - Epoch   9, Step:    87100, Batch Loss:     1.388205, Batch Acc: 0.583298, Tokens per Sec:     7885, Lr: 0.000300
2025-05-30 03:25:41,083 - INFO - joeynmt.training - Epoch   9, Step:    87200, Batch Loss:     1.288410, Batch Acc: 0.585641, Tokens per Sec:     8196, Lr: 0.000300
2025-05-30 03:25:49,854 - INFO - joeynmt.training - Epoch   9, Step:    87300, Batch Loss:     1.201864, Batch Acc: 0.579803, Tokens per Sec:     8078, Lr: 0.000300
2025-05-30 03:25:58,555 - INFO - joeynmt.training - Epoch   9, Step:    87400, Batch Loss:     1.415007, Batch Acc: 0.581912, Tokens per Sec:     8101, Lr: 0.000300
2025-05-30 03:26:07,471 - INFO - joeynmt.training - Epoch   9, Step:    87500, Batch Loss:     1.178086, Batch Acc: 0.586220, Tokens per Sec:     8183, Lr: 0.000300
2025-05-30 03:26:07,472 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:26:07,472 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:26:53,638 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.13, acc:   0.55, generation: 46.1275[sec], evaluation: 0.0000[sec]
2025-05-30 03:26:53,785 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/87000.ckpt
2025-05-30 03:26:53,795 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit_bpe_smallvoc/87000.ckpt
2025-05-30 03:26:53,796 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe_smallvoc\87000.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit_bpe_smallvoc\\87000.ckpt')
2025-05-30 03:26:53,802 - INFO - joeynmt.training - Example #0
2025-05-30 03:26:53,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:26:53,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:26:53,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'd@@', 'ing', 'te', 'ver@@', 'ander@@', 'en', 'dat', 'de', 'ar@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 03:26:53,804 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:26:53,804 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:26:53,804 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verbeelding te veranderen dat de artische ijskappen, die voor de grootte van de onderste 48 staten, om 48 staten, om 48 staten, om 40 procent te geslagen om 40 procent te geslagen is.
2025-05-30 03:26:53,804 - INFO - joeynmt.training - Example #1
2025-05-30 03:26:53,805 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:26:53,805 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:26:53,805 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'c@@', 'o@@', 'de', 'd@@', 'ie@@', 'p@@', 'g@@', 'aan@@', 'de', 'd@@', 'ie@@', 'p@@', 'g@@', 'aan@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 03:26:53,806 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:26:53,806 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:26:53,806 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg genoeg de code diepgaande diepgaan, want het is niet de dikke ijsgebeurd.
2025-05-30 03:26:53,806 - INFO - joeynmt.training - Example #2
2025-05-30 03:26:53,806 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:26:53,807 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:26:53,807 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:26:53,808 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:26:53,808 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:26:53,808 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe hart van onze wereldwijde klimaatsysteem.
2025-05-30 03:26:53,808 - INFO - joeynmt.training - Example #3
2025-05-30 03:26:53,808 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:26:53,808 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:26:53,808 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er@@', 's', 'en', 'z@@', 'ich', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 03:26:53,809 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:26:53,809 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:26:53,809 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomers en zich zomers.
2025-05-30 03:26:53,810 - INFO - joeynmt.training - Example #4
2025-05-30 03:26:53,810 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:26:53,810 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:26:53,810 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:26:53,811 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:26:53,811 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:26:53,811 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdslag wat er in de afgelopen 25 jaar gebeurd is.
2025-05-30 03:27:02,434 - INFO - joeynmt.training - Epoch   9, Step:    87600, Batch Loss:     1.216801, Batch Acc: 0.584891, Tokens per Sec:     8213, Lr: 0.000300
2025-05-30 03:27:11,844 - INFO - joeynmt.training - Epoch   9, Step:    87700, Batch Loss:     1.672410, Batch Acc: 0.585931, Tokens per Sec:     7903, Lr: 0.000300
2025-05-30 03:27:19,892 - INFO - joeynmt.training - Epoch   9, Step:    87800, Batch Loss:     1.329231, Batch Acc: 0.580978, Tokens per Sec:     9019, Lr: 0.000300
2025-05-30 03:27:27,780 - INFO - joeynmt.training - Epoch   9, Step:    87900, Batch Loss:     1.263319, Batch Acc: 0.580767, Tokens per Sec:     8693, Lr: 0.000300
2025-05-30 03:27:35,687 - INFO - joeynmt.training - Epoch   9, Step:    88000, Batch Loss:     1.158152, Batch Acc: 0.585791, Tokens per Sec:     9247, Lr: 0.000300
2025-05-30 03:27:35,688 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:27:35,688 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:28:16,591 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.13, acc:   0.55, generation: 40.8618[sec], evaluation: 0.0000[sec]
2025-05-30 03:28:16,759 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/83000.ckpt
2025-05-30 03:28:16,775 - INFO - joeynmt.training - Example #0
2025-05-30 03:28:16,776 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:28:16,776 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:28:16,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'l@@', 'aat', 'zien', 'om', 'te', 'ver@@', 'm@@', 'inder@@', 'en', 'te', 'ver@@', 'k@@', 'eer@@', 'd', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'aat', 'in', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'lo@@', 'ten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'lo@@', 'ten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'lo@@', 'ten', 'te', 'ver@@', 'st@@', 'aan', 'voor', 'de', 'wer@@', 'eld', 'te', 'ver@@', 'st@@', 'or@@', 'ten.', '</s>']
2025-05-30 03:28:16,777 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:28:16,777 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:28:16,778 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia laat zien om te verminderen te verkeerd dat de arctische ijskappe ijskappe ijskapparaat in de grootte van 40 procent gesloten om 40 procent te geslagen om 40 procent te gesloten om 40 procent te gesloten te verstaan voor de wereld te verstorten.
2025-05-30 03:28:16,778 - INFO - joeynmt.training - Example #1
2025-05-30 03:28:16,778 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:28:16,779 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:28:16,779 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'e@@', 'cht', 'gen@@', 'oe@@', 'g', 'de', 'op@@', 'en@@', 'bar@@', 'e', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'ck@@', 'in@@', '.', '</s>']
2025-05-30 03:28:16,780 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:28:16,780 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:28:16,780 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet echt genoeg de openbare probleem van dit speciale probleem uit, want het is niet de dickin.
2025-05-30 03:28:16,780 - INFO - joeynmt.training - Example #2
2025-05-30 03:28:16,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:28:16,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:28:16,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:28:16,781 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:28:16,782 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:28:16,782 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe hart van onze wereldwijde klimaatsysteem.
2025-05-30 03:28:16,782 - INFO - joeynmt.training - Example #3
2025-05-30 03:28:16,782 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:28:16,782 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:28:16,782 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'st@@', 'r@@', 'on@@', 'd', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:28:16,783 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:28:16,784 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:28:16,784 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en strond in de zomer.
2025-05-30 03:28:16,784 - INFO - joeynmt.training - Example #4
2025-05-30 03:28:16,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:28:16,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:28:16,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'er@@', 's', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 03:28:16,785 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:28:16,786 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:28:16,786 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdrappers wat er in de laatste 25 jaar gebeurd.
2025-05-30 03:28:25,594 - INFO - joeynmt.training - Epoch   9, Step:    88100, Batch Loss:     1.385503, Batch Acc: 0.588248, Tokens per Sec:     7958, Lr: 0.000300
2025-05-30 03:28:34,381 - INFO - joeynmt.training - Epoch   9, Step:    88200, Batch Loss:     1.270137, Batch Acc: 0.585528, Tokens per Sec:     7991, Lr: 0.000300
2025-05-30 03:28:43,288 - INFO - joeynmt.training - Epoch   9, Step:    88300, Batch Loss:     1.310229, Batch Acc: 0.587684, Tokens per Sec:     8169, Lr: 0.000300
2025-05-30 03:28:52,241 - INFO - joeynmt.training - Epoch   9, Step:    88400, Batch Loss:     1.268548, Batch Acc: 0.586697, Tokens per Sec:     8196, Lr: 0.000300
2025-05-30 03:29:01,317 - INFO - joeynmt.training - Epoch   9, Step:    88500, Batch Loss:     1.335836, Batch Acc: 0.585860, Tokens per Sec:     7939, Lr: 0.000300
2025-05-30 03:29:01,328 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:29:01,329 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:29:49,905 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.42, ppl:   4.13, acc:   0.55, generation: 48.5348[sec], evaluation: 0.0000[sec]
2025-05-30 03:29:50,124 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/85500.ckpt
2025-05-30 03:29:50,142 - INFO - joeynmt.training - Example #0
2025-05-30 03:29:50,143 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:29:50,143 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:29:50,143 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'l@@', 'aten', 'zi@@', 'en,', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'i@@', 'ë@@', 'r@@', 'en', 'die', 'voor', 'de', 'wer@@', 'eld', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'be@@', 'gr@@', 'ij@@', 'p@@', 'en.', '</s>']
2025-05-30 03:29:50,144 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:29:50,144 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:29:50,144 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's laten zien, om te verbeelden dat de arctische ijiëren die voor de wereld drie miljoen jaar de grootte van de grootte van 48 staten had om 40 procent te begrijpen.
2025-05-30 03:29:50,145 - INFO - joeynmt.training - Example #1
2025-05-30 03:29:50,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:29:50,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:29:50,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'st@@', 'o@@', 'ff@@', 'en', 'dat', 'het', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:29:50,146 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:29:50,146 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:29:50,146 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg genoeg de snstoffen dat het speciale probleem uit, want het laat zien.
2025-05-30 03:29:50,147 - INFO - joeynmt.training - Example #2
2025-05-30 03:29:50,147 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:29:50,147 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:29:50,147 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 'i@@', 'ë@@', 'r@@', 's', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:29:50,148 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:29:50,148 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:29:50,148 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijiërs het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 03:29:50,148 - INFO - joeynmt.training - Example #3
2025-05-30 03:29:50,149 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:29:50,149 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:29:50,149 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:29:50,150 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:29:50,150 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:29:50,150 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroept in de zomer.
2025-05-30 03:29:50,150 - INFO - joeynmt.training - Example #4
2025-05-30 03:29:50,150 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:29:50,151 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:29:50,151 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 'te@@', 'er@@', 'de', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 03:29:50,152 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:29:50,152 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:29:50,152 - INFO - joeynmt.training - 	Hypothesis: De volgende die ik jullie laten zien, is een tijdrapporteerde de laatste 25 jaar gebeurd.
2025-05-30 03:29:58,769 - INFO - joeynmt.training - Epoch   9, Step:    88600, Batch Loss:     1.393247, Batch Acc: 0.585770, Tokens per Sec:     8026, Lr: 0.000210
2025-05-30 03:30:07,277 - INFO - joeynmt.training - Epoch   9, Step:    88700, Batch Loss:     1.373695, Batch Acc: 0.590000, Tokens per Sec:     8513, Lr: 0.000210
2025-05-30 03:30:16,425 - INFO - joeynmt.training - Epoch   9, Step:    88800, Batch Loss:     1.344620, Batch Acc: 0.590375, Tokens per Sec:     8071, Lr: 0.000210
2025-05-30 03:30:25,161 - INFO - joeynmt.training - Epoch   9, Step:    88900, Batch Loss:     1.307237, Batch Acc: 0.594110, Tokens per Sec:     8245, Lr: 0.000210
2025-05-30 03:30:33,997 - INFO - joeynmt.training - Epoch   9, Step:    89000, Batch Loss:     1.362644, Batch Acc: 0.585846, Tokens per Sec:     8033, Lr: 0.000210
2025-05-30 03:30:33,999 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:30:33,999 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:31:17,888 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.40, ppl:   4.05, acc:   0.56, generation: 43.8457[sec], evaluation: 0.0000[sec]
2025-05-30 03:31:17,889 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:31:18,063 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/84500.ckpt
2025-05-30 03:31:18,075 - INFO - joeynmt.training - Example #0
2025-05-30 03:31:18,075 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:31:18,076 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:31:18,076 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'in', 'de', 'V@@', 'S', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 03:31:18,077 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:31:18,077 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:31:18,077 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee miljoen jaar de arctische ijskappe ijskappen, die voor de grootte van de onderste 48 staten om 48 staten te geslagen om 48 staten te geslagen in de VS geslagen om 40 procent te geslagen is.
2025-05-30 03:31:18,077 - INFO - joeynmt.training - Example #1
2025-05-30 03:31:18,078 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:31:18,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:31:18,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'k@@', 'ra@@', 'cht@@', 'ig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ie@@', 'p@@', 'e', 'pro@@', 'ble@@', 'em', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:31:18,079 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:31:18,079 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:31:18,079 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de krachtigheid van dit speciale probleem uit, want het is niet de dikke diepe probleem laat zien.
2025-05-30 03:31:18,079 - INFO - joeynmt.training - Example #2
2025-05-30 03:31:18,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:31:18,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:31:18,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:31:18,080 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:31:18,080 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:31:18,080 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-30 03:31:18,080 - INFO - joeynmt.training - Example #3
2025-05-30 03:31:18,081 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:31:18,081 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:31:18,081 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'r@@', 'on@@', 'd', 'en', 'z@@', 'r@@', 'on@@', 'd', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:31:18,082 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:31:18,082 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:31:18,082 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zrond en zrond de zomer.
2025-05-30 03:31:18,083 - INFO - joeynmt.training - Example #4
2025-05-30 03:31:18,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:31:18,084 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:31:18,084 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'p@@', 'ort', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 03:31:18,085 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:31:18,085 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:31:18,085 - INFO - joeynmt.training - 	Hypothesis: De volgende die ik jullie laat zien is een tijdrappport van de laatste 25 jaar gebeurde in de laatste 25 jaar gebeurd.
2025-05-30 03:31:26,830 - INFO - joeynmt.training - Epoch   9, Step:    89100, Batch Loss:     1.157969, Batch Acc: 0.583616, Tokens per Sec:     8204, Lr: 0.000210
2025-05-30 03:31:35,499 - INFO - joeynmt.training - Epoch   9, Step:    89200, Batch Loss:     1.185480, Batch Acc: 0.585332, Tokens per Sec:     8211, Lr: 0.000210
2025-05-30 03:31:44,234 - INFO - joeynmt.training - Epoch   9, Step:    89300, Batch Loss:     1.029715, Batch Acc: 0.591316, Tokens per Sec:     8362, Lr: 0.000210
2025-05-30 03:31:52,816 - INFO - joeynmt.training - Epoch   9, Step:    89400, Batch Loss:     1.369367, Batch Acc: 0.593410, Tokens per Sec:     8515, Lr: 0.000210
2025-05-30 03:32:02,028 - INFO - joeynmt.training - Epoch   9, Step:    89500, Batch Loss:     1.079892, Batch Acc: 0.587787, Tokens per Sec:     7827, Lr: 0.000210
2025-05-30 03:32:02,028 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:32:02,029 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:32:47,443 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.40, ppl:   4.05, acc:   0.56, generation: 45.3715[sec], evaluation: 0.0000[sec]
2025-05-30 03:32:47,444 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:32:47,602 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/87500.ckpt
2025-05-30 03:32:47,616 - INFO - joeynmt.training - Example #0
2025-05-30 03:32:47,617 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:32:47,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:32:47,617 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'naar', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 's@@', 'n@@', 'el@@', 'we@@', 'g', 'te', 'k@@', 'rij@@', 'gen', 'voor', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'lo@@', 'ten', 'in', 'de', 'l@@', 'aat@@', 'ste', 'p@@', 'aar', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'z@@', 'oe@@', 'k', 'van', 'deze', 'twe@@', 'e', 'm@@', 'il@@', 'j@@']
2025-05-30 03:32:47,618 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:32:47,618 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:32:47,618 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen te bekijken naar de arctische ijskappen die voor de grootte van de grootte van de onderste 48 staten had om 48 staten te geslagen had om 40 procent te geslagen om 40 procent te snelweg te krijgen voor 40 procent gesloten in de laatste paar jaar de grootte van de onderzoek van deze twee milj
2025-05-30 03:32:47,618 - INFO - joeynmt.training - Example #1
2025-05-30 03:32:47,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:32:47,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:32:47,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'f@@', 'un@@', 'ct@@', 'ie', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'ck@@', 's.', '</s>']
2025-05-30 03:32:47,620 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:32:47,620 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:32:47,620 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de functie van dit speciale probleem uit, want het is niet de dikke dicks.
2025-05-30 03:32:47,620 - INFO - joeynmt.training - Example #2
2025-05-30 03:32:47,621 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:32:47,621 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:32:47,621 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:32:47,622 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:32:47,622 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:32:47,622 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijskape hart van onze wereldwijde klimaatsysteem.
2025-05-30 03:32:47,622 - INFO - joeynmt.training - Example #3
2025-05-30 03:32:47,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:32:47,623 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:32:47,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:32:47,623 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:32:47,624 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:32:47,624 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zich in de zomer.
2025-05-30 03:32:47,624 - INFO - joeynmt.training - Example #4
2025-05-30 03:32:47,624 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:32:47,625 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:32:47,625 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 03:32:47,626 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:32:47,626 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:32:47,626 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdperk van de laatste 25 jaar gebeurde in de afgelopen 25 jaar gebeurd.
2025-05-30 03:32:55,640 - INFO - joeynmt.training - Epoch   9, Step:    89600, Batch Loss:     1.318539, Batch Acc: 0.597675, Tokens per Sec:     8941, Lr: 0.000210
2025-05-30 03:33:03,305 - INFO - joeynmt.training - Epoch   9, Step:    89700, Batch Loss:     1.123377, Batch Acc: 0.592026, Tokens per Sec:     9056, Lr: 0.000210
2025-05-30 03:33:11,157 - INFO - joeynmt.training - Epoch   9, Step:    89800, Batch Loss:     1.145774, Batch Acc: 0.585957, Tokens per Sec:     9412, Lr: 0.000210
2025-05-30 03:33:19,552 - INFO - joeynmt.training - Epoch   9, Step:    89900, Batch Loss:     1.114238, Batch Acc: 0.591573, Tokens per Sec:     8530, Lr: 0.000210
2025-05-30 03:33:28,078 - INFO - joeynmt.training - Epoch   9, Step:    90000, Batch Loss:     1.175734, Batch Acc: 0.588912, Tokens per Sec:     8417, Lr: 0.000210
2025-05-30 03:33:28,079 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:33:28,079 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:34:12,729 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.03, acc:   0.56, generation: 44.6085[sec], evaluation: 0.0000[sec]
2025-05-30 03:34:12,730 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:34:12,900 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/88000.ckpt
2025-05-30 03:34:12,917 - INFO - joeynmt.training - Example #0
2025-05-30 03:34:12,919 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:34:12,919 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:34:12,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 's@@', 'la@@', 'gen', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'ru@@', 'm@@', 'p@@', 't.', '</s>']
2025-05-30 03:34:12,920 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:34:12,920 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:34:12,920 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te bekijken dat de arctische ijskappen, die voor de grootte van de grootte van de onderste 48 staten had om 48 staten had geslagen had om 40 procent te gesrumpt.
2025-05-30 03:34:12,921 - INFO - joeynmt.training - Example #1
2025-05-30 03:34:12,921 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:34:12,921 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:34:12,921 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'st@@', 'a@@', 'd', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ie@@', 'p@@', 'er', 'uit@@', '.', '</s>']
2025-05-30 03:34:12,922 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:34:12,922 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:34:12,922 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet sterk genoeg de stad van dit speciale probleem uit, want het is niet de dikke dieper uit.
2025-05-30 03:34:12,922 - INFO - joeynmt.training - Example #2
2025-05-30 03:34:12,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:34:12,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:34:12,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'ig@@', 'en@@', 'lijk', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en.', '</s>']
2025-05-30 03:34:12,924 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:34:12,924 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:34:12,924 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigenlijk is de arctische ijskappe ijskappe ijskappen.
2025-05-30 03:34:12,925 - INFO - joeynmt.training - Example #3
2025-05-30 03:34:12,925 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:34:12,925 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:34:12,925 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:34:12,926 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:34:12,926 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:34:12,926 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich zomer.
2025-05-30 03:34:12,926 - INFO - joeynmt.training - Example #4
2025-05-30 03:34:12,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:34:12,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:34:12,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'te@@', 'm@@', 'p@@', 'o', 'van', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 03:34:12,928 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:34:12,928 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:34:12,928 - INFO - joeynmt.training - 	Hypothesis: De volgende die ik jullie laat zien is een tempo van wat er in de laatste 25 jaar gebeurd.
2025-05-30 03:34:21,568 - INFO - joeynmt.training - Epoch   9, Step:    90100, Batch Loss:     1.292638, Batch Acc: 0.588488, Tokens per Sec:     8162, Lr: 0.000210
2025-05-30 03:34:30,323 - INFO - joeynmt.training - Epoch   9, Step:    90200, Batch Loss:     1.197069, Batch Acc: 0.591882, Tokens per Sec:     8203, Lr: 0.000210
2025-05-30 03:34:38,852 - INFO - joeynmt.training - Epoch   9, Step:    90300, Batch Loss:     1.145196, Batch Acc: 0.591650, Tokens per Sec:     8731, Lr: 0.000210
2025-05-30 03:34:47,163 - INFO - joeynmt.training - Epoch   9, Step:    90400, Batch Loss:     1.239484, Batch Acc: 0.593434, Tokens per Sec:     9025, Lr: 0.000210
2025-05-30 03:34:55,466 - INFO - joeynmt.training - Epoch   9, Step:    90500, Batch Loss:     1.401644, Batch Acc: 0.596820, Tokens per Sec:     8692, Lr: 0.000210
2025-05-30 03:34:55,467 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:34:55,467 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:35:40,339 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.02, acc:   0.56, generation: 44.8370[sec], evaluation: 0.0000[sec]
2025-05-30 03:35:40,340 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:35:40,494 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/88500.ckpt
2025-05-30 03:35:40,510 - INFO - joeynmt.training - Example #0
2025-05-30 03:35:40,511 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:35:40,511 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:35:40,511 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'onder@@', 'ste', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 's@@', 'la@@', 'gen', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 03:35:40,512 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:35:40,512 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:35:40,512 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde ik deze twee dia om te beginnen, dat de arctische ijskappen die voor de onderste van de onderste 48 staten had om 48 staten had geslagen van de onderste 48 staten had om 48 staten had 40 procent geslagen is.
2025-05-30 03:35:40,512 - INFO - joeynmt.training - Example #1
2025-05-30 03:35:40,513 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:35:40,513 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:35:40,513 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'aar@@', 'to@@', 'e', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:35:40,514 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:35:40,514 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:35:40,514 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg genoeg de snaartoe van dit specifieke probleem uit, omdat het niet de dikke dikke van het ijs van het ijs van het ijs van het ijs laat zien.
2025-05-30 03:35:40,514 - INFO - joeynmt.training - Example #2
2025-05-30 03:35:40,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:35:40,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:35:40,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:35:40,516 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:35:40,516 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:35:40,516 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-30 03:35:40,516 - INFO - joeynmt.training - Example #3
2025-05-30 03:35:40,516 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:35:40,517 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:35:40,517 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:35:40,518 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:35:40,518 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:35:40,518 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomer.
2025-05-30 03:35:40,518 - INFO - joeynmt.training - Example #4
2025-05-30 03:35:40,518 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:35:40,519 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:35:40,519 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'di@@', 'a', 'dat', 'ik', 'jullie', 'een', 'tij@@', 'd@@', 's@@', 'di@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:35:40,519 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:35:40,520 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:35:40,520 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsdia dat ik jullie een tijdsdien 25 jaar is gebeurd is.
2025-05-30 03:35:49,319 - INFO - joeynmt.training - Epoch   9, Step:    90600, Batch Loss:     1.152466, Batch Acc: 0.587242, Tokens per Sec:     8038, Lr: 0.000210
2025-05-30 03:35:58,116 - INFO - joeynmt.training - Epoch   9, Step:    90700, Batch Loss:     1.385710, Batch Acc: 0.590204, Tokens per Sec:     8364, Lr: 0.000210
2025-05-30 03:36:06,835 - INFO - joeynmt.training - Epoch   9, Step:    90800, Batch Loss:     1.270197, Batch Acc: 0.594407, Tokens per Sec:     8298, Lr: 0.000210
2025-05-30 03:36:15,336 - INFO - joeynmt.training - Epoch   9, Step:    90900, Batch Loss:     1.369003, Batch Acc: 0.594479, Tokens per Sec:     8792, Lr: 0.000210
2025-05-30 03:36:24,152 - INFO - joeynmt.training - Epoch   9, Step:    91000, Batch Loss:     1.232317, Batch Acc: 0.589165, Tokens per Sec:     8244, Lr: 0.000210
2025-05-30 03:36:24,153 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:36:24,153 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:37:10,133 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.01, acc:   0.56, generation: 45.9401[sec], evaluation: 0.0000[sec]
2025-05-30 03:37:10,134 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:37:10,295 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/84000.ckpt
2025-05-30 03:37:10,312 - INFO - joeynmt.training - Example #0
2025-05-30 03:37:10,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:37:10,313 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:37:10,313 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'to@@', 'on@@', 'de', 'om', 'te', 'be@@', 'k@@', 'ijk@@', 'en,', 'om', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e,', 'die', 'voor', 'de', 'onder@@', 'ste', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'van', '4@@', '8', 'st@@', 'aten', 'ge@@', 's@@', 'lo@@', 'ten', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ver@@', 'm@@', 'inder@@', 'en.', '</s>']
2025-05-30 03:37:10,314 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:37:10,314 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:37:10,315 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia toonde om te bekijken, om te begrijpen dat de arctische ijskape, die voor de onderste drie miljoen jaar de grootte van de onderste 48 staten had om 48 staten te geslagen van 48 staten gesloten om 48 staten te verminderen.
2025-05-30 03:37:10,315 - INFO - joeynmt.training - Example #1
2025-05-30 03:37:10,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:37:10,315 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:37:10,315 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'st@@', 'a@@', 'p', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 'z@@', 'er', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:37:10,316 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:37:10,316 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:37:10,316 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg genoeg de stap van dit specifieke probleem uit, omdat het niet de dikke ijzer van het ijs laat zien.
2025-05-30 03:37:10,317 - INFO - joeynmt.training - Example #2
2025-05-30 03:37:10,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:37:10,317 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:37:10,317 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:37:10,318 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:37:10,318 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:37:10,318 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe hart van ons wereldwijde klimaatsysteem.
2025-05-30 03:37:10,318 - INFO - joeynmt.training - Example #3
2025-05-30 03:37:10,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:37:10,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:37:10,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:37:10,319 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:37:10,320 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:37:10,320 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomer.
2025-05-30 03:37:10,320 - INFO - joeynmt.training - Example #4
2025-05-30 03:37:10,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:37:10,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:37:10,320 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'die', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 03:37:10,321 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:37:10,322 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:37:10,322 - INFO - joeynmt.training - 	Hypothesis: De volgende die ik jullie laat zien is een tijdje die laatste 25 jaar is gebeurd in de laatste 25 jaar.
2025-05-30 03:37:18,745 - INFO - joeynmt.training - Epoch   9, Step:    91100, Batch Loss:     1.202864, Batch Acc: 0.589214, Tokens per Sec:     8146, Lr: 0.000210
2025-05-30 03:37:27,165 - INFO - joeynmt.training - Epoch   9, Step:    91200, Batch Loss:     1.306068, Batch Acc: 0.589764, Tokens per Sec:     8443, Lr: 0.000210
2025-05-30 03:37:35,789 - INFO - joeynmt.training - Epoch   9, Step:    91300, Batch Loss:     1.232531, Batch Acc: 0.593169, Tokens per Sec:     8662, Lr: 0.000210
2025-05-30 03:37:44,073 - INFO - joeynmt.training - Epoch   9, Step:    91400, Batch Loss:     1.365847, Batch Acc: 0.594930, Tokens per Sec:     8525, Lr: 0.000210
2025-05-30 03:37:52,904 - INFO - joeynmt.training - Epoch   9, Step:    91500, Batch Loss:     1.220043, Batch Acc: 0.586024, Tokens per Sec:     8086, Lr: 0.000210
2025-05-30 03:37:52,905 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:37:52,905 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:38:32,505 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.01, acc:   0.56, generation: 39.5664[sec], evaluation: 0.0000[sec]
2025-05-30 03:38:32,506 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:38:32,664 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/89000.ckpt
2025-05-30 03:38:32,681 - INFO - joeynmt.training - Example #0
2025-05-30 03:38:32,682 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:38:32,682 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:38:32,682 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'en', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'naar', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'st@@', 'ar@@', 't', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ge@@', 'd@@', 're@@', 'ven', 'is.', '</s>']
2025-05-30 03:38:32,683 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:38:32,683 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:38:32,684 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dien getoond om te bekijken naar de arctische ijskappen die voor de arctische ijskappen die 48 staten had gestart om 48 staten had om 48 staten om 48 staten om 48 staten te gedreven is.
2025-05-30 03:38:32,684 - INFO - joeynmt.training - Example #1
2025-05-30 03:38:32,684 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:38:32,684 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:38:32,684 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'n@@', 'el', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'is.', '</s>']
2025-05-30 03:38:32,685 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:38:32,685 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:38:32,686 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de snel van het specifieke probleem van dit specifieke probleem uit, omdat het niet de dikke van het ijs van het ijs van het ijs is.
2025-05-30 03:38:32,686 - INFO - joeynmt.training - Example #2
2025-05-30 03:38:32,686 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:38:32,686 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:38:32,686 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:38:32,687 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:38:32,687 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:38:32,687 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 03:38:32,687 - INFO - joeynmt.training - Example #3
2025-05-30 03:38:32,688 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:38:32,688 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:38:32,688 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:38:32,688 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:38:32,689 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:38:32,689 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zomer.
2025-05-30 03:38:32,689 - INFO - joeynmt.training - Example #4
2025-05-30 03:38:32,689 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:38:32,689 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:38:32,689 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 't@@', 'on@@', 'en', 'is', 'een', 'tij@@', 'd@@', 'per@@', 'k', 'van', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 03:38:32,690 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:38:32,690 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:38:32,691 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie tonen is een tijdperk van wat er in de afgelopen 25 jaar is.
2025-05-30 03:38:40,533 - INFO - joeynmt.training - Epoch   9, Step:    91600, Batch Loss:     1.169635, Batch Acc: 0.591958, Tokens per Sec:     8802, Lr: 0.000210
2025-05-30 03:38:48,418 - INFO - joeynmt.training - Epoch   9, Step:    91700, Batch Loss:     1.044417, Batch Acc: 0.592909, Tokens per Sec:     9135, Lr: 0.000210
2025-05-30 03:38:56,314 - INFO - joeynmt.training - Epoch   9, Step:    91800, Batch Loss:     1.304625, Batch Acc: 0.589704, Tokens per Sec:     9118, Lr: 0.000210
2025-05-30 03:39:05,070 - INFO - joeynmt.training - Epoch   9, Step:    91900, Batch Loss:     1.328693, Batch Acc: 0.589472, Tokens per Sec:     8637, Lr: 0.000210
2025-05-30 03:39:13,585 - INFO - joeynmt.training - Epoch   9, Step:    92000, Batch Loss:     1.414865, Batch Acc: 0.592443, Tokens per Sec:     8716, Lr: 0.000210
2025-05-30 03:39:13,586 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:39:13,586 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:39:55,133 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.01, acc:   0.56, generation: 41.5144[sec], evaluation: 0.0000[sec]
2025-05-30 03:39:55,134 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:39:55,299 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/89500.ckpt
2025-05-30 03:39:55,315 - INFO - joeynmt.training - Example #0
2025-05-30 03:39:55,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:39:55,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:39:55,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'at@@', 'u@@', 'ur', 'ha@@', 'd', 'ge@@', 'st@@', 'aat', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'st@@', 'eld', 'te', 'k@@', 're@@', 'gen', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ge@@', 'st@@', 'el@@', 'p@@', 't', 'te', 'ge@@', 'st@@', 'ro@@', 'm@@', 'p@@', 't', 'is.', '</s>']
2025-05-30 03:39:55,317 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:39:55,318 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:39:55,318 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen te begrijpen dat de arctische ijskappe ijskapparatuur had gestaat om 48 staten had gesteld te kregen om 48 staten te gestelpt te gestrompt is.
2025-05-30 03:39:55,318 - INFO - joeynmt.training - Example #1
2025-05-30 03:39:55,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:39:55,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:39:55,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'f@@', 'ant@@', 'a@@', 'st@@', 'isch', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:39:55,319 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:39:55,319 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:39:55,319 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de fantastisch van dit speciale probleem uit, omdat het niet de dikke van het ijs van het ijs van het ijs van het ijs van het ijs laat zien.
2025-05-30 03:39:55,320 - INFO - joeynmt.training - Example #2
2025-05-30 03:39:55,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:39:55,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:39:55,320 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'aat', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:39:55,321 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:39:55,321 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:39:55,321 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe ijskapparaat van onze wereldwijde klimaatsysteem.
2025-05-30 03:39:55,321 - INFO - joeynmt.training - Example #3
2025-05-30 03:39:55,321 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:39:55,321 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:39:55,321 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:39:55,321 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:39:55,322 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:39:55,322 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zomer in de zomer.
2025-05-30 03:39:55,322 - INFO - joeynmt.training - Example #4
2025-05-30 03:39:55,322 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:39:55,322 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:39:55,322 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 't@@', 'ige', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 03:39:55,325 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:39:55,325 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:39:55,325 - INFO - joeynmt.training - 	Hypothesis: De volgende die ik jullie laten zien is een tijdrapportige wat er in de laatste 25 jaar.
2025-05-30 03:40:03,828 - INFO - joeynmt.training - Epoch   9, Step:    92100, Batch Loss:     1.337583, Batch Acc: 0.592621, Tokens per Sec:     8310, Lr: 0.000210
2025-05-30 03:40:12,347 - INFO - joeynmt.training - Epoch   9, Step:    92200, Batch Loss:     1.516368, Batch Acc: 0.592340, Tokens per Sec:     8361, Lr: 0.000210
2025-05-30 03:40:20,830 - INFO - joeynmt.training - Epoch   9, Step:    92300, Batch Loss:     1.322918, Batch Acc: 0.589915, Tokens per Sec:     8235, Lr: 0.000210
2025-05-30 03:40:29,880 - INFO - joeynmt.training - Epoch   9, Step:    92400, Batch Loss:     1.241220, Batch Acc: 0.591068, Tokens per Sec:     7703, Lr: 0.000210
2025-05-30 03:40:38,741 - INFO - joeynmt.training - Epoch   9, Step:    92500, Batch Loss:     1.290587, Batch Acc: 0.593842, Tokens per Sec:     8288, Lr: 0.000210
2025-05-30 03:40:38,742 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:40:38,742 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:41:25,092 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.00, acc:   0.56, generation: 46.3084[sec], evaluation: 0.0000[sec]
2025-05-30 03:41:25,093 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:41:25,243 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/90000.ckpt
2025-05-30 03:41:25,259 - INFO - joeynmt.training - Example #0
2025-05-30 03:41:25,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:41:25,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:41:25,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'l@@', 'aten', 'to@@', 'on@@', 'de', 'om', 'te', 'be@@', 'se@@', 'ff@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 's@@', 'lo@@', 'ten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'st@@', 'el@@', 'd.', '</s>']
2025-05-30 03:41:25,260 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:41:25,261 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:41:25,261 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's laten toonde om te beseffen dat de arctische ijskappen, die voor de grootte van de onderste 48 staten had om 48 staten had gesloten had om 48 staten had gesteld.
2025-05-30 03:41:25,261 - INFO - joeynmt.training - Example #1
2025-05-30 03:41:25,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:41:25,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:41:25,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ing', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'op@@', 'er@@', 'at@@', 'ie@@', 'f', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 't.', '</s>']
2025-05-30 03:41:25,262 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:41:25,262 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:41:25,262 - INFO - joeynmt.training - 	Hypothesis: Maar dit ding niet sterk genoeg de operatief van dit specifieke probleem uit, want het is niet de dikke ijskracht.
2025-05-30 03:41:25,263 - INFO - joeynmt.training - Example #2
2025-05-30 03:41:25,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:41:25,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:41:25,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:41:25,264 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:41:25,264 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:41:25,264 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 03:41:25,264 - INFO - joeynmt.training - Example #3
2025-05-30 03:41:25,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:41:25,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:41:25,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:41:25,265 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:41:25,265 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:41:25,266 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich in de zomer en zich in de zomer.
2025-05-30 03:41:25,266 - INFO - joeynmt.training - Example #4
2025-05-30 03:41:25,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:41:25,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:41:25,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'p@@', 'p@@', 'en@@', 'ti@@', 'ë@@', 'l@@', 'e', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 03:41:25,268 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:41:25,268 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:41:25,268 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdslappentiële jaar.
2025-05-30 03:41:33,955 - INFO - joeynmt.training - Epoch   9, Step:    92600, Batch Loss:     1.380460, Batch Acc: 0.588444, Tokens per Sec:     8092, Lr: 0.000210
2025-05-30 03:41:42,633 - INFO - joeynmt.training - Epoch   9, Step:    92700, Batch Loss:     1.220028, Batch Acc: 0.588724, Tokens per Sec:     7970, Lr: 0.000210
2025-05-30 03:41:51,336 - INFO - joeynmt.training - Epoch   9, Step:    92800, Batch Loss:     1.265849, Batch Acc: 0.598145, Tokens per Sec:     8387, Lr: 0.000210
2025-05-30 03:41:59,886 - INFO - joeynmt.training - Epoch   9, Step:    92900, Batch Loss:     1.441670, Batch Acc: 0.591615, Tokens per Sec:     8411, Lr: 0.000210
2025-05-30 03:42:08,573 - INFO - joeynmt.training - Epoch   9, Step:    93000, Batch Loss:     1.209337, Batch Acc: 0.592941, Tokens per Sec:     8473, Lr: 0.000210
2025-05-30 03:42:08,574 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:42:08,574 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:42:55,041 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.00, acc:   0.56, generation: 46.4289[sec], evaluation: 0.0000[sec]
2025-05-30 03:42:55,042 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:42:55,590 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/90500.ckpt
2025-05-30 03:42:55,604 - INFO - joeynmt.training - Example #0
2025-05-30 03:42:55,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:42:55,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:42:55,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a', 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'k@@', 'eer@@', 'd', 'te', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 03:42:55,606 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:42:55,606 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:42:55,607 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia getoond om te verkeerd te kijken dat de arctische ijskappen, die voor de grootte van de grootte van de onderste 48 staten had om 48 staten had geslagen om 48 staten had geslagen om 40 procent te geslagen is.
2025-05-30 03:42:55,607 - INFO - joeynmt.training - Example #1
2025-05-30 03:42:55,607 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:42:55,607 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:42:55,607 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'zo', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 's@@', 'le@@', 'ch@@', 'ts', 'gen@@', 'oe@@', 'g', 'de', 'st@@', 'a@@', 'd', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'er', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'zi@@', 'en.', '</s>']
2025-05-30 03:42:55,608 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:42:55,608 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:42:55,608 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet zo sterk genoeg de slechts genoeg de stad van dit specifieke probleem uit, omdat het niet de dikke ijsker van het ijs van het ijs zien.
2025-05-30 03:42:55,608 - INFO - joeynmt.training - Example #2
2025-05-30 03:42:55,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:42:55,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:42:55,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:42:55,608 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:42:55,608 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:42:55,609 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 03:42:55,609 - INFO - joeynmt.training - Example #3
2025-05-30 03:42:55,609 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:42:55,609 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:42:55,609 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:42:55,609 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:42:55,609 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:42:55,609 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroept in de zomer.
2025-05-30 03:42:55,609 - INFO - joeynmt.training - Example #4
2025-05-30 03:42:55,611 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:42:55,611 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:42:55,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'dat', 'er', 'een', 'tij@@', 'd@@', 'je', 'dat', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:42:55,611 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:42:55,611 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:42:55,611 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdje dat er een tijdje dat de laatste 25 jaar gebeurd is.
2025-05-30 03:43:03,949 - INFO - joeynmt.training - Epoch   9, Step:    93100, Batch Loss:     1.265899, Batch Acc: 0.592649, Tokens per Sec:     8274, Lr: 0.000210
2025-05-30 03:43:12,738 - INFO - joeynmt.training - Epoch   9, Step:    93200, Batch Loss:     1.130513, Batch Acc: 0.591678, Tokens per Sec:     8021, Lr: 0.000210
2025-05-30 03:43:21,434 - INFO - joeynmt.training - Epoch   9, Step:    93300, Batch Loss:     1.047125, Batch Acc: 0.596067, Tokens per Sec:     8351, Lr: 0.000210
2025-05-30 03:43:30,098 - INFO - joeynmt.training - Epoch   9, Step:    93400, Batch Loss:     1.417341, Batch Acc: 0.593290, Tokens per Sec:     8443, Lr: 0.000210
2025-05-30 03:43:38,919 - INFO - joeynmt.training - Epoch   9, Step:    93500, Batch Loss:     1.347918, Batch Acc: 0.589087, Tokens per Sec:     8171, Lr: 0.000210
2025-05-30 03:43:38,920 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:43:38,920 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:44:17,827 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.38, ppl:   3.98, acc:   0.56, generation: 38.8731[sec], evaluation: 0.0000[sec]
2025-05-30 03:44:17,828 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:44:17,980 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/91000.ckpt
2025-05-30 03:44:17,994 - INFO - joeynmt.training - Example #0
2025-05-30 03:44:17,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:44:17,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:44:17,995 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ijk@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 's', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'st@@', 'el@@', 'd.', '</s>']
2025-05-30 03:44:17,996 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:44:17,996 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:44:17,996 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te bekijken, dat de arctische ijskappe ijskape ijskappe ijskappels van 48 staten had om 48 staten had gesteld.
2025-05-30 03:44:17,996 - INFO - joeynmt.training - Example #1
2025-05-30 03:44:17,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:44:17,997 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:44:17,997 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'e', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'zi@@', 'en.', '</s>']
2025-05-30 03:44:17,997 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:44:17,997 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:44:17,997 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de diepe probleem van dit specifieke probleem uit, omdat het niet de dikke dikke ijs van het ijs zien.
2025-05-30 03:44:17,997 - INFO - joeynmt.training - Example #2
2025-05-30 03:44:17,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:44:17,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:44:17,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:44:17,998 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:44:17,998 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:44:17,998 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 03:44:17,998 - INFO - joeynmt.training - Example #3
2025-05-30 03:44:17,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:44:17,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:44:17,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'e@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:44:17,999 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:44:17,999 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:44:17,999 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schroept in de zomer.
2025-05-30 03:44:17,999 - INFO - joeynmt.training - Example #4
2025-05-30 03:44:17,999 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:44:17,999 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:44:17,999 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 03:44:18,000 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:44:18,000 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:44:18,000 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdje van wat er gebeurd in de laatste 25 jaar.
2025-05-30 03:44:25,832 - INFO - joeynmt.training - Epoch   9, Step:    93600, Batch Loss:     1.119316, Batch Acc: 0.596909, Tokens per Sec:     8989, Lr: 0.000210
2025-05-30 03:44:33,622 - INFO - joeynmt.training - Epoch   9, Step:    93700, Batch Loss:     1.235213, Batch Acc: 0.599306, Tokens per Sec:     9220, Lr: 0.000210
2025-05-30 03:44:42,329 - INFO - joeynmt.training - Epoch   9, Step:    93800, Batch Loss:     1.327830, Batch Acc: 0.596267, Tokens per Sec:     8276, Lr: 0.000210
2025-05-30 03:44:51,063 - INFO - joeynmt.training - Epoch   9, Step:    93900, Batch Loss:     1.262901, Batch Acc: 0.591712, Tokens per Sec:     8300, Lr: 0.000210
2025-05-30 03:44:59,566 - INFO - joeynmt.training - Epoch   9, Step:    94000, Batch Loss:     1.319467, Batch Acc: 0.589301, Tokens per Sec:     8469, Lr: 0.000210
2025-05-30 03:44:59,567 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:44:59,567 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:45:47,086 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.38, ppl:   3.99, acc:   0.56, generation: 47.4810[sec], evaluation: 0.0000[sec]
2025-05-30 03:45:47,239 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/91500.ckpt
2025-05-30 03:45:47,253 - INFO - joeynmt.training - Example #0
2025-05-30 03:45:47,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:45:47,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:45:47,254 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'gr@@', 'ij@@', 'p@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 's', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'st@@', 'el@@', 'd.', '</s>']
2025-05-30 03:45:47,255 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:45:47,255 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:45:47,255 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te begrijpen, dat de arctische ijskappe ijskappe ijskappe ijskappels van 48 staten had om 48 staten had gesteld.
2025-05-30 03:45:47,256 - INFO - joeynmt.training - Example #1
2025-05-30 03:45:47,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:45:47,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:45:47,256 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 're@@', 's@@', 'ul@@', 't@@', 'aat', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'er', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:45:47,257 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:45:47,257 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:45:47,257 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de resultaat van dit specifieke probleem uit, omdat het niet de diker laat zien.
2025-05-30 03:45:47,257 - INFO - joeynmt.training - Example #2
2025-05-30 03:45:47,258 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:45:47,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:45:47,258 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'is', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:45:47,259 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:45:47,259 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:45:47,259 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp is het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 03:45:47,259 - INFO - joeynmt.training - Example #3
2025-05-30 03:45:47,259 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:45:47,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:45:47,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:45:47,260 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:45:47,260 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:45:47,261 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomer.
2025-05-30 03:45:47,261 - INFO - joeynmt.training - Example #4
2025-05-30 03:45:47,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:45:47,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:45:47,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'van', 'wat', 'er', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 03:45:47,262 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:45:47,262 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:45:47,262 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdslag van wat er in de laatste 25 jaar is gebeurd in de laatste 25 jaar is.
2025-05-30 03:45:55,925 - INFO - joeynmt.training - Epoch   9, Step:    94100, Batch Loss:     1.365677, Batch Acc: 0.589549, Tokens per Sec:     8094, Lr: 0.000210
2025-05-30 03:46:04,691 - INFO - joeynmt.training - Epoch   9, Step:    94200, Batch Loss:     1.329163, Batch Acc: 0.595877, Tokens per Sec:     8229, Lr: 0.000210
2025-05-30 03:46:13,368 - INFO - joeynmt.training - Epoch   9, Step:    94300, Batch Loss:     1.390877, Batch Acc: 0.594127, Tokens per Sec:     8303, Lr: 0.000210
2025-05-30 03:46:22,080 - INFO - joeynmt.training - Epoch   9, Step:    94400, Batch Loss:     1.243162, Batch Acc: 0.589769, Tokens per Sec:     8318, Lr: 0.000210
2025-05-30 03:46:30,826 - INFO - joeynmt.training - Epoch   9, Step:    94500, Batch Loss:     1.486050, Batch Acc: 0.592307, Tokens per Sec:     8005, Lr: 0.000210
2025-05-30 03:46:30,826 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:46:30,826 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:47:17,170 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.00, acc:   0.56, generation: 46.3099[sec], evaluation: 0.0000[sec]
2025-05-30 03:47:17,327 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/92000.ckpt
2025-05-30 03:47:17,342 - INFO - joeynmt.training - Example #0
2025-05-30 03:47:17,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:47:17,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:47:17,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijk', 'ha@@', 'd', 'ge@@', 'st@@', 'eld', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'voor', '4@@', '8', 'st@@', 'aten', 'te', 'ge@@', 'st@@', 'eld', 'is.', '</s>']
2025-05-30 03:47:17,344 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:47:17,344 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:47:17,344 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te verbeelden dat de arctische ijskappe ijskappe ijskappe ijskappelijk had gesteld om 48 staten had om 48 staten had om 48 staten voor 48 staten te gesteld is.
2025-05-30 03:47:17,344 - INFO - joeynmt.training - Example #1
2025-05-30 03:47:17,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:47:17,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:47:17,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'deze', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's@@', 'k@@', 'er', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'ch@@', 't.', '</s>']
2025-05-30 03:47:17,346 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:47:17,346 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:47:17,346 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste van deze specifieke probleem uit, omdat het niet de dikke probleem uit, omdat het niet de dikke van de ijsker van de ijskracht.
2025-05-30 03:47:17,346 - INFO - joeynmt.training - Example #2
2025-05-30 03:47:17,346 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:47:17,346 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:47:17,347 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:47:17,347 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:47:17,348 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:47:17,349 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slagen van onze wereldwijde klimaatsysteem.
2025-05-30 03:47:17,349 - INFO - joeynmt.training - Example #3
2025-05-30 03:47:17,349 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:47:17,349 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:47:17,349 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:47:17,350 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:47:17,350 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:47:17,350 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich in de winter en zich in de zomer.
2025-05-30 03:47:17,350 - INFO - joeynmt.training - Example #4
2025-05-30 03:47:17,350 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:47:17,351 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:47:17,351 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ver@@', 'n@@', 'am@@', 'en', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:47:17,351 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:47:17,351 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:47:17,351 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsvernamen wat er gebeurd in de afgelopen 25 jaar gebeurd is.
2025-05-30 03:47:25,935 - INFO - joeynmt.training - Epoch   9, Step:    94600, Batch Loss:     1.240667, Batch Acc: 0.592379, Tokens per Sec:     8274, Lr: 0.000210
2025-05-30 03:47:34,446 - INFO - joeynmt.training - Epoch   9, Step:    94700, Batch Loss:     1.179707, Batch Acc: 0.587440, Tokens per Sec:     8340, Lr: 0.000210
2025-05-30 03:47:42,982 - INFO - joeynmt.training - Epoch   9, Step:    94800, Batch Loss:     1.150291, Batch Acc: 0.584615, Tokens per Sec:     8240, Lr: 0.000210
2025-05-30 03:47:51,183 - INFO - joeynmt.training - Epoch   9, Step:    94900, Batch Loss:     1.322193, Batch Acc: 0.598663, Tokens per Sec:     8997, Lr: 0.000210
2025-05-30 03:47:59,544 - INFO - joeynmt.training - Epoch   9, Step:    95000, Batch Loss:     1.239628, Batch Acc: 0.585304, Tokens per Sec:     8636, Lr: 0.000210
2025-05-30 03:47:59,545 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:47:59,545 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:48:41,784 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.38, ppl:   3.98, acc:   0.56, generation: 42.1941[sec], evaluation: 0.0000[sec]
2025-05-30 03:48:41,788 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 03:48:41,967 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/92500.ckpt
2025-05-30 03:48:41,981 - INFO - joeynmt.training - Example #0
2025-05-30 03:48:41,982 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:48:41,982 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:48:41,982 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijk', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'at@@', 'en,', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'at@@', 'en.', '</s>']
2025-05-30 03:48:41,983 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:48:41,983 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:48:41,983 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te verkijken dat de arctische ijskappe ijskappe ijskappelijk had om 48 staten om 48 staten, om 48 staten om 48 staten om 48 staten om 48 staten.
2025-05-30 03:48:41,984 - INFO - joeynmt.training - Example #1
2025-05-30 03:48:41,984 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:48:41,984 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:48:41,984 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'le@@', 'k', 'gen@@', 'oe@@', 'g', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'niet', 'de', 'di@@', 'k@@', 'er', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:48:41,985 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:48:41,985 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:48:41,985 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de eerste plek genoeg van dit specifieke probleem uit, want het niet de diker van het ijs laat zien.
2025-05-30 03:48:41,985 - INFO - joeynmt.training - Example #2
2025-05-30 03:48:41,986 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:48:41,986 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:48:41,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:48:41,986 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:48:41,987 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:48:41,987 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 03:48:41,987 - INFO - joeynmt.training - Example #3
2025-05-30 03:48:41,987 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:48:41,987 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:48:41,987 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'r@@', 'on@@', 'd', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:48:41,988 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:48:41,988 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:48:41,988 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zrond in de zomer.
2025-05-30 03:48:41,988 - INFO - joeynmt.training - Example #4
2025-05-30 03:48:41,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:48:41,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:48:41,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ver@@', 'z@@', 'am@@', 'el@@', 'ing', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 03:48:41,990 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:48:41,990 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:48:41,990 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsverzameling van wat er gebeurde in de afgelopen 25 jaar gebeurd.
2025-05-30 03:48:50,544 - INFO - joeynmt.training - Epoch   9, Step:    95100, Batch Loss:     1.232380, Batch Acc: 0.594956, Tokens per Sec:     8273, Lr: 0.000210
2025-05-30 03:48:59,516 - INFO - joeynmt.training - Epoch   9, Step:    95200, Batch Loss:     1.236373, Batch Acc: 0.591473, Tokens per Sec:     8262, Lr: 0.000210
2025-05-30 03:49:08,240 - INFO - joeynmt.training - Epoch   9, Step:    95300, Batch Loss:     1.191294, Batch Acc: 0.586830, Tokens per Sec:     8523, Lr: 0.000210
2025-05-30 03:49:16,813 - INFO - joeynmt.training - Epoch   9, Step:    95400, Batch Loss:     1.339304, Batch Acc: 0.588859, Tokens per Sec:     8356, Lr: 0.000210
2025-05-30 03:49:23,280 - INFO - joeynmt.training - Epoch   9: total training loss 13582.46
2025-05-30 03:49:23,281 - INFO - joeynmt.training - EPOCH 10
2025-05-30 03:49:25,564 - INFO - joeynmt.training - Epoch  10, Step:    95500, Batch Loss:     1.385559, Batch Acc: 0.605739, Tokens per Sec:     8188, Lr: 0.000210
2025-05-30 03:49:25,564 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:49:25,565 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:50:05,534 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.38, ppl:   3.99, acc:   0.56, generation: 39.9286[sec], evaluation: 0.0000[sec]
2025-05-30 03:50:05,680 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/93000.ckpt
2025-05-30 03:50:05,695 - INFO - joeynmt.training - Example #0
2025-05-30 03:50:05,696 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:50:05,696 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:50:05,696 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 's', 'van', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'lan@@', 'den', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '8', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 03:50:05,697 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:50:05,697 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:50:05,697 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te bekijken dat de arctische ijskappe ijskape ijskappe ijskappels van 48 staten om 48 staten om 48 staten om 48 landen te geslagen om 48 procent te geslagen is.
2025-05-30 03:50:05,698 - INFO - joeynmt.training - Example #1
2025-05-30 03:50:05,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:50:05,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:50:05,698 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'zo', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'f@@', 'ant@@', 'ig@@', 'heid', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'er@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:50:05,699 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:50:05,699 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:50:05,699 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet zo sterk genoeg de fantigheid van dit specifieke probleem uit, omdat het niet de dickers van het ijs laat zien.
2025-05-30 03:50:05,700 - INFO - joeynmt.training - Example #2
2025-05-30 03:50:05,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:50:05,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:50:05,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'p@@', 'ende', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:50:05,701 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:50:05,701 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:50:05,701 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slapende hart van ons wereldwijde klimaatsysteem.
2025-05-30 03:50:05,701 - INFO - joeynmt.training - Example #3
2025-05-30 03:50:05,702 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:50:05,702 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:50:05,702 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-30 03:50:05,703 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:50:05,703 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:50:05,703 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich zomer in de winter en zomer in de winter en zich in de winter en zich verzamelen.
2025-05-30 03:50:05,703 - INFO - joeynmt.training - Example #4
2025-05-30 03:50:05,703 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:50:05,703 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:50:05,703 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 't@@', 'ige', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 03:50:05,703 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:50:05,704 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:50:05,704 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrapportige wat er gebeurd in de afgelopen 25 jaar is.
2025-05-30 03:50:13,595 - INFO - joeynmt.training - Epoch  10, Step:    95600, Batch Loss:     1.079109, Batch Acc: 0.603673, Tokens per Sec:     8863, Lr: 0.000210
2025-05-30 03:50:21,820 - INFO - joeynmt.training - Epoch  10, Step:    95700, Batch Loss:     1.242302, Batch Acc: 0.601663, Tokens per Sec:     8762, Lr: 0.000210
2025-05-30 03:50:30,410 - INFO - joeynmt.training - Epoch  10, Step:    95800, Batch Loss:     1.366985, Batch Acc: 0.603426, Tokens per Sec:     8314, Lr: 0.000210
2025-05-30 03:50:38,782 - INFO - joeynmt.training - Epoch  10, Step:    95900, Batch Loss:     1.151046, Batch Acc: 0.602507, Tokens per Sec:     8720, Lr: 0.000210
2025-05-30 03:50:47,138 - INFO - joeynmt.training - Epoch  10, Step:    96000, Batch Loss:     1.163572, Batch Acc: 0.608037, Tokens per Sec:     8696, Lr: 0.000210
2025-05-30 03:50:47,138 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:50:47,139 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:51:28,625 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.00, acc:   0.56, generation: 41.4431[sec], evaluation: 0.0000[sec]
2025-05-30 03:51:28,640 - INFO - joeynmt.training - Example #0
2025-05-30 03:51:28,641 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:51:28,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:51:28,642 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'sch@@', 'aal', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', 'van', 'de', 'onder@@', 'ste', 'van', 'de', 'onder@@', 'ste', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-30 03:51:28,643 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:51:28,643 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:51:28,643 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te verbeelden dat de arctische ijskappen die voor de schaal van de grootte van de onderste van de onderste van de onderste van de onderste 48 staten om 48 staten om 48 staten om 48 staten te verzamelen.
2025-05-30 03:51:28,643 - INFO - joeynmt.training - Example #1
2025-05-30 03:51:28,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:51:28,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:51:28,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dat', 'is', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'p@@', 'un@@', 't', 'van', 'de', 'eer@@', 'ste', 'pro@@', 'ble@@', 'em', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'de', 'ij@@', 's', 'van', 'de', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:51:28,645 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:51:28,645 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:51:28,645 - INFO - joeynmt.training - 	Hypothesis: Maar dat is niet genoeg de eerste punt van de eerste probleem van dit specifieke probleem uit, want het is niet de dikke van de ijs van de ijs van het ijs laat zien.
2025-05-30 03:51:28,646 - INFO - joeynmt.training - Example #2
2025-05-30 03:51:28,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:51:28,646 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:51:28,646 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', ',', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:51:28,647 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:51:28,647 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:51:28,647 - INFO - joeynmt.training - 	Hypothesis: In zekere zin, is de arctische ijskapp het slagen van ons wereldwijde klimaatsysteem.
2025-05-30 03:51:28,647 - INFO - joeynmt.training - Example #3
2025-05-30 03:51:28,648 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:51:28,648 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:51:28,648 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:51:28,649 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:51:28,649 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:51:28,649 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgen in de zomer.
2025-05-30 03:51:28,649 - INFO - joeynmt.training - Example #4
2025-05-30 03:51:28,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:51:28,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:51:28,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 'ter@@', 'n@@', 'e', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 03:51:28,650 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:51:28,650 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:51:28,651 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdrapporterne wat er gebeurde in de laatste 25 jaar.
2025-05-30 03:51:37,689 - INFO - joeynmt.training - Epoch  10, Step:    96100, Batch Loss:     1.171672, Batch Acc: 0.598458, Tokens per Sec:     7873, Lr: 0.000210
2025-05-30 03:51:46,422 - INFO - joeynmt.training - Epoch  10, Step:    96200, Batch Loss:     1.251613, Batch Acc: 0.607981, Tokens per Sec:     8191, Lr: 0.000210
2025-05-30 03:51:54,979 - INFO - joeynmt.training - Epoch  10, Step:    96300, Batch Loss:     1.145325, Batch Acc: 0.606196, Tokens per Sec:     8526, Lr: 0.000210
2025-05-30 03:52:03,565 - INFO - joeynmt.training - Epoch  10, Step:    96400, Batch Loss:     1.233467, Batch Acc: 0.601448, Tokens per Sec:     8365, Lr: 0.000210
2025-05-30 03:52:12,099 - INFO - joeynmt.training - Epoch  10, Step:    96500, Batch Loss:     1.174775, Batch Acc: 0.599621, Tokens per Sec:     8463, Lr: 0.000210
2025-05-30 03:52:12,099 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:52:12,100 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:53:02,716 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.01, acc:   0.56, generation: 50.5739[sec], evaluation: 0.0000[sec]
2025-05-30 03:53:02,724 - INFO - joeynmt.training - Example #0
2025-05-30 03:53:02,725 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:53:02,725 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:53:02,725 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'l@@', 'aat', 'zien', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ver@@', 'm@@', 'inder@@', 'en.', '</s>']
2025-05-30 03:53:02,726 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:53:02,726 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:53:02,727 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's laat zien om te bekijken dat de arctische ijskappen die voor de grootte van de onderste 48 staten voor de grootte van de onderste 48 staten om 48 staten om 48 staten om 48 staten om 48 staten te verminderen.
2025-05-30 03:53:02,727 - INFO - joeynmt.training - Example #1
2025-05-30 03:53:02,727 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:53:02,727 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:53:02,727 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'het', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:53:02,728 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:53:02,728 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:53:02,728 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo sterk genoeg de eerste van het specifiek van dit specifieke probleem uit, omdat het niet de dicks van het ijs laat zien.
2025-05-30 03:53:02,729 - INFO - joeynmt.training - Example #2
2025-05-30 03:53:02,730 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:53:02,730 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:53:02,731 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:53:02,731 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:53:02,732 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:53:02,732 - INFO - joeynmt.training - 	Hypothesis: In zekere ijskappe ijskappe ijskappe ijskappe ijskappelijke klimaatsysteem.
2025-05-30 03:53:02,732 - INFO - joeynmt.training - Example #3
2025-05-30 03:53:02,732 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:53:02,733 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:53:02,733 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'r@@', 'on@@', 'd@@', 'om', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'r@@', 'on@@', 'd@@', 'om', 'te', 'ver@@', 'm@@', 'inder@@', 'en.', '</s>']
2025-05-30 03:53:02,734 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:53:02,734 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:53:02,734 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zrimpt in de winter en zrondom in de winter en zrondom te verminderen.
2025-05-30 03:53:02,734 - INFO - joeynmt.training - Example #4
2025-05-30 03:53:02,734 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:53:02,734 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:53:02,734 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 03:53:02,736 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:53:02,736 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:53:02,736 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsgebeurde in de laatste 25 jaar gebeurd is.
2025-05-30 03:53:11,204 - INFO - joeynmt.training - Epoch  10, Step:    96600, Batch Loss:     1.110091, Batch Acc: 0.599915, Tokens per Sec:     8553, Lr: 0.000210
2025-05-30 03:53:19,479 - INFO - joeynmt.training - Epoch  10, Step:    96700, Batch Loss:     0.973775, Batch Acc: 0.602797, Tokens per Sec:     8753, Lr: 0.000210
2025-05-30 03:53:27,813 - INFO - joeynmt.training - Epoch  10, Step:    96800, Batch Loss:     1.220892, Batch Acc: 0.599239, Tokens per Sec:     8857, Lr: 0.000210
2025-05-30 03:53:35,764 - INFO - joeynmt.training - Epoch  10, Step:    96900, Batch Loss:     1.051353, Batch Acc: 0.599579, Tokens per Sec:     8914, Lr: 0.000210
2025-05-30 03:53:43,677 - INFO - joeynmt.training - Epoch  10, Step:    97000, Batch Loss:     1.327830, Batch Acc: 0.604397, Tokens per Sec:     9048, Lr: 0.000210
2025-05-30 03:53:43,678 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:53:43,678 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:54:22,310 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.01, acc:   0.56, generation: 38.5923[sec], evaluation: 0.0000[sec]
2025-05-30 03:54:22,320 - INFO - joeynmt.training - Example #0
2025-05-30 03:54:22,321 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:54:22,321 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:54:22,321 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'on@@', 'der', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'st@@', 'or@@', 'm@@', 'p@@', 't.', '</s>']
2025-05-30 03:54:22,322 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:54:22,322 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:54:22,322 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te bekijken dat de arctische ijskappen die voor onder de grootte van de grootte van de grootte van de grootte van de onderkant van de onderkant van 48 staten om 40 procent te gestormpt.
2025-05-30 03:54:22,322 - INFO - joeynmt.training - Example #1
2025-05-30 03:54:22,323 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:54:22,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:54:22,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'zo', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'p@@', 'o@@', 'sit@@', 'ie@@', 'f', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 'in@@', '.', '</s>']
2025-05-30 03:54:22,324 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:54:22,325 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:54:22,325 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet zo sterk genoeg de positief van dit specifieke probleem uit, omdat het niet de dickin.
2025-05-30 03:54:22,325 - INFO - joeynmt.training - Example #2
2025-05-30 03:54:22,326 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:54:22,326 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:54:22,326 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:54:22,327 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:54:22,327 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:54:22,327 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 03:54:22,327 - INFO - joeynmt.training - Example #3
2025-05-30 03:54:22,327 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:54:22,328 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:54:22,328 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gt', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:54:22,329 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:54:22,329 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:54:22,329 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgt in de zomer.
2025-05-30 03:54:22,329 - INFO - joeynmt.training - Example #4
2025-05-30 03:54:22,330 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:54:22,330 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:54:22,330 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'dat', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 03:54:22,331 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:54:22,331 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:54:22,331 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een tijdslag dat de laatste 25 jaar is gebeurd in de laatste 25 jaar is.
2025-05-30 03:54:31,265 - INFO - joeynmt.training - Epoch  10, Step:    97100, Batch Loss:     1.195407, Batch Acc: 0.605682, Tokens per Sec:     8166, Lr: 0.000210
2025-05-30 03:54:40,279 - INFO - joeynmt.training - Epoch  10, Step:    97200, Batch Loss:     1.245476, Batch Acc: 0.605288, Tokens per Sec:     7791, Lr: 0.000210
2025-05-30 03:54:49,275 - INFO - joeynmt.training - Epoch  10, Step:    97300, Batch Loss:     1.167984, Batch Acc: 0.604829, Tokens per Sec:     8040, Lr: 0.000210
2025-05-30 03:54:57,850 - INFO - joeynmt.training - Epoch  10, Step:    97400, Batch Loss:     1.216603, Batch Acc: 0.601964, Tokens per Sec:     8491, Lr: 0.000210
2025-05-30 03:55:06,491 - INFO - joeynmt.training - Epoch  10, Step:    97500, Batch Loss:     1.308811, Batch Acc: 0.597065, Tokens per Sec:     8390, Lr: 0.000210
2025-05-30 03:55:06,493 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:55:06,493 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:55:46,096 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.00, acc:   0.56, generation: 39.5661[sec], evaluation: 0.0000[sec]
2025-05-30 03:55:46,103 - INFO - joeynmt.training - Example #0
2025-05-30 03:55:46,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:55:46,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:55:46,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'zi@@', 'en,', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'd@@', 'ro@@', 'm@@', 'p@@', 't.', '</s>']
2025-05-30 03:55:46,105 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:55:46,105 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:55:46,106 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's gezien, om te beginnen te bekijken dat de arctische ijskappen die voor de grootte van de onderste drie miljoen jaar de grootte van de onderste 48 staten om 40 procent te gedrompt.
2025-05-30 03:55:46,106 - INFO - joeynmt.training - Example #1
2025-05-30 03:55:46,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:55:46,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:55:46,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'g@@', 'aan@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'k', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 's@@', 'h@@', 'ul@@', 'p@@', 'm@@', 'id@@', 'del@@', 'en', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht@@', 'ig@@', 'heid', 'van', 'het', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht@@', 'ig@@', 'heid', 'van', 'het', 'ij@@', 's@@', 'le@@', 'ch@@', 'ts', 'van', 'de', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht']
2025-05-30 03:55:46,107 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:55:46,107 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:55:46,108 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de diepgaande van dit specifiek is dat het niet de dickshulpmiddelen van de ijskracht van de ijskracht van de ijskracht van het ijskracht van het ijskracht van het ijskracht van het ijskracht van het ijskracht van het ijskracht van het ijskrachtigheid van het ijskrachtigheid van het ijslechts van de ijskracht
2025-05-30 03:55:46,108 - INFO - joeynmt.training - Example #2
2025-05-30 03:55:46,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:55:46,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:55:46,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:55:46,109 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:55:46,109 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:55:46,109 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slagen van onze wereldwijde klimaatsysteem.
2025-05-30 03:55:46,110 - INFO - joeynmt.training - Example #3
2025-05-30 03:55:46,110 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:55:46,111 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:55:46,111 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:55:46,112 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:55:46,112 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:55:46,112 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en schrompt in de zomer.
2025-05-30 03:55:46,112 - INFO - joeynmt.training - Example #4
2025-05-30 03:55:46,113 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:55:46,113 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:55:46,113 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'dat', 'ik', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'is', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 03:55:46,114 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:55:46,114 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:55:46,114 - INFO - joeynmt.training - 	Hypothesis: De volgende die ik jullie laat zien is een tijdslag dat ik een tijdslag is in de laatste 25 jaar is.
2025-05-30 03:55:53,724 - INFO - joeynmt.training - Epoch  10, Step:    97600, Batch Loss:     1.253279, Batch Acc: 0.600543, Tokens per Sec:     9229, Lr: 0.000210
2025-05-30 03:56:01,280 - INFO - joeynmt.training - Epoch  10, Step:    97700, Batch Loss:     1.423000, Batch Acc: 0.595338, Tokens per Sec:     9175, Lr: 0.000210
2025-05-30 03:56:09,528 - INFO - joeynmt.training - Epoch  10, Step:    97800, Batch Loss:     1.417756, Batch Acc: 0.597212, Tokens per Sec:     8656, Lr: 0.000210
2025-05-30 03:56:17,997 - INFO - joeynmt.training - Epoch  10, Step:    97900, Batch Loss:     1.323378, Batch Acc: 0.598914, Tokens per Sec:     8594, Lr: 0.000210
2025-05-30 03:56:26,511 - INFO - joeynmt.training - Epoch  10, Step:    98000, Batch Loss:     1.400988, Batch Acc: 0.608528, Tokens per Sec:     8420, Lr: 0.000210
2025-05-30 03:56:26,516 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:56:26,516 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:57:07,492 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.39, ppl:   4.01, acc:   0.56, generation: 40.9370[sec], evaluation: 0.0000[sec]
2025-05-30 03:57:07,499 - INFO - joeynmt.training - Example #0
2025-05-30 03:57:07,500 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:57:07,500 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:57:07,500 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'onder@@', 'ste', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'on@@', 'der', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'st@@', 'ro@@', 'm@@', 'p@@', 't.', '</s>']
2025-05-30 03:57:07,501 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:57:07,501 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:57:07,501 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te bekijken dat de arctische ijskappen, die voor de onderste ijskappen, die voor onder 48 staten had om 48 staten om 48 staten om 48 staten om 40 procent te gestrompt.
2025-05-30 03:57:07,502 - INFO - joeynmt.training - Example #1
2025-05-30 03:57:07,502 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:57:07,502 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:57:07,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'gen@@', 'oe@@', 'g', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'g@@', 'aan@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:57:07,504 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:57:07,504 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:57:07,504 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet genoeg genoeg de diepgaande van dit specifieke probleem uit, omdat het niet de dikke ijs laat zien.
2025-05-30 03:57:07,504 - INFO - joeynmt.training - Example #2
2025-05-30 03:57:07,505 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:57:07,505 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:57:07,505 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en.', '</s>']
2025-05-30 03:57:07,506 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:57:07,506 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:57:07,506 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe ijskappen.
2025-05-30 03:57:07,506 - INFO - joeynmt.training - Example #3
2025-05-30 03:57:07,506 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:57:07,508 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:57:07,508 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'g@@', 'v@@', 'al', 'in', 'de', 'z@@', 'om@@', 'er@@', '.', '</s>']
2025-05-30 03:57:07,508 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:57:07,508 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:57:07,509 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zorgval in de zomer.
2025-05-30 03:57:07,509 - INFO - joeynmt.training - Example #4
2025-05-30 03:57:07,509 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:57:07,509 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:57:07,509 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 03:57:07,510 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:57:07,510 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:57:07,510 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdslag gebeurde in de afgelopen 25 jaar is.
2025-05-30 03:57:16,182 - INFO - joeynmt.training - Epoch  10, Step:    98100, Batch Loss:     1.268605, Batch Acc: 0.596785, Tokens per Sec:     8536, Lr: 0.000210
2025-05-30 03:57:24,832 - INFO - joeynmt.training - Epoch  10, Step:    98200, Batch Loss:     1.117520, Batch Acc: 0.600277, Tokens per Sec:     8500, Lr: 0.000210
2025-05-30 03:57:33,362 - INFO - joeynmt.training - Epoch  10, Step:    98300, Batch Loss:     1.085957, Batch Acc: 0.601705, Tokens per Sec:     8332, Lr: 0.000210
2025-05-30 03:57:42,204 - INFO - joeynmt.training - Epoch  10, Step:    98400, Batch Loss:     1.209327, Batch Acc: 0.603499, Tokens per Sec:     8579, Lr: 0.000210
2025-05-30 03:57:51,408 - INFO - joeynmt.training - Epoch  10, Step:    98500, Batch Loss:     1.333430, Batch Acc: 0.604253, Tokens per Sec:     7951, Lr: 0.000210
2025-05-30 03:57:51,409 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:57:51,409 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:58:32,178 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.38, ppl:   3.99, acc:   0.56, generation: 40.7231[sec], evaluation: 0.0000[sec]
2025-05-30 03:58:32,358 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/94500.ckpt
2025-05-30 03:58:32,372 - INFO - joeynmt.training - Example #0
2025-05-30 03:58:32,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:58:32,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:58:32,373 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'om', 'te', 'beg@@', 'in@@', 'nen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ge@@', 'st@@', 'or@@', 'm@@', 'p@@', 't', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'd.', '</s>']
2025-05-30 03:58:32,374 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:58:32,374 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:58:32,374 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen, om te beginnen dat de arctische ijskappen, die voor de grootte van de onderste 48 staten had om 48 staten te gestormpt te verzameld.
2025-05-30 03:58:32,374 - INFO - joeynmt.training - Example #1
2025-05-30 03:58:32,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:58:32,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:58:32,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'de', 'st@@', 'a@@', 'p', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:58:32,375 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:58:32,376 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:58:32,376 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de eerste van de stap van dit specifieke probleem uit, omdat het niet de dikke ijs laat zien.
2025-05-30 03:58:32,376 - INFO - joeynmt.training - Example #2
2025-05-30 03:58:32,376 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:58:32,376 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:58:32,376 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en.', '</s>']
2025-05-30 03:58:32,376 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:58:32,377 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:58:32,377 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappe ijskappe ijskappen.
2025-05-30 03:58:32,377 - INFO - joeynmt.training - Example #3
2025-05-30 03:58:32,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:58:32,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:58:32,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:58:32,377 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:58:32,377 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:58:32,377 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomer.
2025-05-30 03:58:32,378 - INFO - joeynmt.training - Example #4
2025-05-30 03:58:32,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:58:32,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:58:32,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 03:58:32,379 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:58:32,379 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:58:32,379 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdslag van wat er gebeurd in de afgelopen 25 jaar is.
2025-05-30 03:58:40,874 - INFO - joeynmt.training - Epoch  10, Step:    98600, Batch Loss:     1.420497, Batch Acc: 0.601669, Tokens per Sec:     7954, Lr: 0.000210
2025-05-30 03:58:49,172 - INFO - joeynmt.training - Epoch  10, Step:    98700, Batch Loss:     1.214586, Batch Acc: 0.594191, Tokens per Sec:     8714, Lr: 0.000210
2025-05-30 03:58:57,537 - INFO - joeynmt.training - Epoch  10, Step:    98800, Batch Loss:     1.125313, Batch Acc: 0.597429, Tokens per Sec:     8724, Lr: 0.000210
2025-05-30 03:59:05,574 - INFO - joeynmt.training - Epoch  10, Step:    98900, Batch Loss:     1.141618, Batch Acc: 0.597218, Tokens per Sec:     9304, Lr: 0.000210
2025-05-30 03:59:14,042 - INFO - joeynmt.training - Epoch  10, Step:    99000, Batch Loss:     1.352124, Batch Acc: 0.604035, Tokens per Sec:     8516, Lr: 0.000210
2025-05-30 03:59:14,043 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 03:59:14,043 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 03:59:55,798 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.38, ppl:   3.98, acc:   0.56, generation: 41.7096[sec], evaluation: 0.0000[sec]
2025-05-30 03:59:55,958 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/98500.ckpt
2025-05-30 03:59:55,967 - INFO - joeynmt.helpers - delete C:/Users/gabri/OneDrive/Documents/GitHub/mt-exercise-4/models/transformer_enit_bpe_smallvoc/98500.ckpt
2025-05-30 03:59:55,968 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe_smallvoc\98500.ckpt but file does not exist. ([WinError 2] Das System kann die angegebene Datei nicht finden: 'C:\\Users\\gabri\\OneDrive\\Documents\\GitHub\\mt-exercise-4\\models\\transformer_enit_bpe_smallvoc\\98500.ckpt')
2025-05-30 03:59:55,972 - INFO - joeynmt.training - Example #0
2025-05-30 03:59:55,973 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 03:59:55,973 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 03:59:55,973 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'te', 'be@@', 'se@@', 'ff@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'kan@@', 't', 'van', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ma@@', 'ken.', '</s>']
2025-05-30 03:59:55,974 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 03:59:55,974 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 03:59:55,974 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen, te beseffen dat de arctische ijskapen die de grootte van de grootte van de onderkant van de grootte van 48 staten om 48 staten om 48 staten te maken.
2025-05-30 03:59:55,974 - INFO - joeynmt.training - Example #1
2025-05-30 03:59:55,974 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 03:59:55,974 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 03:59:55,974 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'eer@@', 'ste', 'van', 'deze', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'ck@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 03:59:55,975 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 03:59:55,976 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 03:59:55,976 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de eerste van deze specifieke probleem uit, want het is niet de dicks van het ijs laat zien.
2025-05-30 03:59:55,976 - INFO - joeynmt.training - Example #2
2025-05-30 03:59:55,976 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 03:59:55,976 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 03:59:55,976 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijke', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 03:59:55,977 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 03:59:55,977 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 03:59:55,977 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskappe ijskappelijke hart van ons wereldwijde klimaatsysteem.
2025-05-30 03:59:55,978 - INFO - joeynmt.training - Example #3
2025-05-30 03:59:55,978 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 03:59:55,978 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 03:59:55,978 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 03:59:55,979 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 03:59:55,979 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 03:59:55,979 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich in de zomer.
2025-05-30 03:59:55,979 - INFO - joeynmt.training - Example #4
2025-05-30 03:59:55,980 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 03:59:55,980 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 03:59:55,980 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'de', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 03:59:55,980 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 03:59:55,980 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 03:59:55,980 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een tijdslag van wat er gebeurde in de laatste 25 jaar is.
2025-05-30 04:00:04,697 - INFO - joeynmt.training - Epoch  10, Step:    99100, Batch Loss:     1.266751, Batch Acc: 0.599252, Tokens per Sec:     8144, Lr: 0.000210
2025-05-30 04:00:13,400 - INFO - joeynmt.training - Epoch  10, Step:    99200, Batch Loss:     1.054042, Batch Acc: 0.597519, Tokens per Sec:     8484, Lr: 0.000210
2025-05-30 04:00:22,205 - INFO - joeynmt.training - Epoch  10, Step:    99300, Batch Loss:     1.314780, Batch Acc: 0.597212, Tokens per Sec:     7995, Lr: 0.000210
2025-05-30 04:00:30,813 - INFO - joeynmt.training - Epoch  10, Step:    99400, Batch Loss:     1.199757, Batch Acc: 0.601682, Tokens per Sec:     8287, Lr: 0.000210
2025-05-30 04:00:39,464 - INFO - joeynmt.training - Epoch  10, Step:    99500, Batch Loss:     1.091745, Batch Acc: 0.595717, Tokens per Sec:     8477, Lr: 0.000210
2025-05-30 04:00:39,464 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:00:39,464 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:01:23,127 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.38, ppl:   3.99, acc:   0.56, generation: 43.6264[sec], evaluation: 0.0000[sec]
2025-05-30 04:01:23,288 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/95500.ckpt
2025-05-30 04:01:23,302 - INFO - joeynmt.training - Example #0
2025-05-30 04:01:23,302 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:01:23,303 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:01:23,303 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'en', 'die', 'voor', 'on@@', 'der', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 04:01:23,303 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:01:23,303 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:01:23,303 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te verbeelden dat de arctische ijskape ijskapen die voor onder drie miljoen jaar de grootte van de onderste 48 staten om 48 staten om 48 staten om 48 staten om 40 procent te gebeuren.
2025-05-30 04:01:23,303 - INFO - joeynmt.training - Example #1
2025-05-30 04:01:23,304 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:01:23,304 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:01:23,304 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'e', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ie@@', 'p@@', 'e', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 04:01:23,304 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:01:23,304 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:01:23,305 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de diepe probleem uit, want het is het niet de dikke diepe probleem uit, want het laat zien.
2025-05-30 04:01:23,305 - INFO - joeynmt.training - Example #2
2025-05-30 04:01:23,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:01:23,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:01:23,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 04:01:23,305 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:01:23,306 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:01:23,306 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp van ons wereldwijde klimaatsysteem.
2025-05-30 04:01:23,306 - INFO - joeynmt.training - Example #3
2025-05-30 04:01:23,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:01:23,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:01:23,306 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'om@@', 'er@@', 's.', '</s>']
2025-05-30 04:01:23,306 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:01:23,306 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:01:23,306 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich zomers.
2025-05-30 04:01:23,306 - INFO - joeynmt.training - Example #4
2025-05-30 04:01:23,306 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:01:23,306 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:01:23,308 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'ge@@', 'ven', 'wat', 'er', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 04:01:23,308 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:01:23,308 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:01:23,308 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdsgeven wat er in de afgelopen 25 jaar is.
2025-05-30 04:01:30,971 - INFO - joeynmt.training - Epoch  10, Step:    99600, Batch Loss:     1.161928, Batch Acc: 0.599390, Tokens per Sec:     9117, Lr: 0.000147
2025-05-30 04:01:38,722 - INFO - joeynmt.training - Epoch  10, Step:    99700, Batch Loss:     1.227127, Batch Acc: 0.599492, Tokens per Sec:     9350, Lr: 0.000147
2025-05-30 04:01:46,170 - INFO - joeynmt.training - Epoch  10, Step:    99800, Batch Loss:     1.433014, Batch Acc: 0.605306, Tokens per Sec:     9819, Lr: 0.000147
2025-05-30 04:01:53,896 - INFO - joeynmt.training - Epoch  10, Step:    99900, Batch Loss:     1.454713, Batch Acc: 0.603449, Tokens per Sec:     9098, Lr: 0.000147
2025-05-30 04:02:01,585 - INFO - joeynmt.training - Epoch  10, Step:   100000, Batch Loss:     1.294517, Batch Acc: 0.610885, Tokens per Sec:     9289, Lr: 0.000147
2025-05-30 04:02:01,585 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:02:01,586 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:02:42,645 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.37, ppl:   3.94, acc:   0.56, generation: 41.0241[sec], evaluation: 0.0000[sec]
2025-05-30 04:02:42,646 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 04:02:42,805 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/99500.ckpt
2025-05-30 04:02:42,821 - INFO - joeynmt.training - Example #0
2025-05-30 04:02:42,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:02:42,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:02:42,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 'z@@', 'er@@', 's', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'lo@@', 'ten', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'd.', '</s>']
2025-05-30 04:02:42,823 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:02:42,823 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:02:42,824 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen te bekijken dat de arctische ijskappe ijskappe ijskappe ijskappe ijzers had om 48 staten om 40 procent gesloten te verzameld.
2025-05-30 04:02:42,824 - INFO - joeynmt.training - Example #1
2025-05-30 04:02:42,824 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:02:42,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:02:42,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'er', 'n@@', 'u@@', ',', 'om@@', 'dat', 'het', 'pro@@', 'ble@@', 'em', 'is', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 04:02:42,825 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:02:42,825 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:02:42,825 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de dieper nu, omdat het probleem is dat het niet de dikke ijs van het ijs laat zien.
2025-05-30 04:02:42,826 - INFO - joeynmt.training - Example #2
2025-05-30 04:02:42,826 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:02:42,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:02:42,826 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 04:02:42,827 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:02:42,827 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:02:42,827 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 04:02:42,827 - INFO - joeynmt.training - Example #3
2025-05-30 04:02:42,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:02:42,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:02:42,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gt', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 04:02:42,828 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:02:42,828 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:02:42,829 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgt in de zomer.
2025-05-30 04:02:42,829 - INFO - joeynmt.training - Example #4
2025-05-30 04:02:42,829 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:02:42,829 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:02:42,829 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'p@@', 'p@@', 'en@@', 'ti@@', 'ë@@', 'l@@', 'e', 'j@@', 'aar@@', ',', 'is', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 04:02:42,830 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:02:42,830 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:02:42,830 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een tijdslappentiële jaar, is in de laatste 25 jaar.
2025-05-30 04:02:51,542 - INFO - joeynmt.training - Epoch  10, Step:   100100, Batch Loss:     1.214431, Batch Acc: 0.602170, Tokens per Sec:     7812, Lr: 0.000147
2025-05-30 04:03:00,637 - INFO - joeynmt.training - Epoch  10, Step:   100200, Batch Loss:     1.487113, Batch Acc: 0.605480, Tokens per Sec:     8002, Lr: 0.000147
2025-05-30 04:03:09,357 - INFO - joeynmt.training - Epoch  10, Step:   100300, Batch Loss:     1.286339, Batch Acc: 0.606542, Tokens per Sec:     8425, Lr: 0.000147
2025-05-30 04:03:18,084 - INFO - joeynmt.training - Epoch  10, Step:   100400, Batch Loss:     1.249942, Batch Acc: 0.602755, Tokens per Sec:     8004, Lr: 0.000147
2025-05-30 04:03:26,723 - INFO - joeynmt.training - Epoch  10, Step:   100500, Batch Loss:     1.541960, Batch Acc: 0.608390, Tokens per Sec:     8322, Lr: 0.000147
2025-05-30 04:03:26,724 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:03:26,724 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:04:07,725 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.37, ppl:   3.93, acc:   0.56, generation: 40.9625[sec], evaluation: 0.0000[sec]
2025-05-30 04:04:07,726 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 04:04:07,888 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/94000.ckpt
2025-05-30 04:04:07,905 - INFO - joeynmt.training - Example #0
2025-05-30 04:04:07,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:04:07,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:04:07,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'ver@@', 'be@@', 'el@@', 'den', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', '4@@', '8', 'st@@', 'aten', 'die', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'n@@', 'el', 'ge@@', 'be@@', 'ur@@', 'de.', '</s>']
2025-05-30 04:04:07,907 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:04:07,907 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:04:07,908 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te verbeelden dat de arctische ijskappe ijskappen, die voor 48 staten die 48 staten had geslagen om 48 staten om 40 procent gesnel gebeurde.
2025-05-30 04:04:07,908 - INFO - joeynmt.training - Example #1
2025-05-30 04:04:07,908 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:04:07,908 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:04:07,908 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'g@@', 'aan@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 04:04:07,909 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:04:07,909 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:04:07,909 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de diepgaande van dit specifieke probleem uit, want het is niet de dikke van het ijs laat zien.
2025-05-30 04:04:07,909 - INFO - joeynmt.training - Example #2
2025-05-30 04:04:07,910 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:04:07,910 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:04:07,910 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 04:04:07,911 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:04:07,911 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:04:07,911 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is het arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 04:04:07,911 - INFO - joeynmt.training - Example #3
2025-05-30 04:04:07,912 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:04:07,912 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:04:07,912 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 04:04:07,913 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:04:07,913 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:04:07,913 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomer.
2025-05-30 04:04:07,913 - INFO - joeynmt.training - Example #4
2025-05-30 04:04:07,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:04:07,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:04:07,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'ort', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 04:04:07,914 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:04:07,915 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:04:07,915 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een tijdrapport van wat er gebeurd in de laatste 25 jaar is.
2025-05-30 04:04:16,168 - INFO - joeynmt.training - Epoch  10, Step:   100600, Batch Loss:     1.159920, Batch Acc: 0.607620, Tokens per Sec:     8779, Lr: 0.000147
2025-05-30 04:04:24,444 - INFO - joeynmt.training - Epoch  10, Step:   100700, Batch Loss:     1.392819, Batch Acc: 0.603438, Tokens per Sec:     8719, Lr: 0.000147
2025-05-30 04:04:32,848 - INFO - joeynmt.training - Epoch  10, Step:   100800, Batch Loss:     1.222968, Batch Acc: 0.607456, Tokens per Sec:     8578, Lr: 0.000147
2025-05-30 04:04:41,164 - INFO - joeynmt.training - Epoch  10, Step:   100900, Batch Loss:     1.272335, Batch Acc: 0.601369, Tokens per Sec:     8595, Lr: 0.000147
2025-05-30 04:04:48,935 - INFO - joeynmt.training - Epoch  10, Step:   101000, Batch Loss:     1.212347, Batch Acc: 0.605162, Tokens per Sec:     9409, Lr: 0.000147
2025-05-30 04:04:48,936 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:04:48,936 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:05:36,968 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.37, ppl:   3.93, acc:   0.57, generation: 47.9824[sec], evaluation: 0.0000[sec]
2025-05-30 04:05:37,156 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/93500.ckpt
2025-05-30 04:05:37,164 - INFO - joeynmt.training - Example #0
2025-05-30 04:05:37,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:05:37,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:05:37,165 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en', 'die', 'on@@', 'der', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 04:05:37,166 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:05:37,166 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:05:37,166 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen, dat de arctische ijskappen, die ijskappen die onder de grootte van de onderste 48 staten gebeuren.
2025-05-30 04:05:37,166 - INFO - joeynmt.training - Example #1
2025-05-30 04:05:37,167 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:05:37,167 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:05:37,167 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'g@@', 'aan@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 04:05:37,168 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:05:37,169 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:05:37,169 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de diepgaande van dit specifieke probleem uit, want het is niet de dikke ijskracht van het ijs laat zien.
2025-05-30 04:05:37,169 - INFO - joeynmt.training - Example #2
2025-05-30 04:05:37,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:05:37,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:05:37,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 04:05:37,170 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:05:37,170 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:05:37,170 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is het arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 04:05:37,171 - INFO - joeynmt.training - Example #3
2025-05-30 04:05:37,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:05:37,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:05:37,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 04:05:37,172 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:05:37,172 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:05:37,172 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich in de winter en zich in de zomer.
2025-05-30 04:05:37,172 - INFO - joeynmt.training - Example #4
2025-05-30 04:05:37,173 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:05:37,173 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:05:37,173 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'je', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 04:05:37,174 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:05:37,174 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:05:37,174 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik je laat zien is een tijdslag van wat er gebeurd in de afgelopen 25 jaar.
2025-05-30 04:05:45,802 - INFO - joeynmt.training - Epoch  10, Step:   101100, Batch Loss:     1.062076, Batch Acc: 0.606406, Tokens per Sec:     8129, Lr: 0.000147
2025-05-30 04:05:54,361 - INFO - joeynmt.training - Epoch  10, Step:   101200, Batch Loss:     1.114773, Batch Acc: 0.596207, Tokens per Sec:     8422, Lr: 0.000147
2025-05-30 04:06:03,033 - INFO - joeynmt.training - Epoch  10, Step:   101300, Batch Loss:     1.088567, Batch Acc: 0.601131, Tokens per Sec:     8588, Lr: 0.000147
2025-05-30 04:06:11,660 - INFO - joeynmt.training - Epoch  10, Step:   101400, Batch Loss:     1.292733, Batch Acc: 0.605396, Tokens per Sec:     8204, Lr: 0.000147
2025-05-30 04:06:20,487 - INFO - joeynmt.training - Epoch  10, Step:   101500, Batch Loss:     1.254269, Batch Acc: 0.609236, Tokens per Sec:     8174, Lr: 0.000147
2025-05-30 04:06:20,488 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:06:20,488 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:07:04,037 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.37, ppl:   3.92, acc:   0.57, generation: 43.5090[sec], evaluation: 0.0000[sec]
2025-05-30 04:07:04,038 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 04:07:04,192 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/99000.ckpt
2025-05-30 04:07:04,205 - INFO - joeynmt.training - Example #0
2025-05-30 04:07:04,206 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:07:04,206 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:07:04,206 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'n@@', 'ap@@', 't', 'te', 'ver@@', 'm@@', 'inder@@', 'en.', '</s>']
2025-05-30 04:07:04,207 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:07:04,207 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:07:04,207 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen, dat de arctische ijskappen, die voor de drie miljoen jaar de grootte van de onderste 48 staten om 48 staten om 48 staten om 48 staten om 48 staten om 40 procent gesnapt te verminderen.
2025-05-30 04:07:04,207 - INFO - joeynmt.training - Example #1
2025-05-30 04:07:04,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:07:04,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:07:04,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'g@@', 'aan@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ingen', 'van', 'het', 'ij@@', 's', 'zi@@', 'en.', '</s>']
2025-05-30 04:07:04,209 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:07:04,209 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:07:04,209 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de diepgaande van dit specifieke probleem uit, want het is niet de dikke dingen van het ijs zien.
2025-05-30 04:07:04,209 - INFO - joeynmt.training - Example #2
2025-05-30 04:07:04,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:07:04,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:07:04,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 04:07:04,211 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:07:04,211 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:07:04,211 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is het arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 04:07:04,211 - INFO - joeynmt.training - Example #3
2025-05-30 04:07:04,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:07:04,212 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:07:04,212 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gt', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'st@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'st@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-30 04:07:04,212 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:07:04,213 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:07:04,213 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zorgt in de winter en zich in de winter en zich strompt in de winter en zich strompt in de winter en zich in de winter en zich verzamelen.
2025-05-30 04:07:04,213 - INFO - joeynmt.training - Example #4
2025-05-30 04:07:04,213 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:07:04,213 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:07:04,214 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zi@@', 'en,', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'gen', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 04:07:04,214 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:07:04,215 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:07:04,215 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien, is een tijdragen wat er gebeurd in de afgelopen 25 jaar is.
2025-05-30 04:07:11,790 - INFO - joeynmt.training - Epoch  10, Step:   101600, Batch Loss:     1.276215, Batch Acc: 0.612849, Tokens per Sec:     9057, Lr: 0.000147
2025-05-30 04:07:19,300 - INFO - joeynmt.training - Epoch  10, Step:   101700, Batch Loss:     1.059264, Batch Acc: 0.601757, Tokens per Sec:     9341, Lr: 0.000147
2025-05-30 04:07:26,864 - INFO - joeynmt.training - Epoch  10, Step:   101800, Batch Loss:     1.166040, Batch Acc: 0.603742, Tokens per Sec:     9400, Lr: 0.000147
2025-05-30 04:07:34,569 - INFO - joeynmt.training - Epoch  10, Step:   101900, Batch Loss:     1.257688, Batch Acc: 0.609459, Tokens per Sec:     9276, Lr: 0.000147
2025-05-30 04:07:42,341 - INFO - joeynmt.training - Epoch  10, Step:   102000, Batch Loss:     1.201753, Batch Acc: 0.600774, Tokens per Sec:     9280, Lr: 0.000147
2025-05-30 04:07:42,342 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:07:42,343 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:08:25,766 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.37, ppl:   3.93, acc:   0.57, generation: 43.3856[sec], evaluation: 0.0000[sec]
2025-05-30 04:08:25,918 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/95000.ckpt
2025-05-30 04:08:25,932 - INFO - joeynmt.training - Example #0
2025-05-30 04:08:25,933 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:08:25,933 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:08:25,934 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'om', 'te', 'beg@@', 'in@@', 'nen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'te', 'van', '4@@', '8', 'st@@', 'aten', 'ge@@', 's@@', 'la@@', 'gen', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'te', 'k@@', 'r@@', 'im@@', 'p@@', 't.', '</s>']
2025-05-30 04:08:25,934 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:08:25,935 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:08:25,935 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen, om te beginnen dat de arctische ijskappen, die drie miljoen jaar de grootte van 48 staten geslagen had om 48 staten om 40 procent geslagen te krimpt.
2025-05-30 04:08:25,935 - INFO - joeynmt.training - Example #1
2025-05-30 04:08:25,935 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:08:25,935 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:08:25,935 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'e', 'd@@', 'ie@@', 'p@@', 'e', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'd@@', 'ie@@', 'p@@', 'e', 'pro@@', 'ble@@', 'em@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'd@@', 'ie@@', 'p@@', 'e', 'van', 'het', 'ij@@', 'z@@', 'er', 'van', 'het', 'ij@@', 'z@@', 'er', 'is.', '</s>']
2025-05-30 04:08:25,936 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:08:25,936 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:08:25,937 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de diepe diepe probleem uit, omdat het niet de diepe probleem, omdat het niet de diepe van het ijzer van het ijzer is.
2025-05-30 04:08:25,937 - INFO - joeynmt.training - Example #2
2025-05-30 04:08:25,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:08:25,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:08:25,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in@@', 'tu@@', 'igen', 'is', 'het', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 04:08:25,938 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:08:25,938 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:08:25,938 - INFO - joeynmt.training - 	Hypothesis: In zekere zintuigen is het arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 04:08:25,938 - INFO - joeynmt.training - Example #3
2025-05-30 04:08:25,938 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:08:25,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:08:25,939 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 04:08:25,939 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:08:25,940 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:08:25,940 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomer.
2025-05-30 04:08:25,940 - INFO - joeynmt.training - Example #4
2025-05-30 04:08:25,940 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:08:25,940 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:08:25,940 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'p@@', 'p@@', 'or@@', 't@@', 'ige', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 04:08:25,941 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:08:25,941 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:08:25,941 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdrapportige wat er gebeurd in de afgelopen 25 jaar.
2025-05-30 04:08:34,608 - INFO - joeynmt.training - Epoch  10, Step:   102100, Batch Loss:     1.422672, Batch Acc: 0.599545, Tokens per Sec:     8014, Lr: 0.000147
2025-05-30 04:08:43,325 - INFO - joeynmt.training - Epoch  10, Step:   102200, Batch Loss:     1.309132, Batch Acc: 0.601749, Tokens per Sec:     8082, Lr: 0.000147
2025-05-30 04:08:51,972 - INFO - joeynmt.training - Epoch  10, Step:   102300, Batch Loss:     1.188595, Batch Acc: 0.606358, Tokens per Sec:     8378, Lr: 0.000147
2025-05-30 04:09:00,595 - INFO - joeynmt.training - Epoch  10, Step:   102400, Batch Loss:     1.192127, Batch Acc: 0.605156, Tokens per Sec:     8509, Lr: 0.000147
2025-05-30 04:09:09,393 - INFO - joeynmt.training - Epoch  10, Step:   102500, Batch Loss:     1.177512, Batch Acc: 0.610476, Tokens per Sec:     8197, Lr: 0.000147
2025-05-30 04:09:09,394 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:09:09,394 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:09:55,391 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.36, ppl:   3.91, acc:   0.57, generation: 45.9530[sec], evaluation: 0.0000[sec]
2025-05-30 04:09:55,392 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 04:09:55,551 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/100000.ckpt
2025-05-30 04:09:55,577 - INFO - joeynmt.training - Example #0
2025-05-30 04:09:55,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:09:55,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:09:55,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'om', 'te', 'be@@', 'se@@', 'ff@@', 'en', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'on@@', 'der', '4@@', '8', 'st@@', 'aten', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '8', 'st@@', 'aten', 'ge@@', 'be@@', 'ur@@', 'en.', '</s>']
2025-05-30 04:09:55,579 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:09:55,579 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:09:55,580 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen, om te beseffen dat de arctische ijskappen, die voor onder 48 staten geslagen om 48 staten gebeuren.
2025-05-30 04:09:55,581 - INFO - joeynmt.training - Example #1
2025-05-30 04:09:55,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:09:55,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:09:55,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'e', 'd@@', 'ru@@', 'k', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'ck@@', 's', 'van', 'het', 'ij@@', 's', 'zi@@', 'en.', '</s>']
2025-05-30 04:09:55,583 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:09:55,583 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:09:55,583 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de diepe druk van dit speciale probleem uit, omdat het niet de dicks van het ijs zien.
2025-05-30 04:09:55,583 - INFO - joeynmt.training - Example #2
2025-05-30 04:09:55,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:09:55,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:09:55,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 04:09:55,585 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:09:55,585 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:09:55,585 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is het arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 04:09:55,585 - INFO - joeynmt.training - Example #3
2025-05-30 04:09:55,586 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:09:55,586 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:09:55,586 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 04:09:55,587 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:09:55,587 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:09:55,587 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomer.
2025-05-30 04:09:55,587 - INFO - joeynmt.training - Example #4
2025-05-30 04:09:55,587 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:09:55,588 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:09:55,588 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'gen', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 04:09:55,589 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:09:55,589 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:09:55,589 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdragen wat er gebeurd in de afgelopen 25 jaar is.
2025-05-30 04:10:04,215 - INFO - joeynmt.training - Epoch  10, Step:   102600, Batch Loss:     1.302454, Batch Acc: 0.603000, Tokens per Sec:     8228, Lr: 0.000147
2025-05-30 04:10:12,664 - INFO - joeynmt.training - Epoch  10, Step:   102700, Batch Loss:     1.223637, Batch Acc: 0.601201, Tokens per Sec:     8615, Lr: 0.000147
2025-05-30 04:10:21,162 - INFO - joeynmt.training - Epoch  10, Step:   102800, Batch Loss:     1.256878, Batch Acc: 0.598963, Tokens per Sec:     8627, Lr: 0.000147
2025-05-30 04:10:30,051 - INFO - joeynmt.training - Epoch  10, Step:   102900, Batch Loss:     1.210652, Batch Acc: 0.602544, Tokens per Sec:     8156, Lr: 0.000147
2025-05-30 04:10:38,578 - INFO - joeynmt.training - Epoch  10, Step:   103000, Batch Loss:     1.152879, Batch Acc: 0.604459, Tokens per Sec:     8159, Lr: 0.000147
2025-05-30 04:10:38,579 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:10:38,579 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:11:18,308 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.36, ppl:   3.91, acc:   0.57, generation: 39.6866[sec], evaluation: 0.0000[sec]
2025-05-30 04:11:18,477 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/101000.ckpt
2025-05-30 04:11:18,490 - INFO - joeynmt.training - Example #0
2025-05-30 04:11:18,491 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:11:18,491 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:11:18,492 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 're@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'pen', 'die', 'voor', 'de', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'de', 'gro@@', 'ot@@', 'ste', 'van', 'de', 'gro@@', 'ot@@', 'ste', 'de@@', 'el', 'van', 'de', 'gro@@', 'ot@@', 'ste', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 04:11:18,493 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:11:18,493 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:11:18,494 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te begrepen dat de arctische ijskappen die voor de drie miljoen jaar de grootste van de grootste deel van de grootste 48 staten om 40 procent te geslagen is.
2025-05-30 04:11:18,494 - INFO - joeynmt.training - Example #1
2025-05-30 04:11:18,495 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:11:18,495 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:11:18,495 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'g@@', 'aan@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'in@@', 'gen@@', '.@@', '.@@', '.', '</s>']
2025-05-30 04:11:18,496 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:11:18,496 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:11:18,496 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de diepgaande van dit speciale probleem uit, omdat het niet de dikke dingen...
2025-05-30 04:11:18,498 - INFO - joeynmt.training - Example #2
2025-05-30 04:11:18,498 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:11:18,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:11:18,498 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 04:11:18,499 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:11:18,499 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:11:18,499 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is het arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 04:11:18,500 - INFO - joeynmt.training - Example #3
2025-05-30 04:11:18,500 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:11:18,500 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:11:18,500 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'sch@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 04:11:18,501 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:11:18,501 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:11:18,501 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en schrompt in de zomer.
2025-05-30 04:11:18,502 - INFO - joeynmt.training - Example #4
2025-05-30 04:11:18,502 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:11:18,502 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:11:18,502 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'g', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 04:11:18,503 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:11:18,503 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:11:18,503 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdrag wat er gebeurd in de laatste 25 jaar gebeurd.
2025-05-30 04:11:27,255 - INFO - joeynmt.training - Epoch  10, Step:   103100, Batch Loss:     1.362600, Batch Acc: 0.599287, Tokens per Sec:     7899, Lr: 0.000147
2025-05-30 04:11:36,002 - INFO - joeynmt.training - Epoch  10, Step:   103200, Batch Loss:     1.281794, Batch Acc: 0.599009, Tokens per Sec:     8327, Lr: 0.000147
2025-05-30 04:11:44,692 - INFO - joeynmt.training - Epoch  10, Step:   103300, Batch Loss:     1.220812, Batch Acc: 0.600911, Tokens per Sec:     8441, Lr: 0.000147
2025-05-30 04:11:53,328 - INFO - joeynmt.training - Epoch  10, Step:   103400, Batch Loss:     1.263326, Batch Acc: 0.602944, Tokens per Sec:     8219, Lr: 0.000147
2025-05-30 04:12:01,981 - INFO - joeynmt.training - Epoch  10, Step:   103500, Batch Loss:     1.231177, Batch Acc: 0.599091, Tokens per Sec:     8314, Lr: 0.000147
2025-05-30 04:12:01,982 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:12:01,982 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:12:44,349 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.36, ppl:   3.89, acc:   0.57, generation: 42.3245[sec], evaluation: 0.0000[sec]
2025-05-30 04:12:44,350 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 04:12:44,527 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/100500.ckpt
2025-05-30 04:12:44,543 - INFO - joeynmt.training - Example #0
2025-05-30 04:12:44,544 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:12:44,544 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:12:44,544 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'de', 'gro@@', 'ot@@', 'ste', 'de@@', 'el', 'van', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'ge@@', 'ge@@', 'st@@', 'eld', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'te', 'ge@@', 'd@@', 'om@@', 'p@@', 't.', '</s>']
2025-05-30 04:12:44,545 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:12:44,545 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:12:44,545 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen, dat de arctische ijskappe ijskappen, die voor de grootste deel van 48 staten had gegesteld om 48 staten om 48 staten te gedompt.
2025-05-30 04:12:44,545 - INFO - joeynmt.training - Example #1
2025-05-30 04:12:44,546 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:12:44,546 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:12:44,546 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'e', 'd@@', 'ingen', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 04:12:44,547 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:12:44,547 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:12:44,547 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de diepe dingen van dit speciale probleem uit, omdat het niet de dikke van het ijs van het ijs laat zien.
2025-05-30 04:12:44,547 - INFO - joeynmt.training - Example #2
2025-05-30 04:12:44,547 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:12:44,547 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:12:44,547 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 04:12:44,548 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:12:44,548 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:12:44,549 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is het arctische ijskapp van ons wereldwijde klimaatsysteem.
2025-05-30 04:12:44,549 - INFO - joeynmt.training - Example #3
2025-05-30 04:12:44,549 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:12:44,549 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:12:44,549 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er', 'in', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 04:12:44,550 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:12:44,550 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:12:44,550 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zomer in en zomer.
2025-05-30 04:12:44,550 - INFO - joeynmt.training - Example #4
2025-05-30 04:12:44,551 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:12:44,551 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:12:44,551 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 'ra@@', 'gen', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'is', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 04:12:44,552 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:12:44,552 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:12:44,552 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdragen van wat er gebeurd is in de afgelopen 25 jaar is.
2025-05-30 04:12:52,164 - INFO - joeynmt.training - Epoch  10, Step:   103600, Batch Loss:     1.306737, Batch Acc: 0.605848, Tokens per Sec:     9372, Lr: 0.000147
2025-05-30 04:13:00,319 - INFO - joeynmt.training - Epoch  10, Step:   103700, Batch Loss:     1.371974, Batch Acc: 0.598511, Tokens per Sec:     8945, Lr: 0.000147
2025-05-30 04:13:08,486 - INFO - joeynmt.training - Epoch  10, Step:   103800, Batch Loss:     1.041686, Batch Acc: 0.611487, Tokens per Sec:     8830, Lr: 0.000147
2025-05-30 04:13:17,019 - INFO - joeynmt.training - Epoch  10, Step:   103900, Batch Loss:     1.236609, Batch Acc: 0.601528, Tokens per Sec:     8481, Lr: 0.000147
2025-05-30 04:13:25,675 - INFO - joeynmt.training - Epoch  10, Step:   104000, Batch Loss:     1.344888, Batch Acc: 0.608133, Tokens per Sec:     8170, Lr: 0.000147
2025-05-30 04:13:25,675 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:13:25,676 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:14:07,953 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.36, ppl:   3.91, acc:   0.57, generation: 42.2366[sec], evaluation: 0.0000[sec]
2025-05-30 04:14:08,109 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/102000.ckpt
2025-05-30 04:14:08,123 - INFO - joeynmt.training - Example #0
2025-05-30 04:14:08,124 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:14:08,124 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:14:08,124 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'om', 'te', 'beg@@', 'inn@@', 'en,', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'die', 'voor', 'on@@', 'der', '4@@', '8', 'st@@', 'aten', 'voor', 'de', 'onder@@', 'ste', '4@@', '8', 'st@@', 'aten', 'ha@@', 'd', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'voor', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 'd@@', 'om@@', 'p@@', 't.', '</s>']
2025-05-30 04:14:08,125 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:14:08,125 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:14:08,125 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen, om te beginnen, dat de arctische ijskappen, die voor onder 48 staten voor de onderste 48 staten had om 48 staten om 48 staten om 48 staten om 48 staten voor 40 procent te gedompt.
2025-05-30 04:14:08,125 - INFO - joeynmt.training - Example #1
2025-05-30 04:14:08,126 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:14:08,126 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:14:08,126 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'g@@', 'aan@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'ale', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's@@', 'k@@', 'ra@@', 'cht', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 04:14:08,127 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:14:08,127 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:14:08,127 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de diepgaande van dit speciale probleem uit, omdat het niet de dikke ijskracht van het ijs van het ijs van het ijs van het ijs laat zien.
2025-05-30 04:14:08,127 - INFO - joeynmt.training - Example #2
2025-05-30 04:14:08,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:14:08,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:14:08,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'is', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 04:14:08,128 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:14:08,128 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:14:08,128 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is het arctische ijskapp is het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 04:14:08,128 - INFO - joeynmt.training - Example #3
2025-05-30 04:14:08,129 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:14:08,129 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:14:08,129 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'or@@', 'gen', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 04:14:08,129 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:14:08,130 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:14:08,130 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zich zorgen in de winter en zomer.
2025-05-30 04:14:08,130 - INFO - joeynmt.training - Example #4
2025-05-30 04:14:08,130 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:14:08,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:14:08,130 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 04:14:08,131 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:14:08,131 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:14:08,131 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdslag van wat er gebeurd in de afgelopen 25 jaar is.
2025-05-30 04:14:16,872 - INFO - joeynmt.training - Epoch  10, Step:   104100, Batch Loss:     1.266314, Batch Acc: 0.600802, Tokens per Sec:     8026, Lr: 0.000147
2025-05-30 04:14:25,568 - INFO - joeynmt.training - Epoch  10, Step:   104200, Batch Loss:     1.361330, Batch Acc: 0.598513, Tokens per Sec:     8321, Lr: 0.000147
2025-05-30 04:14:34,373 - INFO - joeynmt.training - Epoch  10, Step:   104300, Batch Loss:     1.262628, Batch Acc: 0.601467, Tokens per Sec:     8132, Lr: 0.000147
2025-05-30 04:14:42,932 - INFO - joeynmt.training - Epoch  10, Step:   104400, Batch Loss:     1.215602, Batch Acc: 0.599629, Tokens per Sec:     8450, Lr: 0.000147
2025-05-30 04:14:51,540 - INFO - joeynmt.training - Epoch  10, Step:   104500, Batch Loss:     1.354486, Batch Acc: 0.606742, Tokens per Sec:     8600, Lr: 0.000147
2025-05-30 04:14:51,540 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:14:51,540 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:15:32,512 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.36, ppl:   3.90, acc:   0.57, generation: 40.9255[sec], evaluation: 0.0000[sec]
2025-05-30 04:15:32,715 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/101500.ckpt
2025-05-30 04:15:32,751 - INFO - joeynmt.training - Example #0
2025-05-30 04:15:32,752 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:15:32,752 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:15:32,752 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'ar@@', 'at@@', 'u@@', 'ur', 'ha@@', 'd', 'ge@@', 's@@', 'la@@', 'gen', 'ha@@', 'd', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'te', 'ge@@', 's@@', 'la@@', 'gen', 'van', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'is.', '</s>']
2025-05-30 04:15:32,753 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:15:32,753 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:15:32,753 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen te bekijken dat de arctische ijskape ijskape ijskappe ijskapparatuur had geslagen had om 40 procent te geslagen van 40 procent geslagen is.
2025-05-30 04:15:32,754 - INFO - joeynmt.training - Example #1
2025-05-30 04:15:32,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:15:32,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:15:32,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'ster@@', 'k', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'er', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 04:15:32,755 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:15:32,755 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:15:32,756 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet sterk genoeg de dieper van dit specifieke probleem uit, omdat het niet de dikke ijs van het ijs van het ijs laat zien.
2025-05-30 04:15:32,756 - INFO - joeynmt.training - Example #2
2025-05-30 04:15:32,756 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:15:32,756 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:15:32,756 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 04:15:32,757 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:15:32,757 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:15:32,757 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is het arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 04:15:32,758 - INFO - joeynmt.training - Example #3
2025-05-30 04:15:32,758 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:15:32,758 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:15:32,758 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'r@@', 'on@@', 'd', 'en', 'z@@', 'r@@', 'on@@', 'd@@', 'om', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'r@@', 'on@@', 'd@@', 'om', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'r@@', 'on@@', 'd@@', 'om', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'r@@', 'on@@', 'd@@', 'om', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-30 04:15:32,759 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:15:32,759 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:15:32,759 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zrond en zrondom in de winter en zrondom in de winter en zrondom in de winter en zrondom te verzamelen.
2025-05-30 04:15:32,759 - INFO - joeynmt.training - Example #4
2025-05-30 04:15:32,760 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:15:32,760 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:15:32,760 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aat', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is.', '</s>']
2025-05-30 04:15:32,761 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:15:32,761 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:15:32,761 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laat zien is een tijdslag van wat er gebeurd in de afgelopen 25 jaar is.
2025-05-30 04:15:42,139 - INFO - joeynmt.training - Epoch  10, Step:   104600, Batch Loss:     1.174250, Batch Acc: 0.603732, Tokens per Sec:     7570, Lr: 0.000147
2025-05-30 04:15:50,750 - INFO - joeynmt.training - Epoch  10, Step:   104700, Batch Loss:     1.129757, Batch Acc: 0.607277, Tokens per Sec:     8305, Lr: 0.000147
2025-05-30 04:15:59,457 - INFO - joeynmt.training - Epoch  10, Step:   104800, Batch Loss:     1.298268, Batch Acc: 0.597343, Tokens per Sec:     8230, Lr: 0.000147
2025-05-30 04:16:07,924 - INFO - joeynmt.training - Epoch  10, Step:   104900, Batch Loss:     1.185449, Batch Acc: 0.609998, Tokens per Sec:     8573, Lr: 0.000147
2025-05-30 04:16:16,865 - INFO - joeynmt.training - Epoch  10, Step:   105000, Batch Loss:     1.204778, Batch Acc: 0.601175, Tokens per Sec:     8034, Lr: 0.000147
2025-05-30 04:16:16,865 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:16:16,865 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:17:02,608 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.36, ppl:   3.90, acc:   0.57, generation: 45.7019[sec], evaluation: 0.0000[sec]
2025-05-30 04:17:02,772 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/103000.ckpt
2025-05-30 04:17:02,786 - INFO - joeynmt.training - Example #0
2025-05-30 04:17:02,786 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:17:02,786 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:17:02,787 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en,', 'om', '4@@', '8', 'st@@', 'aten', 'ge@@', 'be@@', 'ur@@', 'en', 'van', '4@@', '8', 'st@@', 'aten', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'te', 'g@@', 'aan@@', '.', '</s>']
2025-05-30 04:17:02,788 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:17:02,788 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:17:02,788 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te begrijpen dat de arctische ijskappe ijskape ijskappe ijskappen, om 48 staten gebeuren van 48 staten geslagen om 40 procent geslagen te gaan.
2025-05-30 04:17:02,788 - INFO - joeynmt.training - Example #1
2025-05-30 04:17:02,788 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:17:02,788 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:17:02,788 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'g@@', 'aan@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'ck@@', 's.', '</s>']
2025-05-30 04:17:02,789 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:17:02,789 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:17:02,789 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de diepgaande van dit specifieke probleem uit, want het is niet de dicks.
2025-05-30 04:17:02,790 - INFO - joeynmt.training - Example #2
2025-05-30 04:17:02,790 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:17:02,790 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:17:02,790 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'het', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'ons', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 04:17:02,791 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:17:02,791 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:17:02,791 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is het arctische ijskapp het slagende hart van ons wereldwijde klimaatsysteem.
2025-05-30 04:17:02,791 - INFO - joeynmt.training - Example #3
2025-05-30 04:17:02,792 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:17:02,792 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:17:02,792 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'eit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ro@@', 'm@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er', 'en', 'z@@', 'r@@', 'on@@', 'd@@', 'om', 'te', 'ver@@', 'z@@', 'am@@', 'el@@', 'en.', '</s>']
2025-05-30 04:17:02,793 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:17:02,793 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:17:02,793 - INFO - joeynmt.training - 	Hypothesis: Ze groeit in de winter en zrompt in de zomer en zrondom te verzamelen.
2025-05-30 04:17:02,793 - INFO - joeynmt.training - Example #4
2025-05-30 04:17:02,793 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:17:02,794 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:17:02,794 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'van', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd.', '</s>']
2025-05-30 04:17:02,794 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:17:02,794 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:17:02,794 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdslag van wat er gebeurd in de afgelopen 25 jaar gebeurd.
2025-05-30 04:17:11,655 - INFO - joeynmt.training - Epoch  10, Step:   105100, Batch Loss:     1.333202, Batch Acc: 0.602428, Tokens per Sec:     7922, Lr: 0.000147
2025-05-30 04:17:20,345 - INFO - joeynmt.training - Epoch  10, Step:   105200, Batch Loss:     1.119144, Batch Acc: 0.604799, Tokens per Sec:     8207, Lr: 0.000147
2025-05-30 04:17:29,341 - INFO - joeynmt.training - Epoch  10, Step:   105300, Batch Loss:     1.394214, Batch Acc: 0.598639, Tokens per Sec:     8188, Lr: 0.000147
2025-05-30 04:17:38,034 - INFO - joeynmt.training - Epoch  10, Step:   105400, Batch Loss:     1.117199, Batch Acc: 0.609740, Tokens per Sec:     8322, Lr: 0.000147
2025-05-30 04:17:46,661 - INFO - joeynmt.training - Epoch  10, Step:   105500, Batch Loss:     1.250331, Batch Acc: 0.603516, Tokens per Sec:     8632, Lr: 0.000147
2025-05-30 04:17:46,661 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:17:46,662 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:18:26,942 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.36, ppl:   3.89, acc:   0.57, generation: 40.2413[sec], evaluation: 0.0000[sec]
2025-05-30 04:18:26,944 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-30 04:18:27,104 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/102500.ckpt
2025-05-30 04:18:27,117 - INFO - joeynmt.training - Example #0
2025-05-30 04:18:27,118 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:18:27,118 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:18:27,118 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'be@@', 'k@@', 'ij@@', 'ken', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'el@@', 'ijk', 'te', 'k@@', 'rij@@', 'gen', 'van', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '8', 'st@@', 'aten', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'te', 'k@@', 'r@@', 'im@@', 'p@@', 't.', '</s>']
2025-05-30 04:18:27,118 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:18:27,118 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:18:27,118 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te bekijken dat de arctische ijskappe ijskappe ijskappe ijskappelijk te krijgen van 48 staten om 48 staten om 40 procent geslagen te krimpt.
2025-05-30 04:18:27,118 - INFO - joeynmt.training - Example #1
2025-05-30 04:18:27,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:18:27,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:18:27,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'is', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'g@@', 'aan@@', 'de', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ie@@', 'p@@', 'er', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 04:18:27,119 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:18:27,119 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:18:27,120 - INFO - joeynmt.training - 	Hypothesis: Maar dit is niet genoeg de diepgaande van dit specifieke probleem uit, omdat het niet de dikke dieper van het ijs van het ijs van het ijs van het ijs laat zien.
2025-05-30 04:18:27,120 - INFO - joeynmt.training - Example #2
2025-05-30 04:18:27,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:18:27,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:18:27,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p', 'het', 's@@', 'la@@', 'gen@@', 'de', 'h@@', 'ar@@', 't', 'van', 'onze', 'wer@@', 'el@@', 'd@@', 'wij@@', 'de', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.', '</s>']
2025-05-30 04:18:27,120 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:18:27,121 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:18:27,121 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskapp het slagende hart van onze wereldwijde klimaatsysteem.
2025-05-30 04:18:27,121 - INFO - joeynmt.training - Example #3
2025-05-30 04:18:27,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:18:27,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:18:27,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'ich', 'z@@', 'or@@', 'g@@', 'aan@@', '.', '</s>']
2025-05-30 04:18:27,122 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:18:27,122 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:18:27,122 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zich zorgaan.
2025-05-30 04:18:27,122 - INFO - joeynmt.training - Example #4
2025-05-30 04:18:27,123 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:18:27,123 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:18:27,123 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 's@@', 'la@@', 'g', 'wat', 'er', 'ge@@', 'be@@', 'ur@@', 'd', 'in', 'de', 'l@@', 'aat@@', 'ste', '2@@', '5', 'jaar', 'ge@@', 'be@@', 'ur@@', 'd', 'is.', '</s>']
2025-05-30 04:18:27,124 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:18:27,124 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:18:27,124 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdslag wat er gebeurd in de laatste 25 jaar gebeurd is.
2025-05-30 04:18:34,902 - INFO - joeynmt.training - Epoch  10, Step:   105600, Batch Loss:     1.263854, Batch Acc: 0.608125, Tokens per Sec:     9227, Lr: 0.000147
2025-05-30 04:18:42,798 - INFO - joeynmt.training - Epoch  10, Step:   105700, Batch Loss:     1.227658, Batch Acc: 0.599750, Tokens per Sec:     8923, Lr: 0.000147
2025-05-30 04:18:50,670 - INFO - joeynmt.training - Epoch  10, Step:   105800, Batch Loss:     1.206696, Batch Acc: 0.600535, Tokens per Sec:     9358, Lr: 0.000147
2025-05-30 04:18:58,847 - INFO - joeynmt.training - Epoch  10, Step:   105900, Batch Loss:     1.198086, Batch Acc: 0.607218, Tokens per Sec:     9011, Lr: 0.000147
2025-05-30 04:19:07,648 - INFO - joeynmt.training - Epoch  10, Step:   106000, Batch Loss:     1.160302, Batch Acc: 0.611507, Tokens per Sec:     8279, Lr: 0.000147
2025-05-30 04:19:07,648 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:19:07,648 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:19:48,638 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.36, ppl:   3.90, acc:   0.57, generation: 40.9419[sec], evaluation: 0.0000[sec]
2025-05-30 04:19:48,825 - INFO - joeynmt.helpers - delete models/transformer_enit_bpe_smallvoc/104000.ckpt
2025-05-30 04:19:48,840 - INFO - joeynmt.training - Example #0
2025-05-30 04:19:48,841 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'J@@', 'ah@@', 'r', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'ien', 'ge@@', 'zei@@', 'g@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'an@@', 'n@@', 'ä@@', 'her@@', 'n@@', 'd', 'd@@', 're@@', 'i', 'M@@', 'ill@@', 'ion@@', 'en', 'Jahr@@', 'e', 'die', 'Gr@@', 'ö@@', 'ss@@', 'e', 'der', 'un@@', 'ter@@', 'en', '4@@', '8', 'St@@', 'aa@@', 'ten', 'hat@@', 'te,', 'um', '4@@', '0', 'Pro@@', 'z@@', 'ent', 'gesch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'ist@@', '.']
2025-05-30 04:19:48,841 - DEBUG - joeynmt.training - 	Tokenized reference:  ['V@@', 'or@@', 'ig', 'jaar', 'lie@@', 't', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'zien', 'om', 'aan', 'te', 't@@', 'on@@', 'en', 'dat', 'de', 'p@@', 'oo@@', 'l@@', 'ij@@', 's@@', 'k@@', 'ap@@', ',', 'die', 'de', 'af@@', 'gel@@', 'op@@', 'en', 'dr@@', 'ie', 'm@@', 'il@@', 'j@@', 'o@@', 'en', 'jaar', 'on@@', 'ge@@', 've@@', 'er', 'de', 'gro@@', 'ot@@', 'te', 'ha@@', 'd', 'van', 'het', 'v@@', 'a@@', 'st@@', 'el@@', 'and', 'van', 'de', 'V@@', 'S@@', ',', 'met', '4@@', '0@@', '%', 'ge@@', 'k@@', 'ro@@', 'm@@', 'pen', 'wa@@', 's.']
2025-05-30 04:19:48,841 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['V@@', 'or@@', 'ig', 'jaar', 'heb', 'ik', 'deze', 'twe@@', 'e', 'di@@', 'a@@', "'s", 'ge@@', 'to@@', 'on@@', 'd', 'om', 'te', 'beg@@', 'in@@', 'nen', 'te', 'be@@', 'gr@@', 'ij@@', 'pen', 'dat', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 'z@@', 'er@@', 's', 'ha@@', 'd', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'la@@', 'gen', 'om', '4@@', '0', 'pro@@', 'c@@', 'ent', 'ge@@', 's@@', 'n@@', 'ap@@', 't', 'te', 'ver@@', 'st@@', 'r@@', 'en@@', 'n@@', 'en.', '</s>']
2025-05-30 04:19:48,842 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-30 04:19:48,842 - INFO - joeynmt.training - 	Reference:  Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-30 04:19:48,842 - INFO - joeynmt.training - 	Hypothesis: Vorig jaar heb ik deze twee dia's getoond om te beginnen te begrijpen dat de arctische ijskape ijskape ijskape ijskape ijskape ijzers had geslagen om 40 procent geslagen om 40 procent gesnapt te verstrennen.
2025-05-30 04:19:48,842 - INFO - joeynmt.training - Example #1
2025-05-30 04:19:48,843 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'd@@', 'ies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 't@@', 'ig@@', 'k@@', 'eit', 'dies@@', 'es', 'spe@@', 'zi@@', 'ellen', 'Pro@@', 'ble@@', 'm@@', 's', 'au@@', 's,', 'd@@', 'a', 'es', 'nicht', 'die', 'D@@', 'i@@', 'ck@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zei@@', 'g@@', 't.']
2025-05-30 04:19:48,843 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Maar', 'dit', 'onder@@', 'sch@@', 'a@@', 't', 'eigen@@', 'lijk', 'de', 'ern@@', 'st', 'van', 'dit', 'spe@@', 'ci@@', 'f@@', 'ie@@', 'ke', 'pro@@', 'ble@@', 'em', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'kte', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.']
2025-05-30 04:19:48,843 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Maar', 'dit', 'd@@', 'ru@@', 'kt', 'niet', 'gen@@', 'oe@@', 'g', 'de', 'd@@', 'ie@@', 'p@@', 'e', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'wan@@', 't', 'het', 'is', 'niet', 'de', 'di@@', 'k@@', 'ke', 'd@@', 'ie@@', 'p@@', 'e', 'pro@@', 'ble@@', 'em', 'uit@@', ',', 'om@@', 'dat', 'het', 'niet', 'de', 'di@@', 'k@@', 'ke', 'ij@@', 'z@@', 'er', 'van', 'het', 'ij@@', 's', 'l@@', 'aat', 'zi@@', 'en.', '</s>']
2025-05-30 04:19:48,844 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-30 04:19:48,844 - INFO - joeynmt.training - 	Reference:  Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-30 04:19:48,844 - INFO - joeynmt.training - 	Hypothesis: Maar dit drukt niet genoeg de diepe probleem uit, want het is niet de dikke diepe probleem uit, omdat het niet de dikke ijzer van het ijs laat zien.
2025-05-30 04:19:48,844 - INFO - joeynmt.training - Example #2
2025-05-30 04:19:48,845 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gew@@', 'iss@@', 'em', 'S@@', 'inn@@', 'e', 'ist', 'die', 'ar@@', 'kti@@', 'sch@@', 'e', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'sch@@', 'la@@', 'gen@@', 'de', 'H@@', 'er@@', 'z', 'unser@@', 'es', 'g@@', 'lo@@', 'b@@', 'al@@', 'en', 'K@@', 'l@@', 'i@@', 'ma@@', 'sy@@', 'ste@@', 'm@@', 's.']
2025-05-30 04:19:48,845 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'ij@@', 's@@', 'k@@', 'a@@', 'p', 'op', 'de', 'N@@', 'oor@@', 'd@@', 'p@@', 'oo@@', 'l', 'is', 'in', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'het', 'kl@@', 'op@@', 'p@@', 'end', 'h@@', 'ar@@', 't', 'van', 'ons', 'g@@', 'lo@@', 'b@@', 'aal', 'kl@@', 'im@@', 'aat@@', 'sy@@', 'ste@@', 'em@@', '.']
2025-05-30 04:19:48,845 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'ze@@', 'ker@@', 'e', 'z@@', 'in', 'is', 'de', 'ar@@', 'c@@', 'ti@@', 'sch@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'e', 'ij@@', 's@@', 'k@@', 'ap@@', 'p@@', 'en.', '</s>']
2025-05-30 04:19:48,846 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-30 04:19:48,846 - INFO - joeynmt.training - 	Reference:  De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-30 04:19:48,846 - INFO - joeynmt.training - 	Hypothesis: In zekere zin is de arctische ijskape ijskappe ijskappe ijskappen.
2025-05-30 04:19:48,846 - INFO - joeynmt.training - Example #3
2025-05-30 04:19:48,847 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'w@@', 'äch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'ru@@', 'm@@', 'p@@', 'ft', 'im', 'S@@', 'om@@', 'mer@@', '.']
2025-05-30 04:19:48,847 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Het', 'z@@', 'et', 'uit', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'k@@', 'r@@', 'im@@', 'p@@', 't', 'in', 'de', 'z@@', 'om@@', 'er.']
2025-05-30 04:19:48,847 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ze', 'gro@@', 'ei@@', 'en', 'in', 'de', 'w@@', 'in@@', 'ter', 'en', 'z@@', 'or@@', 'gen', 'in', 'de', 'z@@', 'om@@', 'er.', '</s>']
2025-05-30 04:19:48,848 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-30 04:19:48,848 - INFO - joeynmt.training - 	Reference:  Het zet uit in de winter en krimpt in de zomer.
2025-05-30 04:19:48,848 - INFO - joeynmt.training - 	Hypothesis: Ze groeien in de winter en zorgen in de zomer.
2025-05-30 04:19:48,848 - INFO - joeynmt.training - Example #4
2025-05-30 04:19:48,849 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'n@@', 'äch@@', 'ste', 'F@@', 'ol@@', 'ie,', 'die', 'ich', 'Ih@@', 'nen', 'zei@@', 'ge@@', ',', 'ist', 'eine', 'Z@@', 'ei@@', 'tra@@', 'ff@@', 'er@@', 'auf@@', 'na@@', 'h@@', 'me', 'was', 'in', 'den', 'le@@', 'tz@@', 'ten', '2@@', '5', 'Jahr@@', 'en', 'pass@@', 'iert', 'ist@@', '.']
2025-05-30 04:19:48,849 - DEBUG - joeynmt.training - 	Tokenized reference:  ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'l@@', 'aat', 'zien', 'is', 'een', 'ver@@', 's@@', 'n@@', 'el@@', 'de', 'ver@@', 'sie', 'van', 'wat', 'er', 'de', 'af@@', 'gel@@', 'op@@', 'en', '2@@', '5', 'jaar', 'is', 'ge@@', 'be@@', 'ur@@', 'd.']
2025-05-30 04:19:48,849 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['De', 'vol@@', 'gen@@', 'de', 'di@@', 'a', 'die', 'ik', 'jullie', 'l@@', 'aten', 'zien', 'is', 'een', 'tij@@', 'd@@', 'je', 'die', 'l@@', 'aat@@', 'ste', '2@@', '5', 'j@@', 'aar@@', '.', '</s>']
2025-05-30 04:19:48,849 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-30 04:19:48,850 - INFO - joeynmt.training - 	Reference:  De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-30 04:19:48,850 - INFO - joeynmt.training - 	Hypothesis: De volgende dia die ik jullie laten zien is een tijdje die laatste 25 jaar.
2025-05-30 04:19:55,238 - INFO - joeynmt.training - Epoch  10: total training loss 13101.93
2025-05-30 04:19:55,238 - INFO - joeynmt.training - Training ended after  10 epochs.
2025-05-30 04:19:55,239 - INFO - joeynmt.training - Best validation result (greedy) at step   105500:   3.89 ppl.
2025-05-30 04:19:55,281 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-30 04:19:55,383 - INFO - joeynmt.model - Enc-dec model built.
2025-05-30 04:19:55,537 - INFO - joeynmt.helpers - Load model from C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe_smallvoc\105500.ckpt.
2025-05-30 04:19:55,574 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=925),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=906),
	loss_function=None)
2025-05-30 04:19:55,581 - INFO - joeynmt.prediction - Decoding on dev set...
2025-05-30 04:19:55,582 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:19:55,582 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Beam search with beam_size=3, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:21:26,155 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 90.5366[sec], evaluation: 0.0000[sec]
2025-05-30 04:21:26,172 - INFO - joeynmt.prediction - Translations saved to: C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe_smallvoc\00105500.hyps.dev.
2025-05-30 04:21:26,173 - INFO - joeynmt.prediction - Decoding on test set...
2025-05-30 04:21:26,173 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-30 04:21:26,173 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=3, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-30 04:23:38,403 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 132.1884[sec], evaluation: 0.0000[sec]
2025-05-30 04:23:38,414 - INFO - joeynmt.prediction - Translations saved to: C:\Users\gabri\OneDrive\Documents\GitHub\mt-exercise-4\models\transformer_enit_bpe_smallvoc\00105500.hyps.test.
